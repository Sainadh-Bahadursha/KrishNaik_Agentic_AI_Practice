{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e93ba2a",
   "metadata": {},
   "source": [
    "# Pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ea31f5",
   "metadata": {},
   "source": [
    "## data classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac357e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Person():\n",
    "    name:str\n",
    "    age:int\n",
    "    city:str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55163e46",
   "metadata": {},
   "source": [
    "In Python, `dataclasses` (introduced in Python 3.7) are a way to simplify class creation when the class is mainly used to store data. A `dataclass` automatically generates special methods like `__init__`, `__repr__`, `__eq__`, and more, reducing boilerplate code.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Use of `@dataclass`\n",
    "\n",
    "The `@dataclass` decorator helps to:\n",
    "\n",
    "* Auto-generate constructor `__init__()`\n",
    "* Auto-generate string representation `__repr__()`\n",
    "* Auto-generate comparison methods like `__eq__()`, `__lt__()`, etc.\n",
    "* Support default values, type annotations, and immutability (`frozen=True`)\n",
    "* Easily convert to and from dictionaries using `asdict()` and `astuple()`\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ†š Comparison: With and Without `@dataclass`\n",
    "\n",
    "#### ðŸ”´ Without `dataclass`\n",
    "\n",
    "```python\n",
    "class Person:\n",
    "    def __init__(self, name: str, age: int):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Person(name={self.name}, age={self.age})\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.name == other.name and self.age == other.age\n",
    "```\n",
    "\n",
    "You must manually write:\n",
    "\n",
    "* `__init__` method\n",
    "* `__repr__` for debugging\n",
    "* `__eq__` to compare objects\n",
    "\n",
    "---\n",
    "\n",
    "#### âœ… With `dataclass`\n",
    "\n",
    "```python\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Person:\n",
    "    name: str\n",
    "    age: int\n",
    "```\n",
    "\n",
    "You get all the above (`__init__`, `__repr__`, `__eq__`) **automatically**!\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Example: Using the `dataclass`\n",
    "\n",
    "```python\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Product:\n",
    "    id: int\n",
    "    name: str\n",
    "    price: float = 0.0  # default value\n",
    "\n",
    "p1 = Product(1, \"Laptop\", 999.99)\n",
    "p2 = Product(1, \"Laptop\", 999.99)\n",
    "\n",
    "print(p1)           # Product(id=1, name='Laptop', price=999.99)\n",
    "print(p1 == p2)     # True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### âœ¨ Bonus Features\n",
    "\n",
    "* **Default values**:\n",
    "\n",
    "  ```python\n",
    "  @dataclass\n",
    "  class User:\n",
    "      name: str\n",
    "      is_active: bool = True\n",
    "  ```\n",
    "* **Immutability**:\n",
    "\n",
    "  ```python\n",
    "  @dataclass(frozen=True)\n",
    "  class ImmutablePoint:\n",
    "      x: int\n",
    "      y: int\n",
    "  ```\n",
    "* **Conversion**:\n",
    "\n",
    "  ```python\n",
    "  from dataclasses import asdict\n",
    "  asdict(p1)  # {'id': 1, 'name': 'Laptop', 'price': 999.99}\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§  Summary Table\n",
    "\n",
    "| Feature           | Without `@dataclass` | With `@dataclass`  |\n",
    "| ----------------- | -------------------- | ------------------ |\n",
    "| Auto `__init__()` | âŒ                    | âœ…                  |\n",
    "| Auto `__repr__()` | âŒ                    | âœ…                  |\n",
    "| Auto `__eq__()`   | âŒ                    | âœ…                  |\n",
    "| Less boilerplate  | âŒ                    | âœ…                  |\n",
    "| Type safety       | Optional             | âœ… with annotations |\n",
    "| Dict conversion   | Manual               | âœ… (`asdict()`)     |\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you want to compare `dataclass` with `NamedTuple`, `attrs`, or `pydantic` next.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9286c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person(name='Krish', age=35, city='Bangalore')\n"
     ]
    }
   ],
   "source": [
    "person=Person(name=\"Krish\",age=35,city=\"Bangalore\")\n",
    "print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c41bb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person(name='Krish', age=35, city=35)\n"
     ]
    }
   ],
   "source": [
    "person=Person(name=\"Krish\",age=35,city=35)\n",
    "print(person)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dc1864",
   "metadata": {},
   "source": [
    "Strict type checking was not performed by \"dataclasses\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4363d82",
   "metadata": {},
   "source": [
    "## Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3e31062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e9c229a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Krish' age=35 city='Bangalore'\n"
     ]
    }
   ],
   "source": [
    "class Person1(BaseModel):\n",
    "    name:str\n",
    "    age:int\n",
    "    city:str\n",
    "\n",
    "person=Person1(name=\"Krish\",age=35,city=\"Bangalore\")\n",
    "print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a496e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Person1\ncity\n  Input should be a valid string [type=string_type, input_value=35, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m person1=\u001b[43mPerson1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mKrish\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mage\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m35\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcity\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m35\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(person1)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_2_base\\Lib\\site-packages\\pydantic\\main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for Person1\ncity\n  Input should be a valid string [type=string_type, input_value=35, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type"
     ]
    }
   ],
   "source": [
    "# person1=Person1(name=\"Krish\",age=35,city=35)\n",
    "# print(person1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6161c2e0",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "ValidationError                           Traceback (most recent call last)\n",
    "Cell In[6], line 1\n",
    "----> 1 person1=Person1(name=\"Krish\",age=35,city=35)\n",
    "      2 print(person1)\n",
    "\n",
    "File c:\\Users\\saina\\.conda\\envs\\agentic_2_base\\Lib\\site-packages\\pydantic\\main.py:253, in BaseModel.__init__(self, **data)\n",
    "    251 # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n",
    "    252 __tracebackhide__ = True\n",
    "--> 253 validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
    "    254 if self is not validated_self:\n",
    "    255     warnings.warn(\n",
    "    256         'A custom validator is returning a value other than `self`.\\n'\n",
    "    257         \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n",
    "    258         'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n",
    "    259         stacklevel=2,\n",
    "    260     )\n",
    "\n",
    "ValidationError: 1 validation error for Person1\n",
    "city\n",
    "  Input should be a valid string [type=string_type, input_value=35, input_type=int]\n",
    "    For further information visit https://errors.pydantic.dev/2.11/v/string_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897724d2",
   "metadata": {},
   "source": [
    "pydantic does strict type checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c2fbecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Krish' age=35 city='35'\n"
     ]
    }
   ],
   "source": [
    "person2=Person1(name=\"Krish\",age=35,city=\"35\")\n",
    "print(person2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1502411",
   "metadata": {},
   "source": [
    "As \"35\" is string, Pydantic accepted 35 into city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f7c749",
   "metadata": {},
   "source": [
    "## Model with Optional Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f4cc801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "class Employee(BaseModel):\n",
    "    id:int\n",
    "    name:str\n",
    "    department:str\n",
    "    salary:Optional[float] = None #Optional with default value\n",
    "    is_active:Optional[bool] = True #Optional with default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62307795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=1 name='John' department='CS' salary=None is_active=True\n"
     ]
    }
   ],
   "source": [
    "emp1=Employee(id=1,name=\"John\",department=\"CS\")\n",
    "print(emp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceff0c7",
   "metadata": {},
   "source": [
    "Default values are taken in above instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06904437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=2 name='Krish' department='CS' salary=30000.0 is_active=True\n"
     ]
    }
   ],
   "source": [
    "emp2=Employee(id=2,name=\"Krish\",department=\"CS\",salary=\"30000\")\n",
    "print(emp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86970e66",
   "metadata": {},
   "source": [
    "feasible type casting is able to done by pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb36748",
   "metadata": {},
   "source": [
    "Definition:\n",
    "- Optional[type]: Indicates the field can be None\n",
    "\n",
    "- Default value (= None or = True): Makes the field optional\n",
    "\n",
    "- Required fields must still be provided\n",
    "\n",
    "- Pydantic validates types even for optional fields when values are provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e42ef9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=2 name='Krish' department='CS' salary=30000.0 is_active=True\n"
     ]
    }
   ],
   "source": [
    "emp3=Employee(id=2,name=\"Krish\",department=\"CS\",salary=\"30000\",is_active=1)\n",
    "print(emp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28742eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class Classroom(BaseModel):\n",
    "    room_number:str\n",
    "    students: List[str] #List of strings\n",
    "    capacity:int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bfe0f2",
   "metadata": {},
   "source": [
    "we can give data structures like list in data type of variables in pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47b2844e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "room_number='A101' students=['Alice', 'Bob', 'Charlie'] capacity=30\n"
     ]
    }
   ],
   "source": [
    "# Create a classroom\n",
    "classroom = Classroom(\n",
    "    room_number=\"A101\",\n",
    "    students=(\"Alice\", \"Bob\", \"Charlie\"),\n",
    "    capacity=30\n",
    ")\n",
    "print(classroom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27236920",
   "metadata": {},
   "source": [
    "tuple converted to list by type casting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334fa327",
   "metadata": {},
   "outputs": [],
   "source": [
    "list((\"Alice\", \"Bob\", \"Charlie\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed660c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Classroom\nstudents.1\n  Input should be a valid string [type=string_type, input_value=123, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create a classroom\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m classroom1 = \u001b[43mClassroom\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mroom_number\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mA101\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstudents\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAlice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m123\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCharlie\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapacity\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(classroom1)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_2_base\\Lib\\site-packages\\pydantic\\main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for Classroom\nstudents.1\n  Input should be a valid string [type=string_type, input_value=123, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type"
     ]
    }
   ],
   "source": [
    "# # Create a classroom\n",
    "# classroom1 = Classroom(\n",
    "#     room_number=\"A101\",\n",
    "#     students=(\"Alice\", 123, \"Charlie\"),\n",
    "#     capacity=30\n",
    "# )\n",
    "# print(classroom1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d505a4f",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "ValidationError                           Traceback (most recent call last)\n",
    "Cell In[14], line 2\n",
    "      1 # Create a classroom\n",
    "----> 2 classroom1 = Classroom(\n",
    "      3     room_number=\"A101\",\n",
    "      4     students=(\"Alice\", 123, \"Charlie\"),\n",
    "      5     capacity=30\n",
    "      6 )\n",
    "      7 print(classroom1)\n",
    "\n",
    "File c:\\Users\\saina\\.conda\\envs\\agentic_2_base\\Lib\\site-packages\\pydantic\\main.py:253, in BaseModel.__init__(self, **data)\n",
    "    251 # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n",
    "    252 __tracebackhide__ = True\n",
    "--> 253 validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
    "    254 if self is not validated_self:\n",
    "    255     warnings.warn(\n",
    "    256         'A custom validator is returning a value other than `self`.\\n'\n",
    "    257         \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n",
    "    258         'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n",
    "    259         stacklevel=2,\n",
    "    260     )\n",
    "\n",
    "ValidationError: 1 validation error for Classroom\n",
    "students.1\n",
    "  Input should be a valid string [type=string_type, input_value=123, input_type=int]\n",
    "    For further information visit https://errors.pydantic.dev/2.11/v/string_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb00db3",
   "metadata": {},
   "source": [
    "list of strings only are accepted. So validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc433632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for Classroom\n",
      "students.1\n",
      "  Input should be a valid string [type=string_type, input_value=123, input_type=int]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    invalid_val=Classroom(room_number=\"A1\",students=[\"Krish\",123],capacity=30)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4849c06",
   "metadata": {},
   "source": [
    "use try except block to print the concise error and does not stop the execution of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29d65f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Classroom(BaseModel):\n",
    "    room_number:str\n",
    "    students: List[float] #List of floats\n",
    "    capacity:int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc23ac29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "room_number='201' students=[1.0, 2.0, 3.0] capacity=3\n"
     ]
    }
   ],
   "source": [
    "class1 = Classroom(room_number=\"201\",students = [1,2,3], capacity = 3)\n",
    "print(class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30572153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Classroom(BaseModel):\n",
    "    room_number:str\n",
    "    students: List[str] #List of floats\n",
    "    capacity:int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1966a136",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for Classroom\nstudents.0\n  Input should be a valid string [type=string_type, input_value=1, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nstudents.1\n  Input should be a valid string [type=string_type, input_value=2, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nstudents.2\n  Input should be a valid string [type=string_type, input_value=3, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m class1 = \u001b[43mClassroom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroom_number\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m201\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mstudents\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapacity\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(class1)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_2_base\\Lib\\site-packages\\pydantic\\main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 3 validation errors for Classroom\nstudents.0\n  Input should be a valid string [type=string_type, input_value=1, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nstudents.1\n  Input should be a valid string [type=string_type, input_value=2, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nstudents.2\n  Input should be a valid string [type=string_type, input_value=3, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type"
     ]
    }
   ],
   "source": [
    "class1 = Classroom(room_number=\"201\",students = [1,2,3], capacity = 3)\n",
    "print(class1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ac9290",
   "metadata": {},
   "source": [
    "Great question!\n",
    "\n",
    "You're getting a **validation error** because **Pydantic does not automatically cast `List[int]` to `List[str]`** â€” i.e., it wonâ€™t convert `[1, 2, 3]` into `[\"1\", \"2\", \"3\"]` automatically for a field typed as `List[str]`.\n",
    "\n",
    "---\n",
    "\n",
    "### âš ï¸ Here's the error you'll get:\n",
    "\n",
    "```python\n",
    "ValidationError: 1 validation error for Classroom\n",
    "students -> 0\n",
    "  str type expected (type=type_error.str)\n",
    "```\n",
    "\n",
    "This means:\n",
    "Pydantic expected each item in `students` to be a **string**, but found an **integer** at index 0.\n",
    "\n",
    "---\n",
    "\n",
    "### â“Why doesn't Pydantic cast `List[int]` â†’ `List[str]`?\n",
    "\n",
    "Because **element-wise coercion in collections is not automatic**.\n",
    "This is to avoid silently introducing bugs â€” especially when the difference between types matters (e.g., `\"10\"` vs `10` in business logic).\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… How to fix it\n",
    "\n",
    "#### âœ… Option 1: Pass strings correctly\n",
    "\n",
    "```python\n",
    "class1 = Classroom(room_number=\"201\", students=[\"1\", \"2\", \"3\"], capacity=3)\n",
    "```\n",
    "\n",
    "#### âœ… Option 2: Use a custom validator if you still want automatic casting\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, field_validator\n",
    "from typing import List\n",
    "\n",
    "class Classroom(BaseModel):\n",
    "    room_number: str\n",
    "    students: List[str]\n",
    "    capacity: int\n",
    "\n",
    "    @field_validator(\"students\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def cast_all_to_str(cls, v):\n",
    "        return [str(i) for i in v]\n",
    "\n",
    "class1 = Classroom(room_number=\"201\", students=[1, 2, 3], capacity=3)\n",
    "print(class1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Output:\n",
    "\n",
    "```python\n",
    "room_number='201' students=['1', '2', '3'] capacity=3\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§  Summary\n",
    "\n",
    "| Behavior                       | Default in Pydantic |\n",
    "| ------------------------------ | ------------------- |\n",
    "| Cast `int` â†’ `str`             | âœ… Yes               |\n",
    "| Cast `List[int]` â†’ `List[str]` | âŒ No                |\n",
    "\n",
    "> You must handle element-wise coercion explicitly with a validator.\n",
    "\n",
    "Let me know if you want reusable casting utilities for nested lists or dictionaries!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d212b50",
   "metadata": {},
   "source": [
    "## Model with Nested Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ebf38c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Address(BaseModel):\n",
    "    street:str\n",
    "    city:str\n",
    "    zip_code:str\n",
    "\n",
    "class Customer(BaseModel):\n",
    "    customer_id:int\n",
    "    name:str\n",
    "    address:Address  ## Nested Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d577d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_id=1 name='Krish' address=Address(street='Main street', city='Boston', zip_code='02108')\n"
     ]
    }
   ],
   "source": [
    "customer=Customer(customer_id=1,name=\"Krish\",\n",
    "                  address={\"street\":\"Main street\",\"city\":\"Boston\",\"zip_code\":\"02108\"})\n",
    "\n",
    "print(customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13dd3b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Customer\naddress\n  Input should be a valid dictionary or instance of Address [type=model_type, input_value=['Main street', 'Boston', '02108'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m customer=\u001b[43mCustomer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustomer_id\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mKrish\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                  \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMain street\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBoston\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m02108\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(customer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_2_base\\Lib\\site-packages\\pydantic\\main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for Customer\naddress\n  Input should be a valid dictionary or instance of Address [type=model_type, input_value=['Main street', 'Boston', '02108'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type"
     ]
    }
   ],
   "source": [
    "# customer=Customer(customer_id=1,name=\"Krish\",\n",
    "#                   address=[\"Main street\",\"Boston\",\"02108\"])\n",
    "\n",
    "# print(customer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc2e83d",
   "metadata": {},
   "source": [
    "In nested model, dictionary should be used while instantiating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7beffe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Customer\naddress.city\n  Input should be a valid string [type=string_type, input_value=123, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m customer=\u001b[43mCustomer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustomer_id\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mKrish\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                  \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstreet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMain street\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m123\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mzip_code\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m02108\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(customer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_2_base\\Lib\\site-packages\\pydantic\\main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for Customer\naddress.city\n  Input should be a valid string [type=string_type, input_value=123, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type"
     ]
    }
   ],
   "source": [
    "# customer=Customer(customer_id=1,name=\"Krish\",\n",
    "#                   address={\"street\":\"Main street\",\"city\":123,\"zip_code\":\"02108\"})\n",
    "\n",
    "# print(customer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c513f6c2",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "ValidationError                           Traceback (most recent call last)\n",
    "Cell In[18], line 1\n",
    "----> 1 customer=Customer(customer_id=1,name=\"Krish\",\n",
    "      2                   address={\"street\":\"Main street\",\"city\":123,\"zip_code\":\"02108\"})\n",
    "      4 print(customer)\n",
    "\n",
    "File c:\\Users\\saina\\.conda\\envs\\agentic_2_base\\Lib\\site-packages\\pydantic\\main.py:253, in BaseModel.__init__(self, **data)\n",
    "    251 # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n",
    "    252 __tracebackhide__ = True\n",
    "--> 253 validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
    "    254 if self is not validated_self:\n",
    "    255     warnings.warn(\n",
    "    256         'A custom validator is returning a value other than `self`.\\n'\n",
    "    257         \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n",
    "    258         'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n",
    "    259         stacklevel=2,\n",
    "    260     )\n",
    "\n",
    "ValidationError: 1 validation error for Customer\n",
    "address.city\n",
    "  Input should be a valid string [type=string_type, input_value=123, input_type=int]\n",
    "    For further information visit https://errors.pydantic.dev/2.11/v/string_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e06cdd",
   "metadata": {},
   "source": [
    "## Pydantic Fields: Customization and Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0215881",
   "metadata": {},
   "source": [
    "\n",
    "The Field function in Pydantic enhances model fields beyond basic type hints by allowing you to specify validation rules, default values, aliases, and more. Here's a comprehensive tutorial with examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4751b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel,Field\n",
    "\n",
    "class Item(BaseModel):\n",
    "    name:str=Field(min_length=2,max_length=50)\n",
    "    price:float=Field(gt=0,le=10000)  ## greater than 0 and less than or equal to 1000\n",
    "    quantity:int=Field(ge=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bdad33",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Item\nprice\n  Input should be less than or equal to 10000 [type=less_than_equal, input_value=100000, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/less_than_equal",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m item=\u001b[43mItem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBook\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprice\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mquantity\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(item)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_2_base\\Lib\\site-packages\\pydantic\\main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for Item\nprice\n  Input should be less than or equal to 10000 [type=less_than_equal, input_value=100000, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/less_than_equal"
     ]
    }
   ],
   "source": [
    "# item=Item(name=\"Book\", price=100000,quantity=10)\n",
    "# print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed53c7f",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "ValidationError                           Traceback (most recent call last)\n",
    "Cell In[20], line 1\n",
    "----> 1 item=Item(name=\"Book\", price=100000,quantity=10)\n",
    "      2 print(item)\n",
    "\n",
    "File c:\\Users\\saina\\.conda\\envs\\agentic_2_base\\Lib\\site-packages\\pydantic\\main.py:253, in BaseModel.__init__(self, **data)\n",
    "    251 # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n",
    "    252 __tracebackhide__ = True\n",
    "--> 253 validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
    "    254 if self is not validated_self:\n",
    "    255     warnings.warn(\n",
    "    256         'A custom validator is returning a value other than `self`.\\n'\n",
    "    257         \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n",
    "    258         'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n",
    "    259         stacklevel=2,\n",
    "    260     )\n",
    "\n",
    "ValidationError: 1 validation error for Item\n",
    "price\n",
    "  Input should be less than or equal to 10000 [type=less_than_equal, input_value=100000, input_type=int]\n",
    "    For further information visit https://errors.pydantic.dev/2.11/v/less_than_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22883b5",
   "metadata": {},
   "source": [
    "field is used for condition based input data validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e39c5101",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User(BaseModel):\n",
    "    username:str=Field(description=\"Unique username for the user\")\n",
    "    age:int=Field(default=18,description=\"User age default to 18 \")\n",
    "    email:str= Field(default_factory=lambda: \"user@example.com\",description=\"Default email address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eda3226b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username='alice' age=18 email='user@example.com'\n"
     ]
    }
   ],
   "source": [
    "# Examples\n",
    "user1 = User(username=\"alice\")\n",
    "print(user1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871aa907",
   "metadata": {},
   "source": [
    "default factory is dynamic way of creating the default values, Can use datetime now in it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b1a3f4",
   "metadata": {},
   "source": [
    "To dynamically set the `email` field based on the `username` (like `alice@example.com`), you **cannot use `default_factory` alone**, because `default_factory` **doesnâ€™t have access to other field values**.\n",
    "\n",
    "Instead, use a **`@model_validator`** or `@root_validator` (for older Pydantic v1), which gives access to the entire model so you can compute one field based on another.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Pydantic v2 Solution (Recommended)\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "\n",
    "class User(BaseModel):\n",
    "    username: str = Field(description=\"Unique username for the user\")\n",
    "    age: int = Field(default=18, description=\"User age defaults to 18\")\n",
    "    email: str = Field(default=None, description=\"Email will default to username@example.com\")\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def set_email_if_missing(self) -> 'User':\n",
    "        if self.email is None:\n",
    "            self.email = f\"{self.username}@example.com\"\n",
    "        return self\n",
    "\n",
    "# Example\n",
    "user1 = User(username=\"alice\")\n",
    "print(user1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Output\n",
    "\n",
    "```python\n",
    "username='alice' age=18 email='alice@example.com'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”Ž How It Works\n",
    "\n",
    "* `@model_validator(mode=\"after\")`: This hook runs **after** all fields are parsed and validated.\n",
    "* We check if `email` is missing (`None`), and if so, we compute it using `username`.\n",
    "\n",
    "---\n",
    "\n",
    "### âš ï¸ Alternative (Pydantic v1)\n",
    "\n",
    "If you're using Pydantic **v1**, use `@root_validator(pre=False)` instead:\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field, root_validator\n",
    "\n",
    "class User(BaseModel):\n",
    "    username: str = Field(...)\n",
    "    age: int = Field(default=18)\n",
    "    email: str = None\n",
    "\n",
    "    @root_validator\n",
    "    def set_email(cls, values):\n",
    "        if not values.get('email'):\n",
    "            values['email'] = f\"{values['username']}@example.com\"\n",
    "        return values\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Let me know your Pydantic version if youâ€™re unsure, and Iâ€™ll tailor the code to that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b05ed10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ae61672",
   "metadata": {},
   "source": [
    "## Schema from pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3ca49a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'username': {'description': 'Unique username for the user',\n",
       "   'title': 'Username',\n",
       "   'type': 'string'},\n",
       "  'age': {'default': 18,\n",
       "   'description': 'User age default to 18 ',\n",
       "   'title': 'Age',\n",
       "   'type': 'integer'},\n",
       "  'email': {'description': 'Default email address',\n",
       "   'title': 'Email',\n",
       "   'type': 'string'}},\n",
       " 'required': ['username'],\n",
       " 'title': 'User',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "User.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c503b631",
   "metadata": {},
   "source": [
    "## What is Serialisation in pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b5fe14",
   "metadata": {},
   "source": [
    "In **Pydantic**, **serialization** refers to **converting a Pydantic model (Python object) into a data format that can be easily stored or transferred**, such as **JSON, dictionaries, or strings**.\n",
    "\n",
    "### âœ… In simpler terms:\n",
    "\n",
    "**Serialization = Model â†’ JSON or dict**\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”§ Common Use-Cases for Serialization:\n",
    "\n",
    "* Sending data over an API (JSON format)\n",
    "* Saving model data to a file or database\n",
    "* Logging structured data\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§  How it works in Pydantic:\n",
    "\n",
    "Suppose you have a model:\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class User(BaseModel):\n",
    "    id: int\n",
    "    name: str\n",
    "    email: str\n",
    "```\n",
    "\n",
    "#### âž¤ `dict()` â€” serialize to Python dictionary:\n",
    "\n",
    "```python\n",
    "user = User(id=1, name=\"Alice\", email=\"alice@example.com\")\n",
    "user_dict = user.dict()\n",
    "print(user_dict)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```python\n",
    "{'id': 1, 'name': 'Alice', 'email': 'alice@example.com'}\n",
    "```\n",
    "\n",
    "#### âž¤ `json()` â€” serialize to JSON string:\n",
    "\n",
    "```python\n",
    "user_json = user.json()\n",
    "print(user_json)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```json\n",
    "{\"id\": 1, \"name\": \"Alice\", \"email\": \"alice@example.com\"}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”„ Related Term: **Deserialization**\n",
    "\n",
    "The reverse â€” converting from JSON or dict back to a Pydantic model:\n",
    "\n",
    "```python\n",
    "user_data = {'id': 1, 'name': 'Alice', 'email': 'alice@example.com'}\n",
    "user = User(**user_data)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ’¡ Bonus: Custom Serialization\n",
    "\n",
    "You can customize serialization using:\n",
    "\n",
    "* `Config` class with `json_encoders`\n",
    "* `model.dict(include=..., exclude=...)` to include/exclude fields\n",
    "* Aliases and field customization with `Field(..., alias=...)`\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you'd like to see examples with nested models, custom field names, or datetime handling!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c79bfdc",
   "metadata": {},
   "source": [
    "## Pydantic Crash course by CampusX\n",
    "`https://github.com/campusx-official/pydantic-crash-course`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb2d6d",
   "metadata": {},
   "source": [
    "## Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a64c35e",
   "metadata": {},
   "source": [
    "class Item(BaseModel):\n",
    "    id: str \n",
    "    email: str \n",
    "\n",
    "\n",
    "Is it possible to use id as a part in default factory of email? such that email default values is like id+\"@gmail.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59592eb",
   "metadata": {},
   "source": [
    "âœ… **Yes, itâ€™s possible** â€” but **not directly inside `Field(default_factory=...)`** because at the time `default_factory` runs, **other fields like `id` may not be initialized yet**.\n",
    "\n",
    "However, Pydantic provides a clean way to do this using a **`model_post_init`** method in **Pydantic v2**, or a **`@root_validator`** in **Pydantic v1**.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Pydantic v2: Use `model_post_init`\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "from uuid import uuid4\n",
    "\n",
    "class Item(BaseModel):\n",
    "    id: str = Field(default_factory=lambda: str(uuid4()))\n",
    "    email: str | None = None\n",
    "\n",
    "    def model_post_init(self, __context):\n",
    "        if self.email is None:\n",
    "            self.email = f\"{self.id}@gmail.com\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Pydantic v1: Use `@root_validator`\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field, root_validator\n",
    "from uuid import uuid4\n",
    "\n",
    "class Item(BaseModel):\n",
    "    id: str = Field(default_factory=lambda: str(uuid4()))\n",
    "    email: str | None = None\n",
    "\n",
    "    @root_validator(pre=False)\n",
    "    def set_email(cls, values):\n",
    "        if values.get('email') is None:\n",
    "            values['email'] = f\"{values['id']}@gmail.com\"\n",
    "        return values\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§ª Example usage:\n",
    "\n",
    "```python\n",
    "item = Item()\n",
    "print(item.id)      # e.g., \"8d3e8d72-1f75-43a4-9e1e-7b9e457dca8a\"\n",
    "print(item.email)   # e.g., \"8d3e8d72-1f75-43a4-9e1e-7b9e457dca8a@gmail.com\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§  Why `Field(default_factory=...)` won't work here?\n",
    "\n",
    "Because it doesn't **know about other fields** during execution â€” it just calls the function when no value is passed.\n",
    "\n",
    "So for **dependent default values**, always use:\n",
    "\n",
    "* `model_post_init` (Pydantic v2)\n",
    "* `root_validator` (Pydantic v1)\n",
    "\n",
    "---\n",
    "\n",
    "Let me know your Pydantic version if you need a custom solution for your codebase!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e37a4a5",
   "metadata": {},
   "source": [
    "## Difference between Field and field_validator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd86175f",
   "metadata": {},
   "source": [
    "Great question! `Field` and `field_validator` in **Pydantic** serve **very different purposes**, though they both help you control and validate data.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ†š `Field` vs `field_validator` â€” Core Differences\n",
    "\n",
    "| Feature                       | `Field(...)`                                                                       | `@field_validator(...)`                                      |\n",
    "| ----------------------------- | ---------------------------------------------------------------------------------- | ------------------------------------------------------------ |\n",
    "| **Purpose**                   | Declare **defaults**, **metadata**, and **constraints**                            | Implement **custom logic** to validate or transform          |\n",
    "| **Used for**                  | - Default values<br>- Descriptions<br>- Ranges (gt, lt)<br>- Aliases<br>- UI hints | - Conditional rules<br>- Data formatting<br>- Complex checks |\n",
    "| **When it runs**              | During model schema parsing                                                        | During/after field value assignment (based on `mode`)        |\n",
    "| **Declarative or imperative** | Declarative (like saying \"must be > 0\")                                            | Imperative (like writing Python logic)                       |\n",
    "| **Return required?**          | âŒ No return value needed                                                           | âœ… Must return the (possibly modified) value or raise error   |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ `Field(...)` â€“ For Defaults, Constraints, and Metadata\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class User(BaseModel):\n",
    "    age: int = Field(..., gt=0, lt=100, description=\"Age must be between 1 and 99\")\n",
    "    name: str = Field(default=\"Anonymous\", max_length=20)\n",
    "```\n",
    "\n",
    "âœ”ï¸ It adds:\n",
    "\n",
    "* Validation rules (e.g., `gt`, `lt`, `max_length`)\n",
    "* Default values (`default`, `default_factory`)\n",
    "* Schema metadata (`description`, `title`, `example`)\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ `@field_validator(...)` â€“ For Custom Validation Logic\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    email: str\n",
    "\n",
    "    @field_validator('email')\n",
    "    @classmethod\n",
    "    def check_email(cls, v):\n",
    "        if not v.endswith('@gmail.com'):\n",
    "            raise ValueError(\"Email must be a gmail.com address\")\n",
    "        return v\n",
    "```\n",
    "\n",
    "âœ”ï¸ It allows:\n",
    "\n",
    "* Any Python logic\n",
    "* Value transformation (like `.upper()`, formatting)\n",
    "* Cross-field or deep validation (via `@model_validator` or `@root_validator`)\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§ª Example with Both\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "\n",
    "class Product(BaseModel):\n",
    "    name: str\n",
    "    price: float = Field(gt=0, description=\"Price must be positive\")\n",
    "\n",
    "    @field_validator('name')\n",
    "    @classmethod\n",
    "    def strip_name(cls, value):\n",
    "        return value.strip().title()\n",
    "```\n",
    "\n",
    "* `Field(gt=0)` ensures `price > 0`\n",
    "* `@field_validator` formats `name` before storing\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Summary\n",
    "\n",
    "| Aspect                                 | `Field`                         | `@field_validator` |\n",
    "| -------------------------------------- | ------------------------------- | ------------------ |\n",
    "| Controls defaults?                     | âœ… Yes                           | âŒ No               |\n",
    "| Adds metadata for OpenAPI/docs?        | âœ… Yes                           | âŒ No               |\n",
    "| Applies static validation constraints? | âœ… Yes (like `gt`, `max_length`) | âœ… If custom logic  |\n",
    "| Good for dynamic validation?           | âŒ                               | âœ… Yes              |\n",
    "| Required to return value?              | âŒ                               | âœ… Yes              |\n",
    "| Runs on model creation?                | âœ…                               | âœ…                  |\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you want to explore how to **combine both** or use them in **Pydantic v2 with Annotated types**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2576d67",
   "metadata": {},
   "source": [
    "## Difference between field validator and model validator from pydantic? and any other validators present in it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e634e774",
   "metadata": {},
   "source": [
    "Excellent question, Sainadh! Letâ€™s break down the difference between **`field_validator`**, **`model_validator`**, and other available **validators in Pydantic v2**, along with when and why to use each.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… 1. `field_validator` â€“ Validate or transform a **single field**\n",
    "\n",
    "#### ðŸ”¹ Purpose:\n",
    "\n",
    "Used to validate or transform the value of **one specific field** (before or after parsing).\n",
    "\n",
    "#### ðŸ”¹ Syntax:\n",
    "\n",
    "```python\n",
    "@field_validator('field_name', mode='before' or 'after')\n",
    "@classmethod\n",
    "def validator_name(cls, value): ...\n",
    "```\n",
    "\n",
    "#### ðŸ”¹ When to use:\n",
    "\n",
    "* Format or clean field values (`.strip()`, `.upper()`)\n",
    "* Enforce field-specific rules (e.g., `email must end with @gmail.com`)\n",
    "* Normalize types (e.g., convert strings to int)\n",
    "\n",
    "#### ðŸ”¹ Example:\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, field_validator\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "\n",
    "    @field_validator('name')\n",
    "    @classmethod\n",
    "    def validate_name(cls, v):\n",
    "        return v.title()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… 2. `model_validator` â€“ Validate across **the entire model**\n",
    "\n",
    "#### ðŸ”¹ Purpose:\n",
    "\n",
    "Used to validate the model as a whole â€” **after all fields are parsed**, and useful when validation **depends on multiple fields**.\n",
    "\n",
    "#### ðŸ”¹ Syntax:\n",
    "\n",
    "```python\n",
    "@model_validator(mode='before' or 'after')\n",
    "@classmethod\n",
    "def validate_model(cls, data): ...\n",
    "```\n",
    "\n",
    "#### ðŸ”¹ When to use:\n",
    "\n",
    "* Validate relationships between fields (e.g., `start_date < end_date`)\n",
    "* Conditionally require a field (`if x is True, y must be provided`)\n",
    "* Post-process entire object\n",
    "\n",
    "#### ðŸ”¹ Example:\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, model_validator\n",
    "\n",
    "class Booking(BaseModel):\n",
    "    start: int\n",
    "    end: int\n",
    "\n",
    "    @model_validator(mode='after')\n",
    "    @classmethod\n",
    "    def check_duration(cls, model):\n",
    "        if model.end <= model.start:\n",
    "            raise ValueError('End must be after start')\n",
    "        return model\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Other Validators in Pydantic v2\n",
    "\n",
    "| Validator                            | Purpose                                                           |\n",
    "| ------------------------------------ | ----------------------------------------------------------------- |\n",
    "| `@field_validator`                   | Validate or transform **one field**                               |\n",
    "| `@model_validator`                   | Validate the **entire model** (cross-field logic)                 |\n",
    "| `@field_serializer`                  | Custom **serialization logic** for a field                        |\n",
    "| `@model_serializer`                  | Custom **serialization** for the entire model                     |\n",
    "| `@computed_field`                    | Define **derived read-only fields**                               |\n",
    "| `@root_validator` (deprecated in v2) | Old way to validate models in v1 (replaced by `@model_validator`) |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§  Summary Table\n",
    "\n",
    "| Feature                      | `field_validator`   | `model_validator`              |\n",
    "| ---------------------------- | ------------------- | ------------------------------ |\n",
    "| Validates one field?         | âœ… Yes               | âŒ                              |\n",
    "| Uses multiple fields?        | âŒ                   | âœ… Yes                          |\n",
    "| Transform values?            | âœ… Yes               | âœ… Yes                          |\n",
    "| Before parsing?              | âœ… (`mode='before'`) | âœ… (`mode='before'`)            |\n",
    "| After parsing?               | âœ… (`mode='after'`)  | âœ… (`mode='after'`)             |\n",
    "| Replaces `@validator` in v1? | âœ… Yes               | âœ… (replaces `@root_validator`) |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸš¨ Notes:\n",
    "\n",
    "* Use `mode='before'` to validate **raw input** (before parsing/coercion).\n",
    "* Use `mode='after'` to validate **parsed values** (after type enforcement).\n",
    "* You must return the value (`field_validator`) or model (`model_validator`).\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you want:\n",
    "\n",
    "* A cheatsheet of **all decorators in Pydantic v2**\n",
    "* Examples of combining `Annotated` with `Field` and `field_validator`\n",
    "* How these work with **FastAPI** or **custom error messages**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb261e0",
   "metadata": {},
   "source": [
    "## What is computed field?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceb4570",
   "metadata": {},
   "source": [
    "Great choice, Sainadh! In **Pydantic v2**, a `@computed_field` is used to **define a read-only, derived field** â€” one that **is not passed during model creation**, but is **computed from other fields**.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ What is a `@computed_field`?\n",
    "\n",
    "Itâ€™s like a **property** that gets **included in `.model_dump()` and `.json()`**, and can even show up in OpenAPI docs (if used with FastAPI).\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Use Case\n",
    "\n",
    "* Calculate `full_name` from `first_name + last_name`\n",
    "* Compute `total_price = quantity * unit_price`\n",
    "* Convert `datetime` into a `formatted_str`\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Syntax\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, computed_field\n",
    "\n",
    "class Model(BaseModel):\n",
    "    ...\n",
    "\n",
    "    @computed_field\n",
    "    @property\n",
    "    def field_name(self) -> ReturnType:\n",
    "        return ...\n",
    "```\n",
    "\n",
    "> You must annotate the return type. Otherwise, Pydantic will raise an error.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§ª Example: Full Name from First & Last\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, computed_field\n",
    "\n",
    "class Person(BaseModel):\n",
    "    first_name: str\n",
    "    last_name: str\n",
    "\n",
    "    @computed_field\n",
    "    @property\n",
    "    def full_name(self) -> str:\n",
    "        return f\"{self.first_name} {self.last_name}\"\n",
    "```\n",
    "\n",
    "#### Usage:\n",
    "\n",
    "```python\n",
    "p = Person(first_name=\"Sainadh\", last_name=\"Bahadursha\")\n",
    "print(p.full_name)  # Sainadh Bahadursha\n",
    "print(p.model_dump())  # includes full_name!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§ª Example: Total Cost\n",
    "\n",
    "```python\n",
    "class Item(BaseModel):\n",
    "    name: str\n",
    "    unit_price: float\n",
    "    quantity: int\n",
    "\n",
    "    @computed_field\n",
    "    @property\n",
    "    def total(self) -> float:\n",
    "        return self.unit_price * self.quantity\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§  Key Rules\n",
    "\n",
    "| Rule                       | Explanation                            |\n",
    "| -------------------------- | -------------------------------------- |\n",
    "| Must return annotated type | Required: `-> str`, `-> float`, etc.   |\n",
    "| Must be a `@property`      | It's always accessed like an attribute |\n",
    "| Included in `model_dump()` | Even though itâ€™s not part of input     |\n",
    "| Read-only                  | Cannot be passed during model creation |\n",
    "\n",
    "---\n",
    "\n",
    "### âš ï¸ Cannot assign it!\n",
    "\n",
    "```python\n",
    "p = Person(first_name=\"Sainadh\", last_name=\"Bahadursha\", full_name=\"Wrong\")  # âŒ Error\n",
    "```\n",
    "\n",
    "Itâ€™s **computed only**, not assignable.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Summary\n",
    "\n",
    "| Feature                      | `@computed_field` |\n",
    "| ---------------------------- | ----------------- |\n",
    "| Read-only field?             | âœ… Yes             |\n",
    "| Included in `.model_dump()`? | âœ… Yes             |\n",
    "| Accept user input?           | âŒ No              |\n",
    "| Used for?                    | Derived fields    |\n",
    "| Pydantic v2 only?            | âœ… Yes (new in v2) |\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you want examples of `computed_field` used with `datetime`, nested models, or how to make it show in **FastAPI** Swagger docs!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f208ea7",
   "metadata": {},
   "source": [
    "In **Pydantic v2**, serialization is more customizable with two new features:\n",
    "\n",
    "#### âœ… `@field_serializer`\n",
    "\n",
    "Used to **customize how a single field** is serialized (i.e., converted to JSON or dict).\n",
    "\n",
    "#### âœ… `@model_serializer`\n",
    "\n",
    "Used to **customize how the entire model** is serialized.\n",
    "\n",
    "These are useful when you want to:\n",
    "\n",
    "* Format fields in a specific way for output\n",
    "* Hide or transform data when exporting\n",
    "* Implement custom JSON encodings\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ 1. `@field_serializer` â€” Per Field Customization\n",
    "\n",
    "#### ðŸ§  Purpose:\n",
    "\n",
    "Customize how **a particular field** is serialized (e.g., hiding, masking, formatting dates, etc.)\n",
    "\n",
    "#### âœ… Example: Masking an email field\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field, field_serializer\n",
    "\n",
    "class User(BaseModel):\n",
    "    username: str\n",
    "    email: str\n",
    "\n",
    "    @field_serializer('email')\n",
    "    def mask_email(self, email):\n",
    "        user, domain = email.split('@')\n",
    "        return f\"{user[0]}***@{domain}\"\n",
    "\n",
    "u = User(username=\"alice\", email=\"alice@example.com\")\n",
    "print(u.model_dump())   # {'username': 'alice', 'email': 'a***@example.com'}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ 2. `@model_serializer` â€” Full Model Customization\n",
    "\n",
    "#### ðŸ§  Purpose:\n",
    "\n",
    "Customize how the **entire model** is converted to a dictionary or JSON.\n",
    "\n",
    "#### âœ… Example: Convert model to camelCase keys\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, model_serializer\n",
    "\n",
    "def to_camel(string: str) -> str:\n",
    "    parts = string.split('_')\n",
    "    return parts[0] + ''.join(word.capitalize() for word in parts[1:])\n",
    "\n",
    "class Product(BaseModel):\n",
    "    product_name: str\n",
    "    in_stock: bool\n",
    "\n",
    "    @model_serializer(mode='wrap')\n",
    "    def camel_case_serializer(self, handler):\n",
    "        data = handler(self)\n",
    "        return {to_camel(k): v for k, v in data.items()}\n",
    "\n",
    "p = Product(product_name=\"Phone\", in_stock=True)\n",
    "print(p.model_dump())  # {'productName': 'Phone', 'inStock': True}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ”„ Comparison Table\n",
    "\n",
    "| Feature       | `@field_serializer`             | `@model_serializer`                  |\n",
    "| ------------- | ------------------------------- | ------------------------------------ |\n",
    "| Scope         | Single field                    | Entire model                         |\n",
    "| Use Case      | Formatting, masking, converting | Renaming keys, flattening, reshaping |\n",
    "| Mode          | Default is `'plain'`            | `'plain'` or `'wrap'`                |\n",
    "| Output Format | Controls just one field         | Controls the full dict/JSON          |\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ§ª Bonus: Combine Both\n",
    "\n",
    "```python\n",
    "class Employee(BaseModel):\n",
    "    first_name: str\n",
    "    last_name: str\n",
    "    salary: float\n",
    "\n",
    "    @field_serializer(\"salary\")\n",
    "    def mask_salary(self, value):\n",
    "        return \"Confidential\"\n",
    "\n",
    "    @model_serializer(mode=\"wrap\")\n",
    "    def serialize_full_name(self, handler):\n",
    "        data = handler(self)\n",
    "        data[\"full_name\"] = f\"{self.first_name} {self.last_name}\"\n",
    "        del data[\"first_name\"]\n",
    "        del data[\"last_name\"]\n",
    "        return data\n",
    "\n",
    "e = Employee(first_name=\"John\", last_name=\"Doe\", salary=100000)\n",
    "print(e.model_dump())\n",
    "# {'salary': 'Confidential', 'full_name': 'John Doe'}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ”š Summary\n",
    "\n",
    "| Decorator           | Purpose                                | Use Whenâ€¦                            |\n",
    "| ------------------- | -------------------------------------- | ------------------------------------ |\n",
    "| `@field_serializer` | You want to modify just **one field**  | e.g., mask email, format timestamp   |\n",
    "| `@model_serializer` | You want to modify the **whole model** | e.g., rename keys, flatten structure |\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you want real-world use cases like hiding sensitive fields in API responses or converting nested models to flat ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9cfef5",
   "metadata": {},
   "source": [
    "# Lang Chain Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e73ccd6",
   "metadata": {},
   "source": [
    "## Loading the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e31b600f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3359433f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agentic2.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73c1667",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "## Langsmith Tracking And Tracing\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=os.getenv(\"LANGCHAIN_TRACING_V2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2e5aa7",
   "metadata": {},
   "source": [
    "## Langchain chatopenai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf63686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000029D73ED08D0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000029D7536CF90> root_client=<openai.OpenAI object at 0x0000029D72DBBB90> root_async_client=<openai.AsyncOpenAI object at 0x0000029D74F3A290> model_name='o1-mini' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(model=\"o1-mini\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef74fd32",
   "metadata": {},
   "source": [
    "langchain chatopenai automatically extract openai_api_key from environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57aaecbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**Agentic AI** refers to artificial intelligence systems designed to act as autonomous agents capable of perceiving their environment, making decisions, and executing actions to achieve specific goals. The term \"agentic\" emphasizes characteristics such as autonomy, proactivity, and the ability to take initiative, distinguishing these AI systems from more passive or reactive forms of artificial intelligence.\\n\\n### Key Characteristics of Agentic AI\\n\\n1. **Autonomy**: Agentic AI systems operate independently without continuous human intervention. They can make decisions based on their programming and learned experiences.\\n\\n2. **Goal-Directed Behavior**: These AI agents are designed to achieve specific objectives. They can set sub-goals, plan actions, and adjust strategies as needed to accomplish their primary goals.\\n\\n3. **Perception and Environment Interaction**: Agentic AI can perceive its environment through sensors or data inputs and interact with it effectively. This interaction enables the AI to gather information, assess situations, and respond appropriately.\\n\\n4. **Learning and Adaptation**: Many agentic AI systems incorporate machine learning algorithms allowing them to learn from experiences, adapt to new situations, and improve their performance over time.\\n\\n5. **Decision-Making Capabilities**: These AI agents can evaluate options, weigh potential outcomes, and choose actions that align best with their objectives.\\n\\n### Examples of Agentic AI\\n\\n- **Autonomous Vehicles**: Self-driving cars are a prime example of agentic AI. They navigate roads, make real-time decisions based on traffic conditions, and respond to dynamic environments to transport passengers safely.\\n\\n- **Robotics**: Industrial robots in manufacturing settings operate autonomously to perform tasks such as assembly, welding, and packaging, adjusting their actions based on real-time feedback.\\n\\n- **Virtual Assistants and Chatbots**: Advanced virtual assistants can manage schedules, initiate tasks, and engage in complex interactions with users, demonstrating a level of agency in handling various requests.\\n\\n- **Intelligent Personal Assistants**: AI systems that manage emails, set reminders, and optimize daily routines by making proactive decisions to enhance user productivity.\\n\\n### Applications of Agentic AI\\n\\n1. **Healthcare**: AI agents can monitor patient vitals, manage treatment plans, and even perform preliminary diagnostics, acting proactively to improve patient outcomes.\\n\\n2. **Finance**: Autonomous trading systems analyze market data in real-time, make investment decisions, and execute trades with minimal human oversight.\\n\\n3. **Smart Homes and IoT**: AI agents manage home environments by controlling lighting, heating, security systems, and appliances based on user preferences and behaviors.\\n\\n4. **Customer Service**: Advanced chatbots and virtual agents handle customer inquiries, resolve issues, and provide personalized support without human intervention.\\n\\n### Ethical and Societal Considerations\\n\\nWhile agentic AI offers numerous benefits, it also raises several ethical and societal concerns:\\n\\n- **Accountability**: Determining responsibility for the actions of autonomous AI agents can be challenging, especially in scenarios where decisions lead to unintended consequences.\\n\\n- **Bias and Fairness**: AI agents can inherit biases present in their training data or algorithms, leading to unfair or discriminatory outcomes.\\n\\n- **Privacy**: Autonomous agents often require access to vast amounts of data, raising concerns about data privacy and security.\\n\\n- **Job Displacement**: Increased automation through agentic AI may lead to displacement of jobs, necessitating strategies for workforce transition and reskilling.\\n\\n- **Control and Autonomy**: Ensuring that AI agents remain aligned with human values and objectives is critical to prevent scenarios where AI actions diverge from intended goals.\\n\\n### Future Directions\\n\\nThe development of agentic AI is advancing toward more sophisticated and capable systems. Future trends include:\\n\\n- **Enhanced Learning Capabilities**: Incorporating more advanced machine learning techniques to improve adaptability and decision-making.\\n\\n- **Better Human-AI Collaboration**: Designing AI agents that can effectively collaborate with humans, augmenting human capabilities rather than replacing them.\\n\\n- **Robust Ethical Frameworks**: Developing comprehensive ethical guidelines and regulations to govern the deployment and behavior of agentic AI systems.\\n\\n- **Explainability and Transparency**: Ensuring that AI agents can provide understandable explanations for their actions to foster trust and accountability.\\n\\n### Conclusion\\n\\nAgentic AI represents a significant advancement in artificial intelligence, enabling systems to act with a degree of autonomy and purposefulness that can transform various industries and aspects of daily life. While the potential benefits are substantial, it is essential to address the accompanying ethical, societal, and technical challenges to ensure that agentic AI contributes positively to society.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 983, 'prompt_tokens': 13, 'total_tokens': 996, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o1-mini-2024-09-12', 'system_fingerprint': 'fp_3da8b0b088', 'id': 'chatcmpl-BhG5VSBveTcxG47pk9Se36yGPkKfr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--8b04a864-56c3-48af-9d3c-ccd7811651c2-0' usage_metadata={'input_tokens': 13, 'output_tokens': 983, 'total_tokens': 996, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}\n"
     ]
    }
   ],
   "source": [
    "result=llm.invoke(\"What is Agentic AI\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaa5c11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Agentic AI** refers to artificial intelligence systems designed to act as autonomous agents capable of perceiving their environment, making decisions, and executing actions to achieve specific goals. The term \"agentic\" emphasizes characteristics such as autonomy, proactivity, and the ability to take initiative, distinguishing these AI systems from more passive or reactive forms of artificial intelligence.\n",
      "\n",
      "### Key Characteristics of Agentic AI\n",
      "\n",
      "1. **Autonomy**: Agentic AI systems operate independently without continuous human intervention. They can make decisions based on their programming and learned experiences.\n",
      "\n",
      "2. **Goal-Directed Behavior**: These AI agents are designed to achieve specific objectives. They can set sub-goals, plan actions, and adjust strategies as needed to accomplish their primary goals.\n",
      "\n",
      "3. **Perception and Environment Interaction**: Agentic AI can perceive its environment through sensors or data inputs and interact with it effectively. This interaction enables the AI to gather information, assess situations, and respond appropriately.\n",
      "\n",
      "4. **Learning and Adaptation**: Many agentic AI systems incorporate machine learning algorithms allowing them to learn from experiences, adapt to new situations, and improve their performance over time.\n",
      "\n",
      "5. **Decision-Making Capabilities**: These AI agents can evaluate options, weigh potential outcomes, and choose actions that align best with their objectives.\n",
      "\n",
      "### Examples of Agentic AI\n",
      "\n",
      "- **Autonomous Vehicles**: Self-driving cars are a prime example of agentic AI. They navigate roads, make real-time decisions based on traffic conditions, and respond to dynamic environments to transport passengers safely.\n",
      "\n",
      "- **Robotics**: Industrial robots in manufacturing settings operate autonomously to perform tasks such as assembly, welding, and packaging, adjusting their actions based on real-time feedback.\n",
      "\n",
      "- **Virtual Assistants and Chatbots**: Advanced virtual assistants can manage schedules, initiate tasks, and engage in complex interactions with users, demonstrating a level of agency in handling various requests.\n",
      "\n",
      "- **Intelligent Personal Assistants**: AI systems that manage emails, set reminders, and optimize daily routines by making proactive decisions to enhance user productivity.\n",
      "\n",
      "### Applications of Agentic AI\n",
      "\n",
      "1. **Healthcare**: AI agents can monitor patient vitals, manage treatment plans, and even perform preliminary diagnostics, acting proactively to improve patient outcomes.\n",
      "\n",
      "2. **Finance**: Autonomous trading systems analyze market data in real-time, make investment decisions, and execute trades with minimal human oversight.\n",
      "\n",
      "3. **Smart Homes and IoT**: AI agents manage home environments by controlling lighting, heating, security systems, and appliances based on user preferences and behaviors.\n",
      "\n",
      "4. **Customer Service**: Advanced chatbots and virtual agents handle customer inquiries, resolve issues, and provide personalized support without human intervention.\n",
      "\n",
      "### Ethical and Societal Considerations\n",
      "\n",
      "While agentic AI offers numerous benefits, it also raises several ethical and societal concerns:\n",
      "\n",
      "- **Accountability**: Determining responsibility for the actions of autonomous AI agents can be challenging, especially in scenarios where decisions lead to unintended consequences.\n",
      "\n",
      "- **Bias and Fairness**: AI agents can inherit biases present in their training data or algorithms, leading to unfair or discriminatory outcomes.\n",
      "\n",
      "- **Privacy**: Autonomous agents often require access to vast amounts of data, raising concerns about data privacy and security.\n",
      "\n",
      "- **Job Displacement**: Increased automation through agentic AI may lead to displacement of jobs, necessitating strategies for workforce transition and reskilling.\n",
      "\n",
      "- **Control and Autonomy**: Ensuring that AI agents remain aligned with human values and objectives is critical to prevent scenarios where AI actions diverge from intended goals.\n",
      "\n",
      "### Future Directions\n",
      "\n",
      "The development of agentic AI is advancing toward more sophisticated and capable systems. Future trends include:\n",
      "\n",
      "- **Enhanced Learning Capabilities**: Incorporating more advanced machine learning techniques to improve adaptability and decision-making.\n",
      "\n",
      "- **Better Human-AI Collaboration**: Designing AI agents that can effectively collaborate with humans, augmenting human capabilities rather than replacing them.\n",
      "\n",
      "- **Robust Ethical Frameworks**: Developing comprehensive ethical guidelines and regulations to govern the deployment and behavior of agentic AI systems.\n",
      "\n",
      "- **Explainability and Transparency**: Ensuring that AI agents can provide understandable explanations for their actions to foster trust and accountability.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Agentic AI represents a significant advancement in artificial intelligence, enabling systems to act with a degree of autonomy and purposefulness that can transform various industries and aspects of daily life. While the potential benefits are substantial, it is essential to address the accompanying ethical, societal, and technical challenges to ensure that agentic AI contributes positively to society.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeac7de",
   "metadata": {},
   "source": [
    "## Lang chain chat groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d01db12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n<think>\\nOkay, the user introduced themselves as Sainadh. I should respond politely and maybe ask how I can assist them. Let me keep it friendly and open-ended so they feel comfortable to ask anything they need help with.\\n\\nHmm, should I use an emoji? Maybe a smiley to keep it friendly. Also, make sure the tone is welcoming. I need to make sure the response is concise but inviting. Alright, that should work.\\n</think>\\n\\nHello Sainadh! ðŸ˜Š How can I assist you today? Feel free to ask anything!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 111, 'prompt_tokens': 17, 'total_tokens': 128, 'completion_time': 0.269894638, 'prompt_time': 0.003155706, 'queue_time': 0.33128514200000003, 'total_time': 0.273050344}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_512a3da6bb', 'finish_reason': 'stop', 'logprobs': None}, id='run--099a3401-fa3e-4327-8783-d0a37d238403-0', usage_metadata={'input_tokens': 17, 'output_tokens': 111, 'total_tokens': 128})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"qwen-qwq-32b\")\n",
    "model.invoke(\"Hi My name is Sainadh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c4de7e",
   "metadata": {},
   "source": [
    "> qwen-qwq-32b\n",
    "\n",
    "Hereâ€™s a detailed overview of **QwQâ€‘32B** â€” a powerful reasoning-oriented large language model:\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§  What is QwQâ€‘32B?\n",
    "\n",
    "* **Reasoning-specialized model**: Part of Alibaba Cloud's Qwen family, QwQâ€‘32B is specifically designed for deep analytical reasoning, surpassing general instruction-tuned models on complex, multi-step tasks ([medium.com][1]).\n",
    "* **Size and architecture**:\n",
    "\n",
    "  * \\~32.5â€¯B total parameters (\\~31â€¯B non-embedding)\n",
    "  * 64 Transformer layers\n",
    "  * 40 Q / 8 KV attention heads\n",
    "  * Supports ultra-long context: up to 131,072 tokens ([huggingface.co][2]).\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ Capabilities\n",
    "\n",
    "* **Advanced reasoning**: Strong in math, coding, and challenging problem-solvingâ€”achieves top-tier results on benchmarks like AIME24, BFCL, LiveBench, competing closely with models up to 20Ã— larger (e.g., DeepSeekâ€‘R1 of 671â€¯B params) ([datacamp.com][3]).\n",
    "* **Tool-use and function calling**: Built to interact with external tools and manage agentic workflowsâ€”outperforming models like o1â€‘mini in the Berkeley Function Calling leaderboard ([groq.com][4]).\n",
    "* **Self-reflective reasoning (â€œchain-of-thoughtâ€)**: Internally uses RL to pause and reflect (â€œ<think>â€¦â€) before producing answers, enhancing accuracy despite verbose outputs ([groq.com][4]).\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ› ï¸ Training & Access\n",
    "\n",
    "* **Built by Alibaba Cloud's Qwen team**: Based on preâ€‘training Qwen 2.5â€‘32B, then RLâ€‘finetuned for reasoning tasks using verifiers for math and code correctness ([qwenlm.github.io][5]).\n",
    "* **Open-source**: Released under the Apacheâ€¯2.0 license, available via Hugging Face and ModelScope, and accessible through Qwen Chat ([alibabacloud.com][6]).\n",
    "* **Deployment support**: Available on platforms like Groq Cloud and SambaNova, offering high-speed inference (e.g., \\~400â€¯tokens/sec at competitive pricing) ([groq.com][4]).\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŒ Who built it?\n",
    "\n",
    "* **Developer**: **Alibaba Cloud** (Qwen team)\n",
    "* **Part of**: The Qwen LLM familyâ€”a growing open-source series from Alibaba, with Qwen3 being the latest ([en.wikipedia.org][7], [arxiv.org][8]).\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ” Summary Table\n",
    "\n",
    "| Feature            | Details                                                 |\n",
    "| ------------------ | ------------------------------------------------------- |\n",
    "| **Parameters**     | \\~32â€¯B                                                  |\n",
    "| **Architecture**   | Transformer with RoPE, SwiGLU, RMSNorm, QKV bias        |\n",
    "| **Context window** | Up to 131K tokens                                       |\n",
    "| **Strengths**      | Reasoning, math, code, tool use                         |\n",
    "| **Benchmarks**     | Comparable to much larger models (DeepSeek-R1, o1-mini) |\n",
    "| **Access**         | Open-source (Apacheâ€¯2.0); hosted on multiple platforms  |\n",
    "| **Built by**       | Alibaba Cloudâ€™s Qwen team                               |\n",
    "\n",
    "---\n",
    "\n",
    "In essence, **QwQâ€‘32B** is a mid-sized, open-source reasoning powerhouse from Alibabaâ€”delivering sophisticated analytical performance while remaining efficient and accessible.\n",
    "\n",
    "* [barrons.com](https://www.barrons.com/articles/alibaba-baba-stock-adr-price-qwen-deepseek-064f5fcc?utm_source=chatgpt.com)\n",
    "* [time.com](https://time.com/7265415/alibaba-model-ai-china-deepseek/?utm_source=chatgpt.com)\n",
    "* [reuters.com](https://www.reuters.com/technology/alibaba-shares-surge-after-it-unveils-reasoning-model-2025-03-06/?utm_source=chatgpt.com)\n",
    "\n",
    "[1]: https://medium.com/%40ferreradaniel/power-of-ai-reasoning-qwen-qwq-32b-revolutionizes-problem-solving-8c775607826f?utm_source=chatgpt.com \"Power of AI Reasoning: Qwen QwQ-32B Revolutionizes Problem ...\"\n",
    "[2]: https://huggingface.co/Qwen/QwQ-32B?utm_source=chatgpt.com \"Qwen/QwQ-32B - Hugging Face\"\n",
    "[3]: https://www.datacamp.com/blog/qwq-32b?utm_source=chatgpt.com \"QwQ-32B: Features, Access, DeepSeek-R1 Comparison & More\"\n",
    "[4]: https://groq.com/a-guide-to-reasoning-with-qwen-qwq-32b/?utm_source=chatgpt.com \"A Guide to Reasoning with Qwen QwQ 32B - Groq is Fast AI Inference\"\n",
    "[5]: https://qwenlm.github.io/blog/qwq-32b/?utm_source=chatgpt.com \"QwQ-32B: Embracing the Power of Reinforcement Learning - Qwen\"\n",
    "[6]: https://www.alibabacloud.com/blog/alibaba-cloud-unveils-qwq-32b-a-compact-reasoning-model-with-cutting-edge-performance_602039?utm_source=chatgpt.com \"Alibaba Cloud Unveils QwQ-32B: A Compact Reasoning Model with ...\"\n",
    "[7]: https://en.wikipedia.org/wiki/Qwen?utm_source=chatgpt.com \"Qwen\"\n",
    "[8]: https://arxiv.org/abs/2505.09388?utm_source=chatgpt.com \"Qwen3 Technical Report\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654e779b",
   "metadata": {},
   "source": [
    "## Langchain chat prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68c53691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Prompt Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26c6411d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000029D7CF682D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000029D7CF68E10>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"gemma2-9b-it\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b39c1e",
   "metadata": {},
   "source": [
    "> gemma2-9b-it\n",
    "\n",
    "**Gemmaâ€¯2â€¯9Bâ€‘IT** is the instruction-tuned, text-generation-focused variant of Googleâ€™s open-source Gemma 2 model series. Here's a breakdown of what makes it special:\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§  What is Gemmaâ€¯2â€¯9B-IT?\n",
    "\n",
    "* **Text-to-text, decoderâ€‘only LLM**: Based on the same research and architecture as Google's Gemini models and fine-tuned for instruction-following tasks like chat, summarization, code generation, reasoning, and more ([huggingface.co][1]).\n",
    "* **Mid-sized (\\~9â€¯billion parameters)**: Offers a strong balance between performance and computational efficiency â€” outperforming models like Llamaâ€¯3â€¯8B in its category ([blog.google][2]).\n",
    "* **Core design improvements**: Utilizes advanced techniques like group-query attention, extra RMSNorm layers, and distillation from larger variants to boost performance and stability ([developers.googleblog.com][3]).\n",
    "* **Context window**: Typically supports around 8K tokens (as part of the Gemmaâ€¯2 family), although future variants (Gemmaâ€¯3) expand this ([docsbot.ai][4]).\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ Capabilities & Usage\n",
    "\n",
    "* **Instruction-tuned** (â€œITâ€): Specialized to follow user instructions, making it excellent for chatbots, content creation, Q\\&A, and language transformation.\n",
    "* **Versatile applications**: Works well for text generation (stories, essays), summarization, translation, basic code generation and reasoning, and more ([build.nvidia.com][5]).\n",
    "* **Developer-friendly**: Open weights under Googleâ€™s Gemma license, usable via Hugging Face, NVIDIA NIM containers, Ollama, OpenRouter, DeepInfra, etc. ([huggingface.co][1]).\n",
    "* **Hardware-friendly**: Efficient enough to run inference on GPUs (e.g., A100/H100 or even home hardware setups) and via on-device frameworks like Gemma.cpp or llama.cpp ([huggingface.co][6]).\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŒ Who built it?\n",
    "\n",
    "* **Developed by**: Google (Gemma Team / Google DeepMind), as part of the Gemma 2 model family ([huggingface.co][1]).\n",
    "* **Instruction-tuned variant**: The â€œITâ€ suffix indicates fine-tuning on conversational and instructional datasets to optimize behavior in chat and command-following scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§ª Community Impressions\n",
    "\n",
    "On Reddit (r/LocalLLaMA), users praise its performance and personality:\n",
    "\n",
    "> â€œThis is the best model I have ever run on my 3060 shitâ€‘boxâ€¦ Itâ€™s the first model that genuinely felt better than GPTâ€‘3.5.â€ ([developers.googleblog.com][7], [reddit.com][8])\n",
    "\n",
    "They highlight its friendly tone, multilingual capabilities, and strong suitability for roleplay â€” albeit with occasional factual inaccuracies ([reddit.com][8]).\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“‹ Quick Overview\n",
    "\n",
    "| Feature            | Details                                                                               |\n",
    "| ------------------ | ------------------------------------------------------------------------------------- |\n",
    "| **Params**         | \\~9â€¯billion                                                                           |\n",
    "| **Architecture**   | Gemmaâ€¯2 backbone; instructionâ€‘tuned                                                   |\n",
    "| **Context window** | \\~8K tokens                                                                           |\n",
    "| **Strengths**      | Efficient inference, instruction-following, multilingual writing, creative generation |\n",
    "| **Usage**          | Chatbots, summarization, code, general text                                           |\n",
    "| **Access**         | Open-source on Hugging Face, NVIDIA NIM, Ollama, DeepInfra, etc.                      |\n",
    "| **Developer**      | Google / DeepMind Gemma Team                                                          |\n",
    "\n",
    "---\n",
    "\n",
    "**In summary:**\n",
    "Gemmaâ€¯2â€¯9Bâ€‘IT is a highly capable, efficient, instructionâ€‘tuned language model from Google. It's optimized for chat and content generation tasks within a practical 9B parameter size, offering open access for developers and strong performance relative to similarly sized models.\n",
    "\n",
    "Feel free to ask if you want usage examples, benchmarks, or deployment pointers!\n",
    "\n",
    "[1]: https://huggingface.co/google/gemma-2-9b-it?utm_source=chatgpt.com \"google/gemma-2-9b-it - Hugging Face\"\n",
    "[2]: https://blog.google/technology/developers/google-gemma-2/?utm_source=chatgpt.com \"Gemma 2 is now available to researchers and developers\"\n",
    "[3]: https://developers.googleblog.com/gemma-explained-new-in-gemma-2?utm_source=chatgpt.com \"Gemma explained: What's new in Gemma 2 - Google Developers Blog\"\n",
    "[4]: https://docsbot.ai/models/gemma-2-9b?utm_source=chatgpt.com \"Google's Gemma 2 9B - AI Model Details - DocsBot AI\"\n",
    "[5]: https://build.nvidia.com/google/gemma-2-9b-it/modelcard?utm_source=chatgpt.com \"gemma-2-9b-it Model by Google | NVIDIA NIM\"\n",
    "[6]: https://huggingface.co/INSAIT-Institute/BgGPT-Gemma-2-9B-IT-v1.0?utm_source=chatgpt.com \"INSAIT-Institute/BgGPT-Gemma-2-9B-IT-v1.0 - Hugging Face\"\n",
    "[7]: https://developers.googleblog.com/en/gemma-explained-overview-gemma-model-family-architectures/?utm_source=chatgpt.com \"Gemma explained: An overview of Gemma model family architectures\"\n",
    "[8]: https://www.reddit.com/r/LocalLLaMA/comments/1drxhlh/gemma_2_9b_appreciation_post/?utm_source=chatgpt.com \"Gemma 2 9b appreciation post : r/LocalLLaMA - Reddit\"\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffefe77e",
   "metadata": {},
   "source": [
    "## chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81c90369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000029D7CF682D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000029D7CF68E10>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=prompt|model\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31f1a0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI engineer, I'm familiar with Langsmith! \n",
      "\n",
      "Langsmith is an open-source platform designed to simplify the development and deployment of large language models (LLMs). Think of it as a toolbox specifically built for working with powerful AI like me. \n",
      "\n",
      "Here are some key things to know about Langsmith:\n",
      "\n",
      "**What it does:**\n",
      "\n",
      "* **Fine-tuning:** Langsmith makes it easier to customize pre-trained LLMs for specific tasks. Imagine taking a general-purpose language model and training it to excel at summarizing medical documents, writing different kinds of creative content, or answering questions about a particular subject. \n",
      "* **Evaluation:** It provides tools to assess the performance of your fine-tuned models. This helps you understand how well your model is doing and identify areas for improvement.\n",
      "* **Deployment:** Langsmith streamlines the process of putting your trained models into action. It can help you create APIs or integrate your models into existing applications.\n",
      "\n",
      "**Why it's useful:**\n",
      "\n",
      "* **Accessibility:**  Langsmith lowers the barrier to entry for working with LLMs. It doesn't require extensive machine learning expertise to get started.\n",
      "* **Efficiency:** It automates many of the tedious tasks involved in LLM development, saving you time and effort.\n",
      "* **Collaboration:** As an open-source platform, Langsmith encourages community contributions and knowledge sharing.\n",
      "\n",
      "**Who uses it:**\n",
      "\n",
      "* **Researchers:**  Langsmith can be used to experiment with new LLM architectures and training techniques.\n",
      "* **Developers:** It's a valuable tool for building AI-powered applications.\n",
      "* **Anyone interested in exploring the potential of LLMs:**  Even if you don't have a deep technical background, Langsmith can be a fun and educational way to learn about this exciting field.\n",
      "\n",
      "\n",
      "Let me know if you have any more questions about Langsmith or LLMs in general!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({\"input\":\"Can you tell me something about Langsmith\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cd689a",
   "metadata": {},
   "source": [
    "## Langchain Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fb5ec8",
   "metadata": {},
   "source": [
    "### StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0c91736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI engineer, I'm happy to tell you about Langsmith!  \n",
      "\n",
      "Langsmith is an open-source tool developed by AssemblyAI that simplifies the process of fine-tuning large language models (LLMs) for specific tasks.  Essentially, it acts as a user-friendly interface and framework for customizing powerful LLMs like GPT-3 and making them more effective for your particular needs. \n",
      "\n",
      "Here's a breakdown of Langsmith's key features and benefits:\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **Simplified Fine-Tuning:** Langsmith streamlines the fine-tuning process, making it accessible to a wider range of users, even those without extensive machine learning expertise.\n",
      "* **Pythonic API:** It provides a Python-based API that's intuitive and easy to integrate into existing workflows.\n",
      "* **Data Management:** Langsmith helps you manage your training data effectively, including splitting it, cleaning it, and formatting it for fine-tuning.\n",
      "* **Experiment Tracking:** It allows you to track your fine-tuning experiments, compare different models and parameters, and easily reproduce your best results.\n",
      "* **Model Deployment:** Langsmith aids in deploying your fine-tuned models for real-world applications.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* **Improved Performance:** Fine-tuning LLMs on your specific data can significantly enhance their accuracy and performance for your target tasks.\n",
      "* **Customization:** You can tailor LLMs to your unique domain or use case, achieving better results than using a generic pre-trained model.\n",
      "* **Cost-Effectiveness:** By fine-tuning existing models instead of training new ones from scratch, you can save on computational resources and time.\n",
      "* **Accessibility:** Langsmith lowers the barrier to entry for using LLMs, enabling more people to leverage their power.\n",
      "\n",
      "**Use Cases:**\n",
      "\n",
      "Langsmith is versatile and can be used for various applications, including:\n",
      "\n",
      "* **Chatbots:** Fine-tune LLMs to create more conversational and context-aware chatbots.\n",
      "* **Text Summarization:** Improve the accuracy and quality of text summarization tasks.\n",
      "* **Code Generation:** Train LLMs to generate code in specific programming languages.\n",
      "* **Question Answering:** Enhance the performance of question-answering systems.\n",
      "* **Sentiment Analysis:** Fine-tune LLMs for more accurate sentiment analysis in text.\n",
      "\n",
      "\n",
      "\n",
      "Let me know if you have any more questions about Langsmith or want to delve deeper into specific aspects!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser=StrOutputParser()\n",
    "\n",
    "chain=prompt|model|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f184ba5",
   "metadata": {},
   "source": [
    "### JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4659204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f28edc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24008f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'Return a JSON object.'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42281dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Langsmith', 'description': 'Langsmith is an open-source platform for building and deploying large language models (LLMs). It provides a modular and scalable architecture that allows developers to easily customize and experiment with different LLM components.', 'key_features': ['Modular and extensible design', 'Support for various LLM architectures', 'Easy deployment and management', 'Open-source and community-driven', 'Integration with popular machine learning frameworks'], 'website': 'https://github.com/langs-platform/langs'}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model|output_parser\n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55498157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Langsmith is an open-source platform for building and deploying large '\n",
      " 'language models (LLMs). It provides a modular and scalable architecture that '\n",
      " 'allows developers to easily customize and experiment with different LLM '\n",
      " 'components.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(response['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "377712a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7611d5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'Langsmith is an open-source framework developed by the Hugging Face community for fine-tuning large language models (LLMs). \\n\\n  **Key Features:**\\n\\n  * **Simplified Fine-Tuning:** Langsmith makes it easier to fine-tune LLMs by providing a user-friendly interface and streamlined workflows.\\n\\n  * **Model Management:** It offers tools for managing and versioning your fine-tuned models.\\n\\n  * **Dataset Integration:** Langsmith supports various data formats and integrates with popular datasets.\\n\\n  * **Experiment Tracking:** It allows you to track your fine-tuning experiments and compare results.\\n\\n  * **Community-Driven:** As an open-source project, Langsmith benefits from the contributions and support of a large community of developers.\\n\\n  **Benefits:**\\n\\n  * **Accessibility:** Makes fine-tuning LLMs accessible to a wider range of users.\\n  * **Efficiency:** Streamlines the fine-tuning process, saving time and resources.\\n  * **Customization:** Allows you to tailor LLMs to specific tasks and domains.\\n  * **Collaboration:** Fosters collaboration and knowledge sharing within the AI community.\\n\\n  **Use Cases:**\\n\\n  * **Text Generation:** Fine-tune LLMs for tasks like creative writing, summarization, and dialogue systems.\\n  * **Code Generation:** Train LLMs to generate code in different programming languages.\\n  * **Question Answering:**\\n\\n  Adapt LLMs to answer questions based on specific knowledge bases.\\n  * **Sentiment Analysis:** Fine-tune LLMs to classify text sentiment.\\n\\n  **Getting Started:**\\n\\n  Langsmith can be installed using pip. The Hugging Face website provides comprehensive documentation and tutorials to help you get started.'}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model|output_parser\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47cfd824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'Langsmith is an open-source framework developed by the Hugging '\n",
      "             'Face community for fine-tuning large language models (LLMs). \\n'\n",
      "             '\\n'\n",
      "             '  **Key Features:**\\n'\n",
      "             '\\n'\n",
      "             '  * **Simplified Fine-Tuning:** Langsmith makes it easier to '\n",
      "             'fine-tune LLMs by providing a user-friendly interface and '\n",
      "             'streamlined workflows.\\n'\n",
      "             '\\n'\n",
      "             '  * **Model Management:** It offers tools for managing and '\n",
      "             'versioning your fine-tuned models.\\n'\n",
      "             '\\n'\n",
      "             '  * **Dataset Integration:** Langsmith supports various data '\n",
      "             'formats and integrates with popular datasets.\\n'\n",
      "             '\\n'\n",
      "             '  * **Experiment Tracking:** It allows you to track your '\n",
      "             'fine-tuning experiments and compare results.\\n'\n",
      "             '\\n'\n",
      "             '  * **Community-Driven:** As an open-source project, Langsmith '\n",
      "             'benefits from the contributions and support of a large community '\n",
      "             'of developers.\\n'\n",
      "             '\\n'\n",
      "             '  **Benefits:**\\n'\n",
      "             '\\n'\n",
      "             '  * **Accessibility:** Makes fine-tuning LLMs accessible to a '\n",
      "             'wider range of users.\\n'\n",
      "             '  * **Efficiency:** Streamlines the fine-tuning process, saving '\n",
      "             'time and resources.\\n'\n",
      "             '  * **Customization:** Allows you to tailor LLMs to specific '\n",
      "             'tasks and domains.\\n'\n",
      "             '  * **Collaboration:** Fosters collaboration and knowledge '\n",
      "             'sharing within the AI community.\\n'\n",
      "             '\\n'\n",
      "             '  **Use Cases:**\\n'\n",
      "             '\\n'\n",
      "             '  * **Text Generation:** Fine-tune LLMs for tasks like creative '\n",
      "             'writing, summarization, and dialogue systems.\\n'\n",
      "             '  * **Code Generation:** Train LLMs to generate code in '\n",
      "             'different programming languages.\\n'\n",
      "             '  * **Question Answering:**\\n'\n",
      "             '\\n'\n",
      "             '  Adapt LLMs to answer questions based on specific knowledge '\n",
      "             'bases.\\n'\n",
      "             '  * **Sentiment Analysis:** Fine-tune LLMs to classify text '\n",
      "             'sentiment.\\n'\n",
      "             '\\n'\n",
      "             '  **Getting Started:**\\n'\n",
      "             '\\n'\n",
      "             '  Langsmith can be installed using pip. The Hugging Face website '\n",
      "             'provides comprehensive documentation and tutorials to help you '\n",
      "             'get started.'}\n"
     ]
    }
   ],
   "source": [
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144be5ba",
   "metadata": {},
   "source": [
    "### XML output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c770ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer.<response><answer>Your answer here</answer></response>.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "output_parser=XMLOutputParser()\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.<response><answer>Your answer here</answer></response>.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ff59004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'The output should be formatted as a XML file.\\n1. Output should conform to the tags below.\\n2. If tags are not given, make them on your own.\\n3. Remember to always open and close all the tags.\\n\\nAs an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n1. String \"<foo>\\n   <bar>\\n      <baz></baz>\\n   </bar>\\n</foo>\" is a well-formatted instance of the schema.\\n2. String \"<foo>\\n   <bar>\\n   </foo>\" is a badly-formatted instance.\\n3. String \"<foo>\\n   <tag>\\n   </tag>\\n</foo>\" is a badly-formatted instance.\\n\\nHere are the output tags:\\n```\\nNone\\n```'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=XMLOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88d60a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```xml\\n<response>\\n  <info>\\n    <name>Langsmith</name>\\n    <description>Langsmith is an open-weights platform for developing and deploying AI assistants.</description>\\n    <creator>It is created by the Gemma team at Google DeepMind.</creator>\\n    <features>\\n      <feature>Modular design allows for easy customization and extension.</feature>\\n      <feature>Focuses on responsible AI development with transparency and ethical considerations.</feature>\\n      <feature>Supports various AI models and allows users to fine-tune them for specific tasks.</feature>\\n    </features>\\n  </info>\\n</response>\\n```\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 144, 'prompt_tokens': 195, 'total_tokens': 339, 'completion_time': 0.261818182, 'prompt_time': 0.007734238, 'queue_time': 0.16343249199999998, 'total_time': 0.26955242}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--e4f61e62-2582-4ee9-91b7-b4fed69358f6-0' usage_metadata={'input_tokens': 195, 'output_tokens': 144, 'total_tokens': 339}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model\n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34856aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('```xml\\n'\n",
      " '<response>\\n'\n",
      " '  <info>\\n'\n",
      " '    <name>Langsmith</name>\\n'\n",
      " '    <description>Langsmith is an open-weights platform for developing and '\n",
      " 'deploying AI assistants.</description>\\n'\n",
      " '    <creator>It is created by the Gemma team at Google DeepMind.</creator>\\n'\n",
      " '    <features>\\n'\n",
      " '      <feature>Modular design allows for easy customization and '\n",
      " 'extension.</feature>\\n'\n",
      " '      <feature>Focuses on responsible AI development with transparency and '\n",
      " 'ethical considerations.</feature>\\n'\n",
      " '      <feature>Supports various AI models and allows users to fine-tune them '\n",
      " 'for specific tasks.</feature>\\n'\n",
      " '    </features>\\n'\n",
      " '  </info>\\n'\n",
      " '</response>\\n'\n",
      " '```\\n')\n"
     ]
    }
   ],
   "source": [
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5776587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<response><answer>LangChain is an open-source framework designed to simplify the development of applications powered by large language models (LLMs). It provides a suite of tools and components that enable developers to build, chain, and manage LLM interactions in a modular and efficient way.</answer></response>\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 39, 'total_tokens': 103, 'completion_time': 0.116363636, 'prompt_time': 0.003605134, 'queue_time': 0.258729756, 'total_time': 0.11996877}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--d8d73875-78f3-44c7-9ad1-59a5c10ccf21-0' usage_metadata={'input_tokens': 39, 'output_tokens': 64, 'total_tokens': 103}\n"
     ]
    }
   ],
   "source": [
    "##output parser\n",
    "#from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain.output_parsers.xml import XMLOutputParser\n",
    "\n",
    "# XML Output Parser\n",
    "output_parser = XMLOutputParser()\n",
    "\n",
    "# Prompt that instructs the model to return XML\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Respond in this XML format: <response><answer>Your answer here</answer></response>\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Build the chain\n",
    "chain = prompt | model\n",
    "\n",
    "# Run the chain\n",
    "#response = chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "raw_output =chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "# Print result\n",
    "print(raw_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec4c83e",
   "metadata": {},
   "source": [
    "### Custom output parsing by Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b498c3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why couldn't the bicycle find its way home?\", 'punchline': 'Because it lost its bearings!'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## With Pydantic\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "model = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2fe2a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': \"Why couldn't the bicycle stand up by itself? Because it was two tired!\"}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Without Pydantic\n",
    "joke_query = \"Tell me a joke .\"\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32480023",
   "metadata": {},
   "source": [
    "pydantic is helpful in JSON output parser to get required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19ba37c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<movie>Big</movie>\n",
      "<movie>Forrest Gump</movie>\n",
      "<movie>Saving Private Ryan</movie>\n",
      "<movie>Cast Away</movie>\n",
      "<movie>The Green Mile</movie>\n",
      "<movie>Toy Story (voice of Woody)</movie>\n",
      "<movie>Apollo 13</movie>\n",
      "<movie>Philadelphia</movie>\n",
      "<movie>Sully</movie>\n",
      "<movie>Bridge of Spies</movie>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "actor_query = \"Generate the shortened filmography for Tom Hanks.\"\n",
    "\n",
    "output = model.invoke(\n",
    "    f\"\"\"{actor_query}\n",
    "Please enclose the movies in <movie></movie> tags\"\"\"\n",
    ")\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87b25b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why couldn't the bicycle stand up by itself?\", punchline='Because it was two tired!')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import YamlOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "model = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = YamlOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bfb688",
   "metadata": {},
   "source": [
    "## Assigments: https://python.langchain.com/docs/how_to/#prompt-templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a50b16",
   "metadata": {},
   "source": [
    "Here's a **comprehensive summary** of **all types of prompt templates in LangChain**, covering:\n",
    "\n",
    "* ðŸ“Œ Classes from your **uploaded image**\n",
    "* ðŸ“Œ Examples and use-cases\n",
    "* ðŸ“Œ Concepts from the linked guides:\n",
    "\n",
    "  * Few-shot examples\n",
    "  * Chat format examples\n",
    "  * Partial prompts\n",
    "  * Prompt composition\n",
    "  * Multimodal prompts\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ§  1. **BasePromptTemplate**\n",
    "\n",
    "* **Abstract base** class for all prompt templates.\n",
    "* Others like `PromptTemplate`, `ChatPromptTemplate` inherit from this.\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ“„ 2. **PromptTemplate**\n",
    "\n",
    "* For **simple string-based** prompts.\n",
    "\n",
    "```python\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "template = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "print(template.format(topic=\"dogs\"))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ§µ 3. **StringPromptTemplate**\n",
    "\n",
    "* Same as `PromptTemplate`, but explicitly focuses on templates with `.format()` method exposure.\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ’¬ 4. **ChatPromptTemplate**\n",
    "\n",
    "* Structured prompt for chat models.\n",
    "\n",
    "```python\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"user\", \"What is the capital of {country}?\")\n",
    "])\n",
    "chat_prompt.format(country=\"France\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ‘¤ 5. **HumanMessagePromptTemplate**\n",
    "\n",
    "* Message from the **user** in chat.\n",
    "\n",
    "```python\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "HumanMessagePromptTemplate.from_template(\"Translate {text} to Hindi.\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ¤– 6. **AIMessagePromptTemplate**\n",
    "\n",
    "* Message from the **assistant/AI** in a chat.\n",
    "\n",
    "```python\n",
    "from langchain_core.prompts import AIMessagePromptTemplate\n",
    "AIMessagePromptTemplate.from_template(\"Sure! Here is the translation.\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ›  7. **SystemMessagePromptTemplate**\n",
    "\n",
    "* System-level instruction in a chat.\n",
    "\n",
    "```python\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate\n",
    "SystemMessagePromptTemplate.from_template(\"You are a scientific research assistant.\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ” 8. **ChatMessagePromptTemplate**\n",
    "\n",
    "* Generic chat message with role (human, AI, system, function).\n",
    "\n",
    "```python\n",
    "ChatMessagePromptTemplate.from_template(role=\"function\", template=\"Function name: {name}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ§± 9. **BaseChatPromptTemplate, BaseMessagePromptTemplate, BaseStringMessagePromptTemplate**\n",
    "\n",
    "* Abstract base classes. Used internally for inheritance and consistency across chat/message templates.\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ”„ 10. **MessagesPlaceholder**\n",
    "\n",
    "* Used to inject a **list of existing messages** into a prompt dynamically.\n",
    "\n",
    "```python\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "MessagesPlaceholder(variable_name=\"chat_history\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### âœ¨ 11. **FewShotPromptTemplate**\n",
    "\n",
    "* For **few-shot learning** in **string-based** prompts.\n",
    "\n",
    "```python\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "example_prompt = PromptTemplate.from_template(\"Q: {question}\\nA: {answer}\")\n",
    "examples = [{\"question\": \"2+2\", \"answer\": \"4\"}, {\"question\": \"3+5\", \"answer\": \"8\"}]\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Q: {input}\\nA:\",\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "print(prompt.format(input=\"6+7\"))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ’¬âœ¨ 12. **FewShotChatMessagePromptTemplate**\n",
    "\n",
    "* Few-shot for **chat-based prompts**.\n",
    "\n",
    "```python\n",
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate, ChatPromptTemplate\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\")\n",
    "])\n",
    "examples = [{\"input\": \"Hi\", \"output\": \"Hello!\"}]\n",
    "\n",
    "fewshot = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Be friendly.\"),\n",
    "    fewshot,\n",
    "    (\"human\", \"How are you?\")\n",
    "])\n",
    "print(final_prompt.format(input=\"How are you?\"))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ§© 13. **FewShotPromptWithTemplates**\n",
    "\n",
    "* A variant combining **few-shot logic** with multiple templates dynamically.\n",
    "* Used when templates are complex or structured.\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸŽ¥ 14. **ImagePromptTemplate**\n",
    "\n",
    "* For **multimodal models** (image + text).\n",
    "\n",
    "```python\n",
    "ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Describe the image\"),\n",
    "    (\"user\", [{\"type\": \"image_url\", \"url\": \"{image_url}\"}])\n",
    "])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ”— 15. **PipelinePromptTemplate**\n",
    "\n",
    "* Combines multiple prompt templates in a **pipeline**.\n",
    "\n",
    "```python\n",
    "from langchain_core.prompts import PipelinePromptTemplate\n",
    "PipelinePromptTemplate(\n",
    "    final_prompt=PromptTemplate.from_template(\"Q: {question}\\nA:\"),\n",
    "    pipeline_prompts=[\n",
    "        (\"question\", PromptTemplate.from_template(\"Summarize: {text}\"))\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ§± 16. **StructuredPrompt**\n",
    "\n",
    "* Represents structured formats, often used with output parsers or schemas.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ” Partial Prompts â€“ \\[Docs Summary]\n",
    "\n",
    "* Fill some variables now, others later.\n",
    "* Great for **dynamic chaining** and **reuse**.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”§ Prompt Composition â€“ \\[Docs Summary]\n",
    "\n",
    "* Combine strings or message templates via `+` operator or `extend()`.\n",
    "* Encourages **modular prompt building**.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ–¼ Multimodal Prompts â€“ \\[Docs Summary]\n",
    "\n",
    "* Allow embedding **images, audio, PDFs** inside prompts.\n",
    "* Works only with **multimodal models** like GPT-4V or Gemini.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Summary Table\n",
    "\n",
    "| Template                           | Input Style       | Best For                         |\n",
    "| ---------------------------------- | ----------------- | -------------------------------- |\n",
    "| `PromptTemplate`                   | String            | Simple instructions              |\n",
    "| `ChatPromptTemplate`               | Messages          | Chatbots or assistants           |\n",
    "| `FewShotPromptTemplate`            | String + Examples | Improve learning via demos       |\n",
    "| `FewShotChatMessagePromptTemplate` | Chat + Examples   | Chat-style examples              |\n",
    "| `MessagesPlaceholder`              | List Injection    | Adding existing message history  |\n",
    "| `ImagePromptTemplate`              | Media block       | Multimodal inputs (images/audio) |\n",
    "| `PipelinePromptTemplate`           | Modular pipeline  | Building chained prompts         |\n",
    "| `PartialPrompt`                    | Partial values    | Dynamic reuse                    |\n",
    "| `StructuredPrompt`                 | Structured output | Controlled formatting            |\n",
    "\n",
    "---\n",
    "\n",
    "Would you like a visual diagram (e.g. mindmap or table image) showing relationships and use cases for each class?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e723f999",
   "metadata": {},
   "source": [
    "## Different types of Output parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6359ea",
   "metadata": {},
   "source": [
    "Hereâ€™s a comprehensive overview of **all builtâ€‘in output parser types in LangChain**, with clear explanations, examples, and when to use each:\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“¦ Output Parser Types\n",
    "\n",
    "([python.langchain.com][1])\n",
    "\n",
    "#### 1. **StringOutputParser**\n",
    "\n",
    "* **Purpose**: Normalizes LLM or Chat output into a plain Python string.\n",
    "* **Example**:\n",
    "\n",
    "  ```python\n",
    "  from langchain_core.output_parsers import StringOutputParser\n",
    "  parser = StringOutputParser()\n",
    "  parser.parse(\"Hello, world!\")  # => \"Hello, world!\"\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **JSON (JsonOutputParser or PydanticParser)**\n",
    "\n",
    "* **Purpose**: Extracts structured JSON using optional Pydantic validation.\n",
    "* **Example**:\n",
    "\n",
    "  ````python\n",
    "  from langchain_core.output_parsers import JsonOutputParser\n",
    "  from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "  class Joke(BaseModel):\n",
    "      setup: str\n",
    "      punchline: str\n",
    "\n",
    "  parser = JsonOutputParser(pydantic_object=Joke)\n",
    "  instructions = parser.get_format_instructions()\n",
    "  # Include `instructions` in prompt...\n",
    "  result = parser.parse(response_text)\n",
    "  # => {'setup': \"...\", 'punchline': \"...\"}\n",
    "  ``` :contentReference[oaicite:4]{index=4}\n",
    "  ````\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **YAML OutputParser**\n",
    "\n",
    "* **Purpose**: Outputs validated structured data in YAML format using Pydantic.\n",
    "* Use `JsonOutputParser(..., mode=\"yaml\")` or `YAMLOutputParser`.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **XML Parser**\n",
    "\n",
    "* **Purpose**: Parses XML-formatted strings into Python `dict`.\n",
    "* Use when dealing with XML-based tool formats. ([reddit.com][2], [python.langchain.com][1])\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **CSV Parser (CommaSeparatedListOutputParser)**\n",
    "\n",
    "* **Purpose**: Converts comma-separated LLM output into a `List[str]`.\n",
    "* **Example**:\n",
    "\n",
    "  ````python\n",
    "  from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "  parser = CommaSeparatedListOutputParser()\n",
    "  instructions = parser.get_format_instructions()\n",
    "  # Prompt: \"List fruits: â€¦{instructions}\"\n",
    "  result = parser.parse(\"Apple, Banana, Cherry\")\n",
    "  # => [\"Apple\", \"Banana\", \"Cherry\"]\n",
    "  ``` :contentReference[oaicite:11]{index=11}\n",
    "  ````\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. **EnumOutputParser**\n",
    "\n",
    "* **Purpose**: Ensures output matches one value from a given Python `Enum`.\n",
    "* Use when only specific categorical responses are valid. ([python.langchain.com][3])\n",
    "\n",
    "---\n",
    "\n",
    "#### 7. **DatetimeOutputParser**\n",
    "\n",
    "* **Purpose**: Parses output into a Python `datetime.datetime`.\n",
    "* **Example**:\n",
    "\n",
    "  ````python\n",
    "  from langchain.output_parsers import DatetimeOutputParser\n",
    "  parser = DatetimeOutputParser()\n",
    "  # Use parser.get_format_instructions() in prompt\n",
    "  parser.parse(\"1991-02-20 00:00:00\")\n",
    "  # => datetime.datetime(1991, 2, 20)\n",
    "  ``` :contentReference[oaicite:16]{index=16}\n",
    "  ````\n",
    "\n",
    "---\n",
    "\n",
    "#### 8. **PandasDataFrame Parser**\n",
    "\n",
    "* **Purpose**: Outputs structured tabular data as a pandas DataFrame.\n",
    "* Great for spreadsheet-style outputs. ([python.langchain.com][4], [python.langchain.com][1])\n",
    "\n",
    "---\n",
    "\n",
    "#### 9. **StructuredOutputParser**\n",
    "\n",
    "* **Purpose**: Generates `Dict[str, str]` with predefined keys onlyâ€”lighter weight than JSON/YAML.\n",
    "* **Example**:\n",
    "\n",
    "  ````python\n",
    "  from langchain.output_parsers import StructuredOutputParser\n",
    "  parser = StructuredOutputParser.from_names_and_descriptions({\n",
    "      \"meaning\": \"detailed meaning of the expression\"\n",
    "  })\n",
    "  instructions = parser.get_format_instructions()\n",
    "  # Include in chat prompt...\n",
    "  parser.parse(response_text)\n",
    "  # => {\"meaning\": \"...\"}\n",
    "  ``` :contentReference[oaicite:21]{index=21}\n",
    "  ````\n",
    "\n",
    "---\n",
    "\n",
    "#### 10. **OutputFixingParser & RetryWithErrorParser**\n",
    "\n",
    "* **Purpose**: Wrap another parser; on failure, invoke the LLM to:\n",
    "\n",
    "  * *OutputFixingParser*: fix just the failed output.\n",
    "  * *RetryWithErrorParser*: retry with full context.\n",
    "* Useful for making parsing more robust. ([python.langchain.com][1])\n",
    "\n",
    "---\n",
    "\n",
    "#### 11. **OpenAIFunctions & OpenAITools Parsers**\n",
    "\n",
    "* **Purpose**: Use native OpenAI (or tools) function-calling protocol to get structured outputs.\n",
    "* **Example**:\n",
    "\n",
    "  ```python\n",
    "  from langchain.output_parsers import OpenAIFunctionsOutputParser\n",
    "  parser = OpenAIFunctionsOutputParser(functions=...)\n",
    "  # Use this with ChatOpenAI(..., functions=...)\n",
    "  ```\n",
    "* Recommended when using GPT models supporting function calls. ([python.langchain.com][4])\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§° Custom Parsers\n",
    "\n",
    "* **BaseOutputParser** or **BaseGenerationOutputParser**: for complex or bespoke formats.\n",
    "* **Example**: Boolean parser converting `\"YES\"/\"NO\"` to `bool`Â ([python.langchain.com][3])\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Summary Table\n",
    "\n",
    "| Parser Type                | Output Type              | Use Case                                |\n",
    "| -------------------------- | ------------------------ | --------------------------------------- |\n",
    "| StringOutputParser         | `str`                    | Normalize raw outputs                   |\n",
    "| JsonOutputParser           | `dict` or Pydantic model | Structured JSON data                    |\n",
    "| YAMLOutputParser           | Pydantic model via YAML  | Humanâ€‘friendly structured data          |\n",
    "| XML Parser                 | `dict`                   | XML output parsing                      |\n",
    "| CSV Parser                 | `List[str]`              | CSVâ€‘style lists                         |\n",
    "| EnumOutputParser           | Enum                     | Categorical singleâ€‘choice responses     |\n",
    "| DatetimeOutputParser       | `datetime.datetime`      | Date/time extraction                    |\n",
    "| PandasDataFrame Parser     | `pd.DataFrame` or `dict` | Tabular data analysis                   |\n",
    "| StructuredOutputParser     | `Dict[str, str]`         | Lightweight structured responses        |\n",
    "| OutputFixing/Retry Parsers | Wrapped another parser   | Enhanced parsing reliability            |\n",
    "| OpenAIFunctions/Tools      | JSON object              | Use native functionâ€‘calling support     |\n",
    "| Custom Parsers             | Any Python type          | Special formats and raw output handling |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”— Best Practices\n",
    "\n",
    "* Use **native function-call parsers** (OpenAIFunctions/OpenAITools) if available for guaranteed structured output.\n",
    "* Otherwise, choose **JSON/YAML** with Pydantic for robustness.\n",
    "* Use **CSV, Enum, Datetime** for simpler, common data types.\n",
    "* Add **Fixing/Retry wrappers** to handle parsing errors gracefully.\n",
    "* Create **custom parsers** when facing unique output formats.\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you'd like example chains showcasing these parsers in action!\n",
    "\n",
    "[1]: https://python.langchain.com/docs/concepts/output_parsers/?utm_source=chatgpt.com \"Output parsers | ðŸ¦œï¸ðŸ”— LangChain\"\n",
    "[2]: https://www.reddit.com/r/LangChain/comments/1fdxh8o?utm_source=chatgpt.com \"PromptTemplate coupled to LLM parsing output\"\n",
    "[3]: https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/custom/?utm_source=chatgpt.com \"Custom Output Parsers | ðŸ¦œï¸ðŸ”— LangChain\"\n",
    "[4]: https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/?utm_source=chatgpt.com \"Output Parsers | ðŸ¦œï¸ðŸ”— LangChain\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955f6ed8",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "Create a simple assistant that uses any LLM and should be pydantic, when we ask about any product it should give you two information product Name, product details tentative price in USD (integer). use chat Prompt Template.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fff6f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Step 1: Define Pydantic schema for structured output\n",
    "class ProductInfo(BaseModel):\n",
    "    name: str\n",
    "    details: str\n",
    "    price_usd: int\n",
    "\n",
    "# Step 2: Initialize the parser\n",
    "parser = PydanticOutputParser(pydantic_object=ProductInfo)\n",
    "\n",
    "# Step 3: Define the prompt with format instructions\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that provides product information.\"),\n",
    "    (\"human\", \"Give information about the following product: {product_query}\\n{format_instructions}\")\n",
    "])\n",
    "formatted_prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "# Step 4: Initialize the ChatGroq model\n",
    "llm = ChatGroq(model=\"gemma2-9b-it\")\n",
    "\n",
    "# Step 5: Chain everything together\n",
    "chain = formatted_prompt | llm | parser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "577cbfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Product Info ---\n",
      "Name       : HP Victus 16\n",
      "Details    : A gaming laptop featuring an AMD Ryzen processor, NVIDIA GeForce RTX graphics, and a 16.1-inch display.\n",
      "Price (USD): $900\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Ask about a product: \")\n",
    "try:\n",
    "    response = chain.invoke({\"product_query\": query})\n",
    "    print(\"\\n--- Product Info ---\")\n",
    "    print(f\"Name       : {response.name}\")\n",
    "    print(f\"Details    : {response.details}\")\n",
    "    print(f\"Price (USD): ${response.price_usd}\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd33c774",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d36d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "### text loader\n",
    "from langchain_community.document_loaders.text import TextLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c36598c",
   "metadata": {},
   "source": [
    "### Text loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313b3c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.text.TextLoader at 0x27e9fc96e90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader=TextLoader('data\\speech.txt')\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "584c2fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\speech.txt'}, page_content='The world must be made safe for democracy. Its peace must be planted upon the tested foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no dominion. We seek no indemnities for ourselves, no material compensation for the sacrifices we shall freely make. We are but one of the champions of the rights of mankind. We shall be satisfied when those rights have been made as secure as the faith and the freedom of nations can make them.\\n\\nJust because we fight without rancor and without selfish object, seeking nothing for ourselves but what we shall wish to share with all free peoples, we shall, I feel confident, conduct our operations as belligerents without passion and ourselves observe with proud punctilio the principles of right and of fair play we profess to be fighting for.\\n\\nâ€¦\\n\\nIt will be all the easier for us to conduct ourselves as belligerents in a high spirit of right and fairness because we act without animus, not in enmity toward a people or with the desire to bring any injury or disadvantage upon them, but only in armed opposition to an irresponsible government which has thrown aside all considerations of humanity and of right and is running amuck. We are, let me say again, the sincere friends of the German people, and shall desire nothing so much as the early reestablishment of intimate relations of mutual advantage between usâ€”however hard it may be for them, for the time being, to believe that this is spoken from our hearts.\\n\\nWe have borne with their present government through all these bitter months because of that friendshipâ€”exercising a patience and forbearance which would otherwise have been impossible. We shall, happily, still have an opportunity to prove that friendship in our daily attitude and actions toward the millions of men and women of German birth and native sympathy who live among us and share our life, and we shall be proud to prove it toward all who are in fact loyal to their neighbors and to the government in the hour of test. They are, most of them, as true and loyal Americans as if they had never known any other fealty or allegiance. They will be prompt to stand with us in rebuking and restraining the few who may be of a different mind and purpose. If there should be disloyalty, it will be dealt with with a firm hand of stern repression; but, if it lifts its head at all, it will lift it only here and there and without countenance except from a lawless and malignant few.\\n\\nIt is a distressing and oppressive duty, gentlemen of the Congress, which I have performed in thus addressing you. There are, it may be, many months of fiery trial and sacrifice ahead of us. It is a fearful thing to lead this great peaceful people into war, into the most terrible and disastrous of all wars, civilization itself seeming to be in the balance. But the right is more precious than peace, and we shall fight for the things which we have always carried nearest our heartsâ€”for democracy, for the right of those who submit to authority to have a voice in their own governments, for the rights and liberties of small nations, for a universal dominion of right by such a concert of free peoples as shall bring peace and safety to all nations and make the world itself at last free.\\n\\nTo such a task we can dedicate our lives and our fortunes, everything that we are and everything that we have, with the pride of those who know that the day has come when America is privileged to spend her blood and her might for the principles that gave her birth and happiness and the peace which she has treasured. God helping her, she can do no other.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_documents=loader.load()\n",
    "text_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9750454",
   "metadata": {},
   "source": [
    "### Pdf loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a13646d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 0, 'page_label': '1'}, page_content='MACHINE\\nLEARNING\\nDEEP\\nLEARNING\\nPYTHON +\\nSTATS\\nCOMPUTER VISIONNATURAL LANGUAGE PROCESSING\\nGENERATIVE AI\\nRETRIEVAL AUGUMENT GENERATION\\nVECTOR DB'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 1, 'page_label': '2'}, page_content='This course is designed for aspiring data scientists, machine learning enthusiasts, and\\nprofessionals looking to build expertise in Python programming, data analysis, machine learning,\\nand deep learning. Whether you are just starting or have some experience, this comprehensive\\ncourse will equip you with the skills needed to work with real-world datasets, apply machine\\nlearning algorithms, and deploy AI solutions. By the end of the course, youâ€™ll have a solid\\nfoundation in AI, a portfolio of end-to-end projects, and the confidence to tackle complex\\nchallenges in data science and AI.\\nLearning Objectives\\nMaster Python Programming: Understand Python fundamentals, including data types,\\ncontrol structures, and object-oriented programming, to write efficient and reusable\\ncode.\\nHandle Data with Pandas and NumPy: Acquire skills to manipulate, clean, and\\npreprocess large datasets using Pandas and NumPy for data analysis tasks.\\nVisualize Data: Create compelling data visualizations using libraries such as Matplotlib,\\nSeaborn, and Plotly to present insights effectively.\\nUnderstand SQL & NoSQL: Gain expertise in both relational (SQL) and non-relational\\n(NoSQL) databases, including MongoDB, for storing, querying, and managing data.\\nGrasp Statistics and Probability: Understand the core concepts of statistics,\\nprobability, and hypothesis testing, applying them to data analysis and machine\\nlearning.\\nMaster Machine Learning Techniques: Learn key machine learning algorithms,\\nincluding supervised, unsupervised, and ensemble methods, and apply them to real-\\nworld problems.\\nDive into Deep Learning: Develop a strong understanding of neural networks, CNNs,\\nRNNs, and transformers, with hands-on implementation for advanced AI tasks.\\nExplore Generative AI & Vector Databases: Learn the concepts and applications of\\ngenerative models, vector databases, and retrieval-augmented generation to handle\\ncomplex AI systems.\\nBuild Real-World Projects: Implement end-to-end machine learning and AI projects,\\nfrom data preprocessing to model deployment, integrating concepts from multiple\\nmodules.\\nUltimate Data Science & GenAI Bootcamp       Page  2'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 2, 'page_label': '3'}, page_content=\"Course Information\\nNo prerequisites are required for this course. The curriculum covers everything from the\\nbasics of Python programming, statistics, and machine learning to advanced topics in deep\\nlearning, NLP, and generative AI. Whether you're a beginner or have some prior experience,\\nthe course will ensure you gain the skills needed to succeed.\\nEstimated Time\\n8 months 6hrs/week*\\nRequired Skill Level\\nBegineer\\nThe course is designed to be completed over a duration of approximately 7 to 8 months, providing\\nan in-depth exploration from Python basics to GenAI, with plenty of time for practical\\nimplementation and real-world applications.\\nPrerequisites\\nUltimate Data Science & GenAI Bootcamp       Page  3\"),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 3, 'page_label': '4'}, page_content='Course Instructors\\nSunny SavitaGenAI Engineer\\nLinkedin\\nKrish NaikChief AI Engineer\\nLinkedin\\nUltimate Data Science & GenAI Bootcamp       Page  4\\nSourangshu PalSenior Data Scientist\\nLinkedin\\nMonal KumarData Scientist\\nLinkedin\\nMayank AggrawalSenior ML Engineer\\nLinkedin\\nDarius B.Head of Product\\nLinkedin'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 4, 'page_label': '5'}, page_content=\"In this module, youâ€™ll get a solid introduction to Python, covering essential programming concepts\\nsuch as variables, data types, operators, and control flow. Youâ€™ll learn how to manipulate strings,\\nlists, dictionaries, and other basic data structures. The module will also guide you through writing\\nsimple functions and using loops and conditionals effectively. By the end, you'll have a strong\\nunderstanding of Python syntax, preparing you to tackle more complex programming challenges\\nand form a foundation for learning advanced concepts.\\nUltimate Data Science & GenAI Bootcamp       Page  5\\nPython Foundations\\nModule 1\\nTopics\\nIntroduction to Python Comparison with other programming\\nlanguages, Python objects: Numbers,\\nBooleans, and Strings\\nData Structures & Operations Container objects and mutability,\\nOperators, Operator precedence and\\nassociativity\\nControl Flow Conditional statements, Loops, break\\nand continue statements\\nString Manipulation Basics of string objects, Inbuilt string\\nmethods, Splitting and joining strings,\\nString formatting functions\\nLists & Collections List methods, list comprehension, Lists as\\nstacks and queues, Tuples, sets, and\\ndictionaries, Dictionary comprehensions\\nand view objects\"),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 5, 'page_label': '6'}, page_content='Topics\\nFunctions & Iterators Function basics and parameter passing,\\nIterators and generator functions,\\nLambda functions, map(), reduce(),\\nfilter()\\nPython Foundations\\nModule 1\\nUltimate Data Science & GenAI Bootcamp       Page  6'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 6, 'page_label': '7'}, page_content='This module takes your Python skills further by diving into object-oriented programming (OOP)\\nconcepts like classes, inheritance, and polymorphism. Youâ€™ll also explore more advanced topics\\nsuch as decorators, lambda functions, iterators, and generator functions. Additionally, we cover\\nexception handling, file operations, and working with modules and libraries. By the end, you will be\\ncomfortable building more sophisticated Python applications and writing efficient, reusable code.\\nAdvanced Python Programming\\nModule 2\\nTopics\\nObject-Oriented Programming (OOP) OOP basics and class creation,\\nInheritance, Polymorphism,\\nEncapsulation, and Abstraction,\\nDecorators, class methods, and static\\nmethods, Special (Magic/Dunder)\\nmethods, Property decorators: Getters,\\nsetters, and delete methods\\nFile Handling & Logging Reading and writing files, Buffered read\\nand write operations, more file methods,\\nLogging and debugging\\nModules & Exception Handling Importing modules and using them\\neffectively, Exception handling\\nConcurrency & Parallelism Introduction to multithreading,\\nMultiprocessing for performance\\noptimization\\nUltimate Data Science & GenAI Bootcamp       Page  7'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 7, 'page_label': '8'}, page_content='In this module, you will master the core aspects of data manipulation using Pandas. Youâ€™ll learn\\nhow to work with Series, DataFrames, and Panels, as well as perform data selection, filtering, and\\nsorting. The module covers critical tasks like handling missing data, reindexing, and applying\\nstatistical functions to datasets. Youâ€™ll also gain hands-on experience with data visualization and\\nadvanced indexing techniques, empowering you to efficiently analyze and manipulate complex\\ndatasets.\\nMastering Data Handling with Pandas\\nTopics\\nData Structures & Fundamentals Series, DataFrame, Panel, Basic\\nFunctionality, Indexing & Selecting, Re-\\nindexing, Iteration\\nData Operations & Transformations Sorting, Working with Text Data, Options\\n& Customization, Categorical Data, Date\\nFunctionality, Time Delta\\nData Analysis & Statistical Functions Data Statistical Functions, Window\\nFunctions\\nReading, Writing & Visualization Reading Data from Different File\\nSystems, Visualization, Tools\\nUltimate Data Science & GenAI Bootcamp       Page  8\\nModule 3'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 8, 'page_label': '9'}, page_content='This module introduces you to NumPy, a key library for numerical computing in Python. Youâ€™ll learn\\nhow to create and manipulate NumPy arrays, perform advanced indexing, and understand\\nbroadcasting. The module covers essential mathematical and statistical functions, including array\\nmanipulations, binary operations, and vectorized operations. By the end, youâ€™ll have the skills to\\nefficiently perform complex numerical computations and leverage NumPy for machine learning\\nand deep learning applications.\\nMastering NumPy\\nTopics\\nNumPy Basics & Array Creation NdArray Object, Data Types, Array\\nAttributes, Array Creation Routines,\\nArray from Existing Data, Data Array from\\nNumerical Ranges\\nIndexing, Slicing & Advanced Indexing Indexing & Slicing, Advanced Indexing\\nArray Operations & Manipulation Array Manipulation, Binary Operators,\\nString Functions, Arithmetic Operations,\\nMathematical Functions\\nMathematical & Statistical Analysis Statistical Functions, Sort, Search &\\nCounting Functions, Matrix Library,\\nLinear Algebra\\nAdvanced Concepts Broadcasting, Iterating Over Array, Byte\\nSwapping, Copies & Views\\nUltimate Data Science & GenAI Bootcamp       Page  9\\nModule 4'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 9, 'page_label': '10'}, page_content=\"In this module, youâ€™ll learn how to visualize data effectively using Python's popular libraries,\\nMatplotlib, Seaborn, and Plotly. Youâ€™ll cover essential plot types like line charts, bar graphs, and\\nscatter plots, and learn how to customize these visualizations to highlight key insights. Additionally,\\nthe module teaches you how to visualize statistical data, correlations, and distributions, helping\\nyou communicate data-driven findings in a visually compelling way.\\nData Visualization with Python\\nTopics\\nIntroduction to Data Visualization Overview of Data Visualization, Principles\\nof Good Visualization\\nMatplotlib Introduction to Matplotlib, Creating\\nBasic Plots (Line, Bar, Scatter),\\nCustomizing Axes, Titles, Legends, and\\nLabels, Working with Subplots, Saving\\nand Exporting Figures\\nSeaborn Introduction to Seaborn, Visualizing\\nDistributions, Relationship Plots\\n(Pairplots, Heatmaps), Categorical Data\\nVisualization, Advanced Plot\\nCustomizations\\nPlotly Introduction to Plotly, Creating\\nInteractive Plots (Line, Bar, Scatter),\\nCustomizing Plots, Dashboards and\\nInteractive Layouts, Plotly Express\\nUltimate Data Science & GenAI Bootcamp       Page  10\\nModule 5\"),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 10, 'page_label': '11'}, page_content='This module dives into advanced SQL techniques, including complex queries, joins, and indexing\\nfor efficient data retrieval. Youâ€™ll learn how to implement stored procedures, triggers, and\\nfunctions, and explore the use of window functions and partitions. The module covers key\\ndatabase design concepts like primary and foreign keys and normalization. By the end, youâ€™ll be\\nproficient in managing large-scale databases and optimizing SQL queries for performance.\\nAdvanced SQL and Database Management\\nTopics\\nIntroduction to SQL Introduction to SQL, SQL Queries:\\nSELECT, INSERT, UPDATE, DELETE\\nSQL Functions and Procedures SQL Functions (Aggregate, Scalar),\\nStored Procedures, User-defined\\nFunctions (UDFs), Function and\\nProcedure Syntax\\nDatabase Constraints Primary and Foreign Keys, Data Integrity,\\nReferential Integrity\\nAdvanced SQL Techniques Window Functions, Partitioning, CTE\\n(Common Table Expressions), Indexing\\nSQL Joins and Unions Inner Join, Left Join, Right Join, Full Outer\\nJoin, Cross Join, Union\\nTriggers and Case Statements Triggers (Before, After), CASE\\nStatements, Conditional Logic\\nUltimate Data Science & GenAI Bootcamp       Page  11\\nModule 6'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 11, 'page_label': '12'}, page_content='Advanced SQL and Database Management\\nTopics\\nNormalization and Pivoting Normalization Forms (1NF, 2NF, 3NF),\\nPivot Tables, Data Aggregation\\nUltimate Data Science & GenAI Bootcamp       Page  12\\nModule 6'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 12, 'page_label': '13'}, page_content=\"In this module, you'll explore the world of NoSQL databases with MongoDB. You'll learn how to\\ncreate and manage databases, collections, and documents, and perform CRUD operations. The\\nmodule covers querying, sorting, and indexing, providing a comprehensive understanding of\\nMongoDB's flexible data model. By the end, youâ€™ll be able to efficiently work with NoSQL\\ndatabases, particularly for use cases that involve unstructured or semi-structured data.\\nIntroduction to NoSQL with MongoDB\\nTopics\\nGetting Started with MongoDB MongoDB Introduction, Setting up\\nMongoDB, MongoDB Shell Commands\\nDatabase and Collection Management MongoDB Create Database, MongoDB\\nCreate Collection\\nCRUD Operations MongoDB Insert, MongoDB Find,\\nMongoDB Update, MongoDB Delete\\nQuerying MongoDB MongoDB Query, MongoDB Sort,\\nMongoDB Limit\\nManaging Collections MongoDB Drop Collection, MongoDB\\nDelete (Specific)\\nUltimate Data Science & GenAI Bootcamp       Page  13\\nModule 7\"),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 13, 'page_label': '14'}, page_content='This module provides a foundation in statistics and probability, covering essential terms, concepts,\\nand methods. Youâ€™ll learn about different types of data, levels of measurement, and key statistical\\nmeasures like mean, median, variance, and standard deviation. The module introduces random\\nvariables, probability distributions, and various types of probability functions, giving you a strong\\nbase to analyze and interpret data from a statistical perspective.\\nFoundations of Statistics and Probability\\nTopics\\nIntroduction to Statistics Introduction to Basic Statistics Terms,\\nTypes of Statistics, Types of Data, Levels\\nof Measurement, Measures of Central\\nTendency, Measures of Dispersion\\nExploring Random Variables and\\nProbability\\nRandom Variables, Set Theory,\\nSkewness, Covariance and Correlation,\\nProbability Density/Distribution Function\\nDistributions and Their Applications Types of Probability Distributions,\\nBinomial Distribution, Poisson\\nDistribution, Normal Distribution\\n(Gaussian Distribution), Probability\\nDensity Function and Mass Function,\\nCumulative Density Function, Examples\\nof Normal Distribution, Bernoulli\\nDistribution, Uniform Distribution\\nStatistical Inference Z-Statistics, Central Limit Theorem,\\nEstimation, Hypothesis Testing\\nUltimate Data Science & GenAI Bootcamp       Page  14\\nModule 8'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 14, 'page_label': '15'}, page_content=\"In this module, you'll delve deeper into statistical inference techniques, including hypothesis\\ntesting, confidence intervals, and the types of errors in statistical tests. Youâ€™ll explore advanced\\nconcepts like P-values, T-tests, and Chi-square tests, learning how to interpret results in the\\ncontext of real-world data. By the end, youâ€™ll be equipped to conduct sophisticated statistical\\nanalysis and make informed decisions based on data-driven evidence.\\nAdvanced Statistical Inference and\\nHypothesis Testing\\nTopics\\nHypothesis Testing and Errors Hypothesis Testing Mechanism, Type 1 &\\nType 2 Error, T-Tests vs. Z-Tests:\\nOverview, When to Use a T-Test vs. Z-\\nTest\\nStatistical Distributions and Tests T-Stats, Student T Distribution, Chi-\\nSquare Test, Chi-Square Distribution\\nUsing Python, Chi-Square for Goodness\\nof Fit Test\\nBayesian Statistics and Confidence\\nIntervals\\nBayes Statistics (Bayes Theorem),\\nConfidence Interval (CI), Confidence\\nIntervals and the Margin of Error,\\nInterpreting Confidence Levels and\\nConfidence Intervals\\nStatistical Significance and\\nInterpretation\\nP-Value, T-Stats vs. Z-Stats: Overview\\nUltimate Data Science & GenAI Bootcamp       Page  15\\nModule 9\"),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 15, 'page_label': '16'}, page_content='This module covers essential techniques for preparing and transforming data before applying\\nmachine learning models. Youâ€™ll learn how to handle missing values, deal with imbalanced data,\\nand scale or encode features. The module also explores methods for handling outliers, feature\\nselection (including forward/backward elimination), and dimensionality reduction techniques. By\\nthe end, youâ€™ll be proficient in preparing high-quality datasets that are ready for modeling.\\nFeature Engineering and Data\\nPreprocessing\\nTopics\\nHandling Missing and Imbalanced\\nData\\nHandling Missing Data, Handling\\nImbalanced Data\\nOutliers and Scaling Handling Outliers, Feature Scaling\\nData Transformation and Encoding Data Encoding\\nFeature Selection Techniques Backward Elimination, Forward\\nElimination, Recursive Feature\\nElimination\\nCorrelation and Multicollinearity Covariance and Correlation, VIF\\nUltimate Data Science & GenAI Bootcamp       Page  16\\nModule 10'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 16, 'page_label': '17'}, page_content='In this module, youâ€™ll learn how to perform Exploratory Data Analysis (EDA) to uncover patterns,\\ntrends, and relationships in your data. Youâ€™ll master techniques for visualizing distributions,\\nidentifying correlations, and detecting anomalies. The module emphasizes the importance of\\nsummary statistics, data cleaning, and feature engineering. By the end, youâ€™ll be able to extract\\nmeaningful insights from raw data and prepare it for further analysis or modeling.\\nExploratory Data Analysis (EDA) for\\nDetailed Insights\\nTopics\\nTrend Analysis and Segmentation Analyzing Bike Sharing Trends,\\nCustomer Segmentation and Effective\\nCross-Selling\\nSentiment and Quality Analysis Analyzing Movie Reviews Sentiment,\\nAnalyzing Wine Types and Quality\\nRecommendation and Forecasting Analyzing Music Trends and\\nRecommendations, Forecasting Stock\\nand Commodity Prices\\nUltimate Data Science & GenAI Bootcamp       Page  17\\nModule 11'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 17, 'page_label': '18'}, page_content='This module provides a comprehensive introduction to machine learning, covering key algorithms\\nand techniques. Youâ€™ll learn the differences between supervised and unsupervised learning, as\\nwell as the core concepts of regression, classification, and clustering. The module introduces\\nmodel evaluation metrics like accuracy, precision, recall, and F1-score, giving you the foundation to\\nunderstand and implement machine learning models in real-world scenarios.\\nMachine Learning Foundations and\\nTechniques\\nTopics\\nIntroduction to Machine Learning AI vs ML vs DL vs DS, Types of ML\\nTechniques, Supervised vs Unsupervised\\nvs Semi-Supervised vs Reinforcement\\nLearning\\nLinear Regression Simple Linear Regression, Multiple Linear\\nRegression, MSE, MAE, RMSE, R-\\nsquared, Adjusted R-squared, Linear\\nRegression with OLS\\nRegularization Techniques Ridge Regression, Lasso Regression,\\nElasticNet\\nLogistic Regression Logistic Regression, Performance\\nMetrics: Confusion Matrix, Accuracy,\\nPrecision, Recall, F-Beta Score, ROC-\\nAUC Curve\\nSupport Vector Machines (SVM) Support Vector Classifiers, Support\\nVector Regressor, Support Vector\\nKernels\\nUltimate Data Science & GenAI Bootcamp       Page  18\\nModule 12'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 18, 'page_label': '19'}, page_content='Machine Learning Foundations and\\nTechniques\\nTopics\\nBayes Theorem and Naive Bayes Introduction to Bayes Theorem, Naive\\nBayes Classifier\\nK-Nearest Neighbors (KNN) KNN Classifier, KNN Regressor\\nDecision Trees Decision Tree Classifier, Decision Tree\\nRegressor\\nEnsemble Methods Bagging, Boosting, Random Forest\\nClassifier, Random Forest Regressor,\\nOut-of-Bag Evaluation, XGBoost\\nClassifier, XGBoost Regressor\\nSupport Vector Machines (SVM) Support Vector Classifiers, Support\\nVector Regressor, Support Vector\\nKernels\\nIntroduction to Unsupervised Learning Overview of Unsupervised Learning, Use\\nCases, and Applications\\nClustering Techniques KMeans Clustering, Hierarchical\\nClustering, DBSCAN Clustering\\nUltimate Data Science & GenAI Bootcamp       Page  19\\nModule 12'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 19, 'page_label': '20'}, page_content='Machine Learning Foundations and\\nTechniques\\nTopics\\nClustering Evaluation Silhouette Coefficient, Evaluation\\nMetrics for Clustering Algorithms\\nUltimate Data Science & GenAI Bootcamp       Page  20\\nModule 12'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 20, 'page_label': '21'}, page_content='In this module, youâ€™ll explore the basics of Natural Language Processing (NLP) for machine\\nlearning applications. Topics include text preprocessing (stemming, lemmatization), tokenization,\\nand POS tagging. Youâ€™ll also learn how to implement key NLP techniques like Named Entity\\nRecognition, word embeddings (Word2Vec), and TF-IDF. By the end of this module, youâ€™ll have the\\nskills to work with textual data and apply machine learning models to solve NLP tasks.\\nNatural Language Processing for\\nMachine Learning\\nTopics\\nIntroduction to NLP for ML Roadmap to Learn NLP for ML, Practical\\nUse Cases of NLP in Machine Learning\\nText Preprocessing Tokenization, Basic Terminology,\\nStemming, Lemmatization, Stopwords\\nText Representation One-Hot Encoding, N-Gram, Bag of\\nWords (BoW), TF-IDF Intuition\\nPart of Speech (POS) Tagging POS Tagging using NLTK, Understanding\\nPOS Tags\\nNamed Entity Recognition (NER) Introduction to NER, Implementing NER\\nwith NLTK\\nWord Embeddings Introduction to Word Embeddings,\\nBenefits of Using Word Embeddings in\\nML\\nUltimate Data Science & GenAI Bootcamp       Page  21\\nModule 13'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 21, 'page_label': '22'}, page_content='Natural Language Processing for\\nMachine Learning\\nTopics\\nWord2Vec Intuition behind Word2Vec, Training\\nWord2Vec Models, Skip-gram and\\nCBOW Architectures\\nUltimate Data Science & GenAI Bootcamp       Page  22\\nModule 13'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 22, 'page_label': '23'}, page_content='This module introduces you to deep learning and the fundamental concepts behind artificial\\nneural networks (ANNs). Youâ€™ll learn about the architecture and workings of a neural network,\\nincluding activation functions, loss functions, and optimization techniques. The module also covers\\nbackpropagation and the vanishing gradient problem. By the end, youâ€™ll be equipped to build and\\ntrain basic neural networks and understand how deep learning models are used in AI applications.\\nIntroduction to Deep Learning and Neural\\nNetworks\\nTopics\\nIntroduction to Deep Learning Why Deep Learning Is Becoming\\nPopular?\\nPerceptron Intuition Understanding the Perceptron Model,\\nBasic Working Principle\\nArtificial Neural Network (ANN)\\nWorking\\nStructure of ANN, Neurons, Layers, and\\nHow Data Passes Through the Network\\nBackpropagation in ANN The Backpropagation Process, Gradient\\nDescent, and Training Networks\\nVanishing Gradient Problem Explanation, Causes, and Solutions\\nExploding Gradient Problem Causes and Mitigation Techniques\\nUltimate Data Science & GenAI Bootcamp       Page  23\\nModule 14'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 23, 'page_label': '24'}, page_content=\"Introduction to Deep Learning and Neural\\nNetworks\\nTopics\\nActivation Functions Different Types of Activation Functions\\n(Sigmoid, ReLU, Tanh, etc.)\\nLoss Functions Common Loss Functions for Regression\\nand Classification\\nOptimizers Types of Optimizers (SGD, Adam,\\nRMSprop, etc.)\\nWeight Initialization Techniques Methods for Initializing Weights (Xavier,\\nHe Initialization)\\nDropout Layer Concept of Dropout and its Role in\\nRegularization\\nBatch Normalization How Batch Normalization Works and\\nWhy It's Important\\nKeras Framework Fundamentals Introduction to Keras, Building Models\\nwith Keras, Basic Operations\\nPyTorch Framework Fundamentals Introduction to PyTorch, Tensor\\nOperations, Building Models with\\nPyTorch\\nUltimate Data Science & GenAI Bootcamp       Page  24\\nModule 14\"),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 24, 'page_label': '25'}, page_content='In this module, youâ€™ll dive into Convolutional Neural Networks (CNNs), a cornerstone of deep\\nlearning in computer vision. Youâ€™ll learn the architecture of CNNs, including convolution layers,\\npooling layers, and fully connected layers. The module covers practical applications like image\\nclassification, object detection, and segmentation using CNNs. By the end, youâ€™ll have hands-on\\nexperience building and training CNNs for real-world vision tasks.\\nDeep Learning : Convolutional Neural\\nNetworks (CNN) Fundamentals and\\nApplications\\nTopics\\nIntroduction to CNN CNN Fundamentals, What is\\nConvolutional Neural Network, CNN\\nArchitecture Overview\\nExplaining CNN in Detail CNN Explained in Detail, Understanding\\nTensor Space, CNN Explainer\\nCNN-Based Architectures Various CNN Architectures, Deep Dive\\ninto ResNet and its Variants\\nTraining CNN from Scratch Steps to Train CNNs, Hyperparameter\\nTuning, Overfitting, and Underfitting\\nBuilding Web Apps for CNN Deploying CNN Models into Web\\nApplications, Using Flask or Django,\\nServing Models with TensorFlow.js\\nExploding Gradient Problem Causes and Mitigation Techniques\\nUltimate Data Science & GenAI Bootcamp       Page  25\\nModule 15'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 25, 'page_label': '26'}, page_content='Deep Learning : Convolutional Neural\\nNetworks (CNN) Fundamentals and\\nApplications\\nTopics\\nObject Detection Using YOLO Introduction to YOLO (You Only Look\\nOnce), YOLO Architecture, Training and\\nDeployment\\nObject Detection Using Detectron2 Understanding Detectron2 for Object\\nDetection, Using Pre-trained Models and\\nFine-tuning\\nSegmentation Using YOLO Semantic and Instance Segmentation\\nwith YOLO, Implementing YOLO for\\nSegmentation Tasks\\nSegmentation Using Detectron2 Using Detectron2 for Semantic and\\nInstance Segmentation, Implementing\\nPre-trained Models for Image\\nSegmentation\\nUltimate Data Science & GenAI Bootcamp       Page  26\\nModule 15'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 26, 'page_label': '27'}, page_content=\"This module covers Recurrent Neural Networks (RNNs) and Transformer models, focusing on their\\napplications in sequential data processing. Youâ€™ll learn how RNNs and LSTMs are used for time\\nseries analysis, speech recognition, and language modeling. The module also explores the\\nTransformer architecture, which powers models like BERT and GPT. By the end, you'll have a\\nstrong grasp of these advanced neural network architectures and their applications in NLP and\\nbeyond.\\nDeep Learning : Recurrent Neural\\nNetworks (RNN) and Transformer\\nModels\\nTopics\\nIntroduction to RNNs Recurrent Neural Networks (RNN)\\nFundamentals, How RNNs Work,\\nApplications of RNN\\nLong Short Term Memory (LSTM) LSTM Cells, How LSTM Solves Vanishing\\nGradient Problem, LSTM for Sequence\\nModeling, Training and Tuning LSTM\\nGated Recurrent Units (GRU) GRU vs LSTM, Understanding GRU\\nArchitecture, Advantages of GRU in\\nSequence Modeling\\nEncoders and Decoders Encoder-Decoder Architecture,\\nApplications in Machine Translation,\\nSequence-to-Sequence Models\\nAttention Mechanism What is Attention, Types of Attention\\nMechanisms, Soft and Hard Attention\\nUltimate Data Science & GenAI Bootcamp       Page  27\\nModule 16\"),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 27, 'page_label': '28'}, page_content='Deep Learning : Recurrent Neural\\nNetworks (RNN) and Transformer\\nModels\\nTopics\\nAttention Neural Networks Self-Attention in Neural Networks,\\nApplying Attention to RNNs, Transformer\\nvs RNN\\nBERT Model BERT (Bidirectional Encoder\\nRepresentations from Transformers),\\nPre-training and Fine-tuning BERT,\\nApplications of BERT in NLP\\nGPT-2 Model GPT-2 (Generative Pre-trained\\nTransformer 2), Autoregressive\\nLanguage Modeling, Fine-tuning GPT-2\\nfor Text Generation\\nUltimate Data Science & GenAI Bootcamp       Page  28\\nModule 16'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 28, 'page_label': '29'}, page_content='In this module, youâ€™ll explore the world of Generative AI, understanding how these models\\ngenerate new data based on patterns learned from existing data. Youâ€™ll compare generative and\\ndiscriminative models and discover their applications in text, image, and audio generation. The\\nmodule also covers advancements in generative models, including GANs and VAEs. By the end,\\nyouâ€™ll be familiar with key concepts and applications of Generative AI.\\nIntroduction to Generative AI\\nTopics\\nOverview of Generative AI What is Generative AI?, Overview of\\nGenerative vs. Discriminative Models,\\nSignificance and Applications of\\nGenerative AI\\nUnderstanding Generative Models How Generative Models Work, Key\\nTypes of Generative Models (e.g., GANs,\\nVAEs), Advantages of Generative Models\\nGenerative AI vs. Discriminative\\nModels\\nKey Differences, Use Cases,\\nPerformance Comparison\\nRecent Advancements and Research Latest Breakthroughs in Generative AI,\\nState-of-the-Art Models and\\nTechniques, Future Trends in Generative\\nAI\\nKey Applications of Generative\\nModels\\nApplications in Art and Creativity (e.g.,\\nImage Synthesis), Healthcare (e.g., Drug\\nDiscovery), Natural Language\\nProcessing, and More\\nUltimate Data Science & GenAI Bootcamp       Page  29\\nModule 17'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 29, 'page_label': '30'}, page_content='This module introduces you to the concept of vector databases, which are designed to store and\\nretrieve high-dimensional data vectors. Youâ€™ll learn how vector databases differ from traditional\\nSQL and NoSQL databases, and explore their use cases, including similarity searches and machine\\nlearning applications. The module also covers popular vector databases like Faiss, Pinecone, and\\nChromaDB. By the end, youâ€™ll be equipped to work with vector databases for handling complex\\ndata queries.\\nIntroduction to Vector Databases\\nTopics\\nOverview of Vector Databases What are Vector Databases?, Key\\nConcepts and Use Cases of Vector\\nDatabases, Difference Between Vector\\nDatabases and Traditional Databases\\nComparison with SQL and NoSQL\\nDatabases\\nSQL vs. NoSQL vs. Vector Databases:\\nKey Differences, Use Cases, and\\nPerformance Considerations\\nCapabilities of Vector Databases Handling High-Dimensional Data, Fast\\nSimilarity Search, Efficient Storage and\\nQuerying, Real-Time Processing\\nData Storage and Architecture of\\nVector Databases\\nStructure of Vector Data, Indexing\\nTechniques, Optimizations for Vector\\nSearch, Performance Considerations\\nTypes of Vector Databases In-Memory Vector Databases: Benefits\\nand Limitations, Local Disk-based Vector\\nDatabases, Cloud-Based Vector\\nDatabases and Their Use Cases\\nUltimate Data Science & GenAI Bootcamp       Page  30\\nModule 18'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 30, 'page_label': '31'}, page_content='Introduction to Vector Databases\\nTopics\\nExploring Popular Vector Databases Chroma DB, Faiss, Quadrant, Pinecone,\\nLanceDB: Overview, Features, and Use\\nCases\\nVector Search with NoSQL Databases Integrating Vector Search with\\nMongoDB and Cassandra, Best\\nPractices for Implementing Vector\\nSearch in NoSQL Databases\\nUltimate Data Science & GenAI Bootcamp       Page  31\\nModule 18'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 31, 'page_label': '32'}, page_content='This module introduces the concept of Retrieval-Augmented Generation (RAG), which combines\\nretrieval-based search with generative models for enhanced language generation tasks. Youâ€™ll\\nlearn about the end-to-end RAG pipeline, including how to implement it with tools like LangChain,\\nvector databases, and LLMs. The module also covers hybrid search, reranking, and multimodal\\nretrieval techniques. By the end, youâ€™ll understand how to implement advanced RAG systems for\\nvarious use cases.\\nIntroduction to Retrieval-Augmented\\nGeneration (RAG)\\nTopics\\nOverview of Retrieval-Augmented\\nGeneration (RAG)\\nWhat is RAG?, Key Components of a\\nRAG System, Why RAG is Important for\\nAdvanced AI Systems\\nUnderstanding the End-to-End RAG\\nPipeline\\nOverview of the RAG Workflow, Data\\nRetrieval, Contextualization, and\\nGeneration Phases, Challenges and\\nOpportunities in RAG\\nIntegrating LangChain in RAG Introduction to LangChain Framework,\\nBuilding End-to-End RAG Pipelines with\\nLangChain\\nLeveraging Vector Databases in RAG Using Vector Databases for Efficient\\nRetrieval in RAG, Popular Vector\\nDatabases for RAG (e.g., Pinecone,\\nFAISS, Chroma DB)\\nRole of LLMs in RAG How LLMs (Large Language Models)\\nEnhance Generation in RAG, Fine-\\nTuning LLMs for Retrieval-Augmented\\nTasks\\nUltimate Data Science & GenAI Bootcamp       Page  32\\nModule 19'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 32, 'page_label': '33'}, page_content='Introduction to Retrieval-Augmented\\nGeneration (RAG)\\nTopics\\nRAG with Hybrid Search and\\nReranking\\nCombining Multiple Retrieval Methods,\\nReranking Results for Improved\\nRelevance, Hybrid Search\\nImplementation Techniques\\nRAG with Various Retrieval Methods Exact vs Approximate Retrieval Methods,\\nFiltering and Ranking Retrieved Data,\\nCustomizing Retrieval Approaches for\\nSpecific Applications\\nIntegrating Memory in RAG Systems How Memory Can Improve RAG,\\nPersisting and Recalling Information for\\nConsistent Results, Implementing Long-\\nTerm Memory in RAG\\nMultimodal Retrieval-Augmented\\nGeneration\\nCombining Text, Images, and Other\\nModalities in RAG, Techniques for\\nMultimodal Retrieval and Generation,\\nPractical Applications of Multimodal\\nRAG Systems\\nUltimate Data Science & GenAI Bootcamp       Page  33\\nModule 19'),\n",
       " Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 33, 'page_label': '34'}, page_content='In this course, youâ€™ll gain hands-on experience in implementing end-to-end AI projects. Youâ€™ll learn\\nhow to manage the entire project lifecycle, from data collection and preprocessing to model\\ndevelopment, evaluation, and deployment. The module includes working on real-world AI projects,\\nwith a focus on best practices for integration, testing, and scalability. By the end, youâ€™ll be\\nprepared to take on AI projects from start to finish, applying machine learning and deep learning\\ntechniques to solve real-world problems.\\nEnd-to-End AI Project Implementation\\nTopics\\nPython Project: Building End-to-End\\nApplications\\nOverview of Python Projects, Project\\nDesign and Architecture, Key\\nConsiderations in Python Projects\\n(Performance, Scalability, etc.), Best\\nPractices for Code Quality\\nEnd-to-End Machine Learning\\nProjects\\nUnderstanding End-to-End ML Projects,\\nKey Components of an End-to-End ML\\nProject, Project Example: Real-World ML\\nApplication\\nDeep Learning Projects Deep Learning Fundamentals in Projects,\\nEnd-to-End Deep Learning Projects \\nGenerative AI End-to-End Projects Introduction to Generative AI Projects,\\nSteps in Building Generative AI Projects\\nUltimate Data Science & GenAI Bootcamp       Page  34\\nPROJECT')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Read a PDf file\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader('data\\syllabus.pdf')\n",
    "docs=loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84955a06",
   "metadata": {},
   "source": [
    "### Web base loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "227d4d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://python.langchain.com/docs/introduction/', 'title': 'Introduction | ðŸ¦œï¸ðŸ”— LangChain', 'description': 'LangChain is a framework for developing applications powered by large language models (LLMs).', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nIntroduction | ðŸ¦œï¸ðŸ”— LangChain\\n\\n\\n\\n\\n\\n\\nSkip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1ðŸ’¬SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain\\'s stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?EcosystemðŸ¦œðŸ› ï¸ LangSmithðŸ¦œðŸ•¸ï¸ LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyIntroductionOn this pageIntroduction\\nLangChain is a framework for developing applications powered by large language models (LLMs).\\nLangChain simplifies every stage of the LLM application lifecycle:\\n\\nDevelopment: Build your applications using LangChain\\'s open-source components and third-party integrations.\\nUse LangGraph to build stateful agents with first-class streaming and human-in-the-loop support.\\nProductionization: Use LangSmith to inspect, monitor and evaluate your applications, so that you can continuously optimize and deploy with confidence.\\nDeployment: Turn your LangGraph applications into production-ready APIs and Assistants with LangGraph Platform.\\n\\n\\n\\nLangChain implements a standard interface for large language models and related\\ntechnologies, such as embedding models and vector stores, and integrates with\\nhundreds of providers. See the integrations page for\\nmore.\\n\\nSelect chat model:Google Geminiâ–¾OpenAIAnthropicAzureGoogle GeminiGoogle VertexAWSGroqCohereNVIDIAFireworks AIMistral AITogether AIIBM watsonxDatabricksxAIPerplexitypip install -qU \"langchain[google-genai]\"import getpassimport osif not os.environ.get(\"GOOGLE_API_KEY\"):  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")from langchain.chat_models import init_chat_modelmodel = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\\nmodel.invoke(\"Hello, world!\")\\nnoteThese docs focus on the Python LangChain library. Head here for docs on the JavaScript LangChain library.\\nArchitecture\\u200b\\nThe LangChain framework consists of multiple open-source libraries. Read more in the\\nArchitecture page.\\n\\nlangchain-core: Base abstractions for chat models and other components.\\nIntegration packages (e.g. langchain-openai, langchain-anthropic, etc.): Important integrations have been split into lightweight packages that are co-maintained by the LangChain team and the integration developers.\\nlangchain: Chains, agents, and retrieval strategies that make up an application\\'s cognitive architecture.\\nlangchain-community: Third-party integrations that are community maintained.\\nlanggraph: Orchestration framework for combining LangChain components into production-ready applications with persistence, streaming, and other key features. See LangGraph documentation.\\n\\nGuides\\u200b\\nTutorials\\u200b\\nIf you\\'re looking to build something specific or are more of a hands-on learner, check out our tutorials section.\\nThis is the best place to get started.\\nThese are the best ones to get started with:\\n\\nBuild a Simple LLM Application\\nBuild a Chatbot\\nBuild an Agent\\nIntroduction to LangGraph\\n\\nExplore the full list of LangChain tutorials here, and check out other LangGraph tutorials here. To learn more about LangGraph, check out our first LangChain Academy course, Introduction to LangGraph, available here.\\nHow-to guides\\u200b\\nHere youâ€™ll find short answers to â€œHow do Iâ€¦.?â€ types of questions.\\nThese how-to guides donâ€™t cover topics in depth â€“ youâ€™ll find that material in the Tutorials and the API Reference.\\nHowever, these guides will help you quickly accomplish common tasks using chat models,\\nvector stores, and other common LangChain components.\\nCheck out LangGraph-specific how-tos here.\\nConceptual guide\\u200b\\nIntroductions to all the key parts of LangChain youâ€™ll need to know! Here you\\'ll find high level explanations of all LangChain concepts.\\nFor a deeper dive into LangGraph concepts, check out this page.\\nIntegrations\\u200b\\nLangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it.\\nIf you\\'re looking to get up and running quickly with chat models, vector stores,\\nor other LangChain components from a specific provider, check out our growing list of integrations.\\nAPI reference\\u200b\\nHead to the reference section for full documentation of all classes and methods in the LangChain Python packages.\\nEcosystem\\u200b\\nðŸ¦œðŸ› ï¸ LangSmith\\u200b\\nTrace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\nðŸ¦œðŸ•¸ï¸ LangGraph\\u200b\\nBuild stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangGraph powers production-grade agents, trusted by Linkedin, Uber, Klarna, GitLab, and many more.\\nAdditional resources\\u200b\\nVersions\\u200b\\nSee what changed in v0.3, learn how to migrate legacy code, read up on our versioning policies, and more.\\nSecurity\\u200b\\nRead up on security best practices to make sure you\\'re developing safely with LangChain.\\nContributing\\u200b\\nCheck out the developer\\'s guide for guidelines on contributing and help getting your dev environment set up.Edit this pageWas this page helpful?NextTutorialsArchitectureGuidesTutorialsHow-to guidesConceptual guideIntegrationsAPI referenceEcosystemðŸ¦œðŸ› ï¸ LangSmithðŸ¦œðŸ•¸ï¸ LangGraphAdditional resourcesVersionsSecurityContributingCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright Â© 2025 LangChain, Inc.\\n\\n')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Web based loader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "loader=WebBaseLoader(web_paths=(\"https://python.langchain.com/docs/introduction/\",),)\n",
    "docs=loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4594bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Introduction | ðŸ¦œï¸ðŸ”— LangChain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1ðŸ’¬SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain's stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?EcosystemðŸ¦œðŸ› ï¸ LangSmithðŸ¦œðŸ•¸ï¸ LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyIntroductionOn this pageIntroduction\n",
      "LangChain is a framework for developing applications powered by large language models (LLMs).\n",
      "LangChain simplifies every stage of the LLM application lifecycle:\n",
      "\n",
      "Development: Build your applications using LangChain's open-source components and third-party integrations.\n",
      "Use LangGraph to build stateful agents with first-class streaming and human-in-the-loop support.\n",
      "Productionization: Use LangSmith to inspect, monitor and evaluate your applications, so that you can continuously optimize and deploy with confidence.\n",
      "Deployment: Turn your LangGraph applications into production-ready APIs and Assistants with LangGraph Platform.\n",
      "\n",
      "\n",
      "\n",
      "LangChain implements a standard interface for large language models and related\n",
      "technologies, such as embedding models and vector stores, and integrates with\n",
      "hundreds of providers. See the integrations page for\n",
      "more.\n",
      "\n",
      "Select chat model:Google Geminiâ–¾OpenAIAnthropicAzureGoogle GeminiGoogle VertexAWSGroqCohereNVIDIAFireworks AIMistral AITogether AIIBM watsonxDatabricksxAIPerplexitypip install -qU \"langchain[google-genai]\"import getpassimport osif not os.environ.get(\"GOOGLE_API_KEY\"):  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")from langchain.chat_models import init_chat_modelmodel = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
      "model.invoke(\"Hello, world!\")\n",
      "noteThese docs focus on the Python LangChain library. Head here for docs on the JavaScript LangChain library.\n",
      "Architectureâ€‹\n",
      "The LangChain framework consists of multiple open-source libraries. Read more in the\n",
      "Architecture page.\n",
      "\n",
      "langchain-core: Base abstractions for chat models and other components.\n",
      "Integration packages (e.g. langchain-openai, langchain-anthropic, etc.): Important integrations have been split into lightweight packages that are co-maintained by the LangChain team and the integration developers.\n",
      "langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture.\n",
      "langchain-community: Third-party integrations that are community maintained.\n",
      "langgraph: Orchestration framework for combining LangChain components into production-ready applications with persistence, streaming, and other key features. See LangGraph documentation.\n",
      "\n",
      "Guidesâ€‹\n",
      "Tutorialsâ€‹\n",
      "If you're looking to build something specific or are more of a hands-on learner, check out our tutorials section.\n",
      "This is the best place to get started.\n",
      "These are the best ones to get started with:\n",
      "\n",
      "Build a Simple LLM Application\n",
      "Build a Chatbot\n",
      "Build an Agent\n",
      "Introduction to LangGraph\n",
      "\n",
      "Explore the full list of LangChain tutorials here, and check out other LangGraph tutorials here. To learn more about LangGraph, check out our first LangChain Academy course, Introduction to LangGraph, available here.\n",
      "How-to guidesâ€‹\n",
      "Here youâ€™ll find short answers to â€œHow do Iâ€¦.?â€ types of questions.\n",
      "These how-to guides donâ€™t cover topics in depth â€“ youâ€™ll find that material in the Tutorials and the API Reference.\n",
      "However, these guides will help you quickly accomplish common tasks using chat models,\n",
      "vector stores, and other common LangChain components.\n",
      "Check out LangGraph-specific how-tos here.\n",
      "Conceptual guideâ€‹\n",
      "Introductions to all the key parts of LangChain youâ€™ll need to know! Here you'll find high level explanations of all LangChain concepts.\n",
      "For a deeper dive into LangGraph concepts, check out this page.\n",
      "Integrationsâ€‹\n",
      "LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it.\n",
      "If you're looking to get up and running quickly with chat models, vector stores,\n",
      "or other LangChain components from a specific provider, check out our growing list of integrations.\n",
      "API referenceâ€‹\n",
      "Head to the reference section for full documentation of all classes and methods in the LangChain Python packages.\n",
      "Ecosystemâ€‹\n",
      "ðŸ¦œðŸ› ï¸ LangSmithâ€‹\n",
      "Trace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\n",
      "ðŸ¦œðŸ•¸ï¸ LangGraphâ€‹\n",
      "Build stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangGraph powers production-grade agents, trusted by Linkedin, Uber, Klarna, GitLab, and many more.\n",
      "Additional resourcesâ€‹\n",
      "Versionsâ€‹\n",
      "See what changed in v0.3, learn how to migrate legacy code, read up on our versioning policies, and more.\n",
      "Securityâ€‹\n",
      "Read up on security best practices to make sure you're developing safely with LangChain.\n",
      "Contributingâ€‹\n",
      "Check out the developer's guide for guidelines on contributing and help getting your dev environment set up.Edit this pageWas this page helpful?NextTutorialsArchitectureGuidesTutorialsHow-to guidesConceptual guideIntegrationsAPI referenceEcosystemðŸ¦œðŸ› ï¸ LangSmithðŸ¦œðŸ•¸ï¸ LangGraphAdditional resourcesVersionsSecurityContributingCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright Â© 2025 LangChain, Inc.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41c0e12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to â€œthink step by stepâ€ to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the modelâ€™s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into â€œProblem PDDLâ€, then (2) requests a classical planner to generate a PDDL plan based on an existing â€œDomain PDDLâ€, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\n\\nExamples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\n\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: â€¦ step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\n\\nIllustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\n\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agentâ€™s working memory, up to three, to be used as context for querying LLM.\\n\\n\\nExperiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)\\n\\nChain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\\\{(x, y_i , r_i , z_i)\\\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\\\geq r_{n-1} \\\\geq \\\\dots \\\\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\\\tau_h = (x, z_i, y_i, z_j, y_j, \\\\dots, z_n, y_n)$, where $\\\\leq i \\\\leq j \\\\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.\\nTo avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training.\\nThe training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.\\n\\n\\nAfter fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\\n\\nThe idea of CoH is to present a history of sequentially improved outputs  in context and train the model to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al. 2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy. Considering that an agent interacts with the environment many times and in each episode the agent gets a little better, AD concatenates this learning history and feeds that into the model. Hence we should expect the next predicted action to lead to better performance than previous trials. The goal is to learn the process of RL instead of training a task-specific policy itself.\\n\\n\\nIllustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\n\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\\n\\n\\nComparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\n\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. Iâ€™ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\n\\nCategorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search (MIPS)#\\nThe external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)\\u200b algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the number of inputs.\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half and each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps; e.g. â€œsix degrees of separationâ€ feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it canâ€™t get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization.\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector quantization. It quantizes a data point $x_i$ to $\\\\tilde{x}_i$ such that the inner product $\\\\langle q, x_i \\\\rangle$ is as similar to the original distance of $\\\\angle q, \\\\tilde{x}_i$ as possible, instead of picking the closet quantization centroid points.\\n\\n\\n\\nComparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\n\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\nComponent Three: Tool Use#\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.\\n\\n\\nA picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\n\\nMRKL (Karpas et al. 2022), short for â€œModular Reasoning, Knowledge and Languageâ€, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of â€œexpertâ€ modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the â€œExternal APIsâ€ section of Prompt Engineering.\\nChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\\n\\n\\nIllustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\n\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\n(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\\nAPI-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\n\\nPseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\n\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agentâ€™s tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an APIâ€™s description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the userâ€™s requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nCase Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\\n\\nOne interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\nFor example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:\\n\\ninquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.\\n\\nThey also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agentsâ€™ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agentâ€™s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agentâ€™s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\n\\nThe generative agent architecture. (Image source: Park et al. 2023)\\n\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes\\n\\nCommands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\\n\\nYou should only respond in JSON format as described below\\nResponse Format:\\n{\\n    \"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": \"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n}\\nEnsure the response can be parsed by Python json.loads\\nGPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:\\n\\nYou will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the codeâ€™s language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the â€œentrypointâ€ file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\nPython toolbelt preferences:\\n\\npytest\\ndataclasses\\n\\n\\nConversatin samples:\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"\\n  },\\n #  â€¦ same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Assumptions:\\\\n1. Model: The model will contain the game\\'s data, such as level information, character states, and enemy positions.\\\\n2. View: The view will handle the game\\'s visuals, including rendering the game objects, backgrounds, and updating the display.\\\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model accordingly.\\\\n\\\\nWith these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\"\\n  }\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\\n\\n\\nFinite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). â€œLLM-powered Autonomous Agentsâ€. Lilâ€™Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\\n\\nOr\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. â€œChain of thought prompting elicits reasoning in large language models.â€ NeurIPS 2022\\n[2] Yao et al. â€œTree of Thoughts: Dliberate Problem Solving with Large Language Models.â€ arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. â€œChain of Hindsight Aligns Language Models with Feedback\\nâ€œ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. â€œLLM+P: Empowering Large Language Models with Optimal Planning Proficiencyâ€ arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. â€œReAct: Synergizing reasoning and acting in language models.â€ ICLR 2023.\\n[6] Google Blog. â€œAnnouncing ScaNN: Efficient Vector Similarity Searchâ€ July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn & Labash. â€œReflexion: an autonomous agent with dynamic memory and self-reflectionâ€ arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. â€œIn-context Reinforcement Learning with Algorithm Distillationâ€ ICLR 2023.\\n[10] Karpas et al. â€œMRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.â€ arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. â€œWebgpt: Browser-assisted question-answering with human feedback.â€ arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. â€œTALM: Tool Augmented Language Modelsâ€\\n[13] Schick et al. â€œToolformer: Language Models Can Teach Themselves to Use Tools.â€ arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li et al. â€œAPI-Bank: A Benchmark for Tool-Augmented LLMsâ€ arXiv preprint arXiv:2304.08244 (2023).\\n[16] Shen et al. â€œHuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFaceâ€ arXiv preprint arXiv:2303.17580 (2023).\\n[17] Bran et al. â€œChemCrow: Augmenting large-language models with chemistry tools.â€ arXiv preprint arXiv:2304.05376 (2023).\\n[18] Boiko et al. â€œEmergent autonomous scientific research capabilities of large language models.â€ arXiv preprint arXiv:2304.05332 (2023).\\n[19] Joon Sung Park, et al. â€œGenerative Agents: Interactive Simulacra of Human Behavior.â€ arXiv preprint arXiv:2304.03442 (2023).\\n[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\\n[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer\\n')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Web based loader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "loader=WebBaseLoader(web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "                     bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "                         class_=(\"post-title\",\"post-content\",\"post-header\")\n",
    "                     ))\n",
    "                     )\n",
    "\n",
    "doc=loader.load()\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c05efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='\\n      LLM Powered Autonomous Agents\\n    ')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Web based loader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "loader=WebBaseLoader(web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "                     bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "                         class_=(\"post-title\")\n",
    "                     ))\n",
    "                     )\n",
    "\n",
    "doc=loader.load()\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d488410e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(doc[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bff393e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
      "Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\n",
      "\n",
      "\n",
      "Tool use\n",
      "\n",
      "The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview of a LLM-powered autonomous agent system.\n",
      "\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to â€œthink step by stepâ€ to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the modelâ€™s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into â€œProblem PDDLâ€, then (2) requests a classical planner to generate a PDDL plan based on an existing â€œDomain PDDLâ€, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "Self-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\n",
      "ReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\n",
      "The ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\n",
      "Thought: ...\n",
      "Action: ...\n",
      "Observation: ...\n",
      "... (Repeated many times)\n",
      "\n",
      "\n",
      "Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\n",
      "\n",
      "In both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: â€¦ step is removed.\n",
      "Reflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\n",
      "\n",
      "\n",
      "Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\n",
      "\n",
      "The heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\n",
      "Self-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agentâ€™s working memory, up to three, to be used as context for querying LLM.\n",
      "\n",
      "\n",
      "Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)\n",
      "\n",
      "Chain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\{(x, y_i , r_i , z_i)\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\geq r_{n-1} \\geq \\dots \\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\tau_h = (x, z_i, y_i, z_j, y_j, \\dots, z_n, y_n)$, where $\\leq i \\leq j \\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.\n",
      "To avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training.\n",
      "The training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.\n",
      "\n",
      "\n",
      "After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\n",
      "\n",
      "The idea of CoH is to present a history of sequentially improved outputs  in context and train the model to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al. 2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy. Considering that an agent interacts with the environment many times and in each episode the agent gets a little better, AD concatenates this learning history and feeds that into the model. Hence we should expect the next predicted action to lead to better performance than previous trials. The goal is to learn the process of RL instead of training a task-specific policy itself.\n",
      "\n",
      "\n",
      "Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\n",
      "\n",
      "The paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\n",
      "In reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\n",
      "In comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\n",
      "\n",
      "\n",
      "Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\n",
      "\n",
      "Component Two: Memory#\n",
      "(Big thank you to ChatGPT for helping me draft this section. Iâ€™ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\n",
      "Types of Memory#\n",
      "Memory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\n",
      "\n",
      "\n",
      "Sensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\n",
      "\n",
      "\n",
      "Short-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\n",
      "\n",
      "\n",
      "Long-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\n",
      "\n",
      "Explicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\n",
      "Implicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Categorization of human memory.\n",
      "\n",
      "We can roughly consider the following mappings:\n",
      "\n",
      "Sensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\n",
      "Short-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\n",
      "Long-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.\n",
      "\n",
      "Maximum Inner Product Search (MIPS)#\n",
      "The external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)â€‹ algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\n",
      "A couple common choices of ANN algorithms for fast MIPS:\n",
      "\n",
      "LSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the number of inputs.\n",
      "ANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half and each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.\n",
      "HNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps; e.g. â€œsix degrees of separationâ€ feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it canâ€™t get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.\n",
      "FAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization.\n",
      "ScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector quantization. It quantizes a data point $x_i$ to $\\tilde{x}_i$ such that the inner product $\\langle q, x_i \\rangle$ is as similar to the original distance of $\\angle q, \\tilde{x}_i$ as possible, instead of picking the closet quantization centroid points.\n",
      "\n",
      "\n",
      "\n",
      "Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\n",
      "\n",
      "Check more MIPS algorithms and performance comparison in ann-benchmarks.com.\n",
      "Component Three: Tool Use#\n",
      "Tool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.\n",
      "\n",
      "\n",
      "A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\n",
      "\n",
      "MRKL (Karpas et al. 2022), short for â€œModular Reasoning, Knowledge and Languageâ€, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of â€œexpertâ€ modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\n",
      "They did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\n",
      "Both TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the â€œExternal APIsâ€ section of Prompt Engineering.\n",
      "ChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\n",
      "HuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\n",
      "\n",
      "\n",
      "Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\n",
      "\n",
      "The system comprises of 4 stages:\n",
      "(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\n",
      "Instruction:\n",
      "\n",
      "The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can't be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\n",
      "\n",
      "(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\n",
      "Instruction:\n",
      "\n",
      "Given the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\n",
      "\n",
      "(3) Task execution: Expert models execute on the specific tasks and log results.\n",
      "Instruction:\n",
      "\n",
      "With the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\n",
      "\n",
      "(4) Response generation: LLM receives the execution results and provides summarized results to users.\n",
      "To put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\n",
      "API-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\n",
      "\n",
      "\n",
      "Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\n",
      "\n",
      "In the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\n",
      "\n",
      "Whether an API call is needed.\n",
      "Identify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\n",
      "Response based on the API results: the model can choose to refine and call again if results are not satisfied.\n",
      "\n",
      "This benchmark evaluates the agentâ€™s tool use capabilities at three levels:\n",
      "\n",
      "Level-1 evaluates the ability to call the API. Given an APIâ€™s description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\n",
      "Level-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the userâ€™s requirement and learn how to use them by reading documentation.\n",
      "Level-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\n",
      "\n",
      "Case Studies#\n",
      "Scientific Discovery Agent#\n",
      "ChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\n",
      "\n",
      "The LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\n",
      "It is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\n",
      "\n",
      "One interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\n",
      "Boiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\n",
      "For example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:\n",
      "\n",
      "inquired about current trends in anticancer drug discovery;\n",
      "selected a target;\n",
      "requested a scaffold targeting these compounds;\n",
      "Once the compound was identified, the model attempted its synthesis.\n",
      "\n",
      "They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\n",
      "Generative Agents Simulation#\n",
      "Generative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\n",
      "The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\n",
      "\n",
      "Memory stream: is a long-term memory module (external database) that records a comprehensive list of agentsâ€™ experience in natural language.\n",
      "\n",
      "Each element is an observation, an event directly provided by the agent.\n",
      "- Inter-agent communication can trigger new natural language statements.\n",
      "\n",
      "\n",
      "Retrieval model: surfaces the context to inform the agentâ€™s behavior, according to relevance, recency and importance.\n",
      "\n",
      "Recency: recent events have higher scores\n",
      "Importance: distinguish mundane from core memories. Ask LM directly.\n",
      "Relevance: based on how related it is to the current situation / query.\n",
      "\n",
      "\n",
      "Reflection mechanism: synthesizes memories into higher level inferences over time and guides the agentâ€™s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\n",
      "\n",
      "Prompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\n",
      "\n",
      "\n",
      "Planning & Reacting: translate the reflections and the environment information into actions\n",
      "\n",
      "Planning is essentially in order to optimize believability at the moment vs in time.\n",
      "Prompt template: {Intro of an agent X}. Here is X's plan today in broad strokes: 1)\n",
      "Relationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\n",
      "Environment information is present in a tree structure.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The generative agent architecture. (Image source: Park et al. 2023)\n",
      "\n",
      "This fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\n",
      "Proof-of-Concept Examples#\n",
      "AutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\n",
      "Here is the system message used by AutoGPT, where {{...}} are user inputs:\n",
      "You are {{ai-name}}, {{user-provided AI bot description}}.\n",
      "Your decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
      "\n",
      "GOALS:\n",
      "\n",
      "1. {{user-provided goal 1}}\n",
      "2. {{user-provided goal 2}}\n",
      "3. ...\n",
      "4. ...\n",
      "5. ...\n",
      "\n",
      "Constraints:\n",
      "1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
      "2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
      "3. No user assistance\n",
      "4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
      "5. Use subprocesses for commands that will not terminate within a few minutes\n",
      "\n",
      "Commands:\n",
      "1. Google Search: \"google\", args: \"input\": \"<search>\"\n",
      "2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\n",
      "3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\n",
      "4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\n",
      "5. List GPT Agents: \"list_agents\", args:\n",
      "6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\n",
      "7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\n",
      "8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\n",
      "9. Read file: \"read_file\", args: \"file\": \"<file>\"\n",
      "10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\n",
      "11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\n",
      "12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\n",
      "13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\n",
      "14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\n",
      "15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\n",
      "16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\n",
      "17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\n",
      "18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\n",
      "19. Do Nothing: \"do_nothing\", args:\n",
      "20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\n",
      "\n",
      "Resources:\n",
      "1. Internet access for searches and information gathering.\n",
      "2. Long Term memory management.\n",
      "3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
      "4. File output.\n",
      "\n",
      "Performance Evaluation:\n",
      "1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n",
      "2. Constructively self-criticize your big-picture behavior constantly.\n",
      "3. Reflect on past decisions and strategies to refine your approach.\n",
      "4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n",
      "\n",
      "You should only respond in JSON format as described below\n",
      "Response Format:\n",
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"thought\",\n",
      "        \"reasoning\": \"reasoning\",\n",
      "        \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n",
      "        \"criticism\": \"constructive self-criticism\",\n",
      "        \"speak\": \"thoughts summary to say to user\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"command name\",\n",
      "        \"args\": {\n",
      "            \"arg name\": \"value\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Ensure the response can be parsed by Python json.loads\n",
      "GPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\n",
      "Here are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\n",
      "[\n",
      "  {\n",
      "    \"role\": \"system\",\n",
      "    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\nThen you will pick one clarifying question, and wait for an answer from the user.\\n\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\n\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Summary of areas that need clarification:\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\n2. Details about the MVC components (e.g. which components are in each file)\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\n\\nClarifying question:\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\n\\nIs anything else unclear? If yes, only answer in the form:\\n{remaining unclear areas} remaining questions.\\n{Next question}\\nIf everything is sufficiently clear, only answer \\\"Nothing more to clarify.\\\".\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Remaining unclear areas: 2 remaining questions.\\nCan you provide more information about how the MVC components are split into separate files?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\n",
      "  }\n",
      "]\n",
      "Then after these clarification, the agent moved into the code writing mode with a different system message.\n",
      "System message:\n",
      "\n",
      "You will get instructions for code to write.\n",
      "You will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\n",
      "Make sure that every detail of the architecture is, in the end, implemented as code.\n",
      "Think step by step and reason yourself to the right decisions to make sure we get it right.\n",
      "You will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\n",
      "Then you will output the content of each file including ALL code.\n",
      "Each file must strictly follow a markdown code block format, where the following tokens must be replaced such that\n",
      "FILENAME is the lowercase file name including the file extension,\n",
      "LANG is the markup code block language for the codeâ€™s language, and CODE is the code:\n",
      "FILENAME\n",
      "CODE\n",
      "You will start with the â€œentrypointâ€ file, then go to the ones that are imported by that file, and so on.\n",
      "Please note that the code should be fully functional. No placeholders.\n",
      "Follow a language and framework appropriate best practice file naming convention.\n",
      "Make sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\n",
      "Ensure to implement all code, if you are unsure, write a plausible implementation.\n",
      "Include module dependency or package manager dependency definition file.\n",
      "Before you finish, double check that all parts of the architecture is present in the files.\n",
      "Useful to know:\n",
      "You almost always put different classes in different files.\n",
      "For Python, you always create an appropriate requirements.txt file.\n",
      "For NodeJS, you always create an appropriate package.json file.\n",
      "You always add a comment briefly describing the purpose of the function definition.\n",
      "You try to add comments explaining very complex bits of logic.\n",
      "You always follow the best practices for the requested languages in terms of describing the code written as a defined\n",
      "package/project.\n",
      "Python toolbelt preferences:\n",
      "\n",
      "pytest\n",
      "dataclasses\n",
      "\n",
      "\n",
      "Conversatin samples:\n",
      "[\n",
      "  {\n",
      "    \"role\": \"system\",\n",
      "    \"content\": \"You will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\n\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\n\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code's language, and CODE is the code:\\n\\nFILENAME\\n```LANG\\nCODE\\n```\\n\\nYou will start with the \\\"entrypoint\\\" file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\n\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\n\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\n\\n\\nPython toolbelt preferences:\\n- pytest\\n- dataclasses\\n\"\n",
      "  },\n",
      " #  â€¦ same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Assumptions:\\n1. Model: The model will contain the game's data, such as level information, character states, and enemy positions.\\n2. View: The view will handle the game's visuals, including rendering the game objects, backgrounds, and updating the display.\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model accordingly.\\n\\nWith these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"Please now remember the steps:\\n\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\n\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code's language, and CODE is the code:\\n\\nFILENAME\\n```LANG\\nCODE\\n```\\n\\nPlease note that the code should be fully functional. No placeholders.\\n\\nYou will start with the \\\"entrypoint\\\" file, then go to the ones that are imported by that file, and so on.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\n\"\n",
      "  }\n",
      "]\n",
      "Challenges#\n",
      "After going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\n",
      "\n",
      "\n",
      "Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\n",
      "\n",
      "\n",
      "Challenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\n",
      "\n",
      "\n",
      "Reliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\n",
      "\n",
      "\n",
      "Citation#\n",
      "Cited as:\n",
      "\n",
      "Weng, Lilian. (Jun 2023). â€œLLM-powered Autonomous Agentsâ€. Lilâ€™Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\n",
      "\n",
      "Or\n",
      "@article{weng2023agent,\n",
      "  title   = \"LLM-powered Autonomous Agents\",\n",
      "  author  = \"Weng, Lilian\",\n",
      "  journal = \"lilianweng.github.io\",\n",
      "  year    = \"2023\",\n",
      "  month   = \"Jun\",\n",
      "  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\n",
      "}\n",
      "References#\n",
      "[1] Wei et al. â€œChain of thought prompting elicits reasoning in large language models.â€ NeurIPS 2022\n",
      "[2] Yao et al. â€œTree of Thoughts: Dliberate Problem Solving with Large Language Models.â€ arXiv preprint arXiv:2305.10601 (2023).\n",
      "[3] Liu et al. â€œChain of Hindsight Aligns Language Models with Feedback\n",
      "â€œ arXiv preprint arXiv:2302.02676 (2023).\n",
      "[4] Liu et al. â€œLLM+P: Empowering Large Language Models with Optimal Planning Proficiencyâ€ arXiv preprint arXiv:2304.11477 (2023).\n",
      "[5] Yao et al. â€œReAct: Synergizing reasoning and acting in language models.â€ ICLR 2023.\n",
      "[6] Google Blog. â€œAnnouncing ScaNN: Efficient Vector Similarity Searchâ€ July 28, 2020.\n",
      "[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\n",
      "[8] Shinn & Labash. â€œReflexion: an autonomous agent with dynamic memory and self-reflectionâ€ arXiv preprint arXiv:2303.11366 (2023).\n",
      "[9] Laskin et al. â€œIn-context Reinforcement Learning with Algorithm Distillationâ€ ICLR 2023.\n",
      "[10] Karpas et al. â€œMRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.â€ arXiv preprint arXiv:2205.00445 (2022).\n",
      "[11] Nakano et al. â€œWebgpt: Browser-assisted question-answering with human feedback.â€ arXiv preprint arXiv:2112.09332 (2021).\n",
      "[12] Parisi et al. â€œTALM: Tool Augmented Language Modelsâ€\n",
      "[13] Schick et al. â€œToolformer: Language Models Can Teach Themselves to Use Tools.â€ arXiv preprint arXiv:2302.04761 (2023).\n",
      "[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\n",
      "[15] Li et al. â€œAPI-Bank: A Benchmark for Tool-Augmented LLMsâ€ arXiv preprint arXiv:2304.08244 (2023).\n",
      "[16] Shen et al. â€œHuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFaceâ€ arXiv preprint arXiv:2303.17580 (2023).\n",
      "[17] Bran et al. â€œChemCrow: Augmenting large-language models with chemistry tools.â€ arXiv preprint arXiv:2304.05376 (2023).\n",
      "[18] Boiko et al. â€œEmergent autonomous scientific research capabilities of large language models.â€ arXiv preprint arXiv:2304.05332 (2023).\n",
      "[19] Joon Sung Park, et al. â€œGenerative Agents: Interactive Simulacra of Human Behavior.â€ arXiv preprint arXiv:2304.03442 (2023).\n",
      "[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\n",
      "[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(doc[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d29194",
   "metadata": {},
   "source": [
    "### Arxiv Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f746a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Published': '2023-08-02', 'Title': 'Attention Is All You Need', 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'}, page_content='Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswaniâˆ—\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeerâˆ—\\nGoogle Brain\\nnoam@google.com\\nNiki Parmarâˆ—\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreitâˆ—\\nGoogle Research\\nusz@google.com\\nLlion Jonesâˆ—\\nGoogle Research\\nllion@google.com\\nAidan N. Gomezâˆ—â€ \\nUniversity of Toronto\\naidan@cs.toronto.edu\\nÅukasz Kaiserâˆ—\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhinâˆ—â€¡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.\\nâˆ—Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\nâ€ Work performed while at Google Brain.\\nâ€¡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\\narXiv:1706.03762v7  [cs.CL]  2 Aug 2023\\n1\\nIntroduction\\nRecurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks\\nin particular, have been firmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [35, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [38, 24, 15].\\nRecurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state htâˆ’1 and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\\ncomputation [32], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2\\nBackground\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difficult to learn dependencies between distant positions [12]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [34].\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3\\nModel Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35].\\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\\nsequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\\n[10], consuming the previously generated symbols as additional input when generating the next.\\n2\\nFigure 1: The Transformer - model architecture.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1\\nEncoder and Decoder Stacks\\nEncoder:\\nThe encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\\nwise fully connected feed-forward network. We employ a residual connection [11] around each of\\nthe two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.\\nDecoder:\\nThe decoder is also composed of a stack of N = 6 identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position i can depend only on the known outputs at positions less than i.\\n3.2\\nAttention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3\\nScaled Dot-Product Attention\\nMulti-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1\\nScaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\nquery with all keys, divide each by âˆšdk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V ) = softmax(QKT\\nâˆšdk\\n)V\\n(1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof\\n1\\nâˆšdk . Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efficient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by\\n1\\nâˆšdk .\\n3.2.2\\nMulti-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\\nwe found it beneficial to linearly project the queries, keys and values h times with different, learned\\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\\nvariables with mean 0 and variance 1. Then their dot product, q Â· k = Pdk\\ni=1 qiki, has mean 0 and variance dk.\\n4\\noutput values. These are concatenated and once again projected, resulting in the final values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\nMultiHead(Q, K, V ) = Concat(head1, ..., headh)W O\\nwhere headi = Attention(QW Q\\ni , KW K\\ni , V W V\\ni )\\nWhere the projections are parameter matrices W Q\\ni\\nâˆˆRdmodelÃ—dk, W K\\ni\\nâˆˆRdmodelÃ—dk, W V\\ni\\nâˆˆRdmodelÃ—dv\\nand W O âˆˆRhdvÃ—dmodel.\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2.3\\nApplications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\nâ€¢ In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\nâ€¢ The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\nâ€¢ Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation flow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to âˆ’âˆž) all values in the input\\nof the softmax which correspond to illegal connections. See Figure 2.\\n3.3\\nPosition-wise Feed-Forward Networks\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\\nconnected feed-forward network, which is applied to each position separately and identically. This\\nconsists of two linear transformations with a ReLU activation in between.\\nFFN(x) = max(0, xW1 + b1)W2 + b2\\n(2)\\nWhile the linear transformations are the same across different positions, they use different parameters\\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\\ndff = 2048.\\n3.4\\nEmbeddings and Softmax\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\\nlinear transformation, similar to [30]. In the embedding layers, we multiply those weights by âˆšdmodel.\\n5\\nTable 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\\nfor different layer types. n is the sequence length, d is the representation dimension, k is the kernel\\nsize of convolutions and r the size of the neighborhood in restricted self-attention.\\nLayer Type\\nComplexity per Layer\\nSequential\\nMaximum Path Length\\nOperations\\nSelf-Attention\\nO(n2 Â· d)\\nO(1)\\nO(1)\\nRecurrent\\nO(n Â· d2)\\nO(n)\\nO(n)\\nConvolutional\\nO(k Â· n Â· d2)\\nO(1)\\nO(logk(n))\\nSelf-Attention (restricted)\\nO(r Â· n Â· d)\\nO(1)\\nO(n/r)\\n3.5\\nPositional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or absolute position of the\\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\\nlearned and fixed [9].\\nIn this work, we use sine and cosine functions of different frequencies:\\nPE(pos,2i) = sin(pos/100002i/dmodel)\\nPE(pos,2i+1) = cos(pos/100002i/dmodel)\\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding\\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2Ï€ to 10000 Â· 2Ï€. We\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative positions, since for any fixed offset k, PEpos+k can be represented as a linear function of\\nPEpos.\\nWe also experimented with using learned positional embeddings [9] instead, and found that the two\\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\\nduring training.\\n4\\nWhy Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi âˆˆRd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse in the network. The shorter these paths between any combination of positions in the input\\nand output sequences, the easier it is to learn long-range dependencies [12]. Hence we also compare\\nthe maximum path length between any two input and output positions in networks composed of the\\ndifferent layer types.\\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\\n6\\nlength n is smaller than the representation dimensionality d, which is most often the case with\\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\\n[38] and byte-pair [31] representations. To improve computational performance for tasks involving\\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size r in\\nthe input sequence centered around the respective output position. This would increase the maximum\\npath length to O(n/r). We plan to investigate this approach further in future work.\\nA single convolutional layer with kernel width k < n does not connect all pairs of input and output\\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\\nor O(logk(n)) in the case of dilated convolutions [18], increasing the length of the longest paths\\nbetween any two positions in the network. Convolutional layers are generally more expensive than\\nrecurrent layers, by a factor of k. Separable convolutions [6], however, decrease the complexity\\nconsiderably, to O(k Â· n Â· d + n Â· d2). Even with k = n, however, the complexity of a separable\\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side benefit, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5\\nTraining\\nThis section describes the training regime for our models.\\n5.1\\nTraining Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\\nvocabulary [38]. Sentence pairs were batched together by approximate sequence length. Each training\\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\\ntarget tokens.\\n5.2\\nHardware and Schedule\\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\\n(3.5 days).\\n5.3\\nOptimizer\\nWe used the Adam optimizer [20] with Î²1 = 0.9, Î²2 = 0.98 and Ïµ = 10âˆ’9. We varied the learning\\nrate over the course of training, according to the formula:\\nlrate = dâˆ’0.5\\nmodel Â· min(step_numâˆ’0.5, step_num Â· warmup_stepsâˆ’1.5)\\n(3)\\nThis corresponds to increasing the learning rate linearly for the first warmup_steps training steps,\\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\\nwarmup_steps = 4000.\\n5.4\\nRegularization\\nWe employ three types of regularization during training:\\n7\\nTable 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\\nModel\\nBLEU\\nTraining Cost (FLOPs)\\nEN-DE\\nEN-FR\\nEN-DE\\nEN-FR\\nByteNet [18]\\n23.75\\nDeep-Att + PosUnk [39]\\n39.2\\n1.0 Â· 1020\\nGNMT + RL [38]\\n24.6\\n39.92\\n2.3 Â· 1019\\n1.4 Â· 1020\\nConvS2S [9]\\n25.16\\n40.46\\n9.6 Â· 1018\\n1.5 Â· 1020\\nMoE [32]\\n26.03\\n40.56\\n2.0 Â· 1019\\n1.2 Â· 1020\\nDeep-Att + PosUnk Ensemble [39]\\n40.4\\n8.0 Â· 1020\\nGNMT + RL Ensemble [38]\\n26.30\\n41.16\\n1.8 Â· 1020\\n1.1 Â· 1021\\nConvS2S Ensemble [9]\\n26.36\\n41.29\\n7.7 Â· 1019\\n1.2 Â· 1021\\nTransformer (base model)\\n27.3\\n38.1\\n3.3 Â· 1018\\nTransformer (big)\\n28.4\\n41.8\\n2.3 Â· 1019\\nResidual Dropout\\nWe apply dropout [33] to the output of each sub-layer, before it is added to the\\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\\nPdrop = 0.1.\\nLabel Smoothing\\nDuring training, we employed label smoothing of value Ïµls = 0.1 [36]. This\\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6\\nResults\\n6.1\\nMachine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is\\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\\nthe competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop = 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\\nused beam search with a beam size of 4 and length penalty Î± = 0.6 [38]. These hyperparameters\\nwere chosen after experimentation on the development set. We set the maximum output length during\\ninference to input length + 50, but terminate early when possible [38].\\nTable 2 summarizes our results and compares our translation quality and training costs to other model\\narchitectures from the literature. We estimate the number of floating point operations used to train a\\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision floating-point capacity of each GPU 5.\\n6.2\\nModel Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model\\nin different ways, measuring the change in performance on English-to-German translation on the\\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\\n8\\nTable 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\\nper-word perplexities.\\nN\\ndmodel\\ndff\\nh\\ndk\\ndv\\nPdrop\\nÏµls\\ntrain\\nPPL\\nBLEU\\nparams\\nsteps\\n(dev)\\n(dev)\\nÃ—106\\nbase\\n6\\n512\\n2048\\n8\\n64\\n64\\n0.1\\n0.1\\n100K\\n4.92\\n25.8\\n65\\n(A)\\n1\\n512\\n512\\n5.29\\n24.9\\n4\\n128\\n128\\n5.00\\n25.5\\n16\\n32\\n32\\n4.91\\n25.8\\n32\\n16\\n16\\n5.01\\n25.4\\n(B)\\n16\\n5.16\\n25.1\\n58\\n32\\n5.01\\n25.4\\n60\\n(C)\\n2\\n6.11\\n23.7\\n36\\n4\\n5.19\\n25.3\\n50\\n8\\n4.88\\n25.5\\n80\\n256\\n32\\n32\\n5.75\\n24.5\\n28\\n1024\\n128\\n128\\n4.66\\n26.0\\n168\\n1024\\n5.12\\n25.4\\n53\\n4096\\n4.75\\n26.2\\n90\\n(D)\\n0.0\\n5.77\\n24.6\\n0.2\\n4.95\\n25.5\\n0.0\\n4.67\\n25.3\\n0.2\\n5.47\\n25.7\\n(E)\\npositional embedding instead of sinusoids\\n4.92\\n25.7\\nbig\\n6\\n1024\\n4096\\n16\\n0.3\\n300K\\n4.33\\n26.4\\n213\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\\ncheckpoint averaging. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected,\\nbigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our\\nsinusoidal positional encoding with learned positional embeddings [9], and observe nearly identical\\nresults to the base model.\\n6.3\\nEnglish Constituency Parsing\\nTo evaluate if the Transformer can generalize to other tasks we performed experiments on English\\nconstituency parsing. This task presents specific challenges: the output is subject to strong structural\\nconstraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence\\nmodels have not been able to attain state-of-the-art results in small-data regimes [37].\\nWe trained a 4-layer transformer with dmodel = 1024 on the Wall Street Journal (WSJ) portion of the\\nPenn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting,\\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences\\n[37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens\\nfor the semi-supervised setting.\\nWe performed only a small number of experiments to select the dropout, both attention and residual\\n(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters\\nremained unchanged from the English-to-German base translation model. During inference, we\\n9\\nTable 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\\nof WSJ)\\nParser\\nTraining\\nWSJ 23 F1\\nVinyals & Kaiser el al. (2014) [37]\\nWSJ only, discriminative\\n88.3\\nPetrov et al. (2006) [29]\\nWSJ only, discriminative\\n90.4\\nZhu et al. (2013) [40]\\nWSJ only, discriminative\\n90.4\\nDyer et al. (2016) [8]\\nWSJ only, discriminative\\n91.7\\nTransformer (4 layers)\\nWSJ only, discriminative\\n91.3\\nZhu et al. (2013) [40]\\nsemi-supervised\\n91.3\\nHuang & Harper (2009) [14]\\nsemi-supervised\\n91.3\\nMcClosky et al. (2006) [26]\\nsemi-supervised\\n92.1\\nVinyals & Kaiser el al. (2014) [37]\\nsemi-supervised\\n92.1\\nTransformer (4 layers)\\nsemi-supervised\\n92.7\\nLuong et al. (2015) [23]\\nmulti-task\\n93.0\\nDyer et al. (2016) [8]\\ngenerative\\n93.3\\nincreased the maximum output length to input length + 300. We used a beam size of 21 and Î± = 0.3\\nfor both WSJ only and the semi-supervised setting.\\nOur results in Table 4 show that despite the lack of task-specific tuning our model performs sur-\\nprisingly well, yielding better results than all previously reported models with the exception of the\\nRecurrent Neural Network Grammar [8].\\nIn contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley-\\nParser [29] even when training only on the WSJ training set of 40K sentences.\\n7\\nConclusion\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs\\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor.\\nAcknowledgements\\nWe are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\\ncomments, corrections and inspiration.\\nReferences\\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\\narXiv:1607.06450, 2016.\\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural\\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\\nreading. arXiv preprint arXiv:1601.06733, 2016.\\n10\\n[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\\nmachine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.\\n[7] Junyoung Chung, Ã‡aglar GÃ¼lÃ§ehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\\nof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\\n[8] Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural\\nnetwork grammars. In Proc. of NAACL, 2016.\\n[9] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\\n[10] Alex Graves.\\nGenerating sequences with recurrent neural networks.\\narXiv preprint\\narXiv:1308.0850, 2013.\\n[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition, pages 770â€“778, 2016.\\n[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and JÃ¼rgen Schmidhuber. Gradient flow in\\nrecurrent nets: the difficulty of learning long-term dependencies, 2001.\\n[13] Sepp Hochreiter and JÃ¼rgen Schmidhuber. Long short-term memory. Neural computation,\\n9(8):1735â€“1780, 1997.\\n[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations\\nacross languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural\\nLanguage Processing, pages 832â€“841. ACL, August 2009.\\n[15] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\\n[16] Åukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS), 2016.\\n[17] Åukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\\non Learning Representations (ICLR), 2016.\\n[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\\nray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2,\\n2017.\\n[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.\\n[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\\n[21] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017.\\n[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[23] Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task\\nsequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\\n11\\n[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated\\ncorpus of english: The penn treebank. Computational linguistics, 19(2):313â€“330, 1993.\\n[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In\\nProceedings of the Human Language Technology Conference of the NAACL, Main Conference,\\npages 152â€“159. ACL, June 2006.\\n[27] Ankur Parikh, Oscar TÃ¤ckstrÃ¶m, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\\nmodel. In Empirical Methods in Natural Language Processing, 2016.\\n[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\\n[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact,\\nand interpretable tree annotation. In Proceedings of the 21st International Conference on\\nComputational Linguistics and 44th Annual Meeting of the ACL, pages 433â€“440. ACL, July\\n2006.\\n[30] Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv\\npreprint arXiv:1608.05859, 2016.\\n[31] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\\n[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538, 2017.\\n[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\\nnov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine\\nLearning Research, 15(1):1929â€“1958, 2014.\\n[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory\\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\\nAdvances in Neural Information Processing Systems 28, pages 2440â€“2448. Curran Associates,\\nInc., 2015.\\n[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\\nnetworks. In Advances in Neural Information Processing Systems, pages 3104â€“3112, 2014.\\n[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\\n[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In\\nAdvances in Neural Information Processing Systems, 2015.\\n[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Googleâ€™s neural machine\\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\\narXiv:1609.08144, 2016.\\n[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\\n[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate\\nshift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume\\n1: Long Papers), pages 434â€“443. ACL, August 2013.\\n12\\nAttention Visualizations\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\\nthe verb â€˜makingâ€™, completing the phrase â€˜making...more difficultâ€™. Attentions here shown only for\\nthe word â€˜makingâ€™. Different colors represent different heads. Best viewed in color.\\n13\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\\nFull attentions for head 5. Bottom: Isolated attentions from just the word â€˜itsâ€™ for attention heads 5\\nand 6. Note that the attentions are very sharp for this word.\\n14\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\\nsentence. We give two such examples above, from two different heads from the encoder self-attention\\nat layer 5 of 6. The heads clearly learned to perform different tasks.\\n15\\n')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Arxiv\n",
    "from langchain_community.document_loaders import ArxivLoader\n",
    "docs = ArxivLoader(query=\"1706.03762\", load_max_docs=2).load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d500e36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00655ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Published': '2024-07-22', 'Title': \"Attention Is All You Need But You Don't Need All Of It For Inference of Large Language Models\", 'Authors': 'Georgy Tyukin, Gbetondji J-S Dovonon, Jean Kaddour, Pasquale Minervini', 'Summary': 'The inference demand for LLMs has skyrocketed in recent months, and serving\\nmodels with low latencies remains challenging due to the quadratic input length\\ncomplexity of the attention layers. In this work, we investigate the effect of\\ndropping MLP and attention layers at inference time on the performance of\\nLlama-v2 models. We find that dropping dreeper attention layers only marginally\\ndecreases performance but leads to the best speedups alongside dropping entire\\nlayers. For example, removing 33\\\\% of attention layers in a 13B Llama2 model\\nresults in a 1.8\\\\% drop in average performance over the OpenLLM benchmark. We\\nalso observe that skipping layers except the latter layers reduces performances\\nfor more layers skipped, except for skipping the attention layers.'}, page_content='Attention Is All You Need But You Donâ€™t Need All Of It\\nFor Inference of Large Language Models\\nGeorgy Tyukin * 1 Gbetondji J-S Dovonon 1 Jean Kaddour 1 Pasquale Minervini 2\\nAbstract\\nThe inference demand for LLMs has skyrocketed\\nin recent months, and serving models with low\\nlatencies remains challenging due to the quadratic\\ninput length complexity of the attention layers.\\nIn this work, we investigate the effect of drop-\\nping MLP and attention layers at inference time\\non the performance of Llama-v2 models. We\\nfind that dropping dreeper attention layers only\\nmarginally decreases performance but leads to the\\nbest speedups alongside dropping entire layers.\\nFor example, removing 33% of attention layers\\nin a 13B Llama2 model results in a 1.8% drop in\\naverage performance over the OpenLLM bench-\\nmark. We also observe that skipping layers except\\nthe latter layers reduces performances for more\\nlayers skipped, except for skipping the attention\\nlayers.\\n1. Introduction\\nThe ubiquitous deployment of Large Language Models\\n(LLMs) results in ever-growing amounts of compute spent\\non inference (Patterson et al., 2021; Chen et al., 2023; Kad-\\ndour et al., 2023a; Xia et al., 2024; Reid et al., 2024). Fur-\\nther, serving models with low latencies remains challenging\\nbecause contemporary Transformer architectures employ\\nthe self-attention mechanism with quadratic input complex-\\nity (Touvron et al., 2023b; Jiang et al., 2023; Bi et al., 2024).\\nIn this work, we delve deeper into the concept of layer\\nskipping (Fan et al., 2019; Wang et al., 2022a) to reduce\\nthe computation on superfluous LLM components. Our\\nfindings demonstrate that pruning deeper attention layers\\ndoes not significantly affect performance. When applied\\nto Llama-v2 (Touvron et al., 2023b), we maintain good\\nperformance on the OpenLLM (ARC (Clark et al., 2018),\\n*Equal contribution\\n1University College London,\\nUK\\n2University of Edinburgh, UK. Correspondence to: Georgy Tyukin\\n<tyukinegor@gmail.com>.\\nWork presented at TF2M workshop at ICML 2024, Vienna, Austria.\\nPMLR 235, 2024. Copyright 2024 by the author(s).\\nHellaSwag (Zellers et al., 2019), MMLU (Hendrycks et al.,\\n2021), TruthfulQA (Lin et al., 2022)) benchmarks (Beech-\\ning et al., 2023), recording only minimal performance devi-\\nations compared to the full model.\\n2. Method\\n0\\n5\\n10\\n15\\n20\\n25\\n30\\n35\\n40\\nLayer\\n0.65\\n0.70\\n0.75\\n0.80\\n0.85\\n0.90\\n0.95\\n1.00\\nCosine Similarity\\nCosine Similarity with previous layer for LLaMA-v2 7b and LLaMA-v2 13\\nLLaMA-v2 7b\\nLLaMA-v2 13b\\nFigure 1. Cosine similarity of Llama-v2 layers with the previous\\nlayer: We observe that the deeper the layer, the more its features\\nare similar to the previous layer except for the very last layer.\\n2.1. Layer skipping\\nConsider a Transformer model M with L layers, each\\nconsisting of an attention sub-layer followed by a multi-\\nlayer perceptron (MLP) sub-layer. We denote each layer as\\nMi = (Attentioni, MLPi) for i âˆˆ{1, 2, . . . , L}.\\nTo compare the performance of Transformer models when\\nskipping specific sub-layers, we create two variants of the\\nmodel:\\n1. Skipping MLP Layers: We construct a model Mskip MLP\\n1\\narXiv:2407.15516v1  [cs.LG]  22 Jul 2024\\nAttention Is All You Need But You Donâ€™t Need All Of It\\nby skipping the MLP sub-layer from the last k layers. The\\nresulting model is Mskip MLP = {(Attentioni, MLPi) | i âˆˆ\\n{1, 2, . . . , L âˆ’k}} âˆª{(Attentioni, âˆ…) | i âˆˆ{L âˆ’k +\\n1, . . . , L}}.\\n2. Skipping Attention Layers: We construct a model\\nMskip Attention by skipping the attention sub-layer from the\\nlast k layers.\\nThe resulting model is Mskip Attention =\\n{(Attentioni, MLPi)\\n|\\ni\\nâˆˆ\\n{1, 2, . . . , L âˆ’k}} âˆª\\n{(âˆ…, MLPi) | i âˆˆ{L âˆ’k + 1, . . . , L}}.\\n3. Skipping Transformer Blocks: We construct a model\\nMskip Attention by skipping the entire last k layers. The re-\\nsulting model is Mskip Block = {(Attentioni, MLPi) | i âˆˆ\\n{1, 2, . . . , L âˆ’k}} âˆª{(âˆ…) | i âˆˆ{L âˆ’k + 1, . . . , L}}.\\nWe then evaluate the performance of these modified models\\non the OpenLLM benchmark (Beeching et al., 2023), com-\\nparing metrics such as accuracy, computational efficiency,\\nand memory usage. This comparison helps in understand-\\ning the individual contributions of the attention and MLP\\nsub-layers to the overall performance of the Transformer\\nmodel.\\n(a) Skip attention lay-\\ners.\\n(b) Skip attention lay-\\ners,\\nkeep last full\\nblock.\\n(c) Skip ffwd layers.\\n(d) Skip ffwd layers,\\nkeep last full block.\\n(e) Skip full blocks.\\n(f) Skip full blocks,\\nkeep last full block.\\nFigure 2. Skip mechanisms for skipping single layers and entire\\nTransformer blocks (ffwd and attention layers) during inference.\\n2.2. Motivation: Are Deeper Layers More Redundant?\\nIn Transformer models, the last layers have been shown to\\ncontribute less information than earlier layers, making it\\npossible to drop those layers at a minimal performance cost\\n(Fan et al., 2019; Zhang & He, 2020; Wang et al., 2022a;\\nSchuster et al., 2022; Kaddour et al., 2023b; Belrose et al.,\\n2023).\\nTo verify this, we experiment with removing either the at-\\ntention sublayers or the MLP sublayers. Figure 1 shows the\\ncosine similarities between a layerâ€™s features and the previ-\\nous layer showing that deeper layers have a lower impact\\non the features than earlier layers. One notable exception\\nto this trend is that the last layer for both Llama-v2 7B and\\n13B has the lowest cosine similarity with the previous layer.\\nPrevious analysis of the attention mechanism has shown\\nthat they can converge to the same value due to attention\\ncollapse (Zhai et al., 2023) and token features that also con-\\nverge to the same value due to over-smoothing (Wang et al.,\\n2022b; Dovonon et al., 2024) or rank collapse (Dong et al.,\\n2023), with solutions to these issues typically improving\\nperformance (Ali et al., 2023; Choi et al., 2024).\\n3. Results\\nExperimental Setup\\nFor all experiments, we use either\\nLlama-v2-7B or Llama-v2-13B (Touvron et al., 2023a;b),\\ntwo LLMs trained on trillions of publically available tokens.\\nWe experiment with keeping 66%, 75%, 90% and 100% of\\nthe network and report the corresponding results in Table 1.\\nWe also experiment with removing attention sublayers in\\nTable 2, MLP sublayers in Table 3, and a varying number of\\nlayers similar to Table 1 but keeping the last layer in Table 4.\\n3.1. Chopping Layers\\nTable 1. Llama-v2 skipping full layer\\nModel\\nPerformances\\nARC\\nHellaSwag\\nTruthfulQA\\nMMLU\\nAverage\\n7B-66%\\n35.2\\n46.8\\n46.2\\n40.3\\n42.1\\n7B-75%\\n38.3\\n53.0\\n45.1\\n45.9\\n45.6\\n7B-90%\\n47.7\\n69.3\\n39.6\\n46.4\\n50.8\\n7B-100%\\n53.1\\n78.6\\n38.8\\n46.6\\n54.3\\n13B-66%\\n37.8\\n46.8\\n45.3\\n51.8\\n45.4\\n13B-75%\\n40.9\\n53.6\\n42.5\\n53.2\\n47.6\\n13B-90%\\n51.3\\n71.3\\n37.1\\n54.8\\n53.6\\n13B-100%\\n59.6\\n82.1\\n36.9\\n55.4\\n58.5\\nOn all datasets except TruthfulQA, performance drops\\nwhich is expected. It had already been observed that larger\\nlanguage models are less truthful (Lin et al., 2022), but we\\nnow also observe that reducing the size of already trained\\nmodels can also make them more truthful. The observa-\\ntion still holds when the last layer is preserved. Skipping\\n2\\nAttention Is All You Need But You Donâ€™t Need All Of It\\nTable 2. Llama-v2 skipping attention sublayers\\nModel\\nPerformances\\nARC\\nHellaSwag\\nTruthfulQA\\nMMLU\\nAverage\\n7B-66%\\n51.2\\n77.0\\n42.2\\n39.4\\n52.5\\n7B-75%\\n52.5\\n78.3\\n42.3\\n41.4\\n53.6\\n7B-90%\\n52.8\\n78.9\\n40.0\\n44.0\\n53.9\\n7B-100%\\n53.1\\n78.6\\n38.8\\n46.6\\n54.3\\n13B-66%\\n55.6\\n80.1\\n40.1\\n51.3\\n56.8\\n13B-75%\\n55.9\\n79.7\\n39.9\\n52.1\\n56.9\\n13B-90%\\n57.0\\n81.3\\n38.2\\n54.8\\n57.8\\n13B-100%\\n59.6\\n82.1\\n36.9\\n55.4\\n58.5\\nTable 3. Llama-v2 skipping ffwd sublayers\\nModel\\nPerformances\\nARC\\nHellaSwag\\nTruthfulQA\\nMMLU\\nAverage\\n7B-66%\\n35.1\\n52.5\\n42.2\\n43.9\\n43.4\\n7B-75%\\n40.4\\n60.3\\n39.2\\n46.3\\n46.6\\n7B-90%\\n48.5\\n71.4\\n38.0\\n46.1\\n51.0\\n7B-100%\\n53.1\\n78.6\\n38.8\\n46.6\\n54.3\\n13B-66%\\n41.6\\n56.9\\n40.7\\n53.4\\n48.2\\n13B-75%\\n47.3\\n65.2\\n40.0\\n53.2\\n51.4\\n13B-90%\\n54.2\\n75.8\\n38.3\\n54.7\\n55.8\\n13B-100%\\n59.6\\n82.1\\n36.9\\n55.4\\n58.5\\nattention layers only leads to better results with only a 1.8%\\ndecrease in performance when keeping 66% of the network\\ncompared to a 13.1% decrease in performance when drop-\\nping dropping the MLP layers only. This seems to indicate\\nthat MLP layers are more important than attention layers, at\\nleast in deeper parts of the network.\\n3.2. Last Layer Inclusion\\nTable 4. Llama-v2 skip full layers with last layer\\nModel\\nPerformances\\nARC\\nHellaSwag\\nTruthfulQA\\nMMLU\\nAverage\\n7B-66%\\n32.0\\n45.8\\n46.9\\n40.7\\n41.3\\n7B-75%\\n34.5\\n49.4\\n45.9\\n38.3\\n42.0\\n7B-90%\\n46.5\\n73.1\\n41.8\\n41.4\\n50.7\\n7B-100%\\n53.1\\n78.6\\n38.8\\n46.6\\n54.3\\n13B-66%\\n35.1\\n50.0\\n46.9\\n19.1\\n37.8\\n13B-75%\\n38.7\\n56.6\\n43.7\\n25.2\\n41.1\\n13B-90%\\n51.2\\n78.1\\n38.0\\n27.1\\n47.9\\n13B-100%\\n59.6\\n82.1\\n36.9\\n55.4\\n58.5\\nSurprisingly, we notice that skipping layers except the lat-\\nter layers reduces performances for more layers skipped,\\nexcept for skipping the attention layers. This is even more\\nexaggerated compared to just dropping layers, including the\\nlast one. The reason for this could be attributed to the (lack\\nof) robustness of feedforward sublayers, as the last layer\\nnow has to process perturbed information from earlier lay-\\ners. For future work, it would be interesting to see if these\\nperformance drops can be compensated by a small amount\\nTable 5. Llama-v2 skip attention sublayers with last layer\\nModel\\nPerformances\\nARC\\nHellaSwag\\nTruthfulQA\\nMMLU\\nAverage\\n7B-66%\\n49.3\\n77.1\\n40.5\\n42.5\\n52.4\\n7B-75%\\n51.8\\n78.3\\n41.1\\n44.1\\n53.8\\n7B-90%\\n51.9\\n78.7\\n39.4\\n45.7\\n53.9\\n7B-100%\\n53.1\\n78.6\\n38.8\\n46.6\\n54.3\\n13B-66%\\n56.8\\n82.1\\n38.0\\n50.3\\n56.8\\n13B-75%\\n57.5\\n82.1\\n37.0\\n51.4\\n57.0\\n13B-90%\\n58.9\\n82.4\\n36.6\\n54.5\\n58.1\\n13B-100%\\n59.6\\n82.1\\n36.9\\n55.4\\n58.5\\nTable 6. Llama-v2 skip ffwd sublayers with last layer\\nModel\\nPerformances\\nARC\\nHellaSwag\\nTruthfulQA\\nMMLU\\nAverage\\n7B-66%\\n32.0\\n45.8\\n46.9\\n39.4\\n41.0\\n7B-75%\\n34.5\\n49.4\\n45.9\\n40.2\\n42.5\\n7B-90%\\n46.5\\n73.1\\n41.8\\n40.2\\n50.4\\n7B-100%\\n53.1\\n78.6\\n38.8\\n46.6\\n54.3\\n13B-66%\\n35.1\\n50.0\\n46.9\\n20.4\\n38.1\\n13B-75%\\n38.7\\n56.6\\n43.7\\n33.6\\n43.2\\n13B-90%\\n51.2\\n78.1\\n38.0\\n34.4\\n50.4\\n13B-100%\\n59.6\\n82.1\\n36.9\\n55.4\\n58.5\\nof continued training; since model growing techniques for\\ntraining seem to not suffer from instabilities (Kaddour et al.,\\n2023b).\\n3.3. Compute-matched Comparison\\nTo measure the efficiency of the networks we conducted\\na separate experiment, where we record the time it takes\\nfor the model to output a sequence of length 1, averaging\\nover 1000 sequences. We conducted this experiment for\\nboth 50 and 100 length input sequences. We notice that full\\nlayer droppings do improve time costs the best, followed by\\nattention sublayers, and then feedforward sublayers which\\ndo not impact the speed of processing a lot.\\nWe report the timeÃ—102 (for clarity) it takes to predict 1\\ntoken for 1000 sequences as well as the percentage improve-\\nment. We show the results of this experiment for Llama 2\\n7B with 0%, 10%, 25%, 33% of layers skipped and we label\\nthese as 7B-100%, 7B-90%, 7B-75%, 7B-66% respectively.\\nTable 7. Llama-v2 time results, 50 length sequence, no last layer\\nModel\\nFull\\nAttention\\nffwd\\nTime(s) Ã—102\\n(%)\\nTime(s) Ã—102\\n(%)\\nTime(s) Ã—102\\n(%)\\n7B-66%\\n31.35\\n32.96\\n36.72\\n21.47\\n43.51\\n6.95\\n7B-75%\\n35.48\\n24.12\\n39.46\\n15.61\\n42.88\\n8.30\\n7B-90%\\n43.31\\n7.38\\n42.93\\n8.19\\n44.17\\n5.53\\n7B-100%\\n46.76\\n0\\n-\\n-\\n-\\n-\\n3\\nAttention Is All You Need But You Donâ€™t Need All Of It\\nTable 8. Llama-v2 time results, 50 length sequence, last layer in-\\ncluded\\nModel\\nFull\\nAttention\\nffwd\\nTime(s) Ã—102\\n(%)\\nTime(s) Ã—102\\n(%)\\nTime(s) Ã—102\\n(%)\\n7B-66%\\n31.78\\n32.04\\n36.92\\n21.04\\n41.31\\n11.66\\n7B-75%\\n34.98\\n25.19\\n40.24\\n13.94\\n42.62\\n8.85\\n7B-90%\\n40.92\\n12.49\\n42.43\\n9.26\\n43.51\\n6.95\\n7B-100%\\n46.76\\n0\\n-\\n-\\n-\\n-\\nTable 9. Llama-v2 time results, 100 length sequence, no last layer\\nModel\\nFull\\nAttention\\nffwd\\nTime(s) Ã—102\\n(%)\\nTime(s) Ã—102\\n(%)\\nTime(s) Ã—102\\n(%)\\n7B-66%\\n32.36\\n32.58\\n38.97\\n18.18\\n43.08\\n10.25\\n7B-75%\\n36.58\\n23.79\\n41.27\\n14.02\\n44.13\\n8.06\\n7B-90%\\n43.65\\n9.06\\n44.62\\n7.04\\n46.30\\n3.54\\n7B-100%\\n48.00\\n0\\n-\\n-\\n-\\n-\\nTable 10. Llama-v2 time results, 100 length sequence, last layer\\nincluded\\nModel\\nFull\\nAttention\\nffwd\\nTime(s) Ã—102\\n(%)\\nTime(s) Ã—102\\n(%)\\nTime(s) Ã—102\\n(%)\\n7B-66%\\n32.05\\n33.23\\n38.52\\n19.75\\n42.66\\n11.13\\n7B-75%\\n36.41\\n24.15\\n41.00\\n14.58\\n43.92\\n8.50\\n7B-90%\\n43.28\\n9.83\\n44.27\\n7.77\\n45.20\\n5.83\\n7B-100%\\n48.00\\n0\\n-\\n-\\n-\\n-\\n4. Related Work\\nEarly Exit during inference\\nEarly exit methods have also\\nbeen proposed in other domains (Graves, 2017; Teerapit-\\ntayanon et al., 2017) before getting adapted to autoregressive\\nmodels (Elbayad et al., 2020; Schuster et al., 2022; Din et al.,\\n2023; Elhoushi et al., 2024; Fan et al., 2024; Chen et al.,\\n2024). The idea works by dynamically allocating compute\\nbased on the difficulty of the input sequence. Our method\\nprunes the deepest layers and does not involve any level of\\nadaptability. This is beneficial because it does not require\\nthe entire model to be loaded in memory. Dropping layers\\nduring inference has been done on BERT-like models in\\n(Wang et al., 2022a; Sajjad et al., 2023). We apply a similar\\nanalysis to more recent LLMs and study the impact of skip-\\nping attention and/or MLP layers in more detail. Concurrent\\nwork to ours by Gromov et al. (2024) yields similar results\\nby pruning deeper layers and applying fine-tuning on the\\npruned model.\\nLayer dropping/growing during training\\nThere are var-\\nious works studying the dropping/growing layers dynami-\\ncally during training (Fan et al., 2019; Gong et al., 2019;\\nKaddour et al., 2023b; Jiang et al., 2020; Liu et al., 2023). In\\ncontrast, this work focuses on dropping layers of an already\\npre-trained model in a way similar to Men et al. (2024).\\nOther Inference Speedup Methods\\nOther works to speed\\nup inference include compressing KV caches (Nawrot et al.,\\n2024; Wu & Tu, 2024; Bi et al., 2024), speculative decoding\\n(Chen et al., 2023), efficient memory management (Kwon\\net al., 2023), or subqudratic attention architectures (Fu et al.,\\n2022; Peng et al., 2023; Gu & Dao, 2023), an overview has\\nbeen provided by Kaddour et al. (2023a).\\n5. Conclusion\\nWe investigated the effect of dropping the last layers from\\nthe 7B and 13B Llama2 models. We observe that dropping\\nattention sublayers lead to much lower drops in performance\\nthan dropping the MLP sublayers, whether the last layer\\nis included or not, while also leading to better inference\\nspeedups. For example, removing 33% of attention layers\\nleads to an 18% speedup in a 13B Llama2 model at the cost\\nof a 1.8% drop in average performance. This shows that\\nmassive improvements can be made over dropping entire\\nlayers from just dropping the attention sublayer.\\nReferences\\nAli, A., Galanti, T., and Wolf, L. Centered self-attention\\nlayers, 2023.\\nBeeching,\\nE.,\\nFourrier,\\nC.,\\nHabib,\\nN.,\\nHan,\\nS.,\\nLambert,\\nN.,\\nRajani,\\nN.,\\nSanseviero,\\nO.,\\nTun-\\nstall,\\nL.,\\nand\\nWolf,\\nT.\\nOpen\\nllm\\nleader-\\nboard.\\nhttps://huggingface.co/spaces/\\nHuggingFaceH4/open_llm_leaderboard,\\n2023.\\nBelrose, N., Furman, Z., Smith, L., Halawi, D., Ostrovsky, I.,\\nMcKinney, L., Biderman, S., and Steinhardt, J. Eliciting\\nlatent predictions from transformers with the tuned lens.\\narXiv preprint arXiv:2303.08112, 2023.\\nBi, X., Chen, D., Chen, G., Chen, S., Dai, D., Deng, C.,\\nDing, H., Dong, K., Du, Q., Fu, Z., et al. Deepseek llm:\\nScaling open-source language models with longtermism.\\narXiv preprint arXiv:2401.02954, 2024.\\nChen, C., Borgeaud, S., Irving, G., Lespiau, J., Sifre, L., and\\nJumper, J. Accelerating large language model decoding\\nwith speculative sampling. CoRR, abs/2302.01318, 2023.\\ndoi: 10.48550/ARXIV.2302.01318. URL https://\\ndoi.org/10.48550/arXiv.2302.01318.\\nChen, Y., Pan, X., Li, Y., Ding, B., and Zhou, J. Ee-llm:\\nLarge-scale training and inference of early-exit large lan-\\nguage models with 3d parallelism, 2024.\\nChoi, J., Wi, H., Kim, J., Shin, Y., Lee, K., Trask, N., and\\nPark, N. Graph convolutions enrich the self-attention in\\ntransformers!, 2024.\\nClark, P., Cowhey, I., Etzioni, O., Khot, T., Sabharwal, A.,\\nSchoenick, C., and Tafjord, O. Think you have solved\\n4\\nAttention Is All You Need But You Donâ€™t Need All Of It\\nquestion answering? try arc, the ai2 reasoning challenge,\\n2018.\\nDin, A. Y., Karidi, T., Choshen, L., and Geva, M. Jump\\nto conclusions: Short-cutting transformers with linear\\ntransformations. arXiv preprint arXiv:2303.09435, 2023.\\nDong, Y., Cordonnier, J.-B., and Loukas, A. Attention\\nis not all you need: Pure attention loses rank doubly\\nexponentially with depth, 2023.\\nDovonon, G. J.-S., Bronstein, M. M., and Kusner, M. J.\\nSetting the record straight on transformer oversmoothing,\\n2024.\\nElbayad, M., Gu, J., Grave, E., and Auli, M. Depth-adaptive\\ntransformer. In International Conference on Learning\\nRepresentations, 2020. URL https://openreview.\\nnet/forum?id=SJg7KhVKPH.\\nElhoushi, M., Shrivastava, A., Liskovich, D., Hosmer, B.,\\nWasti, B., Lai, L., Mahmoud, A., Acun, B., Agarwal,\\nS., Roman, A., et al. Layer skip: Enabling early exit\\ninference and self-speculative decoding. arXiv preprint\\narXiv:2404.16710, 2024.\\nFan, A., Grave, E., and Joulin, A. Reducing transformer\\ndepth on demand with structured dropout, 2019.\\nFan, S., Jiang, X., Li, X., Meng, X., Han, P., Shang, S., Sun,\\nA., Wang, Y., and Wang, Z. Not all layers of llms are\\nnecessary during inference, 2024.\\nFu, D. Y., Dao, T., Saab, K. K., Thomas, A. W., Rudra,\\nA., and RÂ´e, C. Hungry hungry hippos: Towards lan-\\nguage modeling with state space models. arXiv preprint\\narXiv:2212.14052, 2022.\\nGong, L., He, D., Li, Z., Qin, T., Wang, L., and Liu, T.\\nEfficient training of bert by progressively stacking. In\\nInternational conference on machine learning, pp. 2337â€“\\n2346. PMLR, 2019.\\nGraves, A. Adaptive computation time for recurrent neural\\nnetworks, 2017.\\nGromov, A., Tirumala, K., Shapourian, H., Glorioso, P., and\\nRoberts, D. A. The unreasonable ineffectiveness of the\\ndeeper layers, 2024.\\nGu, A. and Dao, T. Mamba: Linear-time sequence modeling\\nwith selective state spaces, 2023.\\nHendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M.,\\nSong, D., and Steinhardt, J. Measuring massive multitask\\nlanguage understanding, 2021.\\nJiang, A. Q., Sablayrolles, A., Mensch, A., Bamford, C.,\\nChaplot, D. S., Casas, D. d. l., Bressand, F., Lengyel, G.,\\nLample, G., Saulnier, L., et al. Mistral 7b. arXiv preprint\\narXiv:2310.06825, 2023.\\nJiang, Y.-G., Cheng, C., Lin, H., and Fu, Y.\\nLearning\\nlayer-skippable inference network. IEEE Transactions on\\nImage Processing, 29:8747â€“8759, 2020. doi: 10.1109/\\nTIP.2020.3018269.\\nKaddour, J., Harris, J., Mozes, M., Bradley, H., Raileanu,\\nR., and McHardy, R. Challenges and applications of\\nlarge language models. CoRR, abs/2307.10169, 2023a.\\ndoi: 10.48550/ARXIV.2307.10169. URL https://\\ndoi.org/10.48550/arXiv.2307.10169.\\nKaddour, J., Key, O., Nawrot, P., Minervini, P., and Kusner,\\nM. J.\\nNo train no gain: Revisiting efficient training\\nalgorithms for transformer-based language models. In\\nOh, A., Naumann, T., Globerson, A., Saenko, K., Hardt,\\nM., and Levine, S. (eds.), Advances in Neural Information\\nProcessing Systems 36: Annual Conference on Neural\\nInformation Processing Systems 2023, NeurIPS 2023,\\nNew Orleans, LA, USA, December 10 - 16, 2023, 2023b.\\nKwon, W., Li, Z., Zhuang, S., Sheng, Y., Zheng, L., Yu,\\nC. H., Gonzalez, J., Zhang, H., and Stoica, I. Efficient\\nmemory management for large language model serving\\nwith pagedattention. In Proceedings of the 29th Sym-\\nposium on Operating Systems Principles, pp. 611â€“626,\\n2023.\\nLin, S., Hilton, J., and Evans, O. Truthfulqa: Measuring\\nhow models mimic human falsehoods, 2022.\\nLiu, Z., Wang, J., Dao, T., Zhou, T., Yuan, B., Song, Z.,\\nShrivastava, A., Zhang, C., Tian, Y., Re, C., and Chen,\\nB. Deja vu: Contextual sparsity for efficient LLMs at\\ninference time. In Krause, A., Brunskill, E., Cho, K.,\\nEngelhardt, B., Sabato, S., and Scarlett, J. (eds.), Pro-\\nceedings of the 40th International Conference on Ma-\\nchine Learning, volume 202 of Proceedings of Machine\\nLearning Research, pp. 22137â€“22176. PMLR, 23â€“29 Jul\\n2023. URL https://proceedings.mlr.press/\\nv202/liu23am.html.\\nMen, X., Xu, M., Zhang, Q., Wang, B., Lin, H., Lu, Y., Han,\\nX., and Chen, W. Shortgpt: Layers in large language\\nmodels are more redundant than you expect, 2024. URL\\nhttps://arxiv.org/abs/2403.03853.\\nNawrot, P., ÅaÂ´ncucki, A., Chochowski, M., Tarjan, D., and\\nPonti, E. M. Dynamic memory compression: Retrofitting\\nllms for accelerated inference, 2024.\\nPatterson, D. A., Gonzalez, J., Le, Q. V., Liang, C., Munguia,\\nL., Rothchild, D., So, D. R., Texier, M., and Dean, J. Car-\\nbon emissions and large neural network training. CoRR,\\n5\\nAttention Is All You Need But You Donâ€™t Need All Of It\\nabs/2104.10350, 2021. URL https://arxiv.org/\\nabs/2104.10350.\\nPeng, B., Alcaide, E., Anthony, Q., Albalak, A., Arcadinho,\\nS., Cao, H., Cheng, X., Chung, M., Grella, M., GV, K. K.,\\net al. Rwkv: Reinventing rnns for the transformer era.\\narXiv preprint arXiv:2305.13048, 2023.\\nReid, M., Savinov, N., Teplyashin, D., Lepikhin, D., Lilli-\\ncrap, T., Alayrac, J.-b., Soricut, R., Lazaridou, A., Firat,\\nO., Schrittwieser, J., et al. Gemini 1.5: Unlocking multi-\\nmodal understanding across millions of tokens of context.\\narXiv preprint arXiv:2403.05530, 2024.\\nSajjad, H., Dalvi, F., Durrani, N., and Nakov, P. On the\\neffect of dropping layers of pre-trained transformer mod-\\nels.\\nComputer Speech & Language, 77:101429, jan\\n2023. doi: 10.1016/j.csl.2022.101429. URL https:\\n//doi.org/10.1016%2Fj.csl.2022.101429.\\nSchuster, T., Fisch, A., Gupta, J., Dehghani, M., Bahri, D.,\\nTran, V., Tay, Y., and Metzler, D. Confident adaptive\\nlanguage modeling. Advances in Neural Information\\nProcessing Systems, 35:17456â€“17472, 2022.\\nTeerapittayanon, S., McDanel, B., and Kung, H. T.\\nBranchynet: Fast inference via early exiting from deep\\nneural networks, 2017.\\nTouvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux,\\nM.-A., Lacroix, T., Rozi`ere, B., Goyal, N., Hambro, E.,\\nAzhar, F., Rodriguez, A., Joulin, A., Grave, E., and Lam-\\nple, G. Llama: Open and efficient foundation language\\nmodels, 2023a.\\nTouvron, H., Martin, L., Stone, K., Albert, P., Almahairi,\\nA., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P.,\\nBhosale, S., Bikel, D., Blecher, L., Ferrer, C. C., Chen,\\nM., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W.,\\nFuller, B., Gao, C., Goswami, V., Goyal, N., Hartshorn,\\nA., Hosseini, S., Hou, R., Inan, H., Kardas, M., Kerkez,\\nV., Khabsa, M., Kloumann, I., Korenev, A., Koura, P. S.,\\nLachaux, M.-A., Lavril, T., Lee, J., Liskovich, D., Lu, Y.,\\nMao, Y., Martinet, X., Mihaylov, T., Mishra, P., Molybog,\\nI., Nie, Y., Poulton, A., Reizenstein, J., Rungta, R., Saladi,\\nK., Schelten, A., Silva, R., Smith, E. M., Subramanian, R.,\\nTan, X. E., Tang, B., Taylor, R., Williams, A., Kuan, J. X.,\\nXu, P., Yan, Z., Zarov, I., Zhang, Y., Fan, A., Kambadur,\\nM., Narang, S., Rodriguez, A., Stojnic, R., Edunov, S.,\\nand Scialom, T. Llama 2: Open foundation and fine-tuned\\nchat models, 2023b.\\nWang, J., Chen, K., Chen, G., Shou, L., and McAuley, J.\\nSkipbert: Efficient inference with shallow layer skipping.\\nIn Proceedings of the 60th Annual Meeting of the Asso-\\nciation for Computational Linguistics (Volume 1: Long\\nPapers), pp. 7287â€“7301, 2022a.\\nWang, P., Zheng, W., Chen, T., and Wang, Z.\\nAnti-\\noversmoothing in deep vision transformers via the fourier\\ndomain analysis:\\nFrom theory to practice.\\nIn In-\\nternational Conference on Learning Representations,\\n2022b. URL https://openreview.net/forum?\\nid=O476oWmiNNp.\\nWu, H. and Tu, K. Layer-condensed kv cache for efficient\\ninference of large language models, 2024.\\nXia, H., Yang, Z., Dong, Q., Wang, P., Li, Y., Ge, T., Liu, T.,\\nLi, W., and Sui, Z. Unlocking efficiency in large language\\nmodel inference: A comprehensive survey of speculative\\ndecoding. arXiv preprint arXiv:2401.07851, 2024.\\nZellers, R., Holtzman, A., Bisk, Y., Farhadi, A., and Choi, Y.\\nHellaswag: Can a machine really finish your sentence?,\\n2019.\\nZhai, S., Likhomanenko, T., Littwin, E., Busbridge, D.,\\nRamapuram, J., Zhang, Y., Gu, J., and Susskind, J. Sta-\\nbilizing transformer training by preventing attention en-\\ntropy collapse, 2023.\\nZhang, M. and He, Y. Accelerating training of transformer-\\nbased language models with progressive layer dropping.\\nAdvances in neural information processing systems, 33:\\n14011â€“14023, 2020.\\n6\\n'),\n",
       " Document(metadata={'Published': '2021-07-16', 'Title': 'All the attention you need: Global-local, spatial-channel attention for image retrieval', 'Authors': 'Chull Hwan Song, Hye Joo Han, Yannis Avrithis', 'Summary': 'We address representation learning for large-scale instance-level image\\nretrieval. Apart from backbone, training pipelines and loss functions, popular\\napproaches have focused on different spatial pooling and attention mechanisms,\\nwhich are at the core of learning a powerful global image representation. There\\nare different forms of attention according to the interaction of elements of\\nthe feature tensor (local and global) and the dimensions where it is applied\\n(spatial and channel). Unfortunately, each study addresses only one or two\\nforms of attention and applies it to different problems like classification,\\ndetection or retrieval.\\n  We present global-local attention module (GLAM), which is attached at the end\\nof a backbone network and incorporates all four forms of attention: local and\\nglobal, spatial and channel. We obtain a new feature tensor and, by spatial\\npooling, we learn a powerful embedding for image retrieval. Focusing on global\\ndescriptors, we provide empirical evidence of the interaction of all forms of\\nattention and improve the state of the art on standard benchmarks.'}, page_content='All the attention you need:\\nGlobal-local, spatial-channel attention for image retrieval\\nChull Hwan Song\\nOdd Concepts\\nHye Joo Han\\nOdd Concepts\\nYannis Avrithis\\nInria, Univ Rennes, CNRS, IRISA\\nAbstract\\nWe address representation learning for large-scale\\ninstance-level image retrieval. Apart from backbone, train-\\ning pipelines and loss functions, popular approaches have\\nfocused on different spatial pooling and attention mecha-\\nnisms, which are at the core of learning a powerful global\\nimage representation. There are different forms of attention\\naccording to the interaction of elements of the feature tensor\\n(local and global) and the dimensions where it is applied\\n(spatial and channel). Unfortunately, each study addresses\\nonly one or two forms of attention and applies it to different\\nproblems like classiï¬cation, detection or retrieval.\\nWe present global-local attention module (GLAM),\\nwhich is attached at the end of a backbone network and\\nincorporates all four forms of attention: local and global,\\nspatial and channel. We obtain a new feature tensor and, by\\nspatial pooling, we learn a powerful embedding for image\\nretrieval. Focusing on global descriptors, we provide em-\\npirical evidence of the interaction of all forms of attention\\nand improve the state of the art on standard benchmarks.\\n1. Introduction\\nInstance-level image retrieval is at the core of visual rep-\\nresentation learning and is connected with many problems\\nof visual recognition and machine learning, for instance\\nmetric learning [30, 26], few-shot learning [42] and unsu-\\npervised learning [8]. Many large-scale open datasets [3,\\n37, 16, 29, 53], and competitions1 have accelerated progress\\nin instance-level image retrieval, which has been trans-\\nformed by deep learning [3].\\nMany studies on instance-level image retrieval focus\\non learning features from convolutional neural networks\\n(CNN), while others focus on re-ranking, for instance by\\ngraph-based methods [11]. The former can be distinguished\\naccording to feature types: local descriptors, reminiscent of\\nSIFT [27], where an image is mapped to a few hundred vec-\\ntors; and global descriptors, where an image is mapped to a\\n1https://www.kaggle.com/c/landmark-retrieval-2020\\nsingle vector. In fact, deep learning has brought global de-\\nscriptors with astounding performance, while allowing efï¬-\\ncient search. Our study belongs to this type.\\nStudies on global descriptors have focused on spatial\\npooling [2, 37]. The need for compact, discriminative rep-\\nresentations that are resistant to clutter has naturally given\\nrise to spatial attention methods [24, 28]. Different kinds\\nof attention have been studied in many areas of computer\\nvision research. There is also channel attention [20, 9]; lo-\\ncal attention, applied independently to elements of the rep-\\nresentation (feature map) [54, 25]; global attention, based\\non interaction between elements [52, 9]; and combinations\\nthereof. Unfortunately, each study has been limited to one or\\ntwo kinds of attention only; attention is not always learned;\\nand applications vary.\\nIt is the objective of our work to perform a compre-\\nhensive study of all forms of attention above, apply them\\nto instance-level image retrieval and provide a detailed ac-\\ncount of their interaction and impact on performance. As\\nshown in Figure 1, we collect contextual information from\\nimages with both local and global attention, giving rise to\\ntwo parallel network streams. Importantly, each operates\\non both spatial locations and feature channels. Local at-\\ntention is about individual locations and channels; global is\\nabout interaction between locations and between channels.\\nThe extracted information is separately embedded in local\\nand global attention feature maps, which are combined in a\\nglobal-local attention feature map before pooling.\\nOur contributions can be summarized as follows:\\n1. We propose a novel network that consists of both\\nglobal and local attention for image retrieval. This is\\nthe ï¬rst study that employs both mechanisms.\\n2. Each of the global and local attention mechanisms\\ncomprises both spatial and channel attention.\\n3. Focusing on global descriptors, we provide empirical\\nevidence of the interaction of all forms of attention and\\nimprove the state of the art on standard benchmarks.\\n1\\narXiv:2107.08000v1  [cs.CV]  16 Jul 2021\\nAl\\nc\\nc Ã— 1 Ã— 1\\nÃ—\\n+\\nFl\\nc\\nAl\\ns\\n1 Ã— h Ã— w\\nÃ—\\n+\\nFl\\nÃ—\\nc Ã— h Ã— w\\nF\\nÃ—\\n+\\nc Ã— h Ã— w\\nFgl\\nAg\\nc\\nc Ã— c\\nÃ—\\nFg\\nc\\nAg\\ns\\nhw Ã— hw\\nÃ—\\n+\\nFg\\nÃ—\\nwl\\nw\\nwg\\nchannel attention\\nspatial attention\\nfusion\\nlocal attention\\nglobal attention\\nFigure 1: Our global-local attention module (GLAM) involves both channel and spatial attention, as well as both local atten-\\ntion (channels/locations weighted independently, based on contextual information obtained by pooling) and global attention\\n(based on pairwise interaction between channels/locations). As a result, four attention maps are used: local channel (Al\\nc),\\nlocal spatial (Al\\ns), global channel (Ag\\nc) and global spatial (Ag\\ns). The input feature map F is weighted into local (Fl) and\\nglobal (Fg) attention feature maps, which are fused with F to yield the global-local attention feature map Fgl. The diagram\\nis abstract: The four attention modules are shown in more detail in Figures 2, 3, 4, 5.\\n2. Related work\\nInstance-level image retrieval\\nStudies on instance-level\\nimage retrieval can be roughly, but not exclusively, di-\\nvided into three types: (1) studies on global descriptors\\n[3, 16, 24, 53, 2, 37]; (2) studies on local descriptors and\\ngeometry-based re-ranking [29, 45, 40, 53]; (3) re-ranking\\nby graph-based methods [11, 21, 55]. The ï¬rst two types\\nof studies focus on the feature representation, while the last\\ntype focuses on re-ranking extracted features.\\nStudies on global descriptors focus on spatial pooling\\nof CNN feature maps into vectors, including MAC [38],\\nSPoC [2], CroW [24], R-MAC [48, 15, 16], GeM [37],\\nand NetVLAD [1, 25], as well as learning the representa-\\ntion [3, 15, 16, 36, 37]. Studies before deep learning dom-\\ninated image retrieval were mostly based on local descrip-\\ntors like SIFT [27] and bag-of-words representation [32] or\\naggregated descriptors like VLAD [22] or ASMK [46]. Lo-\\ncal descriptors have been revived in deep learning, e.g. with\\nDELF [29], DELG [5] and ASMK extensions [45, 47].\\nWe focus on learning a global descriptor in this work, be-\\ncause it is the most efï¬cient in terms of storage and search.\\nHowever, our generic attention mechanism produces a fea-\\nture tensor and could be applicable to local descriptors as\\nwell, if global pooling were replaced by local feature detec-\\ntion. Re-ranking methods are complementary to the repre-\\nsentation and we do not consider them in this work.\\nAttention\\nAttention mechanisms have been ï¬rst proposed\\nin image classiï¬cation studies focusing on channel at-\\nMETHOD\\nLOCAL\\nGLOBAL\\nLRN RET\\nSpatial Channel Spatial Channel\\nSENet [20]\\nâœ“\\nâœ“\\nECA-Net [51]\\nâœ“\\nâœ“\\nGCNet [6]\\nâœ“\\nâœ“\\nCBAM [54]\\nâœ“\\nâœ“\\nâœ“\\nGE [19]\\nâœ“\\nâœ“\\nNL-Net [52]\\nâœ“\\nâœ“\\nAA-Net [4]\\nâœ“\\nâœ“\\nSAN [59]\\nâœ“\\nâœ“\\nN3Net [34]\\nâœ“\\nâœ“\\nA2-Net [9]\\nâœ“\\nâœ“\\nGSoP [14]\\nâœ“\\nâœ“\\nOnA [23]\\nâœ“\\nâœ“\\nAGeM [17]\\nâœ“\\nâœ“\\nCroW [24]\\nâœ“\\nâœ“\\nâœ“\\nCRN [25]\\nâœ“\\nâœ“\\nâœ“\\nDELF [29]\\nâœ“\\nâœ“\\nâœ“\\nDELG [5]\\nâœ“\\nâœ“\\nâœ“\\nTolias et al. [47]\\nâœ“\\nâœ“\\nâœ“\\nSOLAR [28]\\nâœ“\\nâœ“\\nâœ“\\nOurs\\nâœ“\\nâœ“\\nâœ“\\nâœ“\\nâœ“\\nâœ“\\nTable 1: Related work on attention. LRN: learned; RET: ap-\\nplied to instance-level image retrieval.\\ntention [20, 51, 6], spatial attention [19] or both, like\\nCBAM [54]. In image retrieval, CroW [24] also employs\\n2\\nfeature map\\nGAP\\nconv1d(k)\\nsigmoid\\nattention map\\nc Ã— h Ã— w\\nc Ã— 1 Ã— 1\\nc Ã— 1 Ã— 1\\nF\\nAl\\nc\\nFigure 2: Local channel attention.\\nboth spatial and channel attention and can be seen as a pre-\\ncursor of CBAM, but, like other studies of spatial attention\\non retrieval [41, 23, 17], it is not learned. CRN [25] ap-\\nplies spatial attention for feature reweighting and is learned.\\nLearned spatial attention mechanisms are common for local\\ndescriptors [29, 5, 47].\\nWe call the above methods local attention, in the sense\\nthat elements of the feature tensor (channels / spatial loca-\\ntions), are weighted independently, based on contextual in-\\nformation obtained by pooling or learned. By constrast, by\\nglobal attention we refer to mechanisms that model inter-\\naction between elements of the feature tensor, for example\\nbetween channels or between locations.\\nIn image classiï¬cation, non-local neural network (NL-\\nNet) [52] is maybe the ï¬rst global attention mechanism, fol-\\nlowed by similar studies [4, 59, 34]. It is global spatial at-\\ntention, allowing interaction between any pair of spatial lo-\\ncations. Similarly, there are studies of global channel atten-\\ntion, allowing interaction between channels [9, 14]. Global\\nattention has focused mostly on image recognition and has\\nbeen applied to either spatial or channel attention so far, not\\nboth. In image retrieval, SOLAR [28] is a direct application\\nof the global spatial attention mechanism of [52].\\nTable 1 attempts to categorize related work on atten-\\ntion according to whether attention is local or global, spa-\\ntial or channel, whether it is learned and whether it is ap-\\nplied to instance-level image retrieval. We observe that all\\nmethods limit to one or two forms of attention only. Of\\nthose studies that focus on image retrieval, many are not\\nlearned [23, 17, 24], and of those that are, some are de-\\nsigned for local descriptors [29, 47].\\nBy contrast, we provide a comprehensive study of all\\nforms of attention, global and local, spatial and channel, to\\nobtain a learned representation in the form of a tensor that\\ncan be used in any way. We spatially pool it into a global\\ndescriptor and we study the relative gain of different forms\\nof attention in image retrieval.\\nfeature map\\nconv 1 Ã— 1\\nconv 3 Ã— 3\\nconv 5 Ã— 5\\nconv 7 Ã— 7\\nconcat\\nconv 1 Ã— 1\\nattention map\\nc Ã— h Ã— w\\n4câ€² Ã— h Ã— w\\n1 Ã— h Ã— w\\ncâ€² Ã— h Ã— w\\ndilated\\nconv\\nF\\nFâ€²\\nAl\\ns\\nFigure 3: Local spatial attention. Convolutional layers in\\nblue implemented by dilated convolutions with kernel size\\n3 Ã— 3 and dilation factors 1, 3, 5.\\n3. Global-local attention\\nWe design a global-local attention module (GLAM),\\nwhich is attached at the end of a backbone network. Figure 1\\nillustrates its main components. We are given a c Ã— h Ã— w\\nfeature tensor F, where c is the number of channels, and\\nh Ã— w is the spatial resolution. Local attention collects con-\\ntext from the image and applies pooling to obtain a cÃ—1Ã—1\\nlocal channel attention map Al\\nc and a 1 Ã— h Ã— w local spa-\\ntial attention map Al\\ns. Global attention allows interaction\\nbetween channels, resulting in a c Ã— c global channel at-\\ntention map Ag\\nc, and between spatial locations, resulting in\\na hw Ã— hw global spatial attention map Ag\\ns. The feature\\nmaps produced by the two attention streams are combined\\nwith the original one by a learned fusion mechanism into\\nthe global-local attention feature map Fgl before being spa-\\ntially pooled into a global image descriptor.\\n3.1. Local attention\\nWe extract an 1D channel and a 2D spatial attention map\\nto weigh the feature map in the corresponding dimensions.\\nLocal channel attention\\nFollowing ECA-Net [51], this\\nattention captures local channel information. As shown in\\nFigure 2, we are given a cÃ—hÃ—w feature tensor F from our\\nbackbone. We ï¬rst reduce it to a c Ã— 1 Ã— 1 tensor by global\\naverage pooling (GAP). Channel attention is then captured\\nby a 1D convolution of kernel size k along the channel di-\\nmension, where k controls the extent of cross-channel inter-\\naction. This is followed by a sigmoid function, resulting in\\nthe c Ã— 1 Ã— 1 local channel attention map Al\\nc.\\nLocal spatial attention\\nInspired by the inception mod-\\nule [43] and similar to [25], this attention map captures local\\nspatial information at different scales. As shown in Figure 3,\\n3\\nfeature map\\nGAP\\nconv1d(k)\\nconv1d(k)\\nsigmoid\\nsigmoid\\nÃ—\\nÃ—\\nsoftmax\\nattention feature map\\n1 Ã— c\\n1 Ã— c\\n1 Ã— c\\nQc\\nc Ã— c\\nhw Ã— c\\nVc\\nAg\\nc\\nc Ã— h Ã— w\\n1 Ã— c\\n1 Ã— c\\nKc\\nF\\nGc\\nFigure 4: Global channel attention.\\ngiven the same c Ã— h Ã— w feature tensor F from our back-\\nbone, we obtain a new tensor Fâ€² with channels reduced to\\ncâ€², using a 1 Ã— 1 convolution. We then extract local spatial\\ncontextual information using convolutional ï¬lters of kernel\\nsize 3 Ã— 3, 5 Ã— 5, and 7 Ã— 7, which are efï¬ciently imple-\\nmented by 3 Ã— 3 dilated convolutions [7, 57] with dilation\\nparameter 1, 2, and 3 respectively. The resulting features,\\nalong with one obtained by 1 Ã— 1 convolution on Fâ€², are\\nconcatenated into a 4câ€² Ã— h Ã— w tensor. Finally, we obtain\\nthe 1 Ã— h Ã— w local spatial attention map Al\\ns by a 1 Ã— 1\\nconvolution that reduces the channel dimension to 1.\\nThe middle column of Figure 6 shows heat maps of local\\nspatial attention, localizing target objects in images.\\nLocal attention feature map\\nWe use the local channel\\nattention map Al\\nc to weigh F in the channel dimension\\nFl\\nc := F âŠ™Al\\nc + F.\\n(1)\\nWe then use local spatial attention map Al\\ns to weigh Fl\\nc\\nin the spatial dimensions, resulting in the c Ã— h Ã— w local\\nattention feature map\\nFl = Fl\\nc âŠ™Al\\ns + Fl\\nc.\\n(2)\\nHere, AâŠ™B denotes an element-wise multiplication of ten-\\nsors A and B, with broadcasting when one tensor is smaller.\\nWe adopt the choice of applying channel followed by spa-\\ntial attention from convolutional block attention module\\nCBAM [54]. However, apart from computing Al\\ns at differ-\\nent scales, both attention maps are obtained from the orig-\\ninal tensor F rather than sequentially. In addition, both (1)\\nand (2) include residual connections, while CBAM includes\\na single residual connection over both steps.\\n3.2. Global attention\\nWe extract two matrices capturing global pairwise chan-\\nnel and spatial interaction to weigh the feature map.\\nfeature map\\nconv 1 Ã— 1\\nconv 1 Ã— 1\\nconv 1 Ã— 1\\nÃ—\\nÃ—\\nsoftmax\\nconv 1 Ã— 1\\nattention feature map\\ncâ€² Ã— hw\\nQs\\nhw Ã— hw\\nc Ã— h Ã— w\\ncâ€² Ã— hw\\nVs\\ncâ€² Ã— h Ã— w\\nAg\\ns\\nc Ã— h Ã— w\\ncâ€² Ã— hw\\nKc\\nF\\nGs\\nFigure 5: Global spatial attention.\\nGlobal channel attention\\nWe introduce a global channel\\nattention mechanism that captures global channel interac-\\ntion. This mechanism is based on the non-local neural net-\\nwork [52], but with the idea of 1D convolution from ECA-\\nNet [51]. As shown in Figure 4, we are given the c Ã— h Ã— w\\nfeature tensor F from our backbone. We apply GAP and\\nsqueeze spatial dimensions, followed by a 1D convolution\\nof kernel size k and a sigmoid function, to obtain 1Ã—c query\\nQc and key Kc tensors. The value tensor Vc is obtained by\\nmere reshaping of F to hwÃ—c, without GAP. Next, we form\\nthe outer product of Kc and Qc, followed by softmax over\\nchannels to obtain a c Ã— c global channel attention map\\nAg\\nc = softmax(Kc\\nâŠ¤Qc).\\n(3)\\nFinally, this attention map is multiplied with Vc and the ma-\\ntrix product VcAg\\nc is reshaped back to cÃ—hÃ—w to give the\\nglobal channel attention feature map Gc. In GSoP [14] and\\nA2-Net [9], a cÃ—c global channel attention map is obtained\\nby multiplication of hw Ã— c matrices; (3) is more efï¬cient,\\nusing only an outer product of 1 Ã— c vectors.\\nGlobal spatial attention\\nSince ordinary convolution ap-\\nplies only a local neighborhood at a time, it cannot capture\\nglobal contextual information. Thus, we apply non-local ï¬l-\\ntering [52], which is a form of self-attention [49] in the spa-\\ntial dimensions. As shown in Figure 5, we are given the\\nsame c Ã— h Ã— w feature tensor F from our backbone. By\\nusing three 1Ã—1 convolutions, which reduce channels to câ€²,\\nand ï¬‚attening spatial dimensions to hw, we obtain câ€² Ã— hw\\nquery Qs, key Ks, and value Vs tensors, where each col-\\numn is a feature vector corresponding to a particular spatial\\nlocation. We capture pairwise similarities of these vectors\\nby matrix multiplication of Ks and Qs, followed by soft-\\nmax over locations to obtain a hw Ã— hw global spatial at-\\ntention map:\\nAg\\ns = softmax(KâŠ¤\\ns Qs).\\n(4)\\n4\\nThis attention map is multiplied with Vs and the matrix\\nproduct VsAg\\ns is reshaped back to câ€² Ã—hÃ—w by expanding\\nthe spatial dimensions. Finally, using a 1 Ã— 1 convolution,\\nwhich increases channels back to c, we obtain the cÃ—hÃ—w\\nglobal spatial attention feature map Gs.\\nThe right column of Figure 6 shows heat maps for global\\nspatial attention, localizing target objects in images.\\nGlobal attention feature map\\nWe use the global channel\\nattention feature map Fc to weigh F element-wise\\nFg\\nc = F âŠ™Gc.\\n(5)\\nWe then use global spatial attention feature map Gs to\\nweigh Fg\\nc element-wise, resulting in the c Ã— h Ã— w global\\nattention feature map\\nFg = Fg\\nc âŠ™Gs + Fg\\nc.\\n(6)\\nSimilarly to Fl in (1) and (2), we apply channel attention\\nï¬rst, followed by spatial attention. However, unlike (1),\\nthere is no residual connection in (5). This choice is sup-\\nported by early experiments.\\n3.3. Global-local attention\\nFeature fusion\\nAs shown in Figure 1, we combine the\\nlocal and global attention feature maps, Fl and Fg, with\\nthe original feature F. While concatenation and summation\\nare common operations for feature combination, we use a\\nweighted average with weights wl, wg, w respectively, ob-\\ntained by softmax over three learnable scalar parameters, to\\nobtain a c Ã— h Ã— w global-local attention feature map\\nFgl = wlFl + wgFl + wF.\\n(7)\\nEfï¬cientDet [44] has shown that this is the most effective,\\namong a number of choices, for fusion of features across\\ndifferent scales.\\nPooling\\nWe apply GeM [37], a learnable spatial pooling\\nmechanism, to feature map Fgl (7), followed by a fully-\\nconnected (FC) layer with dropout and batch normalization.\\nThe ï¬nal embedding is obtained by â„“2-normalization.\\n4. Experiments\\n4.1. Datasets\\nTraining set\\nThere are a number of open landmark\\ndatasets commonly used for training in image retrieval stud-\\nies, including neural code (NC) [3], neural code clean (NC-\\nclean) [16], as well as Google Landmarks v1 (GLDv1) [29]\\nand v2 (GLDv2) [53]. Table 2 shows relevant statistics.\\nThese datasets can be categorized into noisy and clean. The\\nclean sets were obtained from the original noisy sets for\\nmore effective training [16, 53]. The original noisy datasets\\nare much larger, but they have high intra-class variability.\\n(a) input\\n(b) local\\n(c) global\\nFigure 6: Local and global spatial attention. Left: input\\nimages. Middle: local spatial attention heat maps. Right:\\nglobal spatial attention heat maps. Red (blue) means higher\\n(lower) attention weight.\\nEach class can include visually dissimilar images such as\\nexterior and interior views of a building or landmark, in-\\ncluding ï¬‚oor plans and paintings inside. The clean datasets\\nfocus on views directly relevant to landmark recognition but\\nhave a much smaller number of images.\\nEvaluation set and metrics\\nWe use four common eval-\\nuation datasets for landmark image retrieval: Oxford5k\\n(Ox5k) [32], Paris6k (Par6k) [33], as well as Revisited Ox-\\nford (ROxford or ROxf) and Paris (RParis or RPar) [35].\\nROxford and RParis are used with and without one million\\ndistractors (R1M) [28] and evaluated using the Medium and\\nHard protocols [35]. We evaluate using mean Average Pre-\\ncision (mAP) and mean precision at 10 (mP@10).\\n4.2. Implementation details\\nWe train on 8 TITAN RTX 2080Ti GPUs. All models are\\npre-trained on ImageNet [39] and implemented in PyTorch\\n[31]. For fair comparisons, we set a training environment\\n5\\nFigure 7: Examples of our ranking results. In each row, the ï¬rst image on the left (pink dotted outline) is a query image with a\\ntarget object (red crop box), and the following are the top ranking images for the query. Orange solid outline: positive images\\nfor the query; red solid outline: negative.\\nsimilar to the those of compared studies [56, 53, 28, 35]. We\\nemploy ResNet101 [18] as a backbone model. The kernel\\nsize k of ECANet in subsection 3.1 is set to 3. The param-\\neter p of GeM in subsection 3.3 is set to 3 and the dimen-\\nsion d of ï¬nal embeddings to 512. We adopt ArcFace [10],\\na cosine-softmax based loss, with a margin of 0.3. We use\\nstochastic gradient descent with initial learning rate 10âˆ’3,\\nmomentum 0.9 and weight decay 10âˆ’5.\\nWe adopt the batch sampling of Yokoo et al. [56] where\\nmini-batch samples with similar aspect ratios are resized to\\na particular size. Here, we use a batch size of 64. For image\\naugmentation, we apply scaling, random cropping, and var-\\nied illumination. At inference, we apply a multi-resolution\\nrepresentation [16] to query and database images.\\nOur method is denoted as GLAM (global-local atten-\\ntion module). Using the backbone model alone is referred\\nto as baseline. It is compatible with recent models based\\non ResNet101-GeM trained with ArcFace [53, 28]. Adding\\nour local attention (subsection 3.1) to the baseline model is\\ndenoted +local, while adding our global attention (subsec-\\ntion 3.2) is denoted +global. Since we focus on representa-\\ntion learning, we do not consider post-processing methods\\nlike geometry-based re-ranking [29, 40, 53] or graph-based\\nre-ranking [11, 21, 55].\\n4.3. Benchmarking\\nNoisy vs. clean training sets\\nWe begin by training our\\nbest model (baseline+local+global) on all training sets of\\nTable 2, except NC-noisy because some images are cur-\\nrently unavailable. As shown in Table 3, even though\\nTRAIN SET\\n#IMAGES\\n#CLASSES\\nNC-noisy\\n213,678\\n672\\nNC-clean\\n27,965\\n581\\nSfM-120k\\n117,369\\n713\\nGLDv1-noisy\\n1,225,029\\n14, 951\\nGLDv2-noisy\\n4,132,914\\n203,094\\nGLDv2-clean\\n1,580,470\\n81,313\\nTable 2: Statistics of different training sets.\\nMETHOD\\nTRAIN SET\\nDIM OXF5K PAR6K RMEDIUM\\nRHARD\\nROxf RPar ROxf RPar\\nGeM-Siamese [37, 35]\\nSfM-120k\\n2048\\n87.8\\n92.7\\n64.7\\n77.2\\n38.5\\n56.3\\nSOLAR [28]\\nGLDv1-noisy 2048\\nâ€“\\nâ€“\\n69.9\\n81.6\\n47.9\\n64.5\\nGLDv2 [53]\\nGLDv2-clean 2048\\nâ€“\\nâ€“\\n74.2\\n84.9\\n51.6\\n70.3\\nGLAM (Ours)\\nNC-clean\\n512\\n77.8\\n85.8\\n51.6\\n68.1\\n20.9\\n44.7\\nGLDv1-noisy 512\\n92.8\\n95.0\\n73.7\\n83.5\\n49.8\\n69.4\\nGLDv2-noisy 512\\n93.3\\n95.3\\n75.7\\n86.0\\n53.1\\n73.8\\nGLDv2-clean 512\\n94.2\\n95.6\\n78.6\\n88.5\\n60.2\\n76.8\\nTable 3: mAP comparison of our best model (base-\\nline+local+global) trained on different training sets against\\n[53, 28]. All models use ResNet101-GeM. Red: best results.\\nBlue: GLAM higher than SOLAR [28] on GLDv1-noisy.\\nGLDv2-noisy has 2.6 times more images than GLDv2-\\nclean, the latter is superior by a large margin. This shows\\nthat, in training, a cleaner dataset can be more important\\nthan a larger one. By contrast, NC-clean has the worst\\nperformance despite being clean, aparently because it is\\n6\\nMETHOD\\nTRAIN SET\\nDIM\\nBASE\\nMEDIUM\\nHARD\\nOx5k Par6k\\nROxf\\n+R1M\\nRPar\\n+R1M\\nROxf\\n+R1M\\nRPar\\n+R1M\\nmAP\\nmAP mAP mP mAP mP mAP mP mAP mP\\nmAP mP mAP mP mAP mP mAP mP\\nSPoC-V16 [2, 35]\\n[O]\\n512\\n53.1âˆ—\\nâ€“\\n38.0 54.6 17.1 33.3 59.8 93.0 30.3 83.0 11.4 20.9\\n0.9\\n2.9\\n32.4 69.7\\n7.6\\n30.6\\nSPoC-R101 [35]\\n[O]\\n2048\\nâ€“\\nâ€“\\n39.8 61.0 21.5 40.4 69.2 96.7 41.6 92.0 12.4 23.8\\n2.8\\n5.6\\n44.7 78.0 15.3 54.4\\nCroW-V16 [24, 35]\\n[O]\\n512\\n70.8\\n79.7\\n41.4 58.8 22.5 40.5 62.9 94.4 34.1 87.1 13.9 25.7\\n3.0\\n6.6\\n36.9 77.9 10.3 45.1\\nCroW-R101 [35]\\n[O]\\n2048\\nâ€“\\nâ€“\\n42.4 61.9 21.2 39.4 70.4 97.1 42.7 92.9 13.3 27.7\\n3.3\\n9.3\\n47.2 83.6 16.3 61.6\\nMAC-V16-Siamese [36, 35]\\n[O]\\n512\\n80.0\\n82.9\\n37.8 57.8 21.8 39.7 59.2 93.3 33.6 87.1 14.6 27.0\\n7.4\\n11.9 35.9 78.4 13.2 54.7\\nMAC-R101-Siamese [35]\\n[O]\\n2048\\nâ€“\\nâ€“\\n41.7 65.0 24.2 43.7 66.2 96.4 40.8 93.0 18.0 32.9\\n5.7\\n14.4 44.1 86.3 18.2 67.7\\nRMAC-V16-Siamese [36, 35]\\n[O]\\n512\\n80.1\\n85.0\\n42.5 62.8 21.7 40.3 66.2 95.4 39.9 88.9 12.0 26.1\\n1.7\\n5.8\\n40.9 77.1 14.8 54.0\\nRMAC-R101-Siamese [35]\\n[O]\\n2048\\nâ€“\\nâ€“\\n49.8 68.9 29.2 48.9 74.0 97.7 49.3 93.7 18.5 32.2\\n4.5\\n13.0 52.1 87.1 21.3 67.4\\nRMAC-R101-Triplet [16, 35]\\nNC-clean\\n2048\\n86.1\\n94.5\\n60.9 78.1 39.3 62.1 78.9 96.9 54.8 93.9 32.4 50.0 12.5 24.9 59.4 86.1 28.0 70.0\\nGeM-R101-Siamese [37, 35]\\nSfM-120k\\n2048\\n87.8\\n92.7\\n64.7 84.7 45.2 71.7 77.2 98.1 52.3 95.3 38.5 53.0 19.9 34.9 56.3 89.1 24.7 73.3\\nAGeM-R101-Siamese [17]\\nSfM-120k\\n2048\\nâ€“\\nâ€“\\n67.0\\nâ€“\\nâ€“\\nâ€“\\n78.1\\nâ€“\\nâ€“\\nâ€“\\n40.7\\nâ€“\\nâ€“\\nâ€“\\n57.3\\nâ€“\\nâ€“\\nâ€“\\nSOLAR-GeM-R101-Triplet/SOS [28] GLDv1-noisy 2048\\nâ€“\\nâ€“\\n69.9 86.7 53.5 76.7 81.6 97.1 59.2 94.9 47.9 63.0 29.9 48.9 64.5 93.0 33.4 81.6\\nDELG-GeM-R101-ArcFace [5]\\nGLDv1-noisy 2048\\nâ€“\\nâ€“\\n73.2\\nâ€“\\n54.8\\nâ€“\\n82.4\\nâ€“\\n61.8\\nâ€“\\n51.2\\nâ€“\\n30.3\\nâ€“\\n64.7\\nâ€“\\n35.5\\nâ€“\\nGeM-R101-ArcFace [53]\\nGLDv2-clean 2048\\nâ€“\\nâ€“\\n74.2\\nâ€“\\nâ€“\\nâ€“\\n84.9\\nâ€“\\nâ€“\\nâ€“\\n51.6\\nâ€“\\nâ€“\\nâ€“\\n70.3\\nâ€“\\nâ€“\\nâ€“\\nGLAM-GeM-R101-ArcFace baseline\\nGLDv2-clean\\n512\\n91.9\\n94.5\\n72.8 86.7 58.1 78.2 84.2 95.9 63.9 93.3 49.9 62.1 31.6 49.7 69.7 88.4 37.7 73.7\\n+local\\nGLDv2-clean\\n512\\n91.2\\n95.4\\n73.7 86.2 60.5 77.4 86.5 95.6 68.0 93.9 52.6 65.3 36.1 55.6 73.7 89.3 44.7 79.1\\n+global\\nGLDv2-clean\\n512\\n92.3\\n95.3\\n77.2 87.0 63.8 79.3 86.7 95.4 67.8 93.7 57.4 69.6 38.7 57.9 75.0 89.4 45.0 77.0\\n+global+local\\nGLDv2-clean\\n512\\n94.2\\n95.6\\n78.6 88.2 68.0 82.4 88.5 97.0 73.5 94.9 60.2 72.9 43.5 62.1 76.8 93.4 53.1 84.0\\nTable 4: mAP comparison of our GLAM against SOTA methods based on global descriptors without re-ranking. V16:\\nVGG16; R101: ResNet101. [O]: Off-the-shelf (pre-trained on ImageNet). âˆ—: dimension d = 256 [2]. mP: mP@10. Red:\\nbest results. Black bold: best previous methods. Blue: GLAM higher than previous methods. Weyand et al. [53] is the only\\nmodel other than ours trained on GLDv2-clean, while [28] is trained on GLDv1-noisy and compared in Table 3.\\ntoo small. To achieve best possible performance, we use\\nGLDv2-clean as a training set in the remaining experiments.\\nComparisons on same training set\\nIt is common to com-\\npare methods regardless of training sets as more become\\navailable, e.g., [35, 28]. Since GLDv2-clean is relatively\\nnew, Weyand et al. [53], which introduced the dataset, is the\\nonly study that has trained the same backbone with the same\\nsettings (ResNet101-GeM with ArcFace) on GLDv2-clean.\\nOur baseline is lower than [53], because our dimensinality is\\n512, while other models based on ResNet101 use 2048. Yet,\\nTable 3 shows that our best model trained on GLDv2-clean\\noutperforms [53] by a large margin. But the most impor-\\ntant comparison is with SOLAR [28], also based on self-\\nattention, which has trained ResNet101-GeM on GLDv1-\\nnoisy. On this training set, our best model clearly outper-\\nforms [28] despite lower dimensionality.\\nComparison with state of the art\\nTable 4 shows the\\nperformance of four variants of our model, i.e. baseline\\nwith or without local/global attention, and compares them\\nagainst state-of-the-art (SOTA) methods based on global de-\\nscriptors without re-ranking on the complete set of bench-\\nmarks, including distractors. Both local and global atten-\\ntion bring signiï¬cant gain over the baseline. The effect\\nof global is stronger, while the gain of the two is addi-\\ntive in the combination. The best results are achieved by\\nthe global-local attention network (baseline+global+local).\\nWith this model, we outperform previous best methods\\non most benchmarks except mP@10 on RParis (medium)\\nand RParis+R1M (medium), where we are outperformed\\nby [37, 35]. These results demonstrate that our approach is\\neffective for landmark image retrieval. Figure 7 shows some\\nMETHOD\\nOXF5K PAR6K RMEDIUM\\nRHARD\\nROxf RPar ROxf RPar\\nGLAM baseline\\n91.9\\n94.5\\n72.8\\n84.2\\n49.9\\n69.7\\n+local-channel\\n91.3\\n95.3\\n72.2\\n85.8\\n48.3\\n73.1\\n+local-spatial\\n91.0\\n95.1\\n72.1\\n85.3\\n48.3\\n71.9\\n+local\\n91.2\\n95.4\\n73.7\\n86.5\\n52.6\\n75.0\\n+global-channel\\n92.5\\n94.4\\n73.3\\n84.4\\n49.8\\n70.1\\n+global-spatial\\n92.4\\n95.1\\n73.2\\n86.3\\n50.0\\n72.7\\n+global\\n92.3\\n95.3\\n77.2\\n86.7\\n57.4\\n75.0\\n+global+local\\n94.2\\n95.6\\n78.6\\n88.5\\n60.2\\n76.8\\nTable 5: mAP comparison of spatial and channel variants\\nof our local (+local, subsection 3.1) and global (+global,\\nsubsection 3.1) attention modules to the baseline.\\nMETHOD\\nOXF5K\\nPAR6K\\nRMEDIUM\\nRHARD\\nROxf RPar ROxf RPar\\nCBAM style\\n93.8\\n95.7\\n75.6\\n88.4\\n53.3\\n76.8\\nGLAM (Ours)\\n94.2\\n95.6\\n78.6\\n88.5\\n60.2\\n76.8\\nTable 6: mAP comparison between CBAM style and our\\nlocal spatial attention.\\nexamples of our ranking results.\\n4.4. Ablation study\\nOur ablation study uses the Google Landmark v2 clean\\ndataset (GLDv2-clean) [53] for training, which is shown to\\nbe the most effective in Table 3.\\n7\\nMETHOD\\nOXF5K\\nPAR6K\\nRMEDIUM\\nRHARD\\nROxf\\nRPar\\nROxf\\nRPar\\nConcatenate\\n89.5\\n95.1\\n73.6\\n86.5\\n54.0\\n73.7\\nSum (Ours)\\n94.2\\n95.6\\n78.6\\n88.5\\n60.2\\n76.8\\nTable 7: mAP comparison between weighted concatenation\\nand weighted average for feature fusion.\\nMETHOD\\nOXF5K PAR6K\\nRMEDIUM\\nRHARD\\nROxf RPar ROxf RPar\\nFixed-size\\n76.1\\n82.6\\n55.7\\n68.4\\n29.2\\n47.5\\nGroup-size (Ours)\\n94.2\\n95.6\\n78.6\\n88.5\\n60.2\\n76.8\\nTable 8: mAP comparison between ï¬xed-size (224 Ã— 224)\\nand group-size sampling methods.\\nQUERY DATABASE OXF5K PAR6K RMEDIUM\\nRHARD\\nROxf RPar ROxf RPar\\nSingle\\nSingle\\n93.3\\n95.2\\n76.9\\n87.1\\n58.6\\n74.7\\nMulti\\nSingle\\n93.9\\n95.4\\n78.0\\n87.7\\n59.0\\n75.5\\nSingle\\nMulti\\n93.6\\n95.6\\n77.0\\n87.8\\n57.1\\n76.0\\nMulti\\nMulti\\n94.2\\n95.6\\n78.6\\n88.5\\n60.2\\n76.8\\nTable 9: mAP comparison of using multiresolution repre-\\nsentation (Multi) or not (Single) on query or database.\\nEffect of attention modules\\nWe ablate the effect of our\\nlocal and global attention networks as well as their com-\\nbination. Table 5 shows the results, which are more ï¬ne-\\ngrained than those of Table 4. In particular, it shows the ef-\\nfect of the channel and spatial variants of both local and\\nglobal attention. We observe that, when used alone, the\\nchannel and spatial variants of local attention are harmful\\nin most cases. Even the combination, baseline+local, is not\\nalways effective. By contrast, when used alone, the channel\\nand spatial variants of global attention are mostly beneï¬cial,\\nespecially the latter. Their combination, baseline+global, is\\nimpressive, bringing gain of up to 7.5%. Importantly, the\\ncombination baseline+global+local improves further by up\\nto another 2.8%. This result shows the necessity of local\\nattention in the ï¬nal model.\\nCBAM vs. our local spatial attention\\nWe experiment\\nwith the local spatial attention of CBAM [54]. CBAM ap-\\nplies average and max-pooling to input features and con-\\ncatenates the two for spatial attention. We apply this vari-\\nant to our local spatial attention module for comparison.\\nFor the CBAM style module, we keep the overall design\\nof our module as shown in Figure 3, but apply average and\\nmax-pooling to each of the four convolutional layer outputs\\nbefore concatenation. Table 6 shows that the CBAM style\\nmodule is considerably worse than ours on all benchmarks\\nexcept Paris6k, where it is only slightly better.\\nConcatenation vs. sum for feature fusion\\nWe use a\\nsoftmax-based weighted average of local and global atten-\\ntion feature maps with the original feature map (7). Here,\\nwe compare this weighted average with weighted concate-\\nnation, where concatenation replaces the sum operation\\nin (7). As shown in Table 7, the weighted average outper-\\nforms the weighted concatenation.\\nFixed-size vs. group-size sampling\\nNumerous studies\\nhave proposed methods for constructing batches according\\nto image size for efï¬cient training. For instance, Gordo et\\nal. [16], DELF [29], and Yokoo et al. [56] employed dif-\\nferent image sizes per batch for training instead of a single\\nï¬xed size. We adopt the method of Yokoo et al., which con-\\nstructs a batch with images of similar aspect ratio, so that\\nthe images can be resized to a size with an aspect ratio that\\nis similar to their own. We call this method group-size sam-\\npling. Table 8 compares ï¬xed-size (224 Ã— 224) with group-\\nsize sampling. We observe that maintaining aspect ratios by\\nusing dynamic input sizes is much more effective.\\nMulti-resolution\\nWe use the multi-resolution representa-\\ntion [16] for the ï¬nal feature of an image at inference time.\\nThis method: (1) resizes an image into multiple scales; (2)\\nextracts features from the resized images; and (3) averages\\nthe features to obtain the ï¬nal feature of the image. The\\nmethod is applied to both query and database images to en-\\nhance ranking results, especially for small target objects.\\nTable 9 compares the four cases of applying this method or\\nnot to query or database images.\\n5. Conclusion\\nWe have introduced a novel approach that extracts global\\nand local contextual information using attention mecha-\\nnisms for instance-level image retrieval. It is manifested as\\na network architecture consisting of global and local atten-\\ntion components, each operating on both spatial and chan-\\nnel dimensions. This constitutes a comprehensive study and\\nempirical evaluation of all four forms of attention that have\\npreviously been studied only in isolation. Our ï¬ndings indi-\\ncate that the gain (or loss) brought by one form of attention\\nalone strongly depends on the presence of the others, with\\nthe maximum gain appearing when all forms are present.\\nThe output is a modiï¬ed feature tensor that can be used in\\nany way, for instance with local feature detection instead of\\nspatial pooling for image retrieval.\\nWith the advent of vision transformers [12, 58] and their\\nrecent application to image retrieval [13], attention is ex-\\npected to play a more and more signiï¬cant role in vi-\\nsion. According to our classiï¬cation, transformers perform\\nglobal spatial attention alone. It is of great interest to in-\\nvestigate the role of the other forms of attention, where our\\n8\\napproach may yield a basic building block of such archi-\\ntectures. One may even envision an extension to language\\nmodels, where transformers originate from [50].\\nReferences\\n[1] Relja ArandjeloviÂ´c, Petr Gronat, Akihiko Torii, Tomas Pa-\\njdla, and Josef Sivic.\\nNetVLAD: CNN architecture for\\nweakly supervised place recognition. In CVPR, 2016. 2\\n[2] Artem Babenko and Victor Lempitsky. Aggregating Local\\nDeep Features for Image Retrieval. In ICCV, 2015. 1, 2, 7\\n[3] Artem Babenko, Anton Slesarev, Alexandr Chigorin, and\\nVictor Lempitsky.\\nNeural Codes for Image Retrieval.\\nIn\\nECCV, 2014. 1, 2, 5\\n[4] Irwan Bello, Barret Zoph, Ashish Vaswani, Jonathon Shlens,\\nand Quoc V. Le.\\nAttention augmented convolutional net-\\nworks. In ICCV, 2019. 2, 3\\n[5] Bingyi Cao, AndrÂ´e Araujo, and Jack Sim. Unifying deep\\nlocal and global features for image search. In ECCV, 2020.\\n2, 3, 7\\n[6] Yue Cao, Jiarui Xu, Stephen Lin, Fangyun Wei, and Han Hu.\\nGCNet: Non-Local Networks Meet Squeeze-Excitation Net-\\nworks and Beyond. In ICCV, 2019. 2\\n[7] Liang-Chieh Chen, George Papandreou, Florian Schroff, and\\nHartwig Adam. Rethinking atrous convolution for seman-\\ntic image segmentation. arXiv preprint arXiv:1706.05587,\\n2017. 4\\n[8] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Ge-\\noffrey Hinton. A simple framework for contrastive learning\\nof visual representations. In ICML, 2020. 1\\n[9] Yunpeng Chen, Yannis Kalantidis, Jianshu Li, Shuicheng\\nYan, and Jiashi Feng. AË†2-nets: Double attention networks.\\nIn NeurIPS, 2018. 1, 2, 3, 4\\n[10] Jiankang Deng, Jia Guo, Niannan Xue, and Stefanos\\nZafeiriou. ArcFace: Additive Angular Margin Loss for Deep\\nFace Recognition. In CVPR, 2019. 6\\n[11] Michael Donoser and Horst Bischof. Diffusion Processes for\\nRetrieval Revisited. In CVPR, 2013. 1, 2, 6\\n[12] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,\\nDirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,\\nMostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-\\nvain Gelly, et al. An image is worth 16x16 words: Trans-\\nformers for image recognition at scale.\\narXiv preprint\\narXiv:2010.11929, 2020. 8\\n[13] Alaaeldin El-Nouby, Natalia Neverova, Ivan Laptev, and\\nHervÂ´e JÂ´egou.\\nTraining vision transformers for image re-\\ntrieval. Technical report, 2021. 8\\n[14] Zilin Gao, Jiangtao Xie, Qilong Wang, and Peihua Li. Global\\nsecond-order pooling convolutional networks.\\nIn CVPR,\\n2019. 2, 3, 4\\n[15] Albert Gordo, Jon Almazan, Jerome Revaud, and Diane Lar-\\nlus. Deep image retrieval: Learning global representations\\nfor image search. In ECCV, 2016. 2\\n[16] Albert Gordo, Jon Almazan, Jerome Revaud, and Diane Lar-\\nlus. End-to-end learning of deep visual representations for\\nimage retrieval. IJCV, 2017. 1, 2, 5, 6, 7, 8\\n[17] Yinzheng Gu, Chuanpeng Li, and Jinbin Xie.\\nAttention-\\naware generalized mean pooling for image retrieval. arXiv\\npreprint arXiv:1811.00202, 2018. 2, 3, 7\\n[18] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.\\nDeep residual learning for image recognition.\\nIn CVPR,\\n2016. 6\\n[19] Jie Hu, Li Shen, Samuel Albanie, Gang Sun, and Andrea\\nVedaldi. Gather-excite: Exploiting feature context in con-\\nvolutional neural networks. In NeurIPS, 2018. 2\\n[20] Jie Hu, Li Shen, Samuel Albanie, Gang Sun, and Enhua Wu.\\nSqueeze-and-Excitation Networks. In CVPR, 2018. 1, 2\\n[21] Ahmet Iscen, Giorgos Tolias, Yannis Avrithis, Teddy Furon,\\nand Ondrej Chum. Efï¬cient diffusion on region manifolds:\\nRecovering small objects with compact cnn representations.\\nIn CVPR, 2017. 2, 6\\n[22] H. Jegou, F. Perronnin, M. Douze, J. Sanchez, P. Perez, and\\nC. Schmid. Aggregating local image descriptors into com-\\npact codes. PAMI, (99):1â€“1, 2011. 2\\n[23] Albert Jimenez, Jose M. Alvarez, and Xavier GirÂ´o-i-Nieto.\\nClass weighted convolutional features for visual instance\\nsearch. In BMVC, 2017. 2, 3\\n[24] Yannis Kalantidis, Clayton Mellina, and Simon Osindero.\\nCrossdimensional weighting for aggregated deep convolu-\\ntional features. In ECCV, 2016. 1, 2, 3, 7\\n[25] Hyo Jin Kim, Enrique Dunn, and Jan-Michael Frahm.\\nLearned Contextual Feature Reweighting for Image Geo-\\nLocalization. In CVPR, 2017. 1, 2, 3\\n[26] Sungyeon Kim, Dongwon Kim, Minsu Cho, and Suha Kwak.\\nProxy anchor loss for deep metric learning. In CVPR, 2020.\\n1\\n[27] David G. Lowe.\\nDistinctive image features from scale-\\ninvariant keypoints. In IJCV, 2004. 1, 2\\n[28] Tony Ng, Vassileios Balntas, Yurun Tian, and Krystian\\nMikolajczyk. SOLAR: Second-Order Loss and Attention for\\nImage Retrieval. In ECCV, 2020. 1, 2, 3, 5, 6, 7\\n[29] Hyeonwoo Noh, Andre Araujo, Jack Sim, Tobias Weyand,\\nand Bohyung Han. Large Scale Image Retrieval with Atten-\\ntive Deep Local Features. In ICCV, 2017. 1, 2, 3, 5, 6, 8\\n[30] Hyun Oh Song, Yu Xiang, Stefanie Jegelka, and Silvio\\nSavarese. Deep metric learning via lifted structured feature\\nembedding. In CVPR, 2016. 1\\n[31] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer,\\nJames Bradbury, Gregory Chanan, Trevor Killeen, Zeming\\nLin, Natalia Gimelshein, Luca Antiga, Alban Desmaison,\\nAndreas KÂ¨opf, Edward Yang, Zach DeVito, Martin Raison,\\nAlykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu\\nFang, Junjie Bai, and Soumith Chintala. PyTorch: An im-\\nperative style, high-performance deep learning. In NeurIPS,\\n2019. 5\\n[32] James Philbin, Ondrej Chum, Michael Isard, Josef Sivic, and\\nAndrew Zisserman. Object retrieval with large vocabularies\\nand fast spatial matching. In CVPR, 2007. 2, 5\\n[33] James Philbin, Ondrej Chum, Michael Isard, Josef Sivic, and\\nAndrew Zisserman. Lost in quantization:Improving particu-\\nlar object retrieval in large scale image databases. In CVPR,\\n2008. 5\\n9\\n[34] Tobias PlÂ¨otz and Stefan Roth. Neural nearest neighbors net-\\nworks. In NeurIPS, 2018. 2, 3\\n[35] Filip RadenoviÂ´c, Ahmet Iscen, Giorgos Tolias, Yannis\\nAvrithis, and OndË‡rej Chum. Revisiting Oxford and Paris:\\nLarge-Scale Image Retrieval Benchmarking. In CVPR, 2018.\\n5, 6, 7\\n[36] Filip RadenoviÂ´c, Giorgos Tolias, and OndË‡rej Chum. CNN\\nimage retrieval learns from BoW: Unsupervised ï¬ne-tuning\\nwith hard examples. In ECCV, 2016. 2, 7\\n[37] Filip RadenoviÂ´c, Giorgos Tolias, and OndË‡rej Chum. Fine-\\nTuning CNN Image Retrieval with No Human Annotation.\\nIn TPAMI, 2019. 1, 2, 5, 6, 7\\n[38] Ali Sharif Razavian, Josephine Sullivan, Stefan Carlsson,\\nand Atsuto Maki. Visual Instance Retrieval with Deep Con-\\nvolutional Networks. In CoRR, 2015. 2\\n[39] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, San-\\njeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy,\\nAditya Khosla, Michael Bernstein, Alexander C. Berg, and\\nLi Fei-Fei. ImageNet Large Scale Visual Recognition Chal-\\nlenge. In International booktitle of Computer Vision, 2015.\\n5\\n[40] Oriane SimÂ´eoni, Yannis Avrithis, and Ondrej Chum. Local\\nfeatures and visual words emerge in activations. In CVPR,\\n2019. 2, 6\\n[41] O. SimÂ´eoni, A. Iscen, G. Tolias, Y. Avrithis, and O. Chum.\\nGraph-based particular object discovery. Machine Vision and\\nApplications, 30(2):243â€“254, 3 2019. 3\\n[42] Jake Snell, Kevin Swersky, and Richard S. Zemel. Prototyp-\\nical networks for few-shot learning. In NeurIPS, 2017. 1\\n[43] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet,\\nScott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent\\nVanhoucke, and Andrew Rabinovich.\\nGoing deeper with\\nconvolutions. In CVPR, 2015. 3\\n[44] Mingxing Tan, Ruoming Pang, and Quoc V. Le. Efï¬cientDet:\\nScalable and Efï¬cient Object Detection. In CVPR, 2020. 5\\n[45] Marvin Teichmann, Andre Araujo, Menglong Zhu, and Jack\\nSim.\\nDetect-to-retrieve: Efï¬cient regional aggregation for\\nimage search. In CVPR, 2019. 2\\n[46] Giorgios Tolias, Yannis Avrithis, and HervÂ´e JÂ´egou. To aggre-\\ngate or not to aggregate: Selective match kernels for image\\nsearch. In ICCV, 2013. 2\\n[47] Giorgos Tolias, Tomas Jenicek, and OndË‡rej Chum. Learn-\\ning and aggregating deep local descriptors for instance-level\\nrecognition. In ECCV, 2020. 2, 3\\n[48] Giorgos Tolias, Ronan Sicre, and HervÂ´e JÂ´egou. Particular ob-\\nject retrieval with integral max-pooling of CNN activations.\\nIn ICLR, 2016. 2\\n[49] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko-\\nreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia\\nPolosukhin. Attention is all you need. In NeurIPS, 2017. 4\\n[50] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko-\\nreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia\\nPolosukhin. Attention is all you need. In NeurIPS, 2017. 9\\n[51] Qilong Wang, Banggu Wu, Pengfei Zhu, Peihua Li, Wang-\\nmeng Zuo, and Qinghua Hu.\\nECA-Net: Efï¬cient Chan-\\nnel Attention for Deep Convolutional Neural Networks. In\\nCVPR, 2020. 2, 3, 4\\n[52] Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaim-\\ning He. Non-local Neural Networks. In CVPR, 2018. 1, 2,\\n3, 4\\n[53] Tobias Weyand, Andre Araujo, Bingyi Cao, and Jack Sim.\\nGoogle Landmarks Dataset v2 - A Large-Scale Benchmark\\nfor Instance-Level Recognition and Retrieval.\\nIn CVPR,\\n2020. 1, 2, 5, 6, 7\\n[54] Sanghyun Woo, Jongchan Park, Joon-Young Lee, and In So\\nKweon. CBAM: Convolutional Block Attention Module. In\\nECCV, 2018. 1, 2, 4, 8\\n[55] Fan Yang, Ryota Hinami, Yusuke Matsui, Steven Ly, and\\nShinâ€™ichi Satoh. Efï¬cient image retrieval via decoupling dif-\\nfusion into online and ofï¬‚ine processing. In AAAI, 2019. 2,\\n6\\n[56] Shuhei Yokoo, Kohei Ozaki, Edgar Simo-Serra, and Satoshi\\nIizuka. Two-stage Discriminative Re-ranking for Large-scale\\nLandmark Retrieval. In arXiv:2003.11211, 2020. 6, 8\\n[57] Fisher Yu, Vladlen Koltun, and Thomas Funkhouser. Dilated\\nresidual networks. In CVPR, 2017. 4\\n[58] Li Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi,\\nFrancis EH Tay, Jiashi Feng, and Shuicheng Yan. Tokens-\\nto-token vit: Training vision transformers from scratch on\\nimagenet. arXiv preprint arXiv:2101.11986, 2021. 8\\n[59] Hengshuang Zhao, Jiaya Jia, and Vladlen Koltun. Exploring\\nself-attention for image recognition. In CVPR, 2020. 2, 3\\n10\\n'),\n",
       " Document(metadata={'Published': '2023-06-02', 'Title': 'RITA: Group Attention is All You Need for Timeseries Analytics', 'Authors': 'Jiaming Liang, Lei Cao, Samuel Madden, Zachary Ives, Guoliang Li', 'Summary': \"Timeseries analytics is of great importance in many real-world applications.\\nRecently, the Transformer model, popular in natural language processing, has\\nbeen leveraged to learn high quality feature embeddings from timeseries, core\\nto the performance of various timeseries analytics tasks. However, the\\nquadratic time and space complexities limit Transformers' scalability,\\nespecially for long timeseries. To address these issues, we develop a\\ntimeseries analytics tool, RITA, which uses a novel attention mechanism, named\\ngroup attention, to address this scalability issue. Group attention dynamically\\nclusters the objects based on their similarity into a small number of groups\\nand approximately computes the attention at the coarse group granularity. It\\nthus significantly reduces the time and space complexity, yet provides a\\ntheoretical guarantee on the quality of the computed attention. The dynamic\\nscheduler of RITA continuously adapts the number of groups and the batch size\\nin the training process, ensuring group attention always uses the fewest groups\\nneeded to meet the approximation quality requirement. Extensive experiments on\\nvarious timeseries datasets and analytics tasks demonstrate that RITA\\noutperforms the state-of-the-art in accuracy and is significantly faster --\\nwith speedups of up to 63X.\"}, page_content='RITA: Group Attention is All You Need for Timeseries Analytics\\nJiaming Liang\\nUniversity of Pennsylvania\\nPhiladelphia, PA, USA\\nliangjm@seas.upenn.edu\\nLei Caoâˆ—\\nMassachusetts Institute of Technology\\nCambridge, MA, USA\\nlcao@csail.mit.edu\\nSamuel Madden\\nMassachusetts Institute of Technology\\nCambridge, MA, USA\\nmadden@csail.mit.edu\\nZachary Ives\\nUniversity of Pennsylvania\\nPhiladelphia, PA, USA\\nzives@cis.upenn.edu\\nGuoliang Li\\nTsinghua University\\nBeijing, China\\nliguoliang@tsinghua.edu.cn\\nABSTRACT\\nTimeseries analytics is of great importance in many real-world\\napplications. Recently, the Transformer model, popular in natu-\\nral language processing, has been leveraged to learn high quality\\nfeature embeddings from timeseries, core to the performance of\\nvarious timeseries analytics tasks. However, the quadratic time and\\nspace complexities limit Transformersâ€™ scalability, especially for\\nlong timeseries. To address these issues, we develop a timeseries an-\\nalytics tool, RITA, which uses a novel attention mechanism, named\\ngroup attention, to address this scalability issue. Group attention dy-\\nnamically clusters the objects based on their similarity into a small\\nnumber of groups and approximately computes the attention at\\nthe coarse group granularity. It thus significantly reduces the time\\nand space complexity, yet provides a theoretical guarantee on the\\nquality of the computed attention. The dynamic scheduler of RITA\\ncontinuously adapts the number of groups and the batch size in the\\ntraining process, ensuring group attention always uses the fewest\\ngroups needed to meet the approximation quality requirement. Ex-\\ntensive experiments on various timeseries datasets and analytics\\ntasks demonstrate that RITA outperforms the state-of-the-art in\\naccuracy and is significantly faster â€” with speedups of up to 63X.\\n1\\nINTRODUCTION\\nMotivation. Many data driven applications involve processing\\nmassive timeseries data, including IoT [11], medical AI [14], stock\\nmarket [27], and so on. As such, there is a great need for timeseries\\nanalytics, such as forecasting [8], classification [20], clustering [31],\\nsimilarity search [39], and anomaly detection [50], with applications\\nranging from automatically diagnosing diseases [5], recognizing\\nhuman activities [29], to stopping financial fraud [59].\\nEffective feature extraction [40] lies at the core of almost all\\nthese timeseries analytics tasks. Recently researchers [61] have\\nstarted leveraging the self-supervised pre-training methodology of\\nTransformers [4, 16, 52], which have proven remarkably successful\\nin natural language processing (NLP), to automatically learn high\\nquality feature embeddings from timeseries. In NLP, self-supervised\\npre-training exploits the sequential patterns (correlations) among\\nthe words in sentences to produce contextualized feature embed-\\ndings. Timeseries bear similarity to natural language, because in\\ntimeseries data the sequential order among the values (stock price,\\nvolume, etc.) over time matters. That is, each value is highly cor-\\nrelated with other values observed before or after it. Therefore,\\nâˆ—Corresponding Author\\npre-training a Transformer model which takes the correlations\\namong different observations into account is a natural idea to learn\\nfeature embeddings from timeseries. Indeed, the experiments in [61]\\nconfirm that Transformer-based methods outperform traditional\\ntimeseries analytics techniques.\\nHowever, existing work [61] that directly applies Transformers\\nto learn features from timeseries data have been shown not to be\\nscalable to long timeseries [30]. The idea of self-attention [52] is\\ncentral to pre-training methods in NLP: It computes pairwise cor-\\nrelations among different semantic units in a sequence (in NLP, a\\nsentence); as such, it has quadratic time and space complexity in\\nthe length of the input sequence. Such an approach places limits on\\nthe modelâ€™s scalability, especially when handling large sequences,\\nwhich are common in real-world timeseries applications such as\\nIoT, medical AI, and finance [6, 34, 62]. Predictions about timeseries\\nmay need to look at months or years of historical data to make ac-\\ncurate predictions, spanning hundreds of thousands of samples. As\\nan example, in collaboration with a research hospital we have been\\ndeveloping a seizure classifier that automatically detects seizures\\nbased on EEG signals (timeseries) collected during the clinical ob-\\nservation of patients. As seizures last only a few seconds, we chunk\\nlong EEG data into many 2 second segments and detect seizures at\\na segment level. However, the classification of a particular segment\\ndepends on up to 12 hours of prior signal to determine if one 2\\nsecond segment indicates seizure or not, because seizure diagnosis\\nneeds to consider long-term trends in the EEG data [6]. The number\\nof segments in 12 hours is more than 21k. This is far larger than\\nthe number of semantic units the typical NLP tasks expect. For\\nexample, BERT [16] limits the number of units to 512 and even\\nmassive models like GPT-3 [4] limit the number of units to 2048.\\nAlthough in NLP some lower-complexity methods have been\\nproposed to approximately compute self-attention [10, 26, 54], their\\nperformance degrades dramatically when used on timeseries, due\\nto the gap between natural language and timeseries, as we will\\nshow in our experiments.\\nProposed Approach. To tackle the aforementioned problem, we\\ndevelop RITA, a Transformer-based timeseries analytics tool, which\\nuses a novel attention mechanism, called group attention, to scale\\nto long timeseries.\\nLeveraging the periodicity of timeseries, RITA chunks the input\\ntimeseries into segments and dynamically clusters the segments\\ninto a small number (denoted as ð‘) of groups. Segments in the\\nsame group possess similar feature embeddings during the current\\ntraining iteration, thus enabling them to approximately share the\\n1\\narXiv:2306.01926v1  [cs.LG]  2 Jun 2023\\ncomputation of attention. As the timeseries increases in length,\\nmore sharing opportunities become available. RITA then computes\\nthe self-attention at a group level and produces a compressed group\\nattention matrix. In this way, group attention eliminates both com-\\nputation and memory bottlenecks in Transformer-style models and\\nthus more scalable to long timeseries.\\nHowever, making this idea effective and efficient in Transformer\\narchitectures is challenging for several reasons:\\nâ€¢ Efficiently Producing High Quality Feature Embeddings.\\nAlthough RITA computes the attention matrix at a group level, to\\npreserve the quality of the feature embeddings, it still has to pro-\\nduce different embeddings for different segments. This is because\\neven if some segments share the attention score temporally, it does\\nnot mean they should have the same feature embedding. However,\\nusing the group attention matrix, the existing self-attention mech-\\nanism will only produce a single feature vector for each group. A\\nnaive solution would be to restore the original attention matrix\\nfrom the group attention matrix. However, in this case we again\\nget an attention matrix with quadratic space complexity. Because\\nGPUs have limited memory, GPU memory will remain a bottleneck\\nin group attention.\\nâ€¢ The Number of Groups N. In RITA, the number of groups\\nð‘is a crucial factor that balances the speed up and the quality of\\nattention approximation. A small ð‘will lead to a large speedup,\\nbut the approximation errors can also be significant. On the other\\nhand, although a large ð‘tends to produce high-quality approxima-\\ntions, it inevitably slows down the training process. Therefore, an\\nappropriate ð‘is essential to the performance of group attention.\\nHowever, ð‘depends on the distributional properties of the dataset.\\nFurthermore, like the classical transformer models, RITA stacks\\nmultiple attention layers to produce better embeddings. Ideally,\\ndifferent layers should also use different values of ð‘. In addition,\\nduring the model training phrase, group attention should use dif-\\nferent values of ð‘at different iterations to adapt to the varying\\nfeature embeddings. This makes manually setting appropriate ð‘\\nalmost impossible.\\nâ€¢ Batch Size. Moreover, as we want to dynamically adjust ð‘\\nduring training, a fixed batch size is sub-optimal: as ð‘decreases,\\nthe memory usage of a single sample decreases. This allows a larger\\nbatch size which is beneficial, because: (1) it makes full use of GPU\\nmemory; (2) high-parallelism across the samples in a big batch\\nbrings better performance. Our experimental study shows that\\ndoubling the batch size reduces the training time by 30%, while still\\npreserving the quality of the model. Thus, RITA should dynamically\\nadjust batch size as ð‘changes.\\nTo address the above problems, we first propose an embedding\\naggregation strategy and a customized group softmax function to\\nreplace the classical softmax function [52]. Together they ensure\\nRITA is able to directly use the compressed attention matrix to\\nproduce different feature embeddings for different segments. We\\ntheoretically show the embeddings RITA produces in this way are\\nidentical to those produced by first re-storing the original large\\nattention matrix. Thus RITA is able to produce high quality embed-\\ndings without introducing extra overhead. Further, we design a GPU\\nfriendly algorithm to group the segments in parallel, effectively\\nminimizing the grouping cost.\\nP0\\nPosition\\nEmbedding\\nW1\\n+\\n+\\n+\\nWindow \\nEmbedding\\n+\\nE0\\nRaw\\nTimeseries\\nTime-aware \\nConvolution\\nW[CLS]\\nW2\\nâŠ—\\n.....\\nWn\\nP1\\nP2\\n.....\\nPn\\n.....\\nE1\\nE2\\nEn\\n.....\\nO0\\nO1\\nO2\\nOn\\n.....\\nRITA Encoder\\nScale & Input\\nFigure 1: RITA Architecture\\nSecond, we design an adaptive scheduler which dynamically de-\\ncides an appropriate ð‘for each group attention layer during the\\ntraining process. It starts with a large ð‘and iteratively merges\\ngroups that are similar to each other. Guided by an error bound on\\nthe approximated self-attention that users can tolerate, it automati-\\ncally determines if two groups are mergeable, performing merging\\nefficiently in a GPU-friendly way.\\nMoreover, we propose a learning-based method to model the\\ncorrelation between the number of groups ð‘and the batch size ðµ.\\nThis model is used to predict ðµfor a given ð‘when training RITA.\\nSpecifically, we first sample some ð‘values in a reasonable range.\\nFor each sampled ð‘, we find a batch size that consumes up to a\\ncertain percentage of GPU memory in a cost-efficient way. Using a\\nsmall set of mathematical functions as a prior, RITA learns a model\\nwith only a few <N, B> pairs as ground truth labels.\\nOur experiments on public timeseries benchmarks and the MGH\\nEEG data [6] confirm that RITA outperforms state-of-the-art meth-\\nods in accuracy on various timeseries analytics tasks, while our\\ngroup attention mechanism achieves a 63X speedup with much\\nless memory required, compared to existing self-attention mecha-\\nnisms [10, 52, 54].\\nContributions. The key contributions of this work include:\\nâ€¢ Our group attention mechanism leverages the periodicity of\\ntimeseries, reducing the time and space complexity of the self-\\nattention mechanism with accuracy guarantees, allowing RITA to\\nscale to long timeseries data.\\nâ€¢ Guided by an approximation error bound, our adaptive sched-\\nuler dynamically adapts the number of groups and the batch size\\nto the distribution properties of the evolving feature embeddings,\\nmaking group attention efficient and easily tunable.\\nâ€¢ We conduct experiments on various datasets and different ana-\\nlytics tasks, demonstrating that RITA is 4 to 63 times faster than\\nthe state-of-the-art while achieving better accuracy when handling\\nlong timeseries (length â‰¥2000).\\n2\\n2\\nBACKGROUND\\nWe provide some background on the canonical self-attention mod-\\nule in the Transformer[52]. A self-attention module takes ð‘›hidden\\nembedding vectors ð»âˆˆRð‘›âˆ—ð‘‘â„Žas input, then projects them to\\nqueries (ð‘„), keys (ð¾) and values (ð‘‰) and performs Scaled-dot Prod-\\nuct Attention, which given input hidden state ð», is computed by:\\nð‘„= ð»ð‘Šð‘„, ð¾= ð»ð‘Šð¾,ð‘‰= ð»ð‘Šð‘‰\\nð‘‚= ð´ð‘‰= ð‘†ð‘œð‘“ð‘¡ð‘€ð‘Žð‘¥( ð‘„ð¾ð‘‡\\nâˆšï¸\\nð‘‘ð‘˜\\n)ð‘‰\\n(1)\\nWhere ð‘Šð‘„âˆˆRð‘‘â„Žâˆ—ð‘‘ð‘˜,ð‘Šð¾âˆˆRð‘‘â„Žâˆ—ð‘‘ð‘˜,ð‘Šð‘‰âˆˆRð‘‘â„Žâˆ—ð‘‘ð‘£are projection\\nmatrices for generating ð‘„, ð¾,ð‘‰. ð‘„âˆˆRð‘›âˆ—ð‘‘ð‘˜is also regarded as the\\npacking of ð‘›query vectors {ð‘ž1, ...,ð‘žð‘›} with dimension ð‘‘ð‘˜into a\\nmatrix. ð¾âˆˆRð‘›âˆ—ð‘‘ð‘˜,ð‘‰âˆˆRð‘›âˆ—ð‘‘ð‘£are regarded as the packing of key\\nvectors {ð‘˜1, ...,ð‘˜ð‘›} and value vectors {ð‘£1, ..., ð‘£ð‘›} in the same way.\\nGiven a matrix ð‘€âˆˆRð¿âˆ—ð‘›, the softmax function normalizes ð‘€\\nto ensure the sum of each row equals to 1, as shown below.\\nð‘†ð‘œð‘“ð‘¡ð‘€ð‘Žð‘¥(ð‘€ð‘–,ð‘—) =\\nð‘’ð‘¥ð‘(ð‘€ð‘–,ð‘—)\\nÃð‘›âˆ’1\\nð‘˜=0 ð‘’ð‘¥ð‘(ð‘€ð‘–,ð‘˜)\\n(2)\\nNote the attention matrix A is an ð‘›Ã—ð‘›matrix, where ð‘›represents\\nthe number of elements in the input sequence (e.g. words in NLP).\\n3\\nRITA OVERVIEW\\nGiven a collection of unlabeled timeseries, RITA first pre-trains\\na Transformer-style model to produce high quality feature em-\\nbeddings for timeseries data. This pre-trained model is then used\\nto support various downstream tasks, similar to BERT [16]. Next,\\nwe overview the model architecture of RITA. We show how RITA\\nsupports various downstream tasks in Appendix A.7.\\nAs shown in Fig. 1, RITA is consist of two components: (1) Time-\\naware Convolution Layer (2) RITA Encoder.\\nTime-aware Convolution Layer fills the gap between timeseries\\nand natural language. Despite their high-level similarity, there is a\\nbig gap between timeseries and natural language. First, in natural\\nlanguage each word, as a discrete semantic unit, has an indepen-\\ndent meaning, while each element in a timeseries is a continuous,\\nnumerical value and does not necessarily constitute an independent\\nevent. Furthermore, the input sequences are single-channeled in\\nNLP, but often multi-channeled in timeseries (i.e., sensor data often\\nconsists of several related channels).\\nRITA leverages the classical convolution [28] strategy to solve\\nthis problem. Convolution is widely used to capture the local struc-\\ntures of an image. We use convolution to chunk one input timeseries\\ninto a sequence of windows and learn the local structure of each\\nwindow, similar to the discrete semantic units in natural language.\\nIt also discovers the correlations across different channels, thus\\nnaturally solving the multi-channel problem.\\nMore specifically, treating a multi-variate timeseries of length ð‘›\\nand withð‘švariables as an n Ã— m matrixð‘‡, RITA usesð‘‘convolution\\nkernels to chunkð‘‡into n windows and produce one d-dimensional\\nembedding per window using the convolution operation [28]. Each\\nconvolution kernel corresponds to a w Ã— m matrix, where ð‘¤defines\\nthe number of timestamps that each convolution kernel covers,\\nidentical to the window size in sliding window.\\nRITA Encoder functions as Transformer Encoder as described in\\nthe original Transformer work[52]. It takes the embeddings of ð‘›\\nsemantic units ð‘‹1,ð‘‹2, ...,ð‘‹ð‘›(ð‘‹ð‘–âˆˆð‘…ð‘‘) as input (e.g. embeddings of\\nð‘›windows for a timeseries), then models the correlations between\\nthe semantic units and outputs ð‘Œ1, ...,ð‘Œð‘›(ð‘Œð‘–âˆˆð‘…ð‘‘) as the context-\\naware embedding of each unit.\\nWhat makes RITA Encoder different from Transformer Encoder\\nis that: at the core of Transformer Encoder lies self-attention mech-\\nanism which incurs a ð‘‚(ð‘›2) time complexity and memory usage.\\nThis quadratic cost becomes prohibitive for long timeseries and\\nlimits the scalablity of Transformer-based models. To make the\\nattention computation efficient yet high-quality, we replace the\\ncanonical self-attention with our proposed group attention.\\nSelf-supervised Pretraining. Inspired by the â€œcloze textâ€ pre-\\ntraining task in NLP, we designed a mask-and-predict task as the\\npretraining task for our model. The timeseries is randomly masked\\nand the model should recover the masked values based on corre-\\nsponding contextual information.\\nTo be specific, we generate masks on time-stamps, with a mask\\nrate ð‘. The timeseries is scaled to be non-negative and the values\\nacross all the channels on the masked timestamps are set to be -1,\\nan impossible value on normal timestamps. Then the masked time-\\nseries is fed into RITA and the output representation is translated\\nto the recovered timeseries by a Transpose Convolution layer.\\n4\\nGROUP ATTENTION MECHANISM\\nGroup attention, a novel and efficient approximate attention mecha-\\nnism, addresses the performance bottleneck of self-attention in the\\nvanilla Transformer. In this section, we first introduce the frame-\\nwork of group attention and then theoretically establish the bound\\nof its approximation error.\\n4.1\\nThe Idea of Group Attention\\nAs periodicity is a natural property of timeseries [56], similar\\nwindows frequently occur. Similar windows result in similar\\nqueries/keys for attention computation, bringing opportunities for\\nsaving computation.\\nAs discussed in Sec. 2, ð´ð‘–ð‘—, the attention score of window ð‘–onto\\nwindow ð‘—, is determined by the inner product between the query\\nvector of window ð‘–and the key vector of window ð‘—, that is, ð‘žð‘–Â· ð‘˜ð‘—.\\nGiven another window ð‘¥, if window ð‘¥has the similar key vector\\nto window ð‘—, that is, ð‘˜ð‘—â‰ˆð‘˜ð‘¥, then ð‘žð‘–Â· ð‘˜ð‘—â‰ˆð‘žð‘–Â· ð‘˜ð‘¥. In other words,\\nð´ð‘–ð‘—â‰ˆð´ð‘–ð‘¥when ð‘˜ð‘—â‰ˆð‘˜ð‘¥.\\nThis observation inspires our group attention mechanism. That\\nis, we group the windows by their similarity in keys. Assuming\\nall windows in the same group have the same attention score onto\\nanother window ð‘˜, we then only compute the attention once by\\nusing one single key to represent this group, for example the centroid\\nof the group of keys. This thus saves significant computation cost.\\nBetter yet, after grouping ð‘›windows into ð‘groups, group atten-\\ntion compresses the attention matrix from anð‘›Ã—ð‘›matrix to anð‘›Ã—ð‘\\nmatrix. Because ð‘(number of groups) tends to be much smaller\\nthan ð‘›(number of windows) due to the periodicity of timeseries,\\ngroup attention consumes much less memory than the original\\nself-attention mechanism, successfully eliminating the memory\\nbottleneck. Note that it also doesnâ€™t hurt quality all that much, as\\nconfirmed in our experiments (Sec. 6.2).\\n3\\nGrouping\\nAverage\\nK\\nQ\\nMatMul\\nAttention Matrix\\nWeighted\\nSoftMax\\nV\\nSum\\nAggregate\\nTranspose\\nMatMul\\nOutput\\nQ \\nK \\nV\\nFigure 2: Group Attention\\n4.2\\nComputing the Output Feature Embedding\\nWe now discuss how to efficiently compute the output feature\\nembeddings using the small compressed group attention matrix.\\n4.2.1\\nProblem: Producing Embeddings w/ Group Attention Matrix\\nAs described in the Background, once we have acquired the at-\\ntention matrix ð´, canonical self-attention computes the output\\nembedding ð‘‚as O = AV. Because ð´is an ð‘›Ã— ð‘›matrix and ð‘‰is an\\nð‘›Ã—ð‘‘ð‘£matrix, the matrix product operation still produces an ð‘›Ã—ð‘‘ð‘£\\nmatrix ð‘‚. That is, it produces a ð‘‘ð‘£dimensional feature vector for\\neach window. However, our group attention will produce an ð‘›Ã— ð‘\\nattention matrix e\\nð´, where ð‘corresponds to the number of groups.\\nIn this case the matrix product will produce a ð‘Ã—ð‘‘ð‘£matrix e\\nð‘‚. That\\nis, it produces a feature vector for each group. However, our goal\\nis to produce different embeddings for different windows, because\\neven if some windows share the attention score temporally, it does\\nnot mean they should have the same feature embedding.\\nA Naive Solution. A naive solution would be to restore the full\\nattention matrix ð´from the group attention matrix e\\nð´. For example,\\ngiven one group composed of ð‘¤ð‘–ð‘›ð‘–and ð‘¤ð‘–ð‘›ð‘—, we map its group\\nattention vector in e\\nð´into two rows that correspond to ð‘¤ð‘–ð‘›ð‘–and\\nð‘¤ð‘–ð‘›ð‘—in ð´. However, in this case we again get a ð‘›Ã— ð‘›attention\\nmatrix; and GPU memory remains a bottleneck in group attention.\\n4.2.2\\nSolution: Embedding Aggregation and Group SoftMax\\nUsing an embedding aggregation operation and a group softmax\\nfunction, RITA produces ð‘›embeddings without restoring the full\\nattention matrix. Fig. 2 shows the workflow of group attention.\\nEmbedding Aggregation. The idea is inspired by the observation\\non the matrix product operation O = AV conducted on the fully\\nrestored attention matrix ð´.\\nGiven an elementð‘‚ð‘–,ð‘—ofð‘‚corresponding to the ð‘—ð‘¡â„Ždimension of\\nð‘¤ð‘–ð‘›ð‘–â€™s feature vector,ð‘‚ð‘–,ð‘—= ð‘Žð‘–Â·ð‘£ð‘—, where vector ai âˆˆRn denotes the\\nð‘–ð‘¡â„Žrow of the attention matrix ð´and vector vj âˆˆRn denotes the ð‘—ð‘¡â„Ž\\ndimension of all the ð‘›feature vectors. Given ai =< a1\\ni , a2\\ni , Â· Â· Â· , an\\ni >\\nand vj =< v1\\nj , v2\\nj , Â· Â· Â· , vn\\nj >, ð‘‚ð‘–,ð‘—= Ãn\\nk=1 ak\\ni vk\\nj .\\nAs an example, assume ð‘¤ð‘–ð‘›1 and ð‘¤ð‘–ð‘›2 belong to the same group\\nðº1. Then ð‘Ž1\\nð‘–= ð‘Ž2\\nð‘–= eð‘Ž1\\nð‘–, where eð‘Ž1\\nð‘–âˆˆe\\nð´corresponds to the attention\\nof group ðº1 onto ð‘¤ð‘–ð‘›ð‘–. Therefore, ð‘Ž1\\nð‘–ð‘£1\\nð‘—+ ð‘Ž2\\nð‘–ð‘£2\\nð‘—= eð‘Ž1\\nð‘–(ð‘£1\\nð‘—+ ð‘£2\\nð‘—).\\nAs an immediate generalization of the above analysis, if we ag-\\ngregate up the windows that belong to the same group and convert\\nthe n-dimensional feature vector ð‘£ð‘—into a ð‘-dimensional group fea-\\nture vectoreð‘£ð‘—beforehand, we could directly use the group attention\\nvector eð‘Žð‘–and the group feature vector eð‘£ð‘—to compute ð‘‚ð‘–,ð‘—.\\nUsing embedding aggregation, RITA is able to produce the fea-\\nture embedding e\\nð‘‚that is identical to the embedding ð‘‚produced\\nby using the full attention matrix ð´and the embedding matrix ð‘‰.\\nGroup Softmax Function. In canonical self-attention the atten-\\ntion matrix ð´is computed as ð´= SoftMax( QKT\\nâˆš\\ndk ). To compute ð´,\\nwe have to first compute ð‘„ð¾ð‘‡(denoted as ð‘ƒ) which is an ð‘›Ã— ð‘›\\nmatrix. Then normalizing the ð‘ƒmatrix with softmax produces the\\nattention matrix ð´.\\nGroup attention follows the same procedure. But after grouping\\nkeys into eð¾, ð‘„eð¾ð‘‡produces an ð‘›Ã— ð‘matrix eð‘ƒ. Due to the non-\\nlinearity of the softmax function, applying softmax directly on eð‘ƒ\\nwill result in a group attention matrix e\\nð´from which we are not able\\nto recover a full attention matrix that is identical to first restoring\\neð‘ƒto ð‘ƒand then applying softmax on ð‘ƒ. The ð´matrix produced\\nby the latter is desirable, as we want to approximate the original\\nattention matrix as accurately as possible. However, restoring the\\nsmall ð‘›Ã— ð‘eð‘ƒmatrix is not memory efficient, as it will end up with\\na full ð‘›Ã— ð‘›matrix ð‘ƒ.\\nTo solve the above problems, we introduce a new group softmax\\nfunction to replace the original softmax function (Eq. 2).\\nðºð‘Ÿð‘œð‘¢ð‘ð‘†ð‘œð‘“ð‘¡ð‘€ð‘Žð‘¥(g\\nð‘ƒð‘–,ð‘—) =\\nð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘—)\\nÃð‘âˆ’1\\nð‘˜=0 ð‘ð‘œð‘¢ð‘›ð‘¡ð‘˜ð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘˜)\\n(3)\\nIn Eq. 3, ð‘ð‘œð‘¢ð‘›ð‘¡ð‘˜represents the number of windows that Group\\nðºð‘˜contains. Compared to the original softmax, our group softmax\\nconsiders each group ðºð‘˜as ð‘ð‘œð‘¢ð‘›ð‘¡ð‘˜elements and counts it ð‘ð‘œð‘¢ð‘›ð‘¡ð‘˜\\ntimes when summing up the exponential of each groupâ€™s ð‘ƒð‘–,ð‘˜. In\\nthis way, the group softmax function operating on the small eð‘ƒ\\nmatrix will produce exactly the same result to the softmax function\\noperating on the full ð‘ƒmatrix.\\nTheoretical Guarantee. In Appendix A.4, we prove that the group\\nsoftmax function and the embedding aggregation operation produce\\nthe same output feature embedding with the naive method that has\\nto first restore the big full attention matrix.\\nWe show an efficient implementation of the embedding aggrega-\\ntion operation and group softmax function in Appendix A.2, Alg. 1.\\nTime Complexity. The time complexity of Alg. 1 is ð‘‚(ð‘›ð‘ð‘‘) and\\nthe space complexity isð‘‚(ð‘›ð‘), while the time and space complexity\\nof the original self-attention mechanism are ð‘‚(ð‘›2ð‘‘) and ð‘‚(ð‘›2).\\n4.3\\nError Bound\\nGroup attention produces a group attention matrix e\\nð´which approxi-\\nmates the attention matrixð´produced by the classical self-attention\\nwith a bounded error, as shown in Lemma 1.\\nLemma 1. Let ð‘…be the radius of the ball where all key vectors\\nlive; eð‘˜ð‘–be the representative of the group that contains key ð‘˜ð‘–. Let ð´\\ndenote the full attention matrix restored from e\\nð´. Suppose the distance\\nbetween eð‘˜ð‘–and ð‘˜ð‘–(||ekð‘–âˆ’kð‘–||) satisfies: ||ekð‘–âˆ’kð‘–|| â‰¤d.\\nThen âˆ€ðœ–> 1, if d â‰¤ln(ðœ–)\\n2R , 1\\nðœ–â‰¤Ai,j\\nAi,j â‰¤ðœ–\\nLemma 1 shows that the error bound ðœ–of the group attention is\\ndetermined by the distance ð‘‘. As discussed in Sec. 5.1, it inspires\\nus to design a strategy to dynamically determine the number of\\ngroups ð‘â€“ the most critical parameter of group attention. Please\\nrefer to Appendix A.5 for the proof.\\n4\\n4.4\\nGPU Friendly Grouping Method\\nIn this section, we discuss the implementation of a grouping method.\\nTo make group attention efficient and effective, the grouping\\nmethod has to satisfy the following requirements:\\n(1) Tight distance bound: to ensure the approximation quality,\\nthe distance between each key and its group representative should\\nbe minimized according to Lemma 1.\\n(2) Lightweight: to ensure the performance gain, the grouping\\nmethod must be lightweight, at worst not exceeding the complexity\\nof group attention itself (ð‘‚(ð‘ð‘›)).\\n(3) GPU friendly: to take advantage of GPUs, we prefer a group-\\ning method that mainly consists of matrix operations, which can\\nbe efficiently executed on a GPU.\\nTo satisfy the above requirements, after thorough investigation\\non various clustering algorithms, we design a GPU friendly K-\\nmeans [35] as the grouping method.\\nFirst, K-means minimizes the overall distance between any object\\nand its cluster center, hence naturally satisfying Requirement 1.\\nSecond, given ð‘centers, in each iteration the time and space\\ncomplexity of K-means is ð‘‚(ð‘›ð‘). Usually, the iteration goes until\\nconvergence. However, we observe that rather than seeking a per-\\nfect K-means clustering, training a few iterations is sufficient to\\nget a good grouping for group attention, because typically the later\\niterations only slightly update the clustering and group attention\\nis robust to such imperfection.\\nThird, we design a GPU-friendly implementation of K-means.\\nThe performance bottleneck of K-means comes from the dis-\\ntance computation between each vector and its center, that is,\\n|vi âˆ’cj| =\\nâˆšï¸ƒ\\n(vi âˆ’cj)2, i âˆˆ[1, n], j âˆˆ[1, N]. The performance bot-\\ntleneck is ð‘£ð‘–âˆ’ð‘ð‘—. We instead use a different formulation: |ð‘£ð‘–âˆ’\\nð‘ð‘—| = |vi âˆ’cj| =\\nâˆšï¸ƒ\\n|vi|2 + |cj|2 âˆ’2vi Â· cj, i âˆˆ[1, n], j âˆˆ[1, N]. This is\\nbecause in this formulation, the performance bottleneck is ð‘£ð‘–Â· ð‘ð‘—,\\nwhich could be implemented as a matrix product operation. Al-\\nthough the complexity of the two formulations is the same, in GPUs\\nmatrix product is much more efficient than pairwise difference.\\n5\\nADAPTIVE SCHEDULER\\nNext, we present the adaptive scheduler of RITA which addresses\\nthe challenges of determining an appropriate number of groups\\nð‘and accordingly the batch size ðµ, as described in Introduction.\\nUsing a dynamic scheduling method we propose, the scheduler\\nautomatically determines and adjusts ð‘and ðµbased on the distri-\\nbutional properties of the feature embeddings produced over the\\niterative training process, while guaranteed to produce high quality\\nattention approximation that meets the requirement of users.\\nIn Sec. 5.1 we show how RITA automatically determines ð‘. Then\\nwe introduce in Sec. 5.2 the learning-based method which given an\\nð‘, immediately predicts a good batch size.\\n5.1\\nDynamically Determining the Number of\\nGroups N\\nWithout loss of generality, we use one group attention module as\\nan example to show how RITA automatically gets an appropriate ð‘.\\nThe adaptive scheduler of RITA starts with a large ð‘and decreases\\nit dynamically. This is because in the training process of RITA, the\\nfeature embeddings produced epoch by epoch tend to get stabler\\nand stabler and gradually converge, thus no need to increase ð‘.\\nRITA reduces the number of groups by merging similar groups.\\nIntuitively, given two groups, we could measure their similarity\\nbased on the distance of their centers. If the distance between\\ntheir centers is smaller than a distance threshold, then the two\\ngroups could be merged. However, setting an appropriate distance\\nthreshold seems hard â€“ as difficult as setting an appropriate ð‘.\\nTo solve this problem, RITA leverages the error bound of group\\nattention introduced in Sec. 4.3. It only requires users to set an\\nerror bound ðœ–, and then uses Lemma 1 to translate ðœ–to a distance\\nthreshold ð‘‘. RITA then uses Lemma 2 to determine if merging some\\ngiven clusters still meets the error bound threshold ðœ–.\\nLemma 2. Denote ð‘ð‘˜to be the cluster center of ð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘˜. Assume\\nthe existing grouping satisfies âˆ€k,\\nmax\\nxâˆˆclusterk\\n|ck âˆ’x| â‰¤d , thus satis-\\nfying an error bound ðœ–by Lemma 1. If there exist ð‘šclusters, namely,\\nð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘˜1,ð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘˜2, ...,ð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘˜ð‘š, satisfying that:\\nð‘šð‘Žð‘¥\\nð‘¥âˆˆð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘˜ð‘–\\n|ð‘ð‘˜ð‘–âˆ’ð‘ð‘˜ð‘—| + |ð‘¥âˆ’ð‘ð‘˜ð‘–| â‰¤ð‘‘,ð‘–, ð‘—âˆˆ[1,ð‘š]\\n(4)\\nmerging them into one cluster still meets the error bound ðœ–.\\nPlease refer to Appendix A.6 for the proof.\\nFinding the Mergable Clusters. We formulate the problem of\\nfinding mergeable clusters using graph theory:\\n(1) each cluster is a node in the graph;\\n(2) if ð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘–and ð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘—satisfy:\\nð‘šð‘Žð‘¥\\nð‘¥âˆˆð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘–\\n|ð‘ð‘–âˆ’ð‘ð‘—|+|ð‘¥âˆ’ð‘ð‘–| â‰¤ð‘‘, and\\nð‘šð‘Žð‘¥\\nð‘¥âˆˆð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘—\\n|ð‘ð‘—âˆ’ð‘ð‘–|+|ð‘¥âˆ’ð‘ð‘—| â‰¤ð‘‘\\nthere is an undirected edge between ð‘›ð‘œð‘‘ð‘’ð‘–and ð‘›ð‘œð‘‘ð‘’ð‘—;\\nIn this scenario, finding the maximum number of mergeable\\nclusters is equivalent to finding the minimal clique cover in the\\ncorresponding graph, which is an NP-hard problem [24]. Such\\nheavy computation overhead is not acceptable for RITA. We thus\\noffer a simplified solution:\\n(1) Halve the clusters into two sets ð‘†1,ð‘†2;\\n(2) If ð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘–âˆˆð‘†1 and ð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘—âˆˆð‘†2 satisfy:\\nð‘šð‘Žð‘¥\\nð‘¥âˆˆð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘–\\n|ð‘ð‘–âˆ’ð‘ð‘—| + |ð‘¥âˆ’ð‘ð‘–| â‰¤ð‘‘,\\nð‘šð‘Žð‘¥\\nð‘¥âˆˆð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘—\\n|ð‘ð‘—âˆ’ð‘ð‘–| + |ð‘¥âˆ’ð‘ð‘—| â‰¤ð‘‘\\n2\\n(5)\\nð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘—is marked.\\n(3) Decrease the number of clusters by counting the masks in ð‘†2.\\nIn this solution, clusters in ð‘†1 can be regarded as transfer nodes.\\nIf (5) holds for (ð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘–âˆˆð‘†1,ð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘—1 âˆˆð‘†2) and (ð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘–âˆˆ\\nð‘†1,ð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘—2 âˆˆð‘†2), respectively, we have,\\nð‘šð‘Žð‘¥\\nð‘¥âˆˆð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘—1\\n|ð‘ð‘—1 âˆ’ð‘ð‘—2 | + |ð‘¥âˆ’ð‘ð‘—1 |\\nâ‰¤\\nð‘šð‘Žð‘¥\\nð‘¥âˆˆð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘—1\\n|ð‘ð‘—1 âˆ’ð‘ð‘–| + |ð‘ð‘–âˆ’ð‘ð‘—2 | + |ð‘¥âˆ’ð‘ð‘—1 |\\nâ‰¤\\nð‘šð‘Žð‘¥\\nð‘¥âˆˆð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘—1\\n|ð‘ð‘—1 âˆ’ð‘ð‘–| + |ð‘ð‘–âˆ’ð‘ð‘—2 | + |ð‘¥âˆ’ð‘ð‘—1 | + |ð‘¥âˆ’ð‘ð‘—2 | â‰¤ð‘‘\\n(6)\\nThus (4) holds when merging several clusters in ð‘†2 with one\\ncluster in ð‘†1. As a result, we can greedily merge clusters in ð‘†2, as\\nillustrated in step(3).\\nAssume the number of clusters decreases by ð·after merging,\\nwe apply a momentum update [42] on the number of clusters ð‘, as\\nis commonly used in machine learning to smooth the changing of\\nð‘and avoid sample selection bias. To be specific: ð‘ð‘›ð‘’ð‘¤= ð›¼(ð‘âˆ’\\nð·) + (1 âˆ’ð›¼)ð‘, where ð›¼is a hyper-parameter for momentum.\\n5\\n5.2\\nDynamically Determining the Batch Size\\nBecause of the dynamic grouping operation, the computational\\ngraph in deep learning training [1] varies from sample to sample. As\\na result, it is impossible to precisely compute a batchâ€™s GPU memory\\nusage without indeed feeding it into the model. To overcome this\\nproblem, RITA learns a batch size prediction function offline; then\\nat the RITA training time, given a number of groups ð‘, RITA uses\\nthis function to predict a proper batch size.\\nWhen the model architecture and hardware are fixed, the batch\\nsize depends on the length of the timeseries ð¿and the average\\ngroup number among all attention module ð‘. So RITA samples\\nseveral (ð¿ð‘–, ð‘ð‘–) pairs and estimate a proper batch size for each pair.\\nMore specifically, given a user-defined timeseries maximal length\\nð¿ð‘šð‘Žð‘¥, we randomly sample integral points (ð¿ð‘–, ð‘ð‘–) from plane\\n{1 â‰¤ð¿â‰¤ð¿ð‘šð‘Žð‘¥, 1 â‰¤ð‘â‰¤ð¿}. Then we use a binary search based\\nalgorithm to find the maximal batch size ðµð‘–that consumes less than\\n90% available GPU memory, aiming to avoid wasting GPU memory\\nand the risks of out of memory (OOM).\\nTreating these pairs as ground truth labels, we use function\\nfitting [18] to learn the batch size predicting function B = f (L, N),\\nwhere B is a function of two variables ð¿and ð‘.\\nLearning the Prediction Function. We apply curve fit from\\nSciPy [53] as the function fitting tool to fit the two-variable function\\nðµð‘–= ð‘“(ð¿ð‘–, ð‘ð‘–) on plane {1 â‰¤ð¿â‰¤ð¿ð‘šð‘Žð‘¥, 1 â‰¤ð‘â‰¤ð¿}.\\nWe observe that applying one function to the whole plane incurs\\na huge estimation error. So we develop a dynamic-programming\\n(DP) method to divide the plane into several sub-planes and apply\\na distinct function to each sub-plane respectively. It is optimal in\\nminimizing the total estimation error on all sub-planes\\nWith the learned prediction function ð‘“, we can estimate a proper\\nbatch size for any (ð¿, ð‘) during training, even if it is not seen in\\nthe sampled (ð¿ð‘–, ð‘ð‘–) pairs.\\nThe Algorithms and Optimality Proof. Please refer to Appen-\\ndix A.3 for the pseudo code of the binary search-based algorithm\\nand the description of the DP method for plane-division and the\\nproof for its optimality.\\n6\\nEVALUATION\\nOur experimental study focuses on the following questions:\\n1. Effectiveness and efficiency of RITA: How does RITA com-\\npare with other Transformer-based methods and traditional time-\\nseries representation learning methods in accuracy and efficiency?\\n2. Ablation Study: How do the key techniques of RITA work?\\n6.1\\nExperimental Setup\\nDatasets. We evaluate RITA on classification and imputation tasks\\nusing 5 multi-variate and 3 uni-variate timeseries datasets.\\nâ€¢ WISDM [55] is a popular multivariate timeseries dataset gen-\\nerated from the accelerometer in the mobile phone. The subjects\\nperformed 18 daily activities (e.g. walking, jogging). The dataset\\nwas collected from 51 subjects and the sampling rate is 20 Hz.\\nâ€¢ HHAR dataset [46] contains sensing data of accelerometer col-\\nlected from 9 users performing 5 activities with 12 different smart-\\nphones (varying in sampling rate). This increases the complexity\\nof the task and thus can test the modelâ€™s robustness.\\nâ€¢ RWHAR RealWorld HAR dataset [48] covers 15 subjects per-\\nforming 8 locomotion-style activities. Each subject wears the sen-\\nsors for approximately ten minutes. The sampling rate is 50 Hz.\\nâ€¢ ECG dataset [34] consists of 10,000 EEG recordings for arrhyth-\\nmia classification. Each recording has an uncertain length ranging\\nfrom 6 to 60 seconds sampled at 500 Hz. The ECG recordings corre-\\nspond to 9 types of heart problems such as atrial fibrillation (AF)\\nand premature atrial contraction (PAC), etc.\\nâ€¢ MGH [6] is a EEG dataset collected by Mass. General Hospital.\\nEach timeseries corresponds to the EEG data observed from one\\npatient during their stay in ICU for a couple of days. The EEG\\nmonitoring produced data with 20 channels. The sampling rate is\\n200 HZ. So it produces very long timeseries.\\nâ€¢ WISDM*/HHAR*/RWHAR* are three uni-variate datasets de-\\nrived by picking one channel from WISDM/HHAR/RWHAR.\\nTraining/Validation Data Generation. We apply a sliding win-\\ndow on the raw timeseries to get training/validation samples. The\\nsize of the sliding window is set as 200 on small datasets (WISDM,\\nHHAR, RWHAR), 2000 on medium size dataset (ECG), and 10,000\\non the large dataset (MGH). Table 1 shows the statics of the gen-\\nerated datasets. They are randomly split into training/validation\\nset in a proportion of 0.9/0.1. In â€œpretraining + few-label finetun-\\ningâ€ scenario, we use 100 labeled data per class for finetuning. We\\nguarantee that training set does not overlap with the validation set.\\nDataset\\nTrain. Size\\nValid. Size\\nLength\\nChannel\\nClasses\\nWISDM\\n28,280\\n3,112\\n200\\n3\\n18\\nHHAR\\n20,484\\n2,296\\n200\\n3\\n5\\nRWHAR\\n27,253\\n3,059\\n200\\n3\\n8\\nECG\\n31,091\\n3,551\\n2000\\n12\\n9\\nMGH\\n8,550\\n950\\n10000\\n21\\nN/A\\nTable 1: The statistics of the datasets\\nAlternative Methods. We compare RITA against the SOTA Trans-\\nformer based timeseries representation learning method TST [61].\\nTo evaluate our group attention (referred to as Group Attn.), we\\ndevelop three baselines by replacing the group attention compo-\\nnent in RITA with the classic vanilla Self-Attention [52](referred\\nto as Vanilla) and two SOTA methods that reduce the complexity\\nof self-attention by approximation in NLP, namely, Performer [10]\\n(referred to as Performer) and Linformer [54] (referred to as Lin-\\nformer). Similar to our proposed Group Attn., Vanilla, Performer,\\nLinformer all use RITAâ€™s time-aware convolution operation (Sec. 3)\\nto turn timeseries segments into input feature vectors.\\nWe also compare Group Attn. against GRAIL [40], which is\\nthe SOTA of the non-deep learning methods for timeseries repre-\\nsentation learning. GRAIL supports classification tasks by feeding\\nthe learned representations into a Support-Vector Machine [12]\\nor K-Nearest Neighbor [17] classifier. Note GRAIL only targets\\nuni-variate timeseries and cannot support imputation tasks.\\nMethodology. We mainly focus on two downstream tasks:\\n(1) Classification. First, we train Group Attn. and the base-\\nlines with full labels from scratch to test the effectiveness of RITA\\nframework and the approximation quality of our group attention.\\nSecond, to measure the effectiveness of self-supervised pretrain-\\ning, we evaluate the accuracy of training on few labeled timeseries\\nwith/without pretraining on large scales of unlabeled timeseries. To\\nbe specific, we split the training set into a pretraining set and a fine-\\ntuning set, with very few data in the latter (100 labeled samples per\\n6\\n(a) Effectiveness \\n(b) Efficiency\\nTraining Time/sec\\nFigure 3: Full-label classification results (multi-variate data).\\nclass in our experiment). We train the model on the cloze pretrain-\\ning task with a mask rate ð‘= 0.2. Then we train two classification\\nmodels using the finetuning set, either based on the pretrained\\nversion or from scratch. We repeat the experiment 5 times with\\nrandom data splits and report the median accuracy.\\n(2) Imputation. We run the imputation task on the datasets used\\nin classification as well as the large unlabeled MGH dataset, and\\nmeasure the mean square error and absolute imputation error. To\\nget timeseries with missing values, we randomly mask the values\\nwith an expected mask rate of ð‘= 0.2. The masked values are\\nreplaced with a special value.\\nFinally, to evaluate Group Attn.â€™s benefit on efficiency, the total\\ntime of forward computation, backward propagation, and grouping\\nare measured for all methods in all the experiments.\\nTo save space, we only report the average training time per epoch\\nhere and refer readers to Appendix A.8 for the inference time.\\nWe first compare against the Transformer-based methods on\\nmulti-variate datasets (sec. 6.2, 6.3), then compare against the non-\\ndeep learning method GRAIL on uni-variate datasets (sec. 6.4).\\nConfiguration. Please refer to Appendix A.1 for the experiment\\nconfiguration and hyper-parameter settings.\\n6.2\\nEffectiveness: Transformer-Based Methods\\nWe first evaluate the quality of the models trained with full labels\\nfrom scratch. We then show how the pretraining of RITA increases\\nthe accuracy of the downstream tasks.\\n6.2.1\\nfull-label training (Multi-variate classification)\\nResults shown in Figure 3(a) get us the following observations:\\n(1) RITAâ€™s advantage over TST. On all four datasets for the clas-\\nsification tasks, Group Attn. and the other three baselines that use\\nRITA architecture (Vanilla, Performer, and Linformer) outperform\\nTST. In particular, Group Attn. outperforms TST by 49 percentage\\npoints on the ECG dataset (88.48% vs 39.93%) with long timeseries.\\nTwo deficiencies in TST may cause its poor performance on the long\\ntimeseries. Firstly, TST concatenates the output embedding vector\\nof each time stamp, then uses a linear classifier to do classification\\non the concatenated vector. When the timeseries is long, the linear\\nclassifier has so many parameters that it tends to overfit easily.\\nSecondly, TST replaces Layer Normalization in vanilla Transformer\\nwith Batch Normalization. When the timeseries is long, it can only\\naccommodate a small number of timeseries in each batch, leading\\nto bias in Batch Normalization.\\n(2) Group-attentionâ€™s advantage over other attention mech-\\nanisms. Group Attn. is better than Performer and Linformer on\\n3 out of 4 datasets for classification. Although Linformer works\\nslightly better than Group Attn. on the ECG dataset (90.37% vs\\n88.84%), its performance is the worst in all other cases compared\\nto any other RITA-based methods. Vanilla computes the attention\\nscores precisely. Thus it is expected to work well. However, Group\\nAttn. outperforms Vanilla on WISDM (87.50% vs 86.95%) and is very\\nclose to it on other 3 datasets. This suggests that group attentionâ€™s\\napproximation quality is good.\\n6.2.2\\npretraining + few label finetune (Multi-variate classification)\\nThe results shown in Table 3 get us the following observation:\\n(1) Pretraining is effective. Pretraining always leads to better\\naccuracy than training with a few labels from scratch. In particular,\\non WISDM data all the methods using RITA architecture increase\\nthe accuracy by at least 10%. This is impressive considering we do\\nnot have a very large unlabeled pre-training set to use.\\n(2) RITAâ€™s advantage over TST. our Group Attn. and other\\nthree baselines using RITA architecture (Vanilla, Performer, and\\nLinformer) significantly outperform TST on all four classification\\ndatasets by 25 percentage points.\\n(3) Group Attentionâ€™s advantage over other attention mech-\\nanisms. Group Attn. is better than Performer and Linformer on 3\\nout of 4 datasets. When compared to Vanilla, Group Attn. is better\\non HHAR and ECG, and comparable on the other two, further con-\\nfirming its high quality on approximation. Further, we notice that\\nLinformer struggles in this setting: in average its accuracy is worse\\nthan Vanilla by 8.22% and Group Attn. by 8.01%. This is because the\\nlow-rank projection operation introduces extra model parameters,\\nmaking Linformer more easily overfit, while overfitting is especially\\nharmful when there are only a few labeled training samples.\\n6.2.3\\nfull-dataset training (Multi-variate imputation)\\nSimilar to classification tasks, the results of imputation tasks\\n(Table.2) show that Group Attn. consistently outperforms the base-\\nlines in training time while achieving comparable/better MSE. Again,\\non the large dataset MGH (length = 10,000), TST and Vanilla fail due\\nto out of memory (OOM) errors. Methods using RITA framework\\n(Group Attn., Performer, Linformer) all achieve very low MSE (are\\nhighly accurate). Among them Linformer is the worst.\\n6.3\\nEfficiency: Transformer-based Methods\\nWe measure the efficiency by the average training time per epoch\\nincluding the cost of the forward computation + backward propaga-\\ntion and the grouping overhead. We first show the results on all the\\n5 datasets in Sec. 6.3.1. We then vary the length of the timeseries\\non the MGH dataset to show group attentionâ€™s scalability on long\\ntimeseries in Sec. 6.3.2.\\n6.3.1\\nTraining Time: All Multi-variate Datasets\\nThe results in Fig. 3(b) and Table 2 lead to the below observations:\\n(1) Vanilla Self-Attention is not scalable. In average, it takes\\n2-3 minutes to train one epoch when the length of the timeseries is\\nonly 200 (WISDM, HHAR, RWHAR), takes over 15 minutes when\\nthe length increases to 2,000 (ECG), and fails on the long MGH data\\nwhen the length reaches 10,000 due to out of GPU memory.\\n(2) Group Attn.â€™s advantage over all other attention mecha-\\nnisms. As we have shown in Sec. 6.2, Group Attn. is more accurate\\n7\\nDataset\\nLength\\nTST [61]\\nVanilla\\nPerformer\\nLinformer\\nGroup Attn.\\nMSE\\nTime/s\\nMSE\\nTime/s\\nMSE\\nTime/s\\nMSE\\nTime/s\\nMSE\\nTime/s\\nWISDM\\n200\\n13.30\\n150.3\\n3.240\\n178.1\\n3.449\\n162.6\\n3.852\\n141.9\\n3.277\\n136.7\\nHHAR\\n200\\n1.085\\n78.2\\n0.2968\\n97.4\\n0.2980\\n82.6\\n0.3198\\n81.1\\n0.2974\\n73.3\\nRWHAR\\n200\\n0.0882\\n83.9\\n0.0478\\n108.1\\n0.0489\\n89.1\\n0.0572\\n98.4\\n0.0478\\n81.3\\nECG\\n2000\\n0.0905\\n696.3\\n0.0037\\n857.9\\n0.0033\\n270.2\\n0.0035\\n291.38\\n0.0038\\n164.36\\nMGH\\n10000\\nN/A\\nN/A\\nN/A\\nN/A\\n0.00014\\n356.2\\n0.00088\\n404.9\\n0.00042\\n54.4\\nTable 2: Imputation results (multi-variate data). The best results are marked with bold.\\nDataset\\nPretrain Size\\nTST [61]\\nVanilla\\nPerformer\\nLinformer\\nGroup Attn.\\nScratch\\nPre.\\nScratch\\nPre.\\nScratch\\nPre.\\nScratch\\nPre.\\nScratch\\nPre.\\nWISDM\\n62,231\\n49.13%\\n50.03%\\n66.16%\\n75.89%\\n66.09%\\n73.97%\\n50.12%\\n67.44%\\n62.56%\\n75.06%\\nHHAR\\n68,294\\n72.56%\\n75.30%\\n75.60%\\n81.35%\\n76.52%\\n80.70%\\n65.94%\\n76.52%\\n76.17%\\n82.62%\\nRWHAR\\n63,599\\n69.46%\\n80.41%\\n85.68%\\n91.14%\\n87.54%\\n91.33%\\n81.03%\\n86.33%\\n86.13%\\n89.63%\\nECG\\n561,358\\n20.98%\\n27.99%\\n42.05%\\n46.16%\\n43.34%\\n45.58%\\n27.19%\\n31.34%\\n42.58%\\n46.39%\\nTable 3: Pretrain + few-label finetuning results. The best results are marked with bold.\\nTraining Time/sec\\nMSE\\n(a) Effectiveness\\n(b) Efficiency\\nFigure 4: Varying the lengths of timeseries.\\nthan Performer and Linformer in classification and imputation tasks,\\nwhile Group Attn. is always faster than Performer, Linformer, and\\nall other baselines on all 5 multi-variate datasets, thus a win-win.\\n(3) The longer the timeseries, the larger the speedup. On\\nthe medium sized ECG dataset with a length of 2,000, Group Attn.\\nhas a speedup of 3.86/1.36/2.27 compared to Vanilla/Performer/Lin-\\nformer. When the length increases to 10,000, the speedup on the\\nMGH dataset increases to 6.59/7.48 compared to Performer/Lin-\\nformer (Vanilla and TST failed in this case) on imputation task\\n(Table. 2). However, even on the short WISDM, HHAR, RWHAR\\ndatasets, Group Attn. still consistently outperforms other methods,\\nconfirming that it does not introduce much overhead. This is be-\\ncause when the length of the timeseries gets longer, Group Attn.\\ngets more opportunities to find windows with similar properties.\\n6.3.2\\nTraining time: Varying the Length\\nIn this experiment, we truncate the original MGH timseries into\\nsequences with the lengths at 2000/4000/6000/8000/10000, and com-\\npare Group Attn. against Vanilla and other attention mechanisms.\\nVanilla cannot handle sequences longer than 8000.\\nThe results in Fig. 4 again show that the longer the timeseries, the\\nlarger the speed up. With comparable MSE, Group Attn. outperforms\\nVanilla by 63X. Moreover, as the length increases from 2000 to 10000,\\nthe training time of Group Attn. only increases from 31.2 seconds\\nto 54.4 seconds per epoch. The reason is that as the timeseires\\nbecomes longer, there are more grouping opportunities because of\\nthe similarity of the timeseries segments.\\nAccuracy\\nTraining Time/sec\\n(a)\\n(b)\\nFigure 5: Comparison to non-deep learning method (uni-\\nvariate data).\\n6.4\\nComparison to Non-deep Learning Methods\\nWe compare against GRAIL, the SOTA of non-deep learning time-\\nseries representation learning. We use the three uni-variate datasets,\\nbecause GRAIL only targets uni-variate timeseries.\\nResults in Fig. 5 show that on all 3 datasets RITA significantly\\noutperforms GRAIL in accuracy by 45, 16, and 21 percentage points\\nbecause of the expressive power of Transformer. Moreover, thanks\\nto the GPU-friendly design of RITA, it is at least 2Ã— faster than\\nGRAIL in training time.\\n6.5\\nAblation Study\\n6.5.1\\nAdaptive Scheduler\\nTo evaluate the effectiveness of RITAâ€™s adaptive scheduler (Sec. 5),\\nwe compare it against a baseline using a fixed group number ð‘. We\\nvary ð‘and the error bound threshold ðœ–used by RITA.\\nFrom the results in Table 4 we get the following observations:\\n(1) Adaptive Scheduler is better than fixed ð‘. Training with\\nAdaptive Scheduler already achieves better or comparable perfor-\\nmance compared to the best performing ð‘. More specifically, on\\nthe MGH dataset, dynamic scheduler always achieves better accu-\\nracy and is much faster compared to fixed ð‘. On the ECG dataset,\\nalthough fixed ð‘is slightly better than adaptive scheduler in accu-\\nracy when setting the N as 512, it runs much slower than adaptive\\nscheduler. Of course, finding the best ð‘that balances the accuracy\\nand running time requires careful tuning.\\n(2) Adaptive Scheduler is tuning free. It is robust on both\\naccuracy and running time when ðœ–varies, while the results of\\nfixed ð‘vary significantly when the value of ð‘changes. Therefore,\\nAdaptive Scheduler frees the users from tuning the ðœ–threshold,\\nwhile it is hard to find an appropriate ð‘for a given dataset.\\n8\\nDataset\\nTask\\nScheduler\\nParameter\\nMetric\\nTime\\nECG\\nClass.\\nDynamic\\n1.5\\n88.34%\\n292.5\\n2\\n88.48%\\n236.8\\n3\\n87.83%\\n216.8\\nFixed\\n64\\n87.50%\\n255.2\\n128\\n88.96%\\n297.2\\n256\\n88.82%\\n414.1\\n512\\n90.03%\\n662.6\\n1024\\n88.65%\\n873.7\\nMGH\\nImput.\\nDynamic\\n1.5\\n0.00041\\n60.7\\n2\\n0.00040\\n57.9\\n3\\n0.00042\\n54.4\\nFixed\\n128\\n0.00054\\n128.6\\n256\\n0.00053\\n190.2\\n512\\n0.00049\\n240.8\\n1024\\n0.00046\\n323.3\\nTable 4: Adaptive Scheduling VS Fixed N.\\nPretrain Data size\\nFew-label Accuracy\\nN/A\\n62.56%\\n12,446\\n72.94%\\n24,892\\n72.78%\\n37,338\\n74.10%\\n49,784\\n74.22%\\n62,231\\n75.06%\\nTable 5: RITA Pretraining: increasing sizes of pretrain set.\\n6.5.2\\nThe Sizes of the Pretraining Data\\nNext, we evaluate how the number of unlabeled data influences the\\neffectiveness of pretraining. To get empirical results, we pretrain\\nRITA on WISDM dataset with 20%/40%/60%/80% of the pretraining\\ndata and finetune each pretrained model with 100 labels per class.\\nThe results in Table 5 show that: (1) The more pretraining data,\\nthe larger the improvement. The accuracy increases with the\\nsizes of the pretraining data; (2) Marginal utility diminishing.\\nThe first 20% pretraining data gives a 10.38% improvement in accu-\\nracy (72.94% vs 62.56%), while the remaining 80% pretraining data\\nonly gives an additional improvement of 2.12% (75.06% vs 72.94%).\\n7\\nRELATED WORK\\n7.1\\nTimeseries Analytics\\nThere is a great deal of prior work on timeseries analytics methods.\\nThis work can be divided into three categories: (1) non-deep learn-\\ning methods; (2) CNN/RNN-based deep learning methods; and (3)\\nTransformer-based deep learning methods.\\nTraditional Methods. These methods, such as TS-CHIEF [45],\\nHIVE-COTE [33], ROCKET [15] have achieved notable performance\\non public datasets. Despite that, traditional methods suffer from\\none or more issues: they (1) rely on expert knowledge for feature\\nextraction; (2) incur heavy computation cost and are inappropriate\\nfor GPU devices; (3) support only uni-variate timeseries; (4) perform\\nclassification solely. Some work [61] shows that the transformed-\\nbased methods outperform these traditional methods especially on\\nmulti-variate timeseries.\\nIn particular, as the SOTA of timeseries representation learn-\\ning, GRAIL [40] extracts landmarks from data and computes the\\nrepresentations with the combination of the landmarks. However,\\nGRAIL only supports uni-variate timeseries. Our experiments (Sec. 6.4)\\nshow that RITA significantly outperforms GRAIL in both effective-\\nness and efficiency on uni-variate timeseries.\\nCNN/RNN-based Deep Learning Methods. CNN-based methods,\\nsuch as InceptionTime [21] and Resnet [19], are good at classifica-\\ntion tasks, but can not handle generative tasks such as forecasting\\nbecause of the inductive bias of convolution networks. RNN-based\\nmethods, such as Brit [7] and deepAR [44], are capable for classifi-\\ncation, regression and generation. However, the recurrent structure\\nbrings a lot of problems: (1) limiting the modelâ€™s ability in captur-\\ning long-range correlation; (2) notoriously difficult to train [41]\\nbecause of gradient vanishing and exploding problem. As a result,\\nsuch methods can hardly scale to very long timeseries.\\nTransformer-based Deep Learning Methods. Given that Trans-\\nformer is the best choice for backbone in almost all sequence mod-\\neling tasks, some effort has been made to apply Transformer to\\ntimeseries analytics. Targeting forecasting of uni-variate timeseries,\\nLogTrans [30] introduced a log sparsity assumption to attention\\ncomputation. Informer [62] pushes LogTrans a step further and\\nscales forecasting to multi-variate timeseries. Autoformer [57] per-\\nforms forecasting by decomposing timeseries into two parts, i.e.\\nthe trend part and the seasonal part.\\nFor imputation tasks, CDSA [37] outperforms statistical meth-\\nods and the SOTA of RNN-based method Brit [7] on 3 public and\\n2 competition datasets. For timeseries classification, AutoTrans-\\nformer [43] performs architecture search to adapt to the tasks\\nin different domains. For timeseries anomaly detection, Anomaly\\nTransformer [58] outperforms many widely-used methods such\\nas OmniAnomaly [47], assuming the attention score maps show\\nGaussian distribution.\\nAll of these works are designed for specific tasks, rather than\\nfunctioning as a representation learning framework to serve\\ndifferent downstream tasks. To fill this gap, some researchers pro-\\nposed a Transformer-based architecture, called TST [61]. Like RITA,\\nTST supports regression, classification, and unsupervised learning\\nthrough the â€œcloze testâ€ pretraining task on timeseries. However,\\nTST directly uses the classical Vanilla self-attention, thus not scal-\\nable to long timeseries as shown in our experiments (Sec. 6.3.2).\\n7.2\\nEfficient Transformers\\nThe need of improving the scalability of Transformers has led to\\nmore efficient variations of Transformers, especially for accommo-\\ndating long text data in NLP [49].\\nIntroducing fixed/random patterns to self-attention mechanism\\nis an intuitive idea. Sparse Transformer [9] and Longformer [3] only\\ncompute attention at fixed intervals. ETC [2] and BigBird [60] use\\nglobal-local attention: the attention computation is limited within\\na fixed radius, while some auxiliary tokens are added to attend/get\\nattended globally. The deficiencies of fixed attention patterns are\\nobvious: it heavily depends on users to give an optimal setting.\\nTo decrease the reliance on human labor, some works seek to\\nintroduce learnable/adaptive attention patterns instead of fixed\\npatterns. Reformer [26] proposed only computing the dominant\\nattention terms based on their observation of sparsity in atten-\\ntion matrix from language/image data. Such sparsity is intuitive\\nin language data, in which a wordâ€™s attention mainly focuses on\\nthe nearby sentences. However, attention in timeseries data shows\\nstrong seasonal patterns rather than sparse patterns, mainly as\\n9\\nresult of the periodicity of timeseries data. Therefore, such works\\ndo not work well for timeseries.\\nApart from introducing attention patterns, some works seek\\nto solve this problem with applied mathematics techniques. Lin-\\nformer [54] performs a projection to decrease the size of query,\\nkey and value matrices before attention computation, because the\\nattention matrix tends to be low-ranked. Performer [10] uses linear\\nfunctions to approximate the kernel function softmax, making at-\\ntention computation commutative. When the sequence length is far\\ngreater than the dimension of embedding vectors, Performer ben-\\nefits from changing the order of matrix multiplication. Linformer\\nand Performer do not depend on the unique properties of language\\ndata, thus potentially fitting timeseries better than other techniques,\\nwhich is why we compared against them in our experiments. How-\\never as shown in Sec. 6, our group attention significantly outper-\\nforms them in both accuracy and efficiency (training time), because\\ngroup attention fully leverages the periodicity of timeseries.\\n8\\nCONCLUSION\\nIn this work, we presented RITA, an automatic, self-supervised, and\\nscalable timeseries analytics tool. RITA effectively adapts Trans-\\nformer, popular in NLP, into timeseries analytics. As the key com-\\nponent of RITA, group attention eliminates the performance bottle-\\nneck of the classical self-attention mechanisms, thus successfully\\nscaling RITA to highly complex, long timeseries data. Our experi-\\nments confirm that RITA significantly speeds up the state-of-the-art\\nby 63X with a better accuracy.\\nREFERENCES\\n[1] MartÃ­n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen,\\nCraig Citro, Greg S Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, et al.\\n2016. Tensorflow: Large-scale machine learning on heterogeneous distributed\\nsystems. arXiv preprint arXiv:1603.04467 (2016).\\n[2] Joshua Ainslie, Santiago Ontanon, Chris Alberti, Vaclav Cvicek, Zachary Fisher,\\nPhilip Pham, Anirudh Ravula, Sumit Sanghai, Qifan Wang, and Li Yang. 2020.\\nETC: Encoding long and structured inputs in transformers.\\narXiv preprint\\narXiv:2004.08483 (2020).\\n[3] Iz Beltagy, Matthew E Peters, and Arman Cohan. 2020. Longformer: The long-\\ndocument transformer. arXiv preprint arXiv:2004.05150 (2020).\\n[4] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,\\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\\nAskell, et al. 2020. Language models are few-shot learners. Advances in neural\\ninformation processing systems 33 (2020), 1877â€“1901.\\n[5] C Bui, N Pham, A Vo, A Tran, A Nguyen, and T Le. 2017. Time series forecasting\\nfor healthcare diagnosis and prognostics with the focus on cardiovascular dis-\\neases. In International conference on the development of biomedical engineering in\\nVietnam. Springer, 809â€“818.\\n[6] Lei Cao, Wenbo Tao, Sungtae An, Jing Jin, Yizhou Yan, Xiaoyu Liu, Wendong\\nGe, Adam Sah, Leilani Battle, Jimeng Sun, Remco Chang, M. Brandon Westover,\\nSamuel Madden, and Michael Stonebraker. 2019. Smile: A System to Support\\nMachine Learning on EEG Data at Scale. Proc. VLDB Endow. 12, 12 (2019), 2230â€“\\n2241.\\n[7] Wei Cao, Dong Wang, Jian Li, Hao Zhou, Lei Li, and Yitan Li. 2018.\\nBrits:\\nBidirectional recurrent imputation for time series. Advances in neural information\\nprocessing systems 31 (2018).\\n[8] Chris Chatfield. 2000. Time-series forecasting. Chapman and Hall/CRC.\\n[9] Rewon Child, Scott Gray, Alec Radford, and Ilya Sutskever. 2019. Generating\\nlong sequences with sparse transformers. arXiv preprint arXiv:1904.10509 (2019).\\n[10] Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song,\\nAndreea Gane, Tamas Sarlos, Peter Hawkins, Jared Davis, Afroz Mohiuddin,\\nLukasz Kaiser, et al. 2020. Rethinking attention with performers. arXiv preprint\\narXiv:2009.14794 (2020).\\n[11] Andrew A Cook, GÃ¶ksel MÄ±sÄ±rlÄ±, and Zhong Fan. 2019. Anomaly detection for IoT\\ntime-series data: A survey. IEEE Internet of Things Journal 7, 7 (2019), 6481â€“6494.\\n[12] Corinna Cortes and Vladimir Vapnik. 1995. Support-vector networks. Machine\\nlearning 20, 3 (1995), 273â€“297.\\n[13] David R Cox. 1958. The regression analysis of binary sequences. Journal of the\\nRoyal Statistical Society: Series B (Methodological) 20, 2 (1958), 215â€“232.\\n[14] Benjamin F Crabtree, Subhash C Ray, Priscilla M Schmidt, Patrick T Oâ€™Connor,\\nand David D Schmidt. 1990. The individual over time: time series applications in\\nhealth care research. Journal of clinical epidemiology 43, 3 (1990), 241â€“260.\\n[15] Angus Dempster, FranÃ§ois Petitjean, and Geoffrey I. Webb. 2020. ROCKET: excep-\\ntionally fast and accurate time series classification using random convolutional\\nkernels. Data Min. Knowl. Discov. 34, 5 (2020), 1454â€“1495.\\n[16] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT:\\nPre-training of Deep Bidirectional Transformers for Language Understanding. In\\nProceedings of the 2019 Conference of the North American Chapter of the Association\\nfor Computational Linguistics: Human Language Technologies, NAACL-HLT 2019,\\nMinneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers). 4171â€“\\n4186.\\n[17] Evelyn Fix and Joseph Lawson Hodges. 1989. Discriminatory analysis. Nonpara-\\nmetric discrimination: Consistency properties. International Statistical Review/Re-\\nvue Internationale de Statistique 57, 3 (1989), 238â€“247.\\n[18] Philip George Guest and Philip George Guest. 2012. Numerical methods of curve\\nfitting. Cambridge University Press.\\n[19] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual\\nlearning for image recognition. In Proceedings of the IEEE conference on computer\\nvision and pattern recognition. 770â€“778.\\n[20] Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar,\\nand Pierre-Alain Muller. 2019. Deep learning for time series classification: a\\nreview. Data mining and knowledge discovery 33, 4 (2019), 917â€“963.\\n[21] Hassan Ismail Fawaz, Benjamin Lucas, Germain Forestier, Charlotte Pelletier,\\nDaniel F Schmidt, Jonathan Weber, Geoffrey I Webb, Lhassane Idoumghar, Pierre-\\nAlain Muller, and FranÃ§ois Petitjean. 2020. Inceptiontime: Finding alexnet for\\ntime series classification. Data Mining and Knowledge Discovery 34, 6 (2020),\\n1936â€“1962.\\n[22] Herve Jegou, Matthijs Douze, and Cordelia Schmid. 2010. Product quantization\\nfor nearest neighbor search. IEEE transactions on pattern analysis and machine\\nintelligence 33, 1 (2010), 117â€“128.\\n[23] Jeff Johnson, Matthijs Douze, and HervÃ© JÃ©gou. 2019. Billion-scale similarity\\nsearch with gpus. IEEE Transactions on Big Data 7, 3 (2019), 535â€“547.\\n[24] Richard M Karp. 1972. Reducibility among combinatorial problems. In Complexity\\nof computer computations. Springer, 85â€“103.\\n[25] Eamonn Keogh, Kaushik Chakrabarti, Michael Pazzani, and Sharad Mehrotra.\\n2001. Dimensionality reduction for fast similarity search in large time series\\ndatabases. Knowledge and information Systems 3, 3 (2001), 263â€“286.\\n[26] Nikita Kitaev, Åukasz Kaiser, and Anselm Levskaya. 2020. Reformer: The efficient\\ntransformer. arXiv preprint arXiv:2001.04451 (2020).\\n[27] John Kraft and Arthur Kraft. 1977. Determinants of common stock prices: A time\\nseries analysis. The journal of finance 32, 2 (1977), 417â€“425.\\n[28] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. ImageNet Clas-\\nsification with Deep Convolutional Neural Networks. In Advances in Neural\\nInformation Processing Systems, F. Pereira, C.J. Burges, L. Bottou, and K.Q. Wein-\\nberger (Eds.), Vol. 25. Curran Associates, Inc. https://proceedings.neurips.cc/\\npaper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\\n[29] Oscar D Lara and Miguel A Labrador. 2012. A survey on human activity recog-\\nnition using wearable sensors. IEEE communications surveys & tutorials 15, 3\\n(2012), 1192â€“1209.\\n[30] Shiyang Li, Xiaoyong Jin, Yao Xuan, Xiyou Zhou, Wenhu Chen, Yu-Xiang Wang,\\nand Xifeng Yan. 2019. Enhancing the locality and breaking the memory bottle-\\nneck of transformer on time series forecasting. Advances in Neural Information\\nProcessing Systems 32 (2019).\\n[31] T Warren Liao. 2005. Clustering of time series dataâ€”a survey. Pattern recognition\\n38, 11 (2005), 1857â€“1874.\\n[32] Rake& Agrawal King-lp Lin and Harpreet S Sawhney Kyuseok Shim. 1995. Fast\\nsimilarity search in the presence of noise, scaling, and translation in time-series\\ndatabases. In Proceeding of the 21th International Conference on Very Large Data\\nBases. 490â€“501.\\n[33] Jason Lines, Sarah Taylor, and Anthony Bagnall. 2018. Time Series Classification\\nwith HIVE-COTE: The Hierarchical Vote Collective of Transformation-Based\\nEnsembles. ACM Trans. Knowl. Discov. Data 12, 5, Article 52 (jul 2018), 35 pages.\\n[34] Feifei Liu, Chengyu Liu, Lina Zhao, Xiangyu Zhang, Xiaoling Wu, Xiaoyan\\nXu, Yulin Liu, Caiyun Ma, Shoushui Wei, Zhiqiang He, et al. 2018. An open\\naccess database for evaluating the algorithms of electrocardiogram rhythm and\\nmorphology abnormality detection. Journal of Medical Imaging and Health\\nInformatics 8, 7 (2018), 1368â€“1373.\\n[35] Stuart Lloyd. 1982. Least squares quantization in PCM. IEEE transactions on\\ninformation theory 28, 2 (1982), 129â€“137.\\n[36] Ilya Loshchilov and Frank Hutter. 2017. Decoupled weight decay regularization.\\narXiv preprint arXiv:1711.05101 (2017).\\n[37] Jiawei Ma, Zheng Shou, Alireza Zareian, Hassan Mansour, Anthony Vetro, and\\nShih-Fu Chang. 2019. CDSA: cross-dimensional self-attention for multivariate,\\ngeo-tagged time series imputation. arXiv preprint arXiv:1905.09904 (2019).\\n10\\n[38] Yu A Malkov and Dmitry A Yashunin. 2018. Efficient and robust approximate\\nnearest neighbor search using hierarchical navigable small world graphs. IEEE\\ntransactions on pattern analysis and machine intelligence 42, 4 (2018), 824â€“836.\\n[39] Tripti Negi and Veena Bansal. 2005. Time series: Similarity search and its appli-\\ncations. In Proceedings of the International Conference on Systemics, Cybernetics\\nand Informatics: ICSCI-04, Hyderabad, India. 528â€“533.\\n[40] John Paparrizos and Michael J Franklin. 2019. Grail: efficient time-series repre-\\nsentation learning. Proceedings of the VLDB Endowment 12, 11 (2019), 1762â€“1777.\\n[41] Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio. 2013. On the difficulty\\nof training recurrent neural networks. In International conference on machine\\nlearning. PMLR, 1310â€“1318.\\n[42] Ning Qian. 1999. On the momentum term in gradient descent learning algorithms.\\nNeural networks 12, 1 (1999), 145â€“151.\\n[43] Yankun Ren, Longfei Li, Xinxing Yang, and Jun Zhou. 2022. AutoTransformer:\\nAutomatic Transformer Architecture Design for Time Series Classification. In\\nPacific-Asia Conference on Knowledge Discovery and Data Mining. Springer, 143â€“\\n155.\\n[44] David Salinas, Valentin Flunkert, Jan Gasthaus, and Tim Januschowski. 2020.\\nDeepAR: Probabilistic forecasting with autoregressive recurrent networks. Inter-\\nnational Journal of Forecasting 36, 3 (2020), 1181â€“1191.\\n[45] Ahmed Shifaz, Charlotte Pelletier, FranÃ§ois Petitjean, and Geoffrey I. Webb. 2020.\\nTS-CHIEF: a scalable and accurate forest algorithm for time series classification.\\nData Mining and Knowledge Discovery 34 (2020), 742â€“775.\\n[46] Allan Stisen, Henrik Blunck, Sourav Bhattacharya, Thor Siiger Prentow,\\nMikkel Baun KjÃ¦rgaard, Anind Dey, Tobias Sonne, and Mads MÃ¸ller Jensen.\\n2015. Smart devices are different: Assessing and mitigatingmobile sensing het-\\nerogeneities for activity recognition. In Proceedings of the 13th ACM conference\\non embedded networked sensor systems. 127â€“140.\\n[47] Ya Su, Youjian Zhao, Chenhao Niu, Rong Liu, Wei Sun, and Dan Pei. 2019. Robust\\nanomaly detection for multivariate time series through stochastic recurrent\\nneural network. In Proceedings of the 25th ACM SIGKDD international conference\\non knowledge discovery & data mining. 2828â€“2837.\\n[48] Timo Sztyler and Heiner Stuckenschmidt. 2016. On-body localization of wearable\\ndevices: An investigation of position-aware activity recognition. In 2016 IEEE\\nInternational Conference on Pervasive Computing and Communications (PerCom).\\nIEEE, 1â€“9.\\n[49] Yi Tay, Mostafa Dehghani, Dara Bahri, and Donald Metzler. 2020. Efficient\\ntransformers: A survey. ACM Computing Surveys (CSUR) (2020).\\n[50] Mingyan Teng. 2010. Anomaly detection on time series. In 2010 IEEE International\\nConference on Progress in Informatics and Computing, Vol. 1. IEEE, 603â€“608.\\n[51] Patrick A Thompson. 1990. An MSE statistic for comparing forecast accuracy\\nacross series. International Journal of Forecasting 6, 2 (1990), 219â€“227.\\n[52] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\\nAidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All\\nyou Need. In Advances in Neural Information Processing Systems 30: Annual Con-\\nference on Neural Information Processing Systems 2017, December 4-9, 2017, Long\\nBeach, CA, USA. 5998â€“6008.\\n[53] Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler\\nReddy, David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser,\\nJonathan Bright, StÃ©fan J. van der Walt, Matthew Brett, Joshua Wilson, K. Jar-\\nrod Millman, Nikolay Mayorov, Andrew R. J. Nelson, Eric Jones, Robert Kern,\\nEric Larson, C J Carey, Ä°lhan Polat, Yu Feng, Eric W. Moore, Jake VanderPlas,\\nDenis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E. A. Quintero,\\nCharles R. Harris, Anne M. Archibald, AntÃ´nio H. Ribeiro, Fabian Pedregosa,\\nPaul van Mulbregt, and SciPy 1.0 Contributors. 2020. SciPy 1.0: Fundamental Al-\\ngorithms for Scientific Computing in Python. Nature Methods 17 (2020), 261â€“272.\\nhttps://doi.org/10.1038/s41592-019-0686-2\\n[54] Sinong Wang, Belinda Z Li, Madian Khabsa, Han Fang, and Hao Ma. 2020. Lin-\\nformer: Self-attention with linear complexity. arXiv preprint arXiv:2006.04768\\n(2020).\\n[55] Gary M Weiss, Kenichi Yoneda, and Thaier Hayajneh. 2019. Smartphone and\\nsmartwatch-based biometrics using activities of daily living. IEEE Access 7 (2019),\\n133190â€“133202.\\n[56] Qingsong Wen, Kai He, Liang Sun, Yingying Zhang, Min Ke, and Huan Xu. 2021.\\nRobustPeriod: Robust Time-Frequency Mining for Multiple Periodicity Detection.\\nIn Proceedings of the 2021 International Conference on Management of Data (Virtual\\nEvent, China) (SIGMOD â€™21). Association for Computing Machinery, New York,\\nNY, USA, 2328â€“2337. https://doi.org/10.1145/3448016.3452779\\n[57] Haixu Wu, Jiehui Xu, Jianmin Wang, and Mingsheng Long. 2021. Autoformer: De-\\ncomposition transformers with auto-correlation for long-term series forecasting.\\nAdvances in Neural Information Processing Systems 34 (2021), 22419â€“22430.\\n[58] Jiehui Xu, Haixu Wu, Jianmin Wang, and Mingsheng Long. 2021. Anomaly\\nTransformer: Time Series Anomaly Detection with Association Discrepancy.\\narXiv preprint arXiv:2110.02642 (2021).\\n[59] Dianmin Yue, Xiaodan Wu, Yunfeng Wang, Yue Li, and Chao-Hsien Chu. 2007. A\\nreview of data mining-based financial fraud detection research. In 2007 Interna-\\ntional Conference on Wireless Communications, Networking and Mobile Computing.\\nIeee, 5519â€“5522.\\n[60] Manzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua Ainslie, Chris\\nAlberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang,\\net al. 2020. Big bird: Transformers for longer sequences. Advances in Neural\\nInformation Processing Systems 33 (2020), 17283â€“17297.\\n[61] George Zerveas, Srideepika Jayaraman, Dhaval Patel, Anuradha Bhamidipaty, and\\nCarsten Eickhoff. 2021. A Transformer-based Framework for Multivariate Time\\nSeries Representation Learning. In KDD â€™21: The 27th ACM SIGKDD Conference\\non Knowledge Discovery and Data Mining, Virtual Event, Singapore, August 14-18,\\n2021. 2114â€“2124.\\n[62] Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong,\\nand Wancai Zhang. 2021. Informer: Beyond efficient transformer for long se-\\nquence time-series forecasting. In Proceedings of AAAI.\\nA\\nAPPENDIX: SUPPLEMENTARY MATERIAL\\nA.1\\nExperiment Configuration and\\nHyper-parameter Settings\\nConfiguration. All models were trained on an NVIDIA Tesla V100\\n16GB GPU. All the methods are optimized with AdamW [36] of\\nwhich the starting learning rate and weight decay parameter are\\nboth 1ð‘’âˆ’4. In full-label training scenario, we train the models for\\n100 epochs. In â€œpretraining + few-label finetuning scenarioâ€, as the\\npretrained models require fewer epochs to converge [61], we train\\nthe model for 50 epochs. For a fair comparison, the baselines use a\\nmaximal batch size within GPUâ€™s capacity during training.\\nAs for model hyper-parameter setting, RITA and the baselines\\nuse a Transformer structure balancing Vanilla â€™s accuracy and\\nefficiency: 8-layer stack of 2-head attention with hidden vectors\\nin dimension of 64. Convolution kernel size is set to 5 by default.\\nWe set the error bound threshold (ðœ–, Sec. 5.1) of Group Attention\\nto 2, as it balances the accuracy and the efficiency in general on\\nall datasets. Because Linformer requires the users to set the sizes\\nof projection matrix, in different settings we choose an accuracy-\\nefficiency balancing one among {64,128,256,512}.\\nA.2\\nEfficient Computation of Group Attention\\nAlgorithm 1 Efficient Computation of Group Attention\\nRequire: ð‘„,ð‘‰, ð‘…,ð¶ð‘‚ð‘ˆð‘ð‘‡, ðµð¸ð¿ð‘‚ð‘ðº\\nEnsure: ð‘„,ð‘‰âˆˆRð‘›âˆ—ð‘‘,ð‘…âˆˆRð‘âˆ—ð‘‘,ð¶ð‘‚ð‘ˆð‘ð‘‡âˆˆNð‘,ðµð¸ð¿ð‘‚ð‘ðºâˆˆNð‘›\\n1: function group_attention(ð‘„,ð‘‰, ð‘…)\\n2:\\nfor ð‘–= 0 â†’ð‘âˆ’1 do\\n3:\\neð‘£ð‘–â†Ãð‘›âˆ’1\\nð‘—=0 (ðµð¸ð¿ð‘‚ð‘ðºð‘—== ð‘–)ð‘£ð‘—\\n4:\\neð‘ƒâ†ð‘„ð‘…ð‘‡\\n5:\\nfor ð‘–= 0 â†’ð‘›âˆ’1 do\\n6:\\nfor ð‘—= 0 â†’ð‘âˆ’1 do\\n7:\\nð‘¤ð‘–,ð‘—â†ð‘’ð‘¥ð‘(eð‘ƒð‘–,ð‘—)ð¶ð‘‚ð‘ˆð‘ð‘‡ð‘—\\n8:\\nfor ð‘–= 0 â†’ð‘›âˆ’1 do\\n9:\\nð‘ ð‘–â†Ãð‘âˆ’1\\nð‘—=0 ð‘¤ð‘–,ð‘—\\n10:\\nfor ð‘–= 0 â†’ð‘›âˆ’1 do\\n11:\\nð‘œð‘–â†Ãð‘âˆ’1\\nð‘—=0\\nð‘’ð‘¥ð‘( eð‘ƒð‘–,ð‘—)\\nð‘ ð‘–\\neð‘£ð‘—\\n12:\\nreturn ð‘‚\\nIn Alg. 1, we denoteð¶ð‘‚ð‘ˆð‘ð‘‡ð‘–to be the size of the ð‘–ð‘¡â„Žgroup, ð‘to\\nbe the number of groups, rð‘–to be the representative key of the ð‘–ð‘¡â„Ž\\ngroup and R to be the matrix consisting of all rð‘–, ðµð¸ð¿ð‘‚ð‘ðºð‘–to be\\nthe group that kð‘–belongs to. ð‘„,ð‘‰are the packing matrices of query\\nvectors and value vectors as described in Sec.2. Alg. 1 outputs the\\n11\\npacking matrix ð‘‚for new feature emebddings {ð‘œ1, ...,ð‘œð‘›}, where ð‘œð‘–\\ncorresponds to the feature embedding of ð‘¤ð‘–ð‘›ð‘–. Lines 2-3 implement\\nthe embedding aggregation operation, while Lines 8-11 implement\\nthe group softmax function.\\nA.3\\nThe Algorithms and Optimality Proof for\\nDynamically Determing Batch Size\\nAlgorithm 2 Binary Search for Batch Size\\nRequire: ð¿, ð‘\\nEnsure: 1 â‰¤ð¿â‰¤ð¿ð‘šð‘Žð‘¥, 1 â‰¤ð‘â‰¤ð¿\\n1: function binary_search(ð¿, ð‘)\\n2:\\nð¿â†1\\n3:\\nð‘…â†ð‘€ð‘Žð‘¥ðµð‘Žð‘¡ð‘â„Žð‘†ð‘–ð‘§ð‘’\\n4:\\nð‘‘ð‘Žð‘¡ð‘Žâ†ð‘…ð‘Žð‘›ð‘‘ð‘œð‘šð‘‡ð‘–ð‘šð‘’ð‘†ð‘’ð‘Ÿð‘–ð‘’ð‘ ð‘–ð‘›ð‘™ð‘’ð‘›ð‘”ð‘¡â„Žð¿\\n5:\\nðµð‘¡ð‘’ð‘šð‘ð‘œð‘Ÿð‘Žð‘™\\n6:\\nwhile ð¿â‰¤ð‘…do\\n7:\\nð¼ð‘›ð‘ð‘¢ð‘¡â†ð‘‘ð‘Žð‘¡ð‘ŽÃ— ðµð‘¡ð‘’ð‘šð‘ð‘œð‘Ÿð‘Žð‘™\\n8:\\nð‘€ð‘œð‘‘ð‘’ð‘™ð¹ð‘œð‘Ÿð‘¤ð‘Žð‘Ÿð‘‘(ð¼ð‘›ð‘ð‘¢ð‘¡)\\n9:\\nð‘€ð‘œð‘‘ð‘’ð‘™ðµð‘Žð‘ð‘˜ð‘¤ð‘Žð‘Ÿð‘‘\\n10:\\nð‘¢â†ð‘ƒð‘’ð‘Žð‘˜ð‘€ð‘’ð‘šð‘œð‘Ÿð‘¦ð‘ˆð‘ ð‘Žð‘”ð‘’\\nð‘‡ð‘œð‘¡ð‘Žð‘™ð‘€ð‘’ð‘šð‘œð‘Ÿð‘¦\\n11:\\nif 0.9 > ð‘¢then\\n12:\\nð¿â†ðµð‘¡ð‘’ð‘šð‘ð‘œð‘Ÿð‘Žð‘™+ 1\\n13:\\nðµâ†ðµð‘¡ð‘’ð‘šð‘ð‘œð‘Ÿð‘Žð‘™\\n14:\\nelse\\n15:\\nð‘…â†ðµð‘¡ð‘’ð‘šð‘ð‘œð‘Ÿð‘Žð‘™âˆ’1\\n16:\\nðµð‘¡ð‘’ð‘šð‘ð‘œð‘Ÿð‘Žð‘™â†âŒŠð¿+ð‘…âŒ‹\\n2\\n17:\\nreturn ðµ\\nAlgorithm 3 Dynamic Programming for Plane Division\\nRequire: ð¿ð‘–, ð‘ð‘–, ðµð‘–, ð¿ð‘šð‘Žð‘¥\\nEnsure: 1 â‰¤ð¿ð‘–â‰¤ð¿ð‘šð‘Žð‘¥, 1 â‰¤ð‘ð‘–â‰¤ð¿ð‘–\\n1: function cost(S)\\n2:\\nif |ð‘†| < ð‘€then return +âˆž\\n3:\\nð¿, ð‘, ðµâ†ð‘ð‘œð‘–ð‘›ð‘¡ð‘ ð‘–ð‘›ð‘†\\n4:\\nð‘“â†ð‘“ð‘¢ð‘›ð‘ð‘¡ð‘–ð‘œð‘›ð‘“ð‘–ð‘¡ð‘¡ð‘–ð‘›ð‘”(ðµ|ð¿, ð‘)\\nreturn ð¸(ðµ, ð¿, ð‘|ð‘“)\\n5: function dynamic_programming(ð¿ð‘–, ð‘ð‘–, ð¿ð‘šð‘Žð‘¥)\\n6:\\nfor ð‘™1 = 1 â†’ð¿ð‘šð‘Žð‘¥do\\n7:\\nfor ð‘™2 = 1 â†’ð‘™1 do\\n8:\\nfor ð‘›= 1 â†’ð‘™1 do\\n9:\\nð‘†â†ð‘ð‘œð‘–ð‘›ð‘¡ð‘ ð‘ ð‘’ð‘¡ð‘–ð‘›{ð‘™2 â‰¤ð¿â‰¤ð‘™1, ð‘â‰¤ð‘›}\\n10:\\nð‘”(ð‘›) â†ð¶ð‘‚ð‘†ð‘‡(ð‘†)\\n11:\\nfor ð‘–= 1 â†’ð‘›do\\n12:\\nð‘†â†ð‘ð‘œð‘–ð‘›ð‘¡ð‘ ð‘ ð‘’ð‘¡ð‘–ð‘›{ð‘™2 â‰¤ð¿â‰¤ð‘™1,ð‘–â‰¤ð‘â‰¤ð‘›}\\n13:\\nð‘”(ð‘›) â†ð‘šð‘–ð‘›(ð‘”(ð‘›),ð‘”(ð‘–) + ð¶ð‘‚ð‘†ð‘‡(ð‘†))\\n14:\\nð‘“ð‘™2,ð‘™1 â†ð‘”(ð‘™1)\\n15:\\n16:\\nfor ð‘™= 1 â†’ð¿ð‘šð‘Žð‘¥do\\n17:\\nð‘‘ð‘(ð‘™) â†ð‘“(1,ð‘™)\\n18:\\nfor ð‘–= 1 â†’ð‘™do\\n19:\\nð‘‘ð‘(ð‘™) â†ð‘šð‘–ð‘›(ð‘‘ð‘(ð‘™),ð‘‘ð‘(ð‘–) + ð‘“(ð‘–,ð‘™))\\nreturn ð‘‘ð‘(ð¿ð‘šð‘Žð‘¥)\\nWe describe Alg. 3 and intuitively show its optimality. We assume\\nthat Scipy [53] learns an optimal function in Line 4 so that function\\nCOST gives the optimal estimation error when fitting the points in\\nset ð‘†. When fitting very few points, we assign an infinite cost to\\nprevent a biased fitting function (Line 2). ð‘”(ð‘›) denotes the minimal\\nestimation error for points in sub-plane {ð‘™2 â‰¤ð¿â‰¤ð‘™1, ð‘â‰¤ð‘›}. In\\nLines 11-13, we enumerate all possible ways of cutting {ð‘™2 â‰¤ð¿â‰¤\\nð‘™1, ð‘â‰¤ð‘›} horizontally into two sub-plane {ð‘™2 â‰¤ð¿â‰¤ð‘™1, ð‘â‰¤ð‘–} and\\n{ð‘™2 â‰¤ð¿â‰¤ð‘™1,ð‘–â‰¤ð‘â‰¤ð‘›} by iterating ð‘–from 1 to n. Choosing the\\ncutting strategy that minimizes estimation error gets us að‘”(ð‘™1) with\\nminimal estimation error for sub-plane {ð‘™2 â‰¤ð¿â‰¤ð‘™1, ð‘â‰¤ð‘™1}, which\\nis recorded as ð‘“ð‘™1,ð‘™2 in Line 14. ð‘‘ð‘(ð‘™) denotes the minimal estimation\\nerror for sub-plane {ð¿â‰¤ð‘™}. We enumerate all the possible ways\\nof cutting {ð¿â‰¤ð‘™} vertically into two sub-plane {ð¿â‰¤ð‘–} and {ð‘–â‰¤\\nð¿â‰¤ð‘™} by iterating ð‘–from 1 to ð‘™(Line 17-19). Finally, we have the\\nminimal estimation error for the whole plane as ð‘‘ð‘(ð¿ð‘šð‘Žð‘¥). Based\\non the above discussion, this algorithm guarantees to not miss any\\nbetter solution, hence optimal.\\nA.4\\nThe Correctness of Group Attention\\nLemma 3. Assuming the windows belonging to the same group ðºð‘–\\nhave the same key vector, i.e. ð‘˜ð‘—= ð‘Ÿð‘–(ð‘¤ð‘–ð‘›ð‘—âˆˆðºð‘–), then the feature\\nembedding ð‘‚produced by the original self-attention mechanism is\\nidentical to the output of our group attention mechanism implemented\\nin Algorithm 1.\\nProof. Denote e\\nð‘˜ð‘—to be the representative vectors of ð‘˜ð‘—, i.e. e\\nð‘˜ð‘—=\\nð‘Ÿð‘–= ð‘˜ð‘—(ð‘¤ð‘–ð‘›ð‘—âˆˆðºð‘–). Algorithm 1 gives that\\neð‘£ð‘–=\\nð‘›âˆ’1\\nâˆ‘ï¸\\nð‘—=0\\n(ðµð¸ð¿ð‘‚ð‘ðºð‘—== ð‘–)vð‘—, eð‘ƒð‘–,ð‘—= qð‘–Â· rð‘—\\nð‘ ð‘–=\\nð‘âˆ’1\\nâˆ‘ï¸\\nð‘—=0\\nð‘’ð‘¥ð‘(eð‘ƒð‘–,ð‘—)ð¶ð‘‚ð‘ˆð‘ð‘‡ð‘—, eð‘œð‘–=\\nð‘âˆ’1\\nâˆ‘ï¸\\nð‘—=0\\neð‘ƒð‘–,ð‘—\\nð‘ ð‘–\\neð‘£ð‘—\\n(7)\\nBy the canonical self-attention mechanism introduced in Sec. 2,\\nwe get:\\nð‘ƒð‘–,ð‘—= qð‘–Â· kj, ð´ð‘–,ð‘—=\\nð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘—)\\nÃð‘›âˆ’1\\nð‘˜=0 ð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘˜)\\n, oð‘–=\\nð‘›âˆ’1\\nâˆ‘ï¸\\nð‘—=0\\nð´ð‘–,ð‘—vð‘—\\n(8)\\nWith 7 and 8, we have\\nð‘›âˆ’1\\nâˆ‘ï¸\\nð‘—=0\\nð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘—) =\\nð‘›âˆ’1\\nâˆ‘ï¸\\nð‘—=0\\nð‘’ð‘¥ð‘(qð‘–Â· kð‘—)\\n=\\nð‘âˆ’1\\nâˆ‘ï¸\\nð‘—=0\\nð‘›âˆ’1\\nâˆ‘ï¸\\nð‘¥=0\\n(ðµð¸ð¿ð‘‚ð‘ðºð‘¥== ð‘—)ð‘’ð‘¥ð‘(qð‘–Â· kð‘¥)\\n=\\nð‘âˆ’1\\nâˆ‘ï¸\\nð‘—=0\\nð‘’ð‘¥ð‘(qð‘–Â· rð‘—)\\nð‘›âˆ’1\\nâˆ‘ï¸\\nð‘¥=0\\n(ðµð¸ð¿ð‘‚ð‘ðºð‘¥== ð‘—)\\n=\\nð‘âˆ’1\\nâˆ‘ï¸\\nð‘—=0\\nð‘’ð‘¥ð‘(qð‘–Â· rð‘—)ð¶ð‘‚ð‘ˆð‘ð‘‡ð‘—\\n=\\nð‘âˆ’1\\nâˆ‘ï¸\\nð‘—=0\\nð‘’ð‘¥ð‘(eð‘ƒð‘–,ð‘—)ð¶ð‘‚ð‘ˆð‘ð‘‡ð‘—\\n= ð‘ ð‘–\\n(9)\\n12\\nFurther,\\noð‘–=\\nð‘›âˆ’1\\nâˆ‘ï¸\\nð‘—=0\\nð´ð‘–,ð‘—vj\\n=\\nð‘âˆ’1\\nâˆ‘ï¸\\nð‘—=0\\nð‘›âˆ’1\\nâˆ‘ï¸\\nð‘¥=0\\n(ðµð¸ð¿ð‘‚ð‘ðºð‘¥== ð‘—)ð´ð‘–,ð‘¥vð‘¥\\n=\\nð‘âˆ’1\\nâˆ‘ï¸\\nð‘—=0\\nð‘›âˆ’1\\nâˆ‘ï¸\\nð‘¥=0\\n(ðµð¸ð¿ð‘‚ð‘ðºð‘¥== ð‘—)\\nð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘¥)\\nÃð‘›âˆ’1\\nð‘˜=0 ð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘˜)\\nvð‘¥\\n=\\nð‘âˆ’1\\nâˆ‘ï¸\\nð‘—=0\\nð‘›âˆ’1\\nâˆ‘ï¸\\nð‘¥=0\\n(ðµð¸ð¿ð‘‚ð‘ðºð‘¥== ð‘—)\\nð‘’ð‘¥ð‘(qð‘–Â· kð‘¥)\\nÃð‘›âˆ’1\\nð‘˜=0 ð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘˜)\\nvð‘¥\\n=\\nð‘âˆ’1\\nâˆ‘ï¸\\nð‘—=0\\nð‘›âˆ’1\\nâˆ‘ï¸\\nð‘¥=0\\n(ðµð¸ð¿ð‘‚ð‘ðºð‘¥== ð‘—)\\nð‘’ð‘¥ð‘(qð‘–Â· rj)\\nÃð‘›âˆ’1\\nð‘˜=0 ð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘˜)\\nvð‘¥\\n=\\nð‘âˆ’1\\nâˆ‘ï¸\\nð‘—=0\\nð‘’ð‘¥ð‘(qð‘–Â· rj)\\nÃð‘›âˆ’1\\nð‘˜=0 ð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘˜)\\nð‘›âˆ’1\\nâˆ‘ï¸\\nð‘¥=0\\n(ðµð¸ð¿ð‘‚ð‘ðºð‘¥== ð‘—)vð‘¥\\n=\\nð‘âˆ’1\\nâˆ‘ï¸\\nð‘—=0\\nð‘’ð‘¥ð‘(qð‘–Â· rj)\\nÃð‘›âˆ’1\\nð‘˜=0 ð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘˜)\\neð‘£ð‘—\\n(10)\\nCombining (7), (9) (10), we have oi = ÃN âˆ’1\\nj=0\\nePi,j\\nsi evj = eoi.\\nThis concludes that the output of our group attention is identical\\nto vanilla self-attentionâ€™s.\\nâ–¡\\nA.5\\nThe Proof of Error Bound (Lemma 1)\\nProof. We have\\nð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘—)\\nð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘—) = ð‘’ð‘¥ð‘(qð‘–Â· ekð‘—)\\nð‘’ð‘¥ð‘(qð‘–Â· kð‘—) = ð‘’ð‘¥ð‘(qð‘–Â· (ekð‘—âˆ’kð‘—))\\n= ð‘’ð‘¥ð‘(||qð‘–|| Â· ||ekð‘—âˆ’kð‘—|| Â· ð‘ð‘œð‘ (qð‘–,ekð‘—âˆ’kð‘—))\\n(11)\\nSo\\nð‘’ð‘¥ð‘(âˆ’ð‘‘ð‘…) â‰¤ð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘—)\\nð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘—) â‰¤ð‘’ð‘¥ð‘(ð‘‘ð‘…)\\n(12)\\nThen we have:\\nð´ð‘–,ð‘—\\nð´ð‘–,ð‘—\\n=\\nð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘—)\\nÃð‘›\\nð‘˜=1 ð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘˜)\\n/\\nð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘—)\\nÃð‘›\\nð‘˜=1 ð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘˜)\\n= ð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘—)\\nð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘—)\\nÃð‘›\\nð‘˜=1 ð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘˜)\\nÃð‘›\\nð‘˜=1 ð‘’ð‘¥ð‘(ð‘ƒð‘–,ð‘˜)\\n(13)\\nCombining (12) (13), the error is bounded by\\nð‘’ð‘¥ð‘(âˆ’2ð‘‘ð‘…) â‰¤ð´ð‘–,ð‘—\\nð´ð‘–,ð‘—\\nâ‰¤ð‘’ð‘¥ð‘(2ð‘‘ð‘…)\\n(14)\\nThus, if d â‰¤ln(ðœ–)\\n2R , 1\\nðœ–â‰¤Ai,j\\nAi,j â‰¤ðœ–. This proves Lemma 1.\\nA.6\\nThe Proof of Merge Operation (Lemma 2)\\nProof. Denote the cluster size of ð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘˜to be ð‘›ð‘˜.After merge-\\ning, the new center will be:\\nð‘â€² =\\nÃð‘š\\nð‘–=1 ð‘›ð‘˜ð‘–ð‘ð‘˜ð‘–\\nÃð‘š\\nð‘–=1 ð‘›ð‘˜ð‘–\\nFor âˆ€ð‘–âˆˆ[1,ð‘š], âˆ€ð‘¥âˆˆð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿð‘˜ð‘–, it holds that:\\n|ð‘¥âˆ’ð‘â€²| â‰¤|ð‘¥âˆ’ð‘ð‘˜ð‘–| + |ð‘ð‘˜ð‘–âˆ’ð‘â€²| (ð‘‡ð‘Ÿð‘–ð‘Žð‘›ð‘”ð‘™ð‘’ð‘–ð‘›ð‘’ð‘žð‘¢ð‘Žð‘™ð‘–ð‘¡ð‘¦)\\n= |ð‘¥âˆ’ð‘ð‘˜ð‘–| + |\\nÃð‘š\\nð‘—=1 ð‘›ð‘˜ð‘—\\nÃð‘š\\nð‘—=1 ð‘›ð‘˜ð‘—\\nð‘ð‘˜ð‘–âˆ’\\nÃð‘š\\nð‘—=1 ð‘›ð‘˜ð‘—ð‘ð‘˜ð‘—\\nÃð‘š\\nð‘—=1 ð‘›ð‘˜ð‘—\\n|\\n= |ð‘¥âˆ’ð‘ð‘˜ð‘–| + |\\nÃð‘š\\nð‘—=1 ð‘›ð‘˜ð‘—(ð‘ð‘˜ð‘–âˆ’ð‘ð‘˜ð‘—)\\nÃð‘š\\nð‘—=1 ð‘›ð‘˜ð‘—\\n|\\n= |ð‘¥âˆ’ð‘ð‘˜ð‘–| +\\n| Ãð‘š\\nð‘—=1 ð‘›ð‘˜ð‘—(ð‘ð‘˜ð‘–âˆ’ð‘ð‘˜ð‘—) |\\nÃð‘š\\nð‘—=1 ð‘›ð‘˜ð‘—\\nâ‰¤|ð‘¥âˆ’ð‘ð‘˜ð‘–| +\\nÃð‘š\\nð‘—=1 ð‘›ð‘˜ð‘—|ð‘ð‘˜ð‘–âˆ’ð‘ð‘˜ð‘—|\\nÃð‘š\\nð‘—=1 ð‘›ð‘˜ð‘—\\n=\\nÃð‘š\\nð‘—=1 ð‘›ð‘˜ð‘—(|ð‘ð‘˜ð‘–âˆ’ð‘ð‘˜ð‘—| + |ð‘¥âˆ’ð‘ð‘˜ð‘–|)\\nÃð‘š\\nð‘—=1 ð‘›ð‘˜ð‘—\\nâ‰¤\\nÃð‘š\\nð‘—=1 ð‘›ð‘˜ð‘—ð‘‘\\nÃð‘š\\nð‘—=1 ð‘›ð‘˜ð‘—\\n= ð‘‘\\n(15)\\nA.7\\nDownstream Tasks\\nRITA supports a variety of downstream tasks. In this section, we\\nshow that with minimal modification RITA can effectively support\\nclassification, imputation and forecasting tasks. Other unsupervised\\ntasks such as similarity search or clustering are naturally supported\\nby extracting feature embeddings from RITA.\\nA.7.1\\nClassification\\nTo classify timeseries, we input timeseries to the model as described\\nin Sec. 3 and attach a special token [CLS] as the first input em-\\nbedding. [CLS]â€™s embedding acts as the embedding for the entire\\ntimeseries, and the output representation of [CLS] is fed into a\\nclassifier: y = Softmax(WclsZ[CLS] + Bcls), where ð‘[ð¶ð¿ð‘†] âˆˆRð‘‘is\\nthe output representation of [CLS], C is the number of classes, and\\nWcls âˆˆRCÃ—d, Bcls âˆˆRC are learnable parameters for classification\\ntask. The result vector ð‘¦âˆˆRð¶represents the possibility that the\\ninput timeseries belongs to each class.\\nWe apply Cross Entropy Loss as the loss function of the classi-\\nfication task [13]: L = 1\\nC\\nÃC\\ni=1 âˆ’Ë†y(i)log(y(i)), where Ë†ð‘¦is a binary\\nindicator for ground truth label:\\nË†ð‘¦(ð‘–) =\\n(\\n1\\nð‘–is ground truth label\\n0\\nð‘œð‘¡â„Žð‘’ð‘Ÿð‘¤ð‘–ð‘ ð‘’\\n(16)\\nA.7.2\\nImputation\\nTimeseries are mainly generated by sensors, a common problem\\nof which is missing values. This becomes a challenge when many\\ndownstream analytics require the missing values to be recovered.\\nThe recovering task is imputation.\\nDenote the real timeseries asð‘‡ð‘ŸâˆˆRð‘¡Ã—ð‘š, the observed timeseries\\nwith missing values as ð‘‡ð‘œâˆˆRð‘¡Ã—ð‘š, and the set of missing valuesâ€™\\npositions as ð‘€. We scale the values of all timeseries to non-negative\\nand use a special value (-1) to indicate missing values:\\nð‘‡ð‘œ(ð‘–, ð‘—) =\\n(\\nâˆ’1\\n(ð‘–, ð‘—) âˆˆð‘€\\nð‘‡ð‘Ÿ(ð‘–, ð‘—)\\n(ð‘–, ð‘—) âˆ‰ð‘€\\n(17)\\nð‘‡ð‘œis fed into the RITA as input, and the output representa-\\ntions are concatenated and fed into a Transpose Convolution layer\\nwhich decodes the output embedding vectors from hidden space to\\ntimeseries values, corresponding to the convolution operation in\\n13\\nthe input stage, i.e., Y = TransposeCNN (Z1 +â—‹Z2 +â—‹... +â—‹Zn), where\\nð‘ŒâˆˆRð‘¡Ã—ð‘šis the recovered timeseries, and ð‘ð‘–âˆˆRð‘‘is the output of\\neach position.\\nHere Mean Square Error is chosen as the loss function [51]:\\nð¿=\\n1\\n|ð‘€|\\nÃ\\n(ð‘–,ð‘—)âˆˆð‘€(ð‘Œ(ð‘–, ð‘—) âˆ’ð‘‡ð‘Ÿ(ð‘–, ð‘—))2.\\nA.7.3\\nForecasting\\nForecasting can be regarded as a special case of imputation, in\\nwhich all missing values are at the end of timeseries.\\nSo like in imputation task, we scale the timeseries to non-\\nnegative and use a special value (-1) to indicate the values to be\\npredicted:\\nð‘‡ð‘œð‘ð‘ ð‘’ð‘Ÿð‘£ð‘’ð‘‘(ð‘–, ð‘—) =\\n(\\nð‘‡ð‘Ÿð‘’ð‘Žð‘™(ð‘–, ð‘—)\\nð‘–â‰¤ð‘¡ð‘œð‘ð‘ ð‘’ð‘Ÿð‘£ð‘’ð‘‘\\nâˆ’1\\nð‘œð‘¡â„Žð‘’ð‘Ÿð‘¤ð‘–ð‘ ð‘’\\n(18)\\nWhere ð‘¡ð‘œð‘ð‘ ð‘’ð‘Ÿð‘£ð‘’ð‘‘is the observed timestamp. Then the output\\nrepresentations are fed into a Transpose Convolution layer using\\nMean Squared Error as loss function, as described above.\\nA.7.4\\nOther Unsupervised Tasks\\nRITA naturally supports other unsupervised tasks, such as similar-\\nity search and clustering [25, 31, 32], by producing the embedding\\nof one timeseries (output representation of the special token [CLS]).\\nClustering can be performed on the embeddings with flexible choice\\nof distance metrics. Similarly, a high dimensional similarity search\\nsystem [22, 23, 38] can be built on the embeddings.\\nA.8\\nInference Time\\nDataset\\nLength\\nTST[61]\\nVanilla\\nPerformer\\nLinformer\\nGroup Attn.\\nWISDM\\n200\\n2.18\\n2.26\\n2.35\\n2.22\\n2.17\\nHHAR\\n200\\n1.19\\n1.23\\n1.28\\n1.21\\n1.18\\nRWHAR\\n200\\n1.32\\n1.37\\n1.42\\n1.34\\n1.31\\nECG\\n2000\\n18.44\\n15.26\\n5.80\\n6.08\\n5.16\\nTable 6: Inference time: Classification on multi-variate data\\n(seconds).\\nDataset\\nLength\\nTST[61]\\nVanilla\\nPerformer\\nLinformer\\nGroup Attn.\\nWISDM\\n200\\n2.03\\n2.11\\n2.19\\n2.07\\n2.02\\nHHAR\\n200\\n1.11\\n1.14\\n1.19\\n1.12\\n1.10\\nRWHAR\\n200\\n1.23\\n1.27\\n1.32\\n1.25\\n1.22\\nECG\\n2000\\n17.22\\n14.32\\n4.73\\n4.99\\n4.11\\nMGH\\n10000\\nN/A\\nN/A\\n6.58\\n6.88\\n1.35\\nTable 7: Inference time: Imputation on multi-variate data\\n(seconds).\\nIn this section, we present the average inference time on valida-\\ntion sets. The results in Table. 6 and 7 correspond to the average\\ninference time on validation sets of classification and imputation\\ntasks, respectively. Consistent with the results in Section. 6.3, our\\nmethod Group Attn. outperforms the baselines on both classifica-\\ntion and imputation tasks, particularly on the datasets comprising\\nlong timeseries (ECG and MGH).\\n14\\n')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Arxiv\n",
    "from langchain_community.document_loaders import ArxivLoader\n",
    "docs = ArxivLoader(query=\"Attention is all you need\", load_max_docs=2).load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954b5802",
   "metadata": {},
   "source": [
    "### Wikipedia Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bae6cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'title': 'Generative AI pornography', 'summary': 'Generative AI pornography or simply AI pornography is a digitally created pornography produced through generative artificial intelligence (AI) technologies. Unlike traditional pornography, which involves real actors and cameras, this content is synthesized entirely by AI algorithms. These algorithms, including Generative adversarial network (GANs) and text-to-image models, generate lifelike images, videos, or animations from textual descriptions or datasets.', 'source': 'https://en.wikipedia.org/wiki/Generative_AI_pornography'}, page_content='Generative AI pornography or simply AI pornography is a digitally created pornography produced through generative artificial intelligence (AI) technologies. Unlike traditional pornography, which involves real actors and cameras, this content is synthesized entirely by AI algorithms. These algorithms, including Generative adversarial network (GANs) and text-to-image models, generate lifelike images, videos, or animations from textual descriptions or datasets.\\n\\n\\n== History ==\\nThe use of generative AI in the adult industry began in the late 2010s, initially focusing on AI-generated art, music, and visual content. This trend accelerated in 2022 with Stability AI\\'s release of Stable Diffusion (SD), an open-source text-to-image model that enables users to generate images, including NSFW content, from text prompts using the LAION-Aesthetics subset of the LAION-5B dataset. Despite Stability AI\\'s warnings against sexual imagery, SD\\'s public release led to dedicated communities exploring both artistic and explicit content, sparking ethical debates over open-access AI and its use in adult media. By 2020, AI tools had advanced to generate highly realistic adult content, amplifying calls for regulation.\\n\\n\\n=== AI-generated influencers ===\\nOne application of generative AI technology is the creation of AI-generated influencers on platforms such as OnlyFans and Instagram. These AI personas interact with users in ways that can mimic real human engagement, offering an entirely synthetic but convincing experience. While popular among niche audiences, these virtual influencers have prompted discussions about authenticity, consent, and the blurring line between human and AI-generated content, especially in adult entertainment.\\n\\n\\n=== The growth of AI porn sites ===\\nBy 2023, websites dedicated to AI-generated adult content had gained traction, catering to audiences seeking customizable experiences. These platforms allow users to create or view AI-generated pornography tailored to their preferences. These platforms enable users to create or view AI-generated adult content appealing to different preferences through prompts and tags, customizing body type, facial features, and art styles. Tags further refine the output, creating niche and diverse content. Many sites feature extensive image libraries and continuous content feeds, combining personalization with discovery and enhancing user engagement. AI porn sites, therefore, attract those seeking unique or niche experiences, sparking debates on creativity and the ethical boundaries of AI in adult media.\\n\\n\\n== Ethical concerns and misuse ==\\nThe growth of generative AI pornography has also attracted some cause for criticism. AI technology can be exploited to create non-consensual pornographic material, posing risks similar to those seen with deepfake revenge porn and AI-generated NCII (Non-Consensual Intimate Image). A 2023 analysis found that 98% of deepfake videos online are pornographic, with 99% of the victims being women. Some famous celebrities victims of deepfake include Scarlett Johansson, Taylor Swift, and Maisie Williams.\\nOpenAI is exploring whether NSFW content, such as erotica, can be responsibly generated in age-appropriate contexts while maintaining its ban on deepfakes. This proposal has attracted criticism from child safety campaigners who argue it undermines OpenAI\\'s mission to develop \"safe and beneficial\" AI. Additionally, the Internet Watch Foundation has raised concerns about AI being used to generate sexual abuse content involving children.\\n\\n\\n=== AI-generated non-consensual intimate imagery (AI Undress) ===\\nSeveral US states are taking actions against using deepfake apps and sharing them on the internet. In 2024, San Francisco filed a landmark lawsuit to shut down \"undress\" apps that allow users to generate non-consensual AI nude images, citing violations of state laws. The case aligns with California\\'s recent legislationâ€”SB 926, SB 942, and SB 981â€”championed by Senators Aisha Wahab a'), Document(metadata={'title': 'Generative artificial intelligence', 'summary': 'Generative artificial intelligence (Generative AI, GenAI, or GAI) is a subfield of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.\\nGenerative AI tools have become more common since an \"AI boom\" in the 2020s. This boom was made possible by improvements in transformer-based deep neural networks, particularly large language models (LLMs). Major tools include chatbots such as ChatGPT, Copilot, Gemini, Grok, and DeepSeek; text-to-image models such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video models such as Sora. Technology companies developing generative AI include OpenAI, Anthropic, Meta AI, Microsoft, Google, DeepSeek, and Baidu.\\nGenerative AI has raised many ethical questions. It can be used for cybercrime, or to deceive or manipulate people through fake news or deepfakes. Even if used ethically, it may lead to mass replacement of human jobs. The tools themselves have been criticized as violating intellectual property laws, since they are trained on and emulate copyrighted works of art.\\nGenerative AI is used across many industries. Examples include software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design.', 'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence'}, page_content='Generative artificial intelligence (Generative AI, GenAI, or GAI) is a subfield of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.\\nGenerative AI tools have become more common since an \"AI boom\" in the 2020s. This boom was made possible by improvements in transformer-based deep neural networks, particularly large language models (LLMs). Major tools include chatbots such as ChatGPT, Copilot, Gemini, Grok, and DeepSeek; text-to-image models such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video models such as Sora. Technology companies developing generative AI include OpenAI, Anthropic, Meta AI, Microsoft, Google, DeepSeek, and Baidu.\\nGenerative AI has raised many ethical questions. It can be used for cybercrime, or to deceive or manipulate people through fake news or deepfakes. Even if used ethically, it may lead to mass replacement of human jobs. The tools themselves have been criticized as violating intellectual property laws, since they are trained on and emulate copyrighted works of art.\\nGenerative AI is used across many industries. Examples include software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design.\\n\\n\\n== History ==\\n\\n\\n=== Early history ===\\nThe first example of an algorithmically generated media is likely the Markov chain. Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906, and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.\\nComputers were needed to go beyond Markov chains. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.\\nThe terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal. Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use, process plans for manufacturing and decision plans such as in prototype autonomous spacecraft.\\n\\n\\n=== Generative neural networks (2014-2019) ===\\n\\nSince inception, the field of machine learning has used both discriminative models and generative models to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress, and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models due to the difficulty of generative modeling.\\nIn 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\\nIn 2017, the Transformer network enabled advancements in generative models compared to older Long-Short Term Memory models, leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018. This was followed in 2019 by GPT-2, which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.\\nThe new generative models'), Document(metadata={'title': 'AI boom', 'summary': 'The AI boom is an ongoing period of rapid progress in the field of artificial intelligence (AI) that started in the late 2010s before gaining international prominence in the early 2020s. Examples include large language models and generative AI applications developed by OpenAI as well as protein folding prediction led by Google DeepMind. This period is sometimes referred to as an AI spring, to contrast it with previous AI winters.', 'source': 'https://en.wikipedia.org/wiki/AI_boom'}, page_content='The AI boom is an ongoing period of rapid progress in the field of artificial intelligence (AI) that started in the late 2010s before gaining international prominence in the early 2020s. Examples include large language models and generative AI applications developed by OpenAI as well as protein folding prediction led by Google DeepMind. This period is sometimes referred to as an AI spring, to contrast it with previous AI winters.\\n\\n\\n== History ==\\n\\nIn 2012, a University of Toronto research team used artificial neural networks and deep learning techniques to lower the error rate below 25% for the first time during the ImageNet challenge for object recognition in computer vision. The event catalyzed the AI boom later that decade, when many alumni of the ImageNet challenge became leaders in the tech industry. In March 2016, AlphaGo beat Lee Sedol in a five-game match, marking the first time a computer Go program had beaten a 9-dan professional without handicap. This match led to significant increase in public interest in AI. The generative AI race began in earnest in 2016 or 2017 following the founding of OpenAI and earlier advances made in graphics processing units (GPUs), the amount and quality of training data, generative adversarial networks, diffusion models and transformer architectures. \\nIn 2018, the Artificial Intelligence Index, an initiative from Stanford University, reported a global explosion of commercial and research efforts in AI. Europe published the largest number of papers in the field that year, followed by China and North America. Technologies such as AlphaFold led to more accurate predictions of protein folding and improved the process of drug development. Economists and lawmakers began to discuss the potential impact of AI more frequently. By 2022, large language models (LLMs) saw increased usage in chatbot applications; text-to-image-models could generate images that appeared to be human-made; and speech synthesis software was able to replicate human speech efficiently.\\nAccording to metrics from 2017 to 2021, the United States outranks the rest of the world in terms of venture capital funding, the number of startups, and patents granted in AI. Scientists who have immigrated to the U.S. play an outsized role in the country\\'s development of AI technology. Many of them were educated in China, prompting debates about national security concerns amid worsening relations between the two countries.\\nExperts have framed AI development as a competition for economic and geopolitical advantage between the United States and China. In 2021, an analyst for the Council on Foreign Relations outlined ways that the U.S. could maintain its position amid progress made by China. In 2023, an analyst at the Center for Strategic and International Studies advocated for the U.S. to use its dominance in AI technology to drive its foreign policy instead of relying on trade agreements.\\n\\n\\n== Advances ==\\n\\n\\n=== Biomedical ===\\nThe AlphaFold 2 score of more than 90 in CASP\\'s global distance test (GDT) is considered a significant achievement in computational biology and great progress towards a decades-old grand challenge of biology. The structural biologist and Nobel Prize winner Venki Ramakrishnan called the result \"a stunning advance on the protein folding problem\", adding that \"It has occurred decades before many people in the field would have predicted.\"\\nThe ability to predict protein structures accurately based on the constituent amino acid sequence is expected to accelerate drug discovery and enable a better understanding of diseases.\\n\\n\\n=== Images and videos ===\\n\\nText-to-image models captured widespread public attention when OpenAI announced DALL-E, a transformer system, in January 2021. A successor capable of generating complex and realistic images, DALL-E 2, was unveiled in April 2022. An alternative text-to-image model, Midjourney, was released in July 2022. Another alternative, open-source model Stable Diffusion, released in August 20'), Document(metadata={'title': 'Artificial intelligence', 'summary': 'Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.\\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"\\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields. Some companies, such as OpenAI, Google DeepMind and Meta, aim to create artificial general intelligence (AGI)â€”AI that can complete virtually any cognitive task at least as well as a human.\\nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks, and deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture. In the 2020s, the period of rapid progress marked by advanced generative AI became known as the AI boom. Generative AI and its ability to create and modify content exposed several unintended consequences and harms in the present and raised ethical concerns about AI\\'s long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Artificial_intelligence'}, page_content='Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.\\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"\\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields. Some companies, such as OpenAI, Google DeepMind and Meta, aim to create artificial general intelligence (AGI)â€”AI that can complete virtually any cognitive task at least as well as a human.\\nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks, and deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture. In the 2020s, the period of rapid progress marked by advanced generative AI became known as the AI boom. Generative AI and its ability to create and modify content exposed several unintended consequences and harms in the present and raised ethical concerns about AI\\'s long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\\n\\n\\n== Goals ==\\nThe general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.\\n\\n\\n=== Reasoning and problem-solving ===\\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.\\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow. Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments. Accurate and efficient reasoning is an unsolved problem.\\n\\n\\n=== Knowledge representation ===\\n\\nKnowledge representation and knowledge engineering allow AI programs to answer questions intelligently and m')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "docs = WikipediaLoader(query=\"Generative AI\", load_max_docs=4).load()\n",
    "len(docs)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75351256",
   "metadata": {},
   "source": [
    "### Unstructured Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e76bc885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_unstructured import UnstructuredLoader\n",
    "\n",
    "file_paths = [\n",
    "    \"data/syllabus.pdf\",\n",
    "    \"data/speech.txt\",\n",
    "]\n",
    "\n",
    "\n",
    "loader = UnstructuredLoader(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88c5312a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "partition_pdf() is not available because one or more dependencies are not installed. Use: pip install \"unstructured[pdf]\" (including quotes) to install the required dependencies",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m docs = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m docs[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_2_base\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:32\u001b[39m, in \u001b[36mBaseLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m     31\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.lazy_load())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_2_base\\Lib\\site-packages\\langchain_unstructured\\document_loaders.py:174\u001b[39m, in \u001b[36mUnstructuredLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.file_path, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.file_path:\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m load_file(f_path=f_path)\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# Call _UnstructuredBaseLoader normally since file and file_path are not lists\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_2_base\\Lib\\site-packages\\langchain_unstructured\\document_loaders.py:212\u001b[39m, in \u001b[36m_SingleDocumentLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[Document]:\n\u001b[32m    208\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[32m    209\u001b[39m     elements_json = (\n\u001b[32m    210\u001b[39m         \u001b[38;5;28mself\u001b[39m._post_process_elements_json(\u001b[38;5;28mself\u001b[39m._elements_json)\n\u001b[32m    211\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.post_processors\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_elements_json\u001b[49m\n\u001b[32m    213\u001b[39m     )\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m elements_json:\n\u001b[32m    215\u001b[39m         metadata = \u001b[38;5;28mself\u001b[39m._get_metadata()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_2_base\\Lib\\site-packages\\langchain_unstructured\\document_loaders.py:231\u001b[39m, in \u001b[36m_SingleDocumentLoader._elements_json\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.partition_via_api:\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._elements_via_api\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._convert_elements_to_dicts(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_elements_via_local\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_2_base\\Lib\\site-packages\\langchain_unstructured\\document_loaders.py:249\u001b[39m, in \u001b[36m_SingleDocumentLoader._elements_via_local\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.file \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unstructured_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata_filename\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    245\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf partitioning a fileIO object, metadata_filename must be specified\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m as well.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    247\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43munstructured_kwargs\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_2_base\\Lib\\site-packages\\unstructured\\partition\\auto.py:211\u001b[39m, in \u001b[36mpartition\u001b[39m\u001b[34m(filename, file, encoding, content_type, url, headers, ssl_verify, request_timeout, strategy, skip_infer_table_types, ocr_languages, languages, detect_language_per_element, pdf_infer_table_structure, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, data_source_metadata, metadata_filename, hi_res_model_name, model_name, starting_page_number, **kwargs)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;66;03m# -- handle PDF/Image partitioning separately because they have a lot of special-case\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;66;03m# -- parameters. We'll come back to this after sorting out the other file types.\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file_type == FileType.PDF:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     partition_pdf = \u001b[43mpartitioner_loader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m     elements = partition_pdf(\n\u001b[32m    213\u001b[39m         filename=filename,\n\u001b[32m    214\u001b[39m         file=file,\n\u001b[32m   (...)\u001b[39m\u001b[32m    225\u001b[39m         **kwargs,\n\u001b[32m    226\u001b[39m     )\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m augment_metadata(elements)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_2_base\\Lib\\site-packages\\unstructured\\partition\\auto.py:362\u001b[39m, in \u001b[36m_PartitionerLoader.get\u001b[39m\u001b[34m(self, file_type)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;66;03m# -- if the partitioner is not in the cache, load it; note this raises if one or more of\u001b[39;00m\n\u001b[32m    360\u001b[39m \u001b[38;5;66;03m# -- the partitioner's dependencies is not installed.\u001b[39;00m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._partitioners:\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m     \u001b[38;5;28mself\u001b[39m._partitioners[file_type] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_partitioner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._partitioners[file_type]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_2_base\\Lib\\site-packages\\unstructured\\partition\\auto.py:371\u001b[39m, in \u001b[36m_PartitionerLoader._load_partitioner\u001b[39m\u001b[34m(self, file_type)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pkg_name \u001b[38;5;129;01min\u001b[39;00m file_type.importable_package_dependencies:\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dependency_exists(pkg_name):\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    372\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_type.partitioner_function_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() is not available because one or\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    373\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m more dependencies are not installed. Use:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    374\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m pip install \u001b[39m\u001b[33m\"\u001b[39m\u001b[33munstructured[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_type.extra_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m (including quotes)\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    375\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m to install the required dependencies\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    376\u001b[39m         )\n\u001b[32m    378\u001b[39m \u001b[38;5;66;03m# -- load the partitioner and return it --\u001b[39;00m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m file_type.is_partitionable  \u001b[38;5;66;03m# -- would be a programming error if this failed --\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install \"unstructured[pdf]\" (including quotes) to install the required dependencies"
     ]
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3164e91",
   "metadata": {},
   "source": [
    "## Text Splitter or Basic Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb78d551",
   "metadata": {},
   "source": [
    "### Text Splitting from Documents- RecursiveCharacter Text Splitters\n",
    "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text.\n",
    "\n",
    "- How the text is split: by list of characters.\n",
    "- How the chunk size is measured: by number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "101cd2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 0, 'page_label': '1'}, page_content='MACHINE\\nLEARNING\\nDEEP\\nLEARNING\\nPYTHON +\\nSTATS\\nCOMPUTER VISIONNATURAL LANGUAGE PROCESSING\\nGENERATIVE AI\\nRETRIEVAL AUGUMENT GENERATION\\nVECTOR DB'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 1, 'page_label': '2'}, page_content='This course is designed for aspiring data scientists, machine learning enthusiasts, and\\nprofessionals looking to build expertise in Python programming, data analysis, machine learning,\\nand deep learning. Whether you are just starting or have some experience, this comprehensive\\ncourse will equip you with the skills needed to work with real-world datasets, apply machine\\nlearning algorithms, and deploy AI solutions. By the end of the course, youâ€™ll have a solid\\nfoundation in AI, a portfolio of end-to-end projects, and the confidence to tackle complex\\nchallenges in data science and AI.\\nLearning Objectives\\nMaster Python Programming: Understand Python fundamentals, including data types,\\ncontrol structures, and object-oriented programming, to write efficient and reusable\\ncode.\\nHandle Data with Pandas and NumPy: Acquire skills to manipulate, clean, and\\npreprocess large datasets using Pandas and NumPy for data analysis tasks.\\nVisualize Data: Create compelling data visualizations using libraries such as Matplotlib,\\nSeaborn, and Plotly to present insights effectively.\\nUnderstand SQL & NoSQL: Gain expertise in both relational (SQL) and non-relational\\n(NoSQL) databases, including MongoDB, for storing, querying, and managing data.\\nGrasp Statistics and Probability: Understand the core concepts of statistics,\\nprobability, and hypothesis testing, applying them to data analysis and machine\\nlearning.\\nMaster Machine Learning Techniques: Learn key machine learning algorithms,\\nincluding supervised, unsupervised, and ensemble methods, and apply them to real-\\nworld problems.\\nDive into Deep Learning: Develop a strong understanding of neural networks, CNNs,\\nRNNs, and transformers, with hands-on implementation for advanced AI tasks.\\nExplore Generative AI & Vector Databases: Learn the concepts and applications of\\ngenerative models, vector databases, and retrieval-augmented generation to handle\\ncomplex AI systems.\\nBuild Real-World Projects: Implement end-to-end machine learning and AI projects,\\nfrom data preprocessing to model deployment, integrating concepts from multiple\\nmodules.\\nUltimate Data Science & GenAI Bootcamp       Page  2'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 2, 'page_label': '3'}, page_content=\"Course Information\\nNo prerequisites are required for this course. The curriculum covers everything from the\\nbasics of Python programming, statistics, and machine learning to advanced topics in deep\\nlearning, NLP, and generative AI. Whether you're a beginner or have some prior experience,\\nthe course will ensure you gain the skills needed to succeed.\\nEstimated Time\\n8 months 6hrs/week*\\nRequired Skill Level\\nBegineer\\nThe course is designed to be completed over a duration of approximately 7 to 8 months, providing\\nan in-depth exploration from Python basics to GenAI, with plenty of time for practical\\nimplementation and real-world applications.\\nPrerequisites\\nUltimate Data Science & GenAI Bootcamp       Page  3\"), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 3, 'page_label': '4'}, page_content='Course Instructors\\nSunny SavitaGenAI Engineer\\nLinkedin\\nKrish NaikChief AI Engineer\\nLinkedin\\nUltimate Data Science & GenAI Bootcamp       Page  4\\nSourangshu PalSenior Data Scientist\\nLinkedin\\nMonal KumarData Scientist\\nLinkedin\\nMayank AggrawalSenior ML Engineer\\nLinkedin\\nDarius B.Head of Product\\nLinkedin'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 4, 'page_label': '5'}, page_content=\"In this module, youâ€™ll get a solid introduction to Python, covering essential programming concepts\\nsuch as variables, data types, operators, and control flow. Youâ€™ll learn how to manipulate strings,\\nlists, dictionaries, and other basic data structures. The module will also guide you through writing\\nsimple functions and using loops and conditionals effectively. By the end, you'll have a strong\\nunderstanding of Python syntax, preparing you to tackle more complex programming challenges\\nand form a foundation for learning advanced concepts.\\nUltimate Data Science & GenAI Bootcamp       Page  5\\nPython Foundations\\nModule 1\\nTopics\\nIntroduction to Python Comparison with other programming\\nlanguages, Python objects: Numbers,\\nBooleans, and Strings\\nData Structures & Operations Container objects and mutability,\\nOperators, Operator precedence and\\nassociativity\\nControl Flow Conditional statements, Loops, break\\nand continue statements\\nString Manipulation Basics of string objects, Inbuilt string\\nmethods, Splitting and joining strings,\\nString formatting functions\\nLists & Collections List methods, list comprehension, Lists as\\nstacks and queues, Tuples, sets, and\\ndictionaries, Dictionary comprehensions\\nand view objects\"), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 5, 'page_label': '6'}, page_content='Topics\\nFunctions & Iterators Function basics and parameter passing,\\nIterators and generator functions,\\nLambda functions, map(), reduce(),\\nfilter()\\nPython Foundations\\nModule 1\\nUltimate Data Science & GenAI Bootcamp       Page  6'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 6, 'page_label': '7'}, page_content='This module takes your Python skills further by diving into object-oriented programming (OOP)\\nconcepts like classes, inheritance, and polymorphism. Youâ€™ll also explore more advanced topics\\nsuch as decorators, lambda functions, iterators, and generator functions. Additionally, we cover\\nexception handling, file operations, and working with modules and libraries. By the end, you will be\\ncomfortable building more sophisticated Python applications and writing efficient, reusable code.\\nAdvanced Python Programming\\nModule 2\\nTopics\\nObject-Oriented Programming (OOP) OOP basics and class creation,\\nInheritance, Polymorphism,\\nEncapsulation, and Abstraction,\\nDecorators, class methods, and static\\nmethods, Special (Magic/Dunder)\\nmethods, Property decorators: Getters,\\nsetters, and delete methods\\nFile Handling & Logging Reading and writing files, Buffered read\\nand write operations, more file methods,\\nLogging and debugging\\nModules & Exception Handling Importing modules and using them\\neffectively, Exception handling\\nConcurrency & Parallelism Introduction to multithreading,\\nMultiprocessing for performance\\noptimization\\nUltimate Data Science & GenAI Bootcamp       Page  7'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 7, 'page_label': '8'}, page_content='In this module, you will master the core aspects of data manipulation using Pandas. Youâ€™ll learn\\nhow to work with Series, DataFrames, and Panels, as well as perform data selection, filtering, and\\nsorting. The module covers critical tasks like handling missing data, reindexing, and applying\\nstatistical functions to datasets. Youâ€™ll also gain hands-on experience with data visualization and\\nadvanced indexing techniques, empowering you to efficiently analyze and manipulate complex\\ndatasets.\\nMastering Data Handling with Pandas\\nTopics\\nData Structures & Fundamentals Series, DataFrame, Panel, Basic\\nFunctionality, Indexing & Selecting, Re-\\nindexing, Iteration\\nData Operations & Transformations Sorting, Working with Text Data, Options\\n& Customization, Categorical Data, Date\\nFunctionality, Time Delta\\nData Analysis & Statistical Functions Data Statistical Functions, Window\\nFunctions\\nReading, Writing & Visualization Reading Data from Different File\\nSystems, Visualization, Tools\\nUltimate Data Science & GenAI Bootcamp       Page  8\\nModule 3'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 8, 'page_label': '9'}, page_content='This module introduces you to NumPy, a key library for numerical computing in Python. Youâ€™ll learn\\nhow to create and manipulate NumPy arrays, perform advanced indexing, and understand\\nbroadcasting. The module covers essential mathematical and statistical functions, including array\\nmanipulations, binary operations, and vectorized operations. By the end, youâ€™ll have the skills to\\nefficiently perform complex numerical computations and leverage NumPy for machine learning\\nand deep learning applications.\\nMastering NumPy\\nTopics\\nNumPy Basics & Array Creation NdArray Object, Data Types, Array\\nAttributes, Array Creation Routines,\\nArray from Existing Data, Data Array from\\nNumerical Ranges\\nIndexing, Slicing & Advanced Indexing Indexing & Slicing, Advanced Indexing\\nArray Operations & Manipulation Array Manipulation, Binary Operators,\\nString Functions, Arithmetic Operations,\\nMathematical Functions\\nMathematical & Statistical Analysis Statistical Functions, Sort, Search &\\nCounting Functions, Matrix Library,\\nLinear Algebra\\nAdvanced Concepts Broadcasting, Iterating Over Array, Byte\\nSwapping, Copies & Views\\nUltimate Data Science & GenAI Bootcamp       Page  9\\nModule 4'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 9, 'page_label': '10'}, page_content=\"In this module, youâ€™ll learn how to visualize data effectively using Python's popular libraries,\\nMatplotlib, Seaborn, and Plotly. Youâ€™ll cover essential plot types like line charts, bar graphs, and\\nscatter plots, and learn how to customize these visualizations to highlight key insights. Additionally,\\nthe module teaches you how to visualize statistical data, correlations, and distributions, helping\\nyou communicate data-driven findings in a visually compelling way.\\nData Visualization with Python\\nTopics\\nIntroduction to Data Visualization Overview of Data Visualization, Principles\\nof Good Visualization\\nMatplotlib Introduction to Matplotlib, Creating\\nBasic Plots (Line, Bar, Scatter),\\nCustomizing Axes, Titles, Legends, and\\nLabels, Working with Subplots, Saving\\nand Exporting Figures\\nSeaborn Introduction to Seaborn, Visualizing\\nDistributions, Relationship Plots\\n(Pairplots, Heatmaps), Categorical Data\\nVisualization, Advanced Plot\\nCustomizations\\nPlotly Introduction to Plotly, Creating\\nInteractive Plots (Line, Bar, Scatter),\\nCustomizing Plots, Dashboards and\\nInteractive Layouts, Plotly Express\\nUltimate Data Science & GenAI Bootcamp       Page  10\\nModule 5\"), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 10, 'page_label': '11'}, page_content='This module dives into advanced SQL techniques, including complex queries, joins, and indexing\\nfor efficient data retrieval. Youâ€™ll learn how to implement stored procedures, triggers, and\\nfunctions, and explore the use of window functions and partitions. The module covers key\\ndatabase design concepts like primary and foreign keys and normalization. By the end, youâ€™ll be\\nproficient in managing large-scale databases and optimizing SQL queries for performance.\\nAdvanced SQL and Database Management\\nTopics\\nIntroduction to SQL Introduction to SQL, SQL Queries:\\nSELECT, INSERT, UPDATE, DELETE\\nSQL Functions and Procedures SQL Functions (Aggregate, Scalar),\\nStored Procedures, User-defined\\nFunctions (UDFs), Function and\\nProcedure Syntax\\nDatabase Constraints Primary and Foreign Keys, Data Integrity,\\nReferential Integrity\\nAdvanced SQL Techniques Window Functions, Partitioning, CTE\\n(Common Table Expressions), Indexing\\nSQL Joins and Unions Inner Join, Left Join, Right Join, Full Outer\\nJoin, Cross Join, Union\\nTriggers and Case Statements Triggers (Before, After), CASE\\nStatements, Conditional Logic\\nUltimate Data Science & GenAI Bootcamp       Page  11\\nModule 6'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 11, 'page_label': '12'}, page_content='Advanced SQL and Database Management\\nTopics\\nNormalization and Pivoting Normalization Forms (1NF, 2NF, 3NF),\\nPivot Tables, Data Aggregation\\nUltimate Data Science & GenAI Bootcamp       Page  12\\nModule 6'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 12, 'page_label': '13'}, page_content=\"In this module, you'll explore the world of NoSQL databases with MongoDB. You'll learn how to\\ncreate and manage databases, collections, and documents, and perform CRUD operations. The\\nmodule covers querying, sorting, and indexing, providing a comprehensive understanding of\\nMongoDB's flexible data model. By the end, youâ€™ll be able to efficiently work with NoSQL\\ndatabases, particularly for use cases that involve unstructured or semi-structured data.\\nIntroduction to NoSQL with MongoDB\\nTopics\\nGetting Started with MongoDB MongoDB Introduction, Setting up\\nMongoDB, MongoDB Shell Commands\\nDatabase and Collection Management MongoDB Create Database, MongoDB\\nCreate Collection\\nCRUD Operations MongoDB Insert, MongoDB Find,\\nMongoDB Update, MongoDB Delete\\nQuerying MongoDB MongoDB Query, MongoDB Sort,\\nMongoDB Limit\\nManaging Collections MongoDB Drop Collection, MongoDB\\nDelete (Specific)\\nUltimate Data Science & GenAI Bootcamp       Page  13\\nModule 7\"), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 13, 'page_label': '14'}, page_content='This module provides a foundation in statistics and probability, covering essential terms, concepts,\\nand methods. Youâ€™ll learn about different types of data, levels of measurement, and key statistical\\nmeasures like mean, median, variance, and standard deviation. The module introduces random\\nvariables, probability distributions, and various types of probability functions, giving you a strong\\nbase to analyze and interpret data from a statistical perspective.\\nFoundations of Statistics and Probability\\nTopics\\nIntroduction to Statistics Introduction to Basic Statistics Terms,\\nTypes of Statistics, Types of Data, Levels\\nof Measurement, Measures of Central\\nTendency, Measures of Dispersion\\nExploring Random Variables and\\nProbability\\nRandom Variables, Set Theory,\\nSkewness, Covariance and Correlation,\\nProbability Density/Distribution Function\\nDistributions and Their Applications Types of Probability Distributions,\\nBinomial Distribution, Poisson\\nDistribution, Normal Distribution\\n(Gaussian Distribution), Probability\\nDensity Function and Mass Function,\\nCumulative Density Function, Examples\\nof Normal Distribution, Bernoulli\\nDistribution, Uniform Distribution\\nStatistical Inference Z-Statistics, Central Limit Theorem,\\nEstimation, Hypothesis Testing\\nUltimate Data Science & GenAI Bootcamp       Page  14\\nModule 8'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 14, 'page_label': '15'}, page_content=\"In this module, you'll delve deeper into statistical inference techniques, including hypothesis\\ntesting, confidence intervals, and the types of errors in statistical tests. Youâ€™ll explore advanced\\nconcepts like P-values, T-tests, and Chi-square tests, learning how to interpret results in the\\ncontext of real-world data. By the end, youâ€™ll be equipped to conduct sophisticated statistical\\nanalysis and make informed decisions based on data-driven evidence.\\nAdvanced Statistical Inference and\\nHypothesis Testing\\nTopics\\nHypothesis Testing and Errors Hypothesis Testing Mechanism, Type 1 &\\nType 2 Error, T-Tests vs. Z-Tests:\\nOverview, When to Use a T-Test vs. Z-\\nTest\\nStatistical Distributions and Tests T-Stats, Student T Distribution, Chi-\\nSquare Test, Chi-Square Distribution\\nUsing Python, Chi-Square for Goodness\\nof Fit Test\\nBayesian Statistics and Confidence\\nIntervals\\nBayes Statistics (Bayes Theorem),\\nConfidence Interval (CI), Confidence\\nIntervals and the Margin of Error,\\nInterpreting Confidence Levels and\\nConfidence Intervals\\nStatistical Significance and\\nInterpretation\\nP-Value, T-Stats vs. Z-Stats: Overview\\nUltimate Data Science & GenAI Bootcamp       Page  15\\nModule 9\"), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 15, 'page_label': '16'}, page_content='This module covers essential techniques for preparing and transforming data before applying\\nmachine learning models. Youâ€™ll learn how to handle missing values, deal with imbalanced data,\\nand scale or encode features. The module also explores methods for handling outliers, feature\\nselection (including forward/backward elimination), and dimensionality reduction techniques. By\\nthe end, youâ€™ll be proficient in preparing high-quality datasets that are ready for modeling.\\nFeature Engineering and Data\\nPreprocessing\\nTopics\\nHandling Missing and Imbalanced\\nData\\nHandling Missing Data, Handling\\nImbalanced Data\\nOutliers and Scaling Handling Outliers, Feature Scaling\\nData Transformation and Encoding Data Encoding\\nFeature Selection Techniques Backward Elimination, Forward\\nElimination, Recursive Feature\\nElimination\\nCorrelation and Multicollinearity Covariance and Correlation, VIF\\nUltimate Data Science & GenAI Bootcamp       Page  16\\nModule 10'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 16, 'page_label': '17'}, page_content='In this module, youâ€™ll learn how to perform Exploratory Data Analysis (EDA) to uncover patterns,\\ntrends, and relationships in your data. Youâ€™ll master techniques for visualizing distributions,\\nidentifying correlations, and detecting anomalies. The module emphasizes the importance of\\nsummary statistics, data cleaning, and feature engineering. By the end, youâ€™ll be able to extract\\nmeaningful insights from raw data and prepare it for further analysis or modeling.\\nExploratory Data Analysis (EDA) for\\nDetailed Insights\\nTopics\\nTrend Analysis and Segmentation Analyzing Bike Sharing Trends,\\nCustomer Segmentation and Effective\\nCross-Selling\\nSentiment and Quality Analysis Analyzing Movie Reviews Sentiment,\\nAnalyzing Wine Types and Quality\\nRecommendation and Forecasting Analyzing Music Trends and\\nRecommendations, Forecasting Stock\\nand Commodity Prices\\nUltimate Data Science & GenAI Bootcamp       Page  17\\nModule 11'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 17, 'page_label': '18'}, page_content='This module provides a comprehensive introduction to machine learning, covering key algorithms\\nand techniques. Youâ€™ll learn the differences between supervised and unsupervised learning, as\\nwell as the core concepts of regression, classification, and clustering. The module introduces\\nmodel evaluation metrics like accuracy, precision, recall, and F1-score, giving you the foundation to\\nunderstand and implement machine learning models in real-world scenarios.\\nMachine Learning Foundations and\\nTechniques\\nTopics\\nIntroduction to Machine Learning AI vs ML vs DL vs DS, Types of ML\\nTechniques, Supervised vs Unsupervised\\nvs Semi-Supervised vs Reinforcement\\nLearning\\nLinear Regression Simple Linear Regression, Multiple Linear\\nRegression, MSE, MAE, RMSE, R-\\nsquared, Adjusted R-squared, Linear\\nRegression with OLS\\nRegularization Techniques Ridge Regression, Lasso Regression,\\nElasticNet\\nLogistic Regression Logistic Regression, Performance\\nMetrics: Confusion Matrix, Accuracy,\\nPrecision, Recall, F-Beta Score, ROC-\\nAUC Curve\\nSupport Vector Machines (SVM) Support Vector Classifiers, Support\\nVector Regressor, Support Vector\\nKernels\\nUltimate Data Science & GenAI Bootcamp       Page  18\\nModule 12'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 18, 'page_label': '19'}, page_content='Machine Learning Foundations and\\nTechniques\\nTopics\\nBayes Theorem and Naive Bayes Introduction to Bayes Theorem, Naive\\nBayes Classifier\\nK-Nearest Neighbors (KNN) KNN Classifier, KNN Regressor\\nDecision Trees Decision Tree Classifier, Decision Tree\\nRegressor\\nEnsemble Methods Bagging, Boosting, Random Forest\\nClassifier, Random Forest Regressor,\\nOut-of-Bag Evaluation, XGBoost\\nClassifier, XGBoost Regressor\\nSupport Vector Machines (SVM) Support Vector Classifiers, Support\\nVector Regressor, Support Vector\\nKernels\\nIntroduction to Unsupervised Learning Overview of Unsupervised Learning, Use\\nCases, and Applications\\nClustering Techniques KMeans Clustering, Hierarchical\\nClustering, DBSCAN Clustering\\nUltimate Data Science & GenAI Bootcamp       Page  19\\nModule 12'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 19, 'page_label': '20'}, page_content='Machine Learning Foundations and\\nTechniques\\nTopics\\nClustering Evaluation Silhouette Coefficient, Evaluation\\nMetrics for Clustering Algorithms\\nUltimate Data Science & GenAI Bootcamp       Page  20\\nModule 12'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 20, 'page_label': '21'}, page_content='In this module, youâ€™ll explore the basics of Natural Language Processing (NLP) for machine\\nlearning applications. Topics include text preprocessing (stemming, lemmatization), tokenization,\\nand POS tagging. Youâ€™ll also learn how to implement key NLP techniques like Named Entity\\nRecognition, word embeddings (Word2Vec), and TF-IDF. By the end of this module, youâ€™ll have the\\nskills to work with textual data and apply machine learning models to solve NLP tasks.\\nNatural Language Processing for\\nMachine Learning\\nTopics\\nIntroduction to NLP for ML Roadmap to Learn NLP for ML, Practical\\nUse Cases of NLP in Machine Learning\\nText Preprocessing Tokenization, Basic Terminology,\\nStemming, Lemmatization, Stopwords\\nText Representation One-Hot Encoding, N-Gram, Bag of\\nWords (BoW), TF-IDF Intuition\\nPart of Speech (POS) Tagging POS Tagging using NLTK, Understanding\\nPOS Tags\\nNamed Entity Recognition (NER) Introduction to NER, Implementing NER\\nwith NLTK\\nWord Embeddings Introduction to Word Embeddings,\\nBenefits of Using Word Embeddings in\\nML\\nUltimate Data Science & GenAI Bootcamp       Page  21\\nModule 13'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 21, 'page_label': '22'}, page_content='Natural Language Processing for\\nMachine Learning\\nTopics\\nWord2Vec Intuition behind Word2Vec, Training\\nWord2Vec Models, Skip-gram and\\nCBOW Architectures\\nUltimate Data Science & GenAI Bootcamp       Page  22\\nModule 13'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 22, 'page_label': '23'}, page_content='This module introduces you to deep learning and the fundamental concepts behind artificial\\nneural networks (ANNs). Youâ€™ll learn about the architecture and workings of a neural network,\\nincluding activation functions, loss functions, and optimization techniques. The module also covers\\nbackpropagation and the vanishing gradient problem. By the end, youâ€™ll be equipped to build and\\ntrain basic neural networks and understand how deep learning models are used in AI applications.\\nIntroduction to Deep Learning and Neural\\nNetworks\\nTopics\\nIntroduction to Deep Learning Why Deep Learning Is Becoming\\nPopular?\\nPerceptron Intuition Understanding the Perceptron Model,\\nBasic Working Principle\\nArtificial Neural Network (ANN)\\nWorking\\nStructure of ANN, Neurons, Layers, and\\nHow Data Passes Through the Network\\nBackpropagation in ANN The Backpropagation Process, Gradient\\nDescent, and Training Networks\\nVanishing Gradient Problem Explanation, Causes, and Solutions\\nExploding Gradient Problem Causes and Mitigation Techniques\\nUltimate Data Science & GenAI Bootcamp       Page  23\\nModule 14'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 23, 'page_label': '24'}, page_content=\"Introduction to Deep Learning and Neural\\nNetworks\\nTopics\\nActivation Functions Different Types of Activation Functions\\n(Sigmoid, ReLU, Tanh, etc.)\\nLoss Functions Common Loss Functions for Regression\\nand Classification\\nOptimizers Types of Optimizers (SGD, Adam,\\nRMSprop, etc.)\\nWeight Initialization Techniques Methods for Initializing Weights (Xavier,\\nHe Initialization)\\nDropout Layer Concept of Dropout and its Role in\\nRegularization\\nBatch Normalization How Batch Normalization Works and\\nWhy It's Important\\nKeras Framework Fundamentals Introduction to Keras, Building Models\\nwith Keras, Basic Operations\\nPyTorch Framework Fundamentals Introduction to PyTorch, Tensor\\nOperations, Building Models with\\nPyTorch\\nUltimate Data Science & GenAI Bootcamp       Page  24\\nModule 14\"), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 24, 'page_label': '25'}, page_content='In this module, youâ€™ll dive into Convolutional Neural Networks (CNNs), a cornerstone of deep\\nlearning in computer vision. Youâ€™ll learn the architecture of CNNs, including convolution layers,\\npooling layers, and fully connected layers. The module covers practical applications like image\\nclassification, object detection, and segmentation using CNNs. By the end, youâ€™ll have hands-on\\nexperience building and training CNNs for real-world vision tasks.\\nDeep Learning : Convolutional Neural\\nNetworks (CNN) Fundamentals and\\nApplications\\nTopics\\nIntroduction to CNN CNN Fundamentals, What is\\nConvolutional Neural Network, CNN\\nArchitecture Overview\\nExplaining CNN in Detail CNN Explained in Detail, Understanding\\nTensor Space, CNN Explainer\\nCNN-Based Architectures Various CNN Architectures, Deep Dive\\ninto ResNet and its Variants\\nTraining CNN from Scratch Steps to Train CNNs, Hyperparameter\\nTuning, Overfitting, and Underfitting\\nBuilding Web Apps for CNN Deploying CNN Models into Web\\nApplications, Using Flask or Django,\\nServing Models with TensorFlow.js\\nExploding Gradient Problem Causes and Mitigation Techniques\\nUltimate Data Science & GenAI Bootcamp       Page  25\\nModule 15'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 25, 'page_label': '26'}, page_content='Deep Learning : Convolutional Neural\\nNetworks (CNN) Fundamentals and\\nApplications\\nTopics\\nObject Detection Using YOLO Introduction to YOLO (You Only Look\\nOnce), YOLO Architecture, Training and\\nDeployment\\nObject Detection Using Detectron2 Understanding Detectron2 for Object\\nDetection, Using Pre-trained Models and\\nFine-tuning\\nSegmentation Using YOLO Semantic and Instance Segmentation\\nwith YOLO, Implementing YOLO for\\nSegmentation Tasks\\nSegmentation Using Detectron2 Using Detectron2 for Semantic and\\nInstance Segmentation, Implementing\\nPre-trained Models for Image\\nSegmentation\\nUltimate Data Science & GenAI Bootcamp       Page  26\\nModule 15'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 26, 'page_label': '27'}, page_content=\"This module covers Recurrent Neural Networks (RNNs) and Transformer models, focusing on their\\napplications in sequential data processing. Youâ€™ll learn how RNNs and LSTMs are used for time\\nseries analysis, speech recognition, and language modeling. The module also explores the\\nTransformer architecture, which powers models like BERT and GPT. By the end, you'll have a\\nstrong grasp of these advanced neural network architectures and their applications in NLP and\\nbeyond.\\nDeep Learning : Recurrent Neural\\nNetworks (RNN) and Transformer\\nModels\\nTopics\\nIntroduction to RNNs Recurrent Neural Networks (RNN)\\nFundamentals, How RNNs Work,\\nApplications of RNN\\nLong Short Term Memory (LSTM) LSTM Cells, How LSTM Solves Vanishing\\nGradient Problem, LSTM for Sequence\\nModeling, Training and Tuning LSTM\\nGated Recurrent Units (GRU) GRU vs LSTM, Understanding GRU\\nArchitecture, Advantages of GRU in\\nSequence Modeling\\nEncoders and Decoders Encoder-Decoder Architecture,\\nApplications in Machine Translation,\\nSequence-to-Sequence Models\\nAttention Mechanism What is Attention, Types of Attention\\nMechanisms, Soft and Hard Attention\\nUltimate Data Science & GenAI Bootcamp       Page  27\\nModule 16\"), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 27, 'page_label': '28'}, page_content='Deep Learning : Recurrent Neural\\nNetworks (RNN) and Transformer\\nModels\\nTopics\\nAttention Neural Networks Self-Attention in Neural Networks,\\nApplying Attention to RNNs, Transformer\\nvs RNN\\nBERT Model BERT (Bidirectional Encoder\\nRepresentations from Transformers),\\nPre-training and Fine-tuning BERT,\\nApplications of BERT in NLP\\nGPT-2 Model GPT-2 (Generative Pre-trained\\nTransformer 2), Autoregressive\\nLanguage Modeling, Fine-tuning GPT-2\\nfor Text Generation\\nUltimate Data Science & GenAI Bootcamp       Page  28\\nModule 16'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 28, 'page_label': '29'}, page_content='In this module, youâ€™ll explore the world of Generative AI, understanding how these models\\ngenerate new data based on patterns learned from existing data. Youâ€™ll compare generative and\\ndiscriminative models and discover their applications in text, image, and audio generation. The\\nmodule also covers advancements in generative models, including GANs and VAEs. By the end,\\nyouâ€™ll be familiar with key concepts and applications of Generative AI.\\nIntroduction to Generative AI\\nTopics\\nOverview of Generative AI What is Generative AI?, Overview of\\nGenerative vs. Discriminative Models,\\nSignificance and Applications of\\nGenerative AI\\nUnderstanding Generative Models How Generative Models Work, Key\\nTypes of Generative Models (e.g., GANs,\\nVAEs), Advantages of Generative Models\\nGenerative AI vs. Discriminative\\nModels\\nKey Differences, Use Cases,\\nPerformance Comparison\\nRecent Advancements and Research Latest Breakthroughs in Generative AI,\\nState-of-the-Art Models and\\nTechniques, Future Trends in Generative\\nAI\\nKey Applications of Generative\\nModels\\nApplications in Art and Creativity (e.g.,\\nImage Synthesis), Healthcare (e.g., Drug\\nDiscovery), Natural Language\\nProcessing, and More\\nUltimate Data Science & GenAI Bootcamp       Page  29\\nModule 17'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 29, 'page_label': '30'}, page_content='This module introduces you to the concept of vector databases, which are designed to store and\\nretrieve high-dimensional data vectors. Youâ€™ll learn how vector databases differ from traditional\\nSQL and NoSQL databases, and explore their use cases, including similarity searches and machine\\nlearning applications. The module also covers popular vector databases like Faiss, Pinecone, and\\nChromaDB. By the end, youâ€™ll be equipped to work with vector databases for handling complex\\ndata queries.\\nIntroduction to Vector Databases\\nTopics\\nOverview of Vector Databases What are Vector Databases?, Key\\nConcepts and Use Cases of Vector\\nDatabases, Difference Between Vector\\nDatabases and Traditional Databases\\nComparison with SQL and NoSQL\\nDatabases\\nSQL vs. NoSQL vs. Vector Databases:\\nKey Differences, Use Cases, and\\nPerformance Considerations\\nCapabilities of Vector Databases Handling High-Dimensional Data, Fast\\nSimilarity Search, Efficient Storage and\\nQuerying, Real-Time Processing\\nData Storage and Architecture of\\nVector Databases\\nStructure of Vector Data, Indexing\\nTechniques, Optimizations for Vector\\nSearch, Performance Considerations\\nTypes of Vector Databases In-Memory Vector Databases: Benefits\\nand Limitations, Local Disk-based Vector\\nDatabases, Cloud-Based Vector\\nDatabases and Their Use Cases\\nUltimate Data Science & GenAI Bootcamp       Page  30\\nModule 18'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 30, 'page_label': '31'}, page_content='Introduction to Vector Databases\\nTopics\\nExploring Popular Vector Databases Chroma DB, Faiss, Quadrant, Pinecone,\\nLanceDB: Overview, Features, and Use\\nCases\\nVector Search with NoSQL Databases Integrating Vector Search with\\nMongoDB and Cassandra, Best\\nPractices for Implementing Vector\\nSearch in NoSQL Databases\\nUltimate Data Science & GenAI Bootcamp       Page  31\\nModule 18'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 31, 'page_label': '32'}, page_content='This module introduces the concept of Retrieval-Augmented Generation (RAG), which combines\\nretrieval-based search with generative models for enhanced language generation tasks. Youâ€™ll\\nlearn about the end-to-end RAG pipeline, including how to implement it with tools like LangChain,\\nvector databases, and LLMs. The module also covers hybrid search, reranking, and multimodal\\nretrieval techniques. By the end, youâ€™ll understand how to implement advanced RAG systems for\\nvarious use cases.\\nIntroduction to Retrieval-Augmented\\nGeneration (RAG)\\nTopics\\nOverview of Retrieval-Augmented\\nGeneration (RAG)\\nWhat is RAG?, Key Components of a\\nRAG System, Why RAG is Important for\\nAdvanced AI Systems\\nUnderstanding the End-to-End RAG\\nPipeline\\nOverview of the RAG Workflow, Data\\nRetrieval, Contextualization, and\\nGeneration Phases, Challenges and\\nOpportunities in RAG\\nIntegrating LangChain in RAG Introduction to LangChain Framework,\\nBuilding End-to-End RAG Pipelines with\\nLangChain\\nLeveraging Vector Databases in RAG Using Vector Databases for Efficient\\nRetrieval in RAG, Popular Vector\\nDatabases for RAG (e.g., Pinecone,\\nFAISS, Chroma DB)\\nRole of LLMs in RAG How LLMs (Large Language Models)\\nEnhance Generation in RAG, Fine-\\nTuning LLMs for Retrieval-Augmented\\nTasks\\nUltimate Data Science & GenAI Bootcamp       Page  32\\nModule 19'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 32, 'page_label': '33'}, page_content='Introduction to Retrieval-Augmented\\nGeneration (RAG)\\nTopics\\nRAG with Hybrid Search and\\nReranking\\nCombining Multiple Retrieval Methods,\\nReranking Results for Improved\\nRelevance, Hybrid Search\\nImplementation Techniques\\nRAG with Various Retrieval Methods Exact vs Approximate Retrieval Methods,\\nFiltering and Ranking Retrieved Data,\\nCustomizing Retrieval Approaches for\\nSpecific Applications\\nIntegrating Memory in RAG Systems How Memory Can Improve RAG,\\nPersisting and Recalling Information for\\nConsistent Results, Implementing Long-\\nTerm Memory in RAG\\nMultimodal Retrieval-Augmented\\nGeneration\\nCombining Text, Images, and Other\\nModalities in RAG, Techniques for\\nMultimodal Retrieval and Generation,\\nPractical Applications of Multimodal\\nRAG Systems\\nUltimate Data Science & GenAI Bootcamp       Page  33\\nModule 19'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 33, 'page_label': '34'}, page_content='In this course, youâ€™ll gain hands-on experience in implementing end-to-end AI projects. Youâ€™ll learn\\nhow to manage the entire project lifecycle, from data collection and preprocessing to model\\ndevelopment, evaluation, and deployment. The module includes working on real-world AI projects,\\nwith a focus on best practices for integration, testing, and scalability. By the end, youâ€™ll be\\nprepared to take on AI projects from start to finish, applying machine learning and deep learning\\ntechniques to solve real-world problems.\\nEnd-to-End AI Project Implementation\\nTopics\\nPython Project: Building End-to-End\\nApplications\\nOverview of Python Projects, Project\\nDesign and Architecture, Key\\nConsiderations in Python Projects\\n(Performance, Scalability, etc.), Best\\nPractices for Code Quality\\nEnd-to-End Machine Learning\\nProjects\\nUnderstanding End-to-End ML Projects,\\nKey Components of an End-to-End ML\\nProject, Project Example: Real-World ML\\nApplication\\nDeep Learning Projects Deep Learning Fundamentals in Projects,\\nEnd-to-End Deep Learning Projects \\nGenerative AI End-to-End Projects Introduction to Generative AI Projects,\\nSteps in Building Generative AI Projects\\nUltimate Data Science & GenAI Bootcamp       Page  34\\nPROJECT')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reading a PDf File\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader('data\\syllabus.pdf')\n",
    "docs=loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcf7b873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b938e23",
   "metadata": {},
   "source": [
    "34 Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b3db6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 0, 'page_label': '1'}, page_content='MACHINE\\nLEARNING\\nDEEP\\nLEARNING\\nPYTHON +\\nSTATS\\nCOMPUTER VISIONNATURAL LANGUAGE PROCESSING\\nGENERATIVE AI\\nRETRIEVAL AUGUMENT GENERATION\\nVECTOR DB'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 1, 'page_label': '2'}, page_content='This course is designed for aspiring data scientists, machine learning enthusiasts, and\\nprofessionals looking to build expertise in Python programming, data analysis, machine learning,\\nand deep learning. Whether you are just starting or have some experience, this comprehensive\\ncourse will equip you with the skills needed to work with real-world datasets, apply machine\\nlearning algorithms, and deploy AI solutions. By the end of the course, youâ€™ll have a solid\\nfoundation in AI, a portfolio of end-to-end projects, and the confidence to tackle complex\\nchallenges in data science and AI.\\nLearning Objectives\\nMaster Python Programming: Understand Python fundamentals, including data types,\\ncontrol structures, and object-oriented programming, to write efficient and reusable\\ncode.\\nHandle Data with Pandas and NumPy: Acquire skills to manipulate, clean, and\\npreprocess large datasets using Pandas and NumPy for data analysis tasks.'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 1, 'page_label': '2'}, page_content='preprocess large datasets using Pandas and NumPy for data analysis tasks.\\nVisualize Data: Create compelling data visualizations using libraries such as Matplotlib,\\nSeaborn, and Plotly to present insights effectively.\\nUnderstand SQL & NoSQL: Gain expertise in both relational (SQL) and non-relational\\n(NoSQL) databases, including MongoDB, for storing, querying, and managing data.\\nGrasp Statistics and Probability: Understand the core concepts of statistics,\\nprobability, and hypothesis testing, applying them to data analysis and machine\\nlearning.\\nMaster Machine Learning Techniques: Learn key machine learning algorithms,\\nincluding supervised, unsupervised, and ensemble methods, and apply them to real-\\nworld problems.\\nDive into Deep Learning: Develop a strong understanding of neural networks, CNNs,\\nRNNs, and transformers, with hands-on implementation for advanced AI tasks.\\nExplore Generative AI & Vector Databases: Learn the concepts and applications of'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 1, 'page_label': '2'}, page_content='Explore Generative AI & Vector Databases: Learn the concepts and applications of\\ngenerative models, vector databases, and retrieval-augmented generation to handle\\ncomplex AI systems.\\nBuild Real-World Projects: Implement end-to-end machine learning and AI projects,\\nfrom data preprocessing to model deployment, integrating concepts from multiple\\nmodules.\\nUltimate Data Science & GenAI Bootcamp       Page  2'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 2, 'page_label': '3'}, page_content=\"Course Information\\nNo prerequisites are required for this course. The curriculum covers everything from the\\nbasics of Python programming, statistics, and machine learning to advanced topics in deep\\nlearning, NLP, and generative AI. Whether you're a beginner or have some prior experience,\\nthe course will ensure you gain the skills needed to succeed.\\nEstimated Time\\n8 months 6hrs/week*\\nRequired Skill Level\\nBegineer\\nThe course is designed to be completed over a duration of approximately 7 to 8 months, providing\\nan in-depth exploration from Python basics to GenAI, with plenty of time for practical\\nimplementation and real-world applications.\\nPrerequisites\\nUltimate Data Science & GenAI Bootcamp       Page  3\"), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 3, 'page_label': '4'}, page_content='Course Instructors\\nSunny SavitaGenAI Engineer\\nLinkedin\\nKrish NaikChief AI Engineer\\nLinkedin\\nUltimate Data Science & GenAI Bootcamp       Page  4\\nSourangshu PalSenior Data Scientist\\nLinkedin\\nMonal KumarData Scientist\\nLinkedin\\nMayank AggrawalSenior ML Engineer\\nLinkedin\\nDarius B.Head of Product\\nLinkedin'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 4, 'page_label': '5'}, page_content=\"In this module, youâ€™ll get a solid introduction to Python, covering essential programming concepts\\nsuch as variables, data types, operators, and control flow. Youâ€™ll learn how to manipulate strings,\\nlists, dictionaries, and other basic data structures. The module will also guide you through writing\\nsimple functions and using loops and conditionals effectively. By the end, you'll have a strong\\nunderstanding of Python syntax, preparing you to tackle more complex programming challenges\\nand form a foundation for learning advanced concepts.\\nUltimate Data Science & GenAI Bootcamp       Page  5\\nPython Foundations\\nModule 1\\nTopics\\nIntroduction to Python Comparison with other programming\\nlanguages, Python objects: Numbers,\\nBooleans, and Strings\\nData Structures & Operations Container objects and mutability,\\nOperators, Operator precedence and\\nassociativity\\nControl Flow Conditional statements, Loops, break\\nand continue statements\\nString Manipulation Basics of string objects, Inbuilt string\"), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 4, 'page_label': '5'}, page_content='and continue statements\\nString Manipulation Basics of string objects, Inbuilt string\\nmethods, Splitting and joining strings,\\nString formatting functions\\nLists & Collections List methods, list comprehension, Lists as\\nstacks and queues, Tuples, sets, and\\ndictionaries, Dictionary comprehensions\\nand view objects'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 5, 'page_label': '6'}, page_content='Topics\\nFunctions & Iterators Function basics and parameter passing,\\nIterators and generator functions,\\nLambda functions, map(), reduce(),\\nfilter()\\nPython Foundations\\nModule 1\\nUltimate Data Science & GenAI Bootcamp       Page  6'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 6, 'page_label': '7'}, page_content='This module takes your Python skills further by diving into object-oriented programming (OOP)\\nconcepts like classes, inheritance, and polymorphism. Youâ€™ll also explore more advanced topics\\nsuch as decorators, lambda functions, iterators, and generator functions. Additionally, we cover\\nexception handling, file operations, and working with modules and libraries. By the end, you will be\\ncomfortable building more sophisticated Python applications and writing efficient, reusable code.\\nAdvanced Python Programming\\nModule 2\\nTopics\\nObject-Oriented Programming (OOP) OOP basics and class creation,\\nInheritance, Polymorphism,\\nEncapsulation, and Abstraction,\\nDecorators, class methods, and static\\nmethods, Special (Magic/Dunder)\\nmethods, Property decorators: Getters,\\nsetters, and delete methods\\nFile Handling & Logging Reading and writing files, Buffered read\\nand write operations, more file methods,\\nLogging and debugging\\nModules & Exception Handling Importing modules and using them'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 6, 'page_label': '7'}, page_content='Logging and debugging\\nModules & Exception Handling Importing modules and using them\\neffectively, Exception handling\\nConcurrency & Parallelism Introduction to multithreading,\\nMultiprocessing for performance\\noptimization\\nUltimate Data Science & GenAI Bootcamp       Page  7'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 7, 'page_label': '8'}, page_content='In this module, you will master the core aspects of data manipulation using Pandas. Youâ€™ll learn\\nhow to work with Series, DataFrames, and Panels, as well as perform data selection, filtering, and\\nsorting. The module covers critical tasks like handling missing data, reindexing, and applying\\nstatistical functions to datasets. Youâ€™ll also gain hands-on experience with data visualization and\\nadvanced indexing techniques, empowering you to efficiently analyze and manipulate complex\\ndatasets.\\nMastering Data Handling with Pandas\\nTopics\\nData Structures & Fundamentals Series, DataFrame, Panel, Basic\\nFunctionality, Indexing & Selecting, Re-\\nindexing, Iteration\\nData Operations & Transformations Sorting, Working with Text Data, Options\\n& Customization, Categorical Data, Date\\nFunctionality, Time Delta\\nData Analysis & Statistical Functions Data Statistical Functions, Window\\nFunctions\\nReading, Writing & Visualization Reading Data from Different File\\nSystems, Visualization, Tools'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 7, 'page_label': '8'}, page_content='Reading, Writing & Visualization Reading Data from Different File\\nSystems, Visualization, Tools\\nUltimate Data Science & GenAI Bootcamp       Page  8\\nModule 3'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 8, 'page_label': '9'}, page_content='This module introduces you to NumPy, a key library for numerical computing in Python. Youâ€™ll learn\\nhow to create and manipulate NumPy arrays, perform advanced indexing, and understand\\nbroadcasting. The module covers essential mathematical and statistical functions, including array\\nmanipulations, binary operations, and vectorized operations. By the end, youâ€™ll have the skills to\\nefficiently perform complex numerical computations and leverage NumPy for machine learning\\nand deep learning applications.\\nMastering NumPy\\nTopics\\nNumPy Basics & Array Creation NdArray Object, Data Types, Array\\nAttributes, Array Creation Routines,\\nArray from Existing Data, Data Array from\\nNumerical Ranges\\nIndexing, Slicing & Advanced Indexing Indexing & Slicing, Advanced Indexing\\nArray Operations & Manipulation Array Manipulation, Binary Operators,\\nString Functions, Arithmetic Operations,\\nMathematical Functions\\nMathematical & Statistical Analysis Statistical Functions, Sort, Search &'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 8, 'page_label': '9'}, page_content='Mathematical Functions\\nMathematical & Statistical Analysis Statistical Functions, Sort, Search &\\nCounting Functions, Matrix Library,\\nLinear Algebra\\nAdvanced Concepts Broadcasting, Iterating Over Array, Byte\\nSwapping, Copies & Views\\nUltimate Data Science & GenAI Bootcamp       Page  9\\nModule 4'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 9, 'page_label': '10'}, page_content=\"In this module, youâ€™ll learn how to visualize data effectively using Python's popular libraries,\\nMatplotlib, Seaborn, and Plotly. Youâ€™ll cover essential plot types like line charts, bar graphs, and\\nscatter plots, and learn how to customize these visualizations to highlight key insights. Additionally,\\nthe module teaches you how to visualize statistical data, correlations, and distributions, helping\\nyou communicate data-driven findings in a visually compelling way.\\nData Visualization with Python\\nTopics\\nIntroduction to Data Visualization Overview of Data Visualization, Principles\\nof Good Visualization\\nMatplotlib Introduction to Matplotlib, Creating\\nBasic Plots (Line, Bar, Scatter),\\nCustomizing Axes, Titles, Legends, and\\nLabels, Working with Subplots, Saving\\nand Exporting Figures\\nSeaborn Introduction to Seaborn, Visualizing\\nDistributions, Relationship Plots\\n(Pairplots, Heatmaps), Categorical Data\\nVisualization, Advanced Plot\\nCustomizations\\nPlotly Introduction to Plotly, Creating\"), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 9, 'page_label': '10'}, page_content='Visualization, Advanced Plot\\nCustomizations\\nPlotly Introduction to Plotly, Creating\\nInteractive Plots (Line, Bar, Scatter),\\nCustomizing Plots, Dashboards and\\nInteractive Layouts, Plotly Express\\nUltimate Data Science & GenAI Bootcamp       Page  10\\nModule 5'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 10, 'page_label': '11'}, page_content='This module dives into advanced SQL techniques, including complex queries, joins, and indexing\\nfor efficient data retrieval. Youâ€™ll learn how to implement stored procedures, triggers, and\\nfunctions, and explore the use of window functions and partitions. The module covers key\\ndatabase design concepts like primary and foreign keys and normalization. By the end, youâ€™ll be\\nproficient in managing large-scale databases and optimizing SQL queries for performance.\\nAdvanced SQL and Database Management\\nTopics\\nIntroduction to SQL Introduction to SQL, SQL Queries:\\nSELECT, INSERT, UPDATE, DELETE\\nSQL Functions and Procedures SQL Functions (Aggregate, Scalar),\\nStored Procedures, User-defined\\nFunctions (UDFs), Function and\\nProcedure Syntax\\nDatabase Constraints Primary and Foreign Keys, Data Integrity,\\nReferential Integrity\\nAdvanced SQL Techniques Window Functions, Partitioning, CTE\\n(Common Table Expressions), Indexing\\nSQL Joins and Unions Inner Join, Left Join, Right Join, Full Outer'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 10, 'page_label': '11'}, page_content='SQL Joins and Unions Inner Join, Left Join, Right Join, Full Outer\\nJoin, Cross Join, Union\\nTriggers and Case Statements Triggers (Before, After), CASE\\nStatements, Conditional Logic\\nUltimate Data Science & GenAI Bootcamp       Page  11\\nModule 6'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 11, 'page_label': '12'}, page_content='Advanced SQL and Database Management\\nTopics\\nNormalization and Pivoting Normalization Forms (1NF, 2NF, 3NF),\\nPivot Tables, Data Aggregation\\nUltimate Data Science & GenAI Bootcamp       Page  12\\nModule 6'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 12, 'page_label': '13'}, page_content=\"In this module, you'll explore the world of NoSQL databases with MongoDB. You'll learn how to\\ncreate and manage databases, collections, and documents, and perform CRUD operations. The\\nmodule covers querying, sorting, and indexing, providing a comprehensive understanding of\\nMongoDB's flexible data model. By the end, youâ€™ll be able to efficiently work with NoSQL\\ndatabases, particularly for use cases that involve unstructured or semi-structured data.\\nIntroduction to NoSQL with MongoDB\\nTopics\\nGetting Started with MongoDB MongoDB Introduction, Setting up\\nMongoDB, MongoDB Shell Commands\\nDatabase and Collection Management MongoDB Create Database, MongoDB\\nCreate Collection\\nCRUD Operations MongoDB Insert, MongoDB Find,\\nMongoDB Update, MongoDB Delete\\nQuerying MongoDB MongoDB Query, MongoDB Sort,\\nMongoDB Limit\\nManaging Collections MongoDB Drop Collection, MongoDB\\nDelete (Specific)\\nUltimate Data Science & GenAI Bootcamp       Page  13\\nModule 7\"), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 13, 'page_label': '14'}, page_content='This module provides a foundation in statistics and probability, covering essential terms, concepts,\\nand methods. Youâ€™ll learn about different types of data, levels of measurement, and key statistical\\nmeasures like mean, median, variance, and standard deviation. The module introduces random\\nvariables, probability distributions, and various types of probability functions, giving you a strong\\nbase to analyze and interpret data from a statistical perspective.\\nFoundations of Statistics and Probability\\nTopics\\nIntroduction to Statistics Introduction to Basic Statistics Terms,\\nTypes of Statistics, Types of Data, Levels\\nof Measurement, Measures of Central\\nTendency, Measures of Dispersion\\nExploring Random Variables and\\nProbability\\nRandom Variables, Set Theory,\\nSkewness, Covariance and Correlation,\\nProbability Density/Distribution Function\\nDistributions and Their Applications Types of Probability Distributions,\\nBinomial Distribution, Poisson\\nDistribution, Normal Distribution'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 13, 'page_label': '14'}, page_content='Binomial Distribution, Poisson\\nDistribution, Normal Distribution\\n(Gaussian Distribution), Probability\\nDensity Function and Mass Function,\\nCumulative Density Function, Examples\\nof Normal Distribution, Bernoulli\\nDistribution, Uniform Distribution\\nStatistical Inference Z-Statistics, Central Limit Theorem,\\nEstimation, Hypothesis Testing\\nUltimate Data Science & GenAI Bootcamp       Page  14\\nModule 8'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 14, 'page_label': '15'}, page_content=\"In this module, you'll delve deeper into statistical inference techniques, including hypothesis\\ntesting, confidence intervals, and the types of errors in statistical tests. Youâ€™ll explore advanced\\nconcepts like P-values, T-tests, and Chi-square tests, learning how to interpret results in the\\ncontext of real-world data. By the end, youâ€™ll be equipped to conduct sophisticated statistical\\nanalysis and make informed decisions based on data-driven evidence.\\nAdvanced Statistical Inference and\\nHypothesis Testing\\nTopics\\nHypothesis Testing and Errors Hypothesis Testing Mechanism, Type 1 &\\nType 2 Error, T-Tests vs. Z-Tests:\\nOverview, When to Use a T-Test vs. Z-\\nTest\\nStatistical Distributions and Tests T-Stats, Student T Distribution, Chi-\\nSquare Test, Chi-Square Distribution\\nUsing Python, Chi-Square for Goodness\\nof Fit Test\\nBayesian Statistics and Confidence\\nIntervals\\nBayes Statistics (Bayes Theorem),\\nConfidence Interval (CI), Confidence\\nIntervals and the Margin of Error,\"), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 14, 'page_label': '15'}, page_content='Confidence Interval (CI), Confidence\\nIntervals and the Margin of Error,\\nInterpreting Confidence Levels and\\nConfidence Intervals\\nStatistical Significance and\\nInterpretation\\nP-Value, T-Stats vs. Z-Stats: Overview\\nUltimate Data Science & GenAI Bootcamp       Page  15\\nModule 9'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 15, 'page_label': '16'}, page_content='This module covers essential techniques for preparing and transforming data before applying\\nmachine learning models. Youâ€™ll learn how to handle missing values, deal with imbalanced data,\\nand scale or encode features. The module also explores methods for handling outliers, feature\\nselection (including forward/backward elimination), and dimensionality reduction techniques. By\\nthe end, youâ€™ll be proficient in preparing high-quality datasets that are ready for modeling.\\nFeature Engineering and Data\\nPreprocessing\\nTopics\\nHandling Missing and Imbalanced\\nData\\nHandling Missing Data, Handling\\nImbalanced Data\\nOutliers and Scaling Handling Outliers, Feature Scaling\\nData Transformation and Encoding Data Encoding\\nFeature Selection Techniques Backward Elimination, Forward\\nElimination, Recursive Feature\\nElimination\\nCorrelation and Multicollinearity Covariance and Correlation, VIF\\nUltimate Data Science & GenAI Bootcamp       Page  16\\nModule 10'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 16, 'page_label': '17'}, page_content='In this module, youâ€™ll learn how to perform Exploratory Data Analysis (EDA) to uncover patterns,\\ntrends, and relationships in your data. Youâ€™ll master techniques for visualizing distributions,\\nidentifying correlations, and detecting anomalies. The module emphasizes the importance of\\nsummary statistics, data cleaning, and feature engineering. By the end, youâ€™ll be able to extract\\nmeaningful insights from raw data and prepare it for further analysis or modeling.\\nExploratory Data Analysis (EDA) for\\nDetailed Insights\\nTopics\\nTrend Analysis and Segmentation Analyzing Bike Sharing Trends,\\nCustomer Segmentation and Effective\\nCross-Selling\\nSentiment and Quality Analysis Analyzing Movie Reviews Sentiment,\\nAnalyzing Wine Types and Quality\\nRecommendation and Forecasting Analyzing Music Trends and\\nRecommendations, Forecasting Stock\\nand Commodity Prices\\nUltimate Data Science & GenAI Bootcamp       Page  17\\nModule 11'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 17, 'page_label': '18'}, page_content='This module provides a comprehensive introduction to machine learning, covering key algorithms\\nand techniques. Youâ€™ll learn the differences between supervised and unsupervised learning, as\\nwell as the core concepts of regression, classification, and clustering. The module introduces\\nmodel evaluation metrics like accuracy, precision, recall, and F1-score, giving you the foundation to\\nunderstand and implement machine learning models in real-world scenarios.\\nMachine Learning Foundations and\\nTechniques\\nTopics\\nIntroduction to Machine Learning AI vs ML vs DL vs DS, Types of ML\\nTechniques, Supervised vs Unsupervised\\nvs Semi-Supervised vs Reinforcement\\nLearning\\nLinear Regression Simple Linear Regression, Multiple Linear\\nRegression, MSE, MAE, RMSE, R-\\nsquared, Adjusted R-squared, Linear\\nRegression with OLS\\nRegularization Techniques Ridge Regression, Lasso Regression,\\nElasticNet\\nLogistic Regression Logistic Regression, Performance\\nMetrics: Confusion Matrix, Accuracy,'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 17, 'page_label': '18'}, page_content='Logistic Regression Logistic Regression, Performance\\nMetrics: Confusion Matrix, Accuracy,\\nPrecision, Recall, F-Beta Score, ROC-\\nAUC Curve\\nSupport Vector Machines (SVM) Support Vector Classifiers, Support\\nVector Regressor, Support Vector\\nKernels\\nUltimate Data Science & GenAI Bootcamp       Page  18\\nModule 12'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 18, 'page_label': '19'}, page_content='Machine Learning Foundations and\\nTechniques\\nTopics\\nBayes Theorem and Naive Bayes Introduction to Bayes Theorem, Naive\\nBayes Classifier\\nK-Nearest Neighbors (KNN) KNN Classifier, KNN Regressor\\nDecision Trees Decision Tree Classifier, Decision Tree\\nRegressor\\nEnsemble Methods Bagging, Boosting, Random Forest\\nClassifier, Random Forest Regressor,\\nOut-of-Bag Evaluation, XGBoost\\nClassifier, XGBoost Regressor\\nSupport Vector Machines (SVM) Support Vector Classifiers, Support\\nVector Regressor, Support Vector\\nKernels\\nIntroduction to Unsupervised Learning Overview of Unsupervised Learning, Use\\nCases, and Applications\\nClustering Techniques KMeans Clustering, Hierarchical\\nClustering, DBSCAN Clustering\\nUltimate Data Science & GenAI Bootcamp       Page  19\\nModule 12'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 19, 'page_label': '20'}, page_content='Machine Learning Foundations and\\nTechniques\\nTopics\\nClustering Evaluation Silhouette Coefficient, Evaluation\\nMetrics for Clustering Algorithms\\nUltimate Data Science & GenAI Bootcamp       Page  20\\nModule 12'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 20, 'page_label': '21'}, page_content='In this module, youâ€™ll explore the basics of Natural Language Processing (NLP) for machine\\nlearning applications. Topics include text preprocessing (stemming, lemmatization), tokenization,\\nand POS tagging. Youâ€™ll also learn how to implement key NLP techniques like Named Entity\\nRecognition, word embeddings (Word2Vec), and TF-IDF. By the end of this module, youâ€™ll have the\\nskills to work with textual data and apply machine learning models to solve NLP tasks.\\nNatural Language Processing for\\nMachine Learning\\nTopics\\nIntroduction to NLP for ML Roadmap to Learn NLP for ML, Practical\\nUse Cases of NLP in Machine Learning\\nText Preprocessing Tokenization, Basic Terminology,\\nStemming, Lemmatization, Stopwords\\nText Representation One-Hot Encoding, N-Gram, Bag of\\nWords (BoW), TF-IDF Intuition\\nPart of Speech (POS) Tagging POS Tagging using NLTK, Understanding\\nPOS Tags\\nNamed Entity Recognition (NER) Introduction to NER, Implementing NER\\nwith NLTK\\nWord Embeddings Introduction to Word Embeddings,'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 20, 'page_label': '21'}, page_content='with NLTK\\nWord Embeddings Introduction to Word Embeddings,\\nBenefits of Using Word Embeddings in\\nML\\nUltimate Data Science & GenAI Bootcamp       Page  21\\nModule 13'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 21, 'page_label': '22'}, page_content='Natural Language Processing for\\nMachine Learning\\nTopics\\nWord2Vec Intuition behind Word2Vec, Training\\nWord2Vec Models, Skip-gram and\\nCBOW Architectures\\nUltimate Data Science & GenAI Bootcamp       Page  22\\nModule 13'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 22, 'page_label': '23'}, page_content='This module introduces you to deep learning and the fundamental concepts behind artificial\\nneural networks (ANNs). Youâ€™ll learn about the architecture and workings of a neural network,\\nincluding activation functions, loss functions, and optimization techniques. The module also covers\\nbackpropagation and the vanishing gradient problem. By the end, youâ€™ll be equipped to build and\\ntrain basic neural networks and understand how deep learning models are used in AI applications.\\nIntroduction to Deep Learning and Neural\\nNetworks\\nTopics\\nIntroduction to Deep Learning Why Deep Learning Is Becoming\\nPopular?\\nPerceptron Intuition Understanding the Perceptron Model,\\nBasic Working Principle\\nArtificial Neural Network (ANN)\\nWorking\\nStructure of ANN, Neurons, Layers, and\\nHow Data Passes Through the Network\\nBackpropagation in ANN The Backpropagation Process, Gradient\\nDescent, and Training Networks\\nVanishing Gradient Problem Explanation, Causes, and Solutions'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 22, 'page_label': '23'}, page_content='Descent, and Training Networks\\nVanishing Gradient Problem Explanation, Causes, and Solutions\\nExploding Gradient Problem Causes and Mitigation Techniques\\nUltimate Data Science & GenAI Bootcamp       Page  23\\nModule 14'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 23, 'page_label': '24'}, page_content=\"Introduction to Deep Learning and Neural\\nNetworks\\nTopics\\nActivation Functions Different Types of Activation Functions\\n(Sigmoid, ReLU, Tanh, etc.)\\nLoss Functions Common Loss Functions for Regression\\nand Classification\\nOptimizers Types of Optimizers (SGD, Adam,\\nRMSprop, etc.)\\nWeight Initialization Techniques Methods for Initializing Weights (Xavier,\\nHe Initialization)\\nDropout Layer Concept of Dropout and its Role in\\nRegularization\\nBatch Normalization How Batch Normalization Works and\\nWhy It's Important\\nKeras Framework Fundamentals Introduction to Keras, Building Models\\nwith Keras, Basic Operations\\nPyTorch Framework Fundamentals Introduction to PyTorch, Tensor\\nOperations, Building Models with\\nPyTorch\\nUltimate Data Science & GenAI Bootcamp       Page  24\\nModule 14\"), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 24, 'page_label': '25'}, page_content='In this module, youâ€™ll dive into Convolutional Neural Networks (CNNs), a cornerstone of deep\\nlearning in computer vision. Youâ€™ll learn the architecture of CNNs, including convolution layers,\\npooling layers, and fully connected layers. The module covers practical applications like image\\nclassification, object detection, and segmentation using CNNs. By the end, youâ€™ll have hands-on\\nexperience building and training CNNs for real-world vision tasks.\\nDeep Learning : Convolutional Neural\\nNetworks (CNN) Fundamentals and\\nApplications\\nTopics\\nIntroduction to CNN CNN Fundamentals, What is\\nConvolutional Neural Network, CNN\\nArchitecture Overview\\nExplaining CNN in Detail CNN Explained in Detail, Understanding\\nTensor Space, CNN Explainer\\nCNN-Based Architectures Various CNN Architectures, Deep Dive\\ninto ResNet and its Variants\\nTraining CNN from Scratch Steps to Train CNNs, Hyperparameter\\nTuning, Overfitting, and Underfitting\\nBuilding Web Apps for CNN Deploying CNN Models into Web'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 24, 'page_label': '25'}, page_content='Tuning, Overfitting, and Underfitting\\nBuilding Web Apps for CNN Deploying CNN Models into Web\\nApplications, Using Flask or Django,\\nServing Models with TensorFlow.js\\nExploding Gradient Problem Causes and Mitigation Techniques\\nUltimate Data Science & GenAI Bootcamp       Page  25\\nModule 15'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 25, 'page_label': '26'}, page_content='Deep Learning : Convolutional Neural\\nNetworks (CNN) Fundamentals and\\nApplications\\nTopics\\nObject Detection Using YOLO Introduction to YOLO (You Only Look\\nOnce), YOLO Architecture, Training and\\nDeployment\\nObject Detection Using Detectron2 Understanding Detectron2 for Object\\nDetection, Using Pre-trained Models and\\nFine-tuning\\nSegmentation Using YOLO Semantic and Instance Segmentation\\nwith YOLO, Implementing YOLO for\\nSegmentation Tasks\\nSegmentation Using Detectron2 Using Detectron2 for Semantic and\\nInstance Segmentation, Implementing\\nPre-trained Models for Image\\nSegmentation\\nUltimate Data Science & GenAI Bootcamp       Page  26\\nModule 15'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 26, 'page_label': '27'}, page_content=\"This module covers Recurrent Neural Networks (RNNs) and Transformer models, focusing on their\\napplications in sequential data processing. Youâ€™ll learn how RNNs and LSTMs are used for time\\nseries analysis, speech recognition, and language modeling. The module also explores the\\nTransformer architecture, which powers models like BERT and GPT. By the end, you'll have a\\nstrong grasp of these advanced neural network architectures and their applications in NLP and\\nbeyond.\\nDeep Learning : Recurrent Neural\\nNetworks (RNN) and Transformer\\nModels\\nTopics\\nIntroduction to RNNs Recurrent Neural Networks (RNN)\\nFundamentals, How RNNs Work,\\nApplications of RNN\\nLong Short Term Memory (LSTM) LSTM Cells, How LSTM Solves Vanishing\\nGradient Problem, LSTM for Sequence\\nModeling, Training and Tuning LSTM\\nGated Recurrent Units (GRU) GRU vs LSTM, Understanding GRU\\nArchitecture, Advantages of GRU in\\nSequence Modeling\\nEncoders and Decoders Encoder-Decoder Architecture,\\nApplications in Machine Translation,\"), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 26, 'page_label': '27'}, page_content='Encoders and Decoders Encoder-Decoder Architecture,\\nApplications in Machine Translation,\\nSequence-to-Sequence Models\\nAttention Mechanism What is Attention, Types of Attention\\nMechanisms, Soft and Hard Attention\\nUltimate Data Science & GenAI Bootcamp       Page  27\\nModule 16'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 27, 'page_label': '28'}, page_content='Deep Learning : Recurrent Neural\\nNetworks (RNN) and Transformer\\nModels\\nTopics\\nAttention Neural Networks Self-Attention in Neural Networks,\\nApplying Attention to RNNs, Transformer\\nvs RNN\\nBERT Model BERT (Bidirectional Encoder\\nRepresentations from Transformers),\\nPre-training and Fine-tuning BERT,\\nApplications of BERT in NLP\\nGPT-2 Model GPT-2 (Generative Pre-trained\\nTransformer 2), Autoregressive\\nLanguage Modeling, Fine-tuning GPT-2\\nfor Text Generation\\nUltimate Data Science & GenAI Bootcamp       Page  28\\nModule 16'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 28, 'page_label': '29'}, page_content='In this module, youâ€™ll explore the world of Generative AI, understanding how these models\\ngenerate new data based on patterns learned from existing data. Youâ€™ll compare generative and\\ndiscriminative models and discover their applications in text, image, and audio generation. The\\nmodule also covers advancements in generative models, including GANs and VAEs. By the end,\\nyouâ€™ll be familiar with key concepts and applications of Generative AI.\\nIntroduction to Generative AI\\nTopics\\nOverview of Generative AI What is Generative AI?, Overview of\\nGenerative vs. Discriminative Models,\\nSignificance and Applications of\\nGenerative AI\\nUnderstanding Generative Models How Generative Models Work, Key\\nTypes of Generative Models (e.g., GANs,\\nVAEs), Advantages of Generative Models\\nGenerative AI vs. Discriminative\\nModels\\nKey Differences, Use Cases,\\nPerformance Comparison\\nRecent Advancements and Research Latest Breakthroughs in Generative AI,\\nState-of-the-Art Models and\\nTechniques, Future Trends in Generative'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 28, 'page_label': '29'}, page_content='State-of-the-Art Models and\\nTechniques, Future Trends in Generative\\nAI\\nKey Applications of Generative\\nModels\\nApplications in Art and Creativity (e.g.,\\nImage Synthesis), Healthcare (e.g., Drug\\nDiscovery), Natural Language\\nProcessing, and More\\nUltimate Data Science & GenAI Bootcamp       Page  29\\nModule 17'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 29, 'page_label': '30'}, page_content='This module introduces you to the concept of vector databases, which are designed to store and\\nretrieve high-dimensional data vectors. Youâ€™ll learn how vector databases differ from traditional\\nSQL and NoSQL databases, and explore their use cases, including similarity searches and machine\\nlearning applications. The module also covers popular vector databases like Faiss, Pinecone, and\\nChromaDB. By the end, youâ€™ll be equipped to work with vector databases for handling complex\\ndata queries.\\nIntroduction to Vector Databases\\nTopics\\nOverview of Vector Databases What are Vector Databases?, Key\\nConcepts and Use Cases of Vector\\nDatabases, Difference Between Vector\\nDatabases and Traditional Databases\\nComparison with SQL and NoSQL\\nDatabases\\nSQL vs. NoSQL vs. Vector Databases:\\nKey Differences, Use Cases, and\\nPerformance Considerations\\nCapabilities of Vector Databases Handling High-Dimensional Data, Fast\\nSimilarity Search, Efficient Storage and\\nQuerying, Real-Time Processing'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 29, 'page_label': '30'}, page_content='Similarity Search, Efficient Storage and\\nQuerying, Real-Time Processing\\nData Storage and Architecture of\\nVector Databases\\nStructure of Vector Data, Indexing\\nTechniques, Optimizations for Vector\\nSearch, Performance Considerations\\nTypes of Vector Databases In-Memory Vector Databases: Benefits\\nand Limitations, Local Disk-based Vector\\nDatabases, Cloud-Based Vector\\nDatabases and Their Use Cases\\nUltimate Data Science & GenAI Bootcamp       Page  30\\nModule 18'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 30, 'page_label': '31'}, page_content='Introduction to Vector Databases\\nTopics\\nExploring Popular Vector Databases Chroma DB, Faiss, Quadrant, Pinecone,\\nLanceDB: Overview, Features, and Use\\nCases\\nVector Search with NoSQL Databases Integrating Vector Search with\\nMongoDB and Cassandra, Best\\nPractices for Implementing Vector\\nSearch in NoSQL Databases\\nUltimate Data Science & GenAI Bootcamp       Page  31\\nModule 18'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 31, 'page_label': '32'}, page_content='This module introduces the concept of Retrieval-Augmented Generation (RAG), which combines\\nretrieval-based search with generative models for enhanced language generation tasks. Youâ€™ll\\nlearn about the end-to-end RAG pipeline, including how to implement it with tools like LangChain,\\nvector databases, and LLMs. The module also covers hybrid search, reranking, and multimodal\\nretrieval techniques. By the end, youâ€™ll understand how to implement advanced RAG systems for\\nvarious use cases.\\nIntroduction to Retrieval-Augmented\\nGeneration (RAG)\\nTopics\\nOverview of Retrieval-Augmented\\nGeneration (RAG)\\nWhat is RAG?, Key Components of a\\nRAG System, Why RAG is Important for\\nAdvanced AI Systems\\nUnderstanding the End-to-End RAG\\nPipeline\\nOverview of the RAG Workflow, Data\\nRetrieval, Contextualization, and\\nGeneration Phases, Challenges and\\nOpportunities in RAG\\nIntegrating LangChain in RAG Introduction to LangChain Framework,\\nBuilding End-to-End RAG Pipelines with\\nLangChain'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 31, 'page_label': '32'}, page_content='Building End-to-End RAG Pipelines with\\nLangChain\\nLeveraging Vector Databases in RAG Using Vector Databases for Efficient\\nRetrieval in RAG, Popular Vector\\nDatabases for RAG (e.g., Pinecone,\\nFAISS, Chroma DB)\\nRole of LLMs in RAG How LLMs (Large Language Models)\\nEnhance Generation in RAG, Fine-\\nTuning LLMs for Retrieval-Augmented\\nTasks\\nUltimate Data Science & GenAI Bootcamp       Page  32\\nModule 19'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 32, 'page_label': '33'}, page_content='Introduction to Retrieval-Augmented\\nGeneration (RAG)\\nTopics\\nRAG with Hybrid Search and\\nReranking\\nCombining Multiple Retrieval Methods,\\nReranking Results for Improved\\nRelevance, Hybrid Search\\nImplementation Techniques\\nRAG with Various Retrieval Methods Exact vs Approximate Retrieval Methods,\\nFiltering and Ranking Retrieved Data,\\nCustomizing Retrieval Approaches for\\nSpecific Applications\\nIntegrating Memory in RAG Systems How Memory Can Improve RAG,\\nPersisting and Recalling Information for\\nConsistent Results, Implementing Long-\\nTerm Memory in RAG\\nMultimodal Retrieval-Augmented\\nGeneration\\nCombining Text, Images, and Other\\nModalities in RAG, Techniques for\\nMultimodal Retrieval and Generation,\\nPractical Applications of Multimodal\\nRAG Systems\\nUltimate Data Science & GenAI Bootcamp       Page  33\\nModule 19'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 33, 'page_label': '34'}, page_content='In this course, youâ€™ll gain hands-on experience in implementing end-to-end AI projects. Youâ€™ll learn\\nhow to manage the entire project lifecycle, from data collection and preprocessing to model\\ndevelopment, evaluation, and deployment. The module includes working on real-world AI projects,\\nwith a focus on best practices for integration, testing, and scalability. By the end, youâ€™ll be\\nprepared to take on AI projects from start to finish, applying machine learning and deep learning\\ntechniques to solve real-world problems.\\nEnd-to-End AI Project Implementation\\nTopics\\nPython Project: Building End-to-End\\nApplications\\nOverview of Python Projects, Project\\nDesign and Architecture, Key\\nConsiderations in Python Projects\\n(Performance, Scalability, etc.), Best\\nPractices for Code Quality\\nEnd-to-End Machine Learning\\nProjects\\nUnderstanding End-to-End ML Projects,\\nKey Components of an End-to-End ML\\nProject, Project Example: Real-World ML\\nApplication'), Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 33, 'page_label': '34'}, page_content='Key Components of an End-to-End ML\\nProject, Project Example: Real-World ML\\nApplication\\nDeep Learning Projects Deep Learning Fundamentals in Projects,\\nEnd-to-End Deep Learning Projects \\nGenerative AI End-to-End Projects Introduction to Generative AI Projects,\\nSteps in Building Generative AI Projects\\nUltimate Data Science & GenAI Bootcamp       Page  34\\nPROJECT')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=100)\n",
    "final_documents=text_splitter.split_documents(docs)\n",
    "final_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0839cf35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8d8e1a",
   "metadata": {},
   "source": [
    "53 Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "132be250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 1, 'page_label': '2'}, page_content='This course is designed for aspiring data scientists, machine learning enthusiasts, and\\nprofessionals looking to build expertise in Python programming, data analysis, machine learning,\\nand deep learning. Whether you are just starting or have some experience, this comprehensive\\ncourse will equip you with the skills needed to work with real-world datasets, apply machine\\nlearning algorithms, and deploy AI solutions. By the end of the course, youâ€™ll have a solid\\nfoundation in AI, a portfolio of end-to-end projects, and the confidence to tackle complex\\nchallenges in data science and AI.\\nLearning Objectives\\nMaster Python Programming: Understand Python fundamentals, including data types,\\ncontrol structures, and object-oriented programming, to write efficient and reusable\\ncode.\\nHandle Data with Pandas and NumPy: Acquire skills to manipulate, clean, and\\npreprocess large datasets using Pandas and NumPy for data analysis tasks.')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e154e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This course is designed for aspiring data scientists, machine learning enthusiasts, and\\nprofessionals looking to build expertise in Python programming, data analysis, machine learning,\\nand deep learning. Whether you are just starting or have some experience, this comprehensive\\ncourse will equip you with the skills needed to work with real-world datasets, apply machine\\nlearning algorithms, and deploy AI solutions. By the end of the course, youâ€™ll have a solid\\nfoundation in AI, a portfolio of end-to-end projects, and the confidence to tackle complex\\nchallenges in data science and AI.\\nLearning Objectives\\nMaster Python Programming: Understand Python fundamentals, including data types,\\ncontrol structures, and object-oriented programming, to write efficient and reusable\\ncode.\\nHandle Data with Pandas and NumPy: Acquire skills to manipulate, clean, and\\npreprocess large datasets using Pandas and NumPy for data analysis tasks.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_documents[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "497e0214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'preprocess large datasets using Pandas and NumPy for data analysis tasks.\\nVisualize Data: Create compelling data visualizations using libraries such as Matplotlib,\\nSeaborn, and Plotly to present insights effectively.\\nUnderstand SQL & NoSQL: Gain expertise in both relational (SQL) and non-relational\\n(NoSQL) databases, including MongoDB, for storing, querying, and managing data.\\nGrasp Statistics and Probability: Understand the core concepts of statistics,\\nprobability, and hypothesis testing, applying them to data analysis and machine\\nlearning.\\nMaster Machine Learning Techniques: Learn key machine learning algorithms,\\nincluding supervised, unsupervised, and ensemble methods, and apply them to real-\\nworld problems.\\nDive into Deep Learning: Develop a strong understanding of neural networks, CNNs,\\nRNNs, and transformers, with hands-on implementation for advanced AI tasks.\\nExplore Generative AI & Vector Databases: Learn the concepts and applications of'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_documents[2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd7c6b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='MACHINE\n",
      "LEARNING\n",
      "DEEP\n",
      "LEARNING\n",
      "PYTHON +\n",
      "STATS\n",
      "COMPUTER VISIONNATURAL LANGUAGE PROCESSING\n",
      "GENERATIVE AI\n",
      "RETRIEVAL AUGUMENT GENERATION\n",
      "VECTOR DB' metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "page_content='This course is designed for aspiring data scientists, machine learning enthusiasts, and\n",
      "professionals looking to build expertise in Python programming, data analysis, machine learning,\n",
      "and deep learning. Whether you are just starting or have some experience, this comprehensive\n",
      "course will equip you with the skills needed to work with real-world datasets, apply machine\n",
      "learning algorithms, and deploy AI solutions. By the end of the course, youâ€™ll have a solid\n",
      "foundation in AI, a portfolio of end-to-end projects, and the confidence to tackle complex\n",
      "challenges in data science and AI.\n",
      "Learning Objectives\n",
      "Master Python Programming: Understand Python fundamentals, including data types,\n",
      "control structures, and object-oriented programming, to write efficient and reusable\n",
      "code.\n",
      "Handle Data with Pandas and NumPy: Acquire skills to manipulate, clean, and\n",
      "preprocess large datasets using Pandas and NumPy for data analysis tasks.' metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'data\\\\syllabus.pdf', 'total_pages': 34, 'page': 1, 'page_label': '2'}\n"
     ]
    }
   ],
   "source": [
    "print(final_documents[0])\n",
    "print()\n",
    "print(final_documents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "423297ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\speech.txt'}, page_content='The world must be made safe for democracy. Its peace must be planted upon the tested foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no dominion. We seek no indemnities for ourselves, no material compensation for the sacrifices we shall freely make. We are but one of the champions of the rights of mankind. We shall be satisfied when those rights have been made as secure as the faith and the freedom of nations can make them.\\n\\nJust because we fight without rancor and without selfish object, seeking nothing for ourselves but what we shall wish to share with all free peoples, we shall, I feel confident, conduct our operations as belligerents without passion and ourselves observe with proud punctilio the principles of right and of fair play we profess to be fighting for.\\n\\nâ€¦\\n\\nIt will be all the easier for us to conduct ourselves as belligerents in a high spirit of right and fairness because we act without animus, not in enmity toward a people or with the desire to bring any injury or disadvantage upon them, but only in armed opposition to an irresponsible government which has thrown aside all considerations of humanity and of right and is running amuck. We are, let me say again, the sincere friends of the German people, and shall desire nothing so much as the early reestablishment of intimate relations of mutual advantage between usâ€”however hard it may be for them, for the time being, to believe that this is spoken from our hearts.\\n\\nWe have borne with their present government through all these bitter months because of that friendshipâ€”exercising a patience and forbearance which would otherwise have been impossible. We shall, happily, still have an opportunity to prove that friendship in our daily attitude and actions toward the millions of men and women of German birth and native sympathy who live among us and share our life, and we shall be proud to prove it toward all who are in fact loyal to their neighbors and to the government in the hour of test. They are, most of them, as true and loyal Americans as if they had never known any other fealty or allegiance. They will be prompt to stand with us in rebuking and restraining the few who may be of a different mind and purpose. If there should be disloyalty, it will be dealt with with a firm hand of stern repression; but, if it lifts its head at all, it will lift it only here and there and without countenance except from a lawless and malignant few.\\n\\nIt is a distressing and oppressive duty, gentlemen of the Congress, which I have performed in thus addressing you. There are, it may be, many months of fiery trial and sacrifice ahead of us. It is a fearful thing to lead this great peaceful people into war, into the most terrible and disastrous of all wars, civilization itself seeming to be in the balance. But the right is more precious than peace, and we shall fight for the things which we have always carried nearest our heartsâ€”for democracy, for the right of those who submit to authority to have a voice in their own governments, for the rights and liberties of small nations, for a universal dominion of right by such a concert of free peoples as shall bring peace and safety to all nations and make the world itself at last free.\\n\\nTo such a task we can dedicate our lives and our fortunes, everything that we are and everything that we have, with the pride of those who know that the day has come when America is privileged to spend her blood and her might for the principles that gave her birth and happiness and the peace which she has treasured. God helping her, she can do no other.')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Text Loader\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader=TextLoader('data\\speech.txt')\n",
    "docs=loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f26a1bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='The world must be made safe for democracy. Its peace must be planted upon the tested foundations of'\n",
      "page_content='foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no'\n"
     ]
    }
   ],
   "source": [
    "speech=\"\"\n",
    "with open(\"data\\speech.txt\") as f:\n",
    "    speech=f.read()\n",
    "\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=100,chunk_overlap=20)\n",
    "text=text_splitter.create_documents([speech])\n",
    "print(text[0])\n",
    "print(text[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece056f4",
   "metadata": {},
   "source": [
    "Great follow-up! Let's **deep dive into how `RecursiveCharacterTextSplitter` works** â€” especially the `chunk_size`, `chunk_overlap`, and how it handles different **separators**: `\\n\\n`, `\\n`, `\" \"`, and `\"\"`.\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ§  Key Concepts\n",
    "\n",
    "* **`chunk_size`**: Maximum number of characters in each chunk (not exact â€” best effort without breaking sentences/words).\n",
    "* **`chunk_overlap`**: Number of characters to **repeat** from the previous chunk (for context).\n",
    "* **`separators`**: Tries to split using bigger logical breaks first (`\\n\\n`, then `\\n`, then `\" \"`, then `\"\"`) to create cleaner chunks.\n",
    "\n",
    "---\n",
    "\n",
    "##### ðŸ”¤ Sample Text (includes all separators)\n",
    "\n",
    "```python\n",
    "text = \"\"\"LangChain makes it easy to build LLM-powered apps.\n",
    "\n",
    "It includes tools like text splitters, retrievers,\n",
    "and agents. You can also integrate with OpenAI,\n",
    "HuggingFace, and more!LangChain is open source.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "Note:\n",
    "\n",
    "* `\\n\\n` â†’ Between paragraphs\n",
    "* `\\n` â†’ Between lines\n",
    "* `\" \"` â†’ Between words\n",
    "* `\"\"` â†’ Between characters (last resort)\n",
    "\n",
    "---\n",
    "\n",
    "##### ðŸ§ª Code with `RecursiveCharacterTextSplitter`\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=80,     # Try to keep each chunk under 80 chars\n",
    "    chunk_overlap=20,  # Overlap 20 chars from the previous chunk\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(text)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}:\")\n",
    "    print(repr(chunk))\n",
    "    print('-' * 50)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##### ðŸ“¦ Output Explanation:\n",
    "\n",
    "```text\n",
    "Chunk 1:\n",
    "'LangChain makes it easy to build LLM-powered apps.'\n",
    "--------------------------------------------------\n",
    "Chunk 2:\n",
    "'It includes tools like text splitters, retrievers,\\nand agents. You can also'\n",
    "--------------------------------------------------\n",
    "Chunk 3:\n",
    "'also integrate with OpenAI,\\nHuggingFace, and more!LangChain is open source.'\n",
    "--------------------------------------------------\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##### ðŸ” How it worked:\n",
    "\n",
    "1. **Chunk 1**:\n",
    "\n",
    "   * Stopped at `\\n\\n` (paragraph break), first level.\n",
    "   * Length â‰ˆ 50 chars, under `chunk_size`.\n",
    "\n",
    "2. **Chunk 2**:\n",
    "\n",
    "   * Uses `\\n`, ` ` to split.\n",
    "   * Includes **20-char overlap** from end of previous chunk (`\"You can also...\"`).\n",
    "\n",
    "3. **Chunk 3**:\n",
    "\n",
    "   * Uses ` ` and finally falls back to `\"\"` if nothing else fits.\n",
    "   * Ends with `\"LangChain is open source.\"`\n",
    "\n",
    "---\n",
    "\n",
    "##### ðŸ“Š Visualization\n",
    "\n",
    "| Step | Separator Used  | Text                          | Why                                |\n",
    "| ---- | --------------- | ----------------------------- | ---------------------------------- |\n",
    "| 1    | `\\n\\n`          | `\"LangChain makes it...\"`     | Clean paragraph                    |\n",
    "| 2    | `\\n`, `\" \"`     | `\"It includes tools...\"`      | Tries smaller break                |\n",
    "| 3    | `\" \"` then `\"\"` | `\"You can also integrate...\"` | Last part needs character fallback |\n",
    "\n",
    "---\n",
    "\n",
    "#### âœ… Final Notes\n",
    "\n",
    "* **chunk\\_size is soft**: It tries to keep chunks â‰¤ `chunk_size`, but prioritizes clean splits.\n",
    "* **chunk\\_overlap ensures continuity**: This is **critical** for keeping context in RAG systems.\n",
    "* If no separator fits (e.g., a very long word), it **splits by characters** (`\"\"`).\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to visualize this as a diagram or show a version that logs each step internally?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d653e8c",
   "metadata": {},
   "source": [
    "### How to split by character-Character Text Splitter\n",
    "This is the simplest method. This splits based on a given character sequence, which defaults to \"\\n\\n\". Chunk length is measured by number of characters.\n",
    "\n",
    "1. How the text is split: by single character separator.\n",
    "2. How the chunk size is measured: by number of characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afef0218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 470, which is longer than the specified 100\n",
      "Created a chunk of size 347, which is longer than the specified 100\n",
      "Created a chunk of size 668, which is longer than the specified 100\n",
      "Created a chunk of size 982, which is longer than the specified 100\n",
      "Created a chunk of size 789, which is longer than the specified 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\speech.txt'}, page_content='The world must be made safe for democracy. Its peace must be planted upon the tested foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no dominion. We seek no indemnities for ourselves, no material compensation for the sacrifices we shall freely make. We are but one of the champions of the rights of mankind. We shall be satisfied when those rights have been made as secure as the faith and the freedom of nations can make them.'), Document(metadata={'source': 'data\\\\speech.txt'}, page_content='Just because we fight without rancor and without selfish object, seeking nothing for ourselves but what we shall wish to share with all free peoples, we shall, I feel confident, conduct our operations as belligerents without passion and ourselves observe with proud punctilio the principles of right and of fair play we profess to be fighting for.'), Document(metadata={'source': 'data\\\\speech.txt'}, page_content='â€¦'), Document(metadata={'source': 'data\\\\speech.txt'}, page_content='It will be all the easier for us to conduct ourselves as belligerents in a high spirit of right and fairness because we act without animus, not in enmity toward a people or with the desire to bring any injury or disadvantage upon them, but only in armed opposition to an irresponsible government which has thrown aside all considerations of humanity and of right and is running amuck. We are, let me say again, the sincere friends of the German people, and shall desire nothing so much as the early reestablishment of intimate relations of mutual advantage between usâ€”however hard it may be for them, for the time being, to believe that this is spoken from our hearts.'), Document(metadata={'source': 'data\\\\speech.txt'}, page_content='We have borne with their present government through all these bitter months because of that friendshipâ€”exercising a patience and forbearance which would otherwise have been impossible. We shall, happily, still have an opportunity to prove that friendship in our daily attitude and actions toward the millions of men and women of German birth and native sympathy who live among us and share our life, and we shall be proud to prove it toward all who are in fact loyal to their neighbors and to the government in the hour of test. They are, most of them, as true and loyal Americans as if they had never known any other fealty or allegiance. They will be prompt to stand with us in rebuking and restraining the few who may be of a different mind and purpose. If there should be disloyalty, it will be dealt with with a firm hand of stern repression; but, if it lifts its head at all, it will lift it only here and there and without countenance except from a lawless and malignant few.'), Document(metadata={'source': 'data\\\\speech.txt'}, page_content='It is a distressing and oppressive duty, gentlemen of the Congress, which I have performed in thus addressing you. There are, it may be, many months of fiery trial and sacrifice ahead of us. It is a fearful thing to lead this great peaceful people into war, into the most terrible and disastrous of all wars, civilization itself seeming to be in the balance. But the right is more precious than peace, and we shall fight for the things which we have always carried nearest our heartsâ€”for democracy, for the right of those who submit to authority to have a voice in their own governments, for the rights and liberties of small nations, for a universal dominion of right by such a concert of free peoples as shall bring peace and safety to all nations and make the world itself at last free.'), Document(metadata={'source': 'data\\\\speech.txt'}, page_content='To such a task we can dedicate our lives and our fortunes, everything that we are and everything that we have, with the pride of those who know that the day has come when America is privileged to spend her blood and her might for the principles that gave her birth and happiness and the peace which she has treasured. God helping her, she can do no other.')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "text_splitter=CharacterTextSplitter(separator=\"\\n\\n\",chunk_size=100,chunk_overlap=20)\n",
    "text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b028b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 470, which is longer than the specified 100\n",
      "Created a chunk of size 347, which is longer than the specified 100\n",
      "Created a chunk of size 668, which is longer than the specified 100\n",
      "Created a chunk of size 982, which is longer than the specified 100\n",
      "Created a chunk of size 789, which is longer than the specified 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='The world must be made safe for democracy. Its peace must be planted upon the tested foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no dominion. We seek no indemnities for ourselves, no material compensation for the sacrifices we shall freely make. We are but one of the champions of the rights of mankind. We shall be satisfied when those rights have been made as secure as the faith and the freedom of nations can make them.'\n",
      "page_content='Just because we fight without rancor and without selfish object, seeking nothing for ourselves but what we shall wish to share with all free peoples, we shall, I feel confident, conduct our operations as belligerents without passion and ourselves observe with proud punctilio the principles of right and of fair play we profess to be fighting for.'\n"
     ]
    }
   ],
   "source": [
    "speech=\"\"\n",
    "with open(\"data\\speech.txt\") as f:\n",
    "    speech=f.read()\n",
    "\n",
    "\n",
    "text_splitter=CharacterTextSplitter(chunk_size=100,chunk_overlap=20)\n",
    "text=text_splitter.create_documents([speech])\n",
    "print(text[0])\n",
    "print(text[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2669600d",
   "metadata": {},
   "source": [
    "### How to split by HTML header\n",
    "HTMLHeaderTextSplitter is a \"structure-aware\" chunker that splits text at the HTML element level and adds metadata for each header \"relevant\" to any given chunk. It can return chunks element by element or combine elements with the same metadata, with the objectives of (a) keeping related text grouped (more or less) semantically and (b) preserving context-rich information encoded in document structures. It can be used with other text splitters as part of a chunking pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d1f6f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': 'Foo'}, page_content='Foo'), Document(metadata={'Header 1': 'Foo'}, page_content='Some intro text about Foo.'), Document(metadata={'Header 1': 'Foo', 'Header 2': 'Bar main section'}, page_content='Bar main section'), Document(metadata={'Header 1': 'Foo', 'Header 2': 'Bar main section'}, page_content='Some intro text about Bar.'), Document(metadata={'Header 1': 'Foo', 'Header 2': 'Bar main section', 'Header 3': 'Bar subsection 1'}, page_content='Bar subsection 1'), Document(metadata={'Header 1': 'Foo', 'Header 2': 'Bar main section', 'Header 3': 'Bar subsection 1'}, page_content='Some text about the first subtopic of Bar.'), Document(metadata={'Header 1': 'Foo', 'Header 2': 'Bar main section', 'Header 3': 'Bar subsection 2'}, page_content='Bar subsection 2'), Document(metadata={'Header 1': 'Foo', 'Header 2': 'Bar main section', 'Header 3': 'Bar subsection 2'}, page_content='Some text about the second subtopic of Bar.'), Document(metadata={'Header 1': 'Foo', 'Header 2': 'Baz'}, page_content='Baz'), Document(metadata={'Header 1': 'Foo'}, page_content='Some text about Baz  \\nSome concluding text about Foo')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "\n",
    "html_string = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<body>\n",
    "    <div>\n",
    "        <h1>Foo</h1>\n",
    "        <p>Some intro text about Foo.</p>\n",
    "        <div>\n",
    "            <h2>Bar main section</h2>\n",
    "            <p>Some intro text about Bar.</p>\n",
    "            <h3>Bar subsection 1</h3>\n",
    "            <p>Some text about the first subtopic of Bar.</p>\n",
    "            <h3>Bar subsection 2</h3>\n",
    "            <p>Some text about the second subtopic of Bar.</p>\n",
    "        </div>\n",
    "        <div>\n",
    "            <h2>Baz</h2>\n",
    "            <p>Some text about Baz</p>\n",
    "        </div>\n",
    "        <br>\n",
    "        <p>Some concluding text about Foo</p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "headers_to_split_on=[\n",
    "    (\"h1\",\"Header 1\"),\n",
    "    (\"h2\",\"Header 2\"),\n",
    "    (\"h3\",\"Header 3\")\n",
    "]\n",
    "\n",
    "html_splitter=HTMLHeaderTextSplitter(headers_to_split_on)\n",
    "html_header_splits=html_splitter.split_text(html_string)\n",
    "html_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97efbc7d",
   "metadata": {},
   "source": [
    "### How to split JSON data\n",
    "This json splitter splits json data while allowing control over chunk sizes. It traverses json data depth first and builds smaller json chunks. It attempts to keep nested json objects whole but will split them if needed to keep chunks between a min_chunk_size and the max_chunk_size.\n",
    "\n",
    "If the value is not a nested json, but rather a very large string the string will not be split. If you need a hard cap on the chunk size consider composing this with a Recursive Text splitter on those chunks. There is an optional pre-processing step to split lists, by first converting them to json (dict) and then splitting them as such.\n",
    "\n",
    "- How the text is split: json value.\n",
    "- How the chunk size is measured: by number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a6248e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "json_data=requests.get(\"https://api.smith.langchain.com/openapi.json\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7ee30cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'openapi': '3.1.0',\n",
       " 'info': {'title': 'LangSmith', 'version': '0.1.0'},\n",
       " 'paths': {'/api/v1/sessions/{session_id}/dashboard': {'post': {'tags': ['tracer-sessions'],\n",
       "    'summary': 'Get Tracing Project Prebuilt Dashboard',\n",
       "    'description': 'Get a prebuilt dashboard for a tracing project.',\n",
       "    'operationId': 'get_tracing_project_prebuilt_dashboard_api_v1_sessions__session_id__dashboard_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'session_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}},\n",
       "     {'name': 'accept',\n",
       "      'in': 'header',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Accept'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsSectionRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsSection'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/sessions/{session_id}': {'get': {'tags': ['tracer-sessions'],\n",
       "    'summary': 'Read Tracer Session',\n",
       "    'description': 'Get a specific session.',\n",
       "    'operationId': 'read_tracer_session_api_v1_sessions__session_id__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'session_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}},\n",
       "     {'name': 'include_stats',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': False,\n",
       "       'title': 'Include Stats'}},\n",
       "     {'name': 'accept',\n",
       "      'in': 'header',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Accept'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TracerSession'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['tracer-sessions'],\n",
       "    'summary': 'Update Tracer Session',\n",
       "    'description': 'Create a new session.',\n",
       "    'operationId': 'update_tracer_session_api_v1_sessions__session_id__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'session_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TracerSessionUpdate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TracerSessionWithoutVirtualFields'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['tracer-sessions'],\n",
       "    'summary': 'Delete Tracer Session',\n",
       "    'description': 'Delete a specific session.',\n",
       "    'operationId': 'delete_tracer_session_api_v1_sessions__session_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'session_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/sessions': {'get': {'tags': ['tracer-sessions'],\n",
       "    'summary': 'Read Tracer Sessions',\n",
       "    'description': 'Get all sessions.',\n",
       "    'operationId': 'read_tracer_sessions_api_v1_sessions_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'reference_free',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "       'title': 'Reference Free'}},\n",
       "     {'name': 'reference_dataset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Reference Dataset'}},\n",
       "     {'name': 'id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Id'}},\n",
       "     {'name': 'name',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Name'}},\n",
       "     {'name': 'name_contains',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Name Contains'}},\n",
       "     {'name': 'dataset_version',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Dataset Version'}},\n",
       "     {'name': 'sort_by',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'$ref': '#/components/schemas/SessionSortableColumns',\n",
       "       'default': 'start_time'}},\n",
       "     {'name': 'sort_by_desc',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean', 'default': True, 'title': 'Sort By Desc'}},\n",
       "     {'name': 'metadata',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Metadata'}},\n",
       "     {'name': 'sort_by_feedback_key',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Sort By Feedback Key'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 100,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'tag_value_id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Tag Value Id'}},\n",
       "     {'name': 'facets',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean', 'default': False, 'title': 'Facets'}},\n",
       "     {'name': 'filter',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Filter'}},\n",
       "     {'name': 'include_stats',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': True,\n",
       "       'title': 'Include Stats'}},\n",
       "     {'name': 'use_approx_stats',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': False,\n",
       "       'title': 'Use Approx Stats'}},\n",
       "     {'name': 'accept',\n",
       "      'in': 'header',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Accept'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/TracerSession'},\n",
       "         'title': 'Response Read Tracer Sessions Api V1 Sessions Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['tracer-sessions'],\n",
       "    'summary': 'Create Tracer Session',\n",
       "    'description': 'Create a new session.',\n",
       "    'operationId': 'create_tracer_session_api_v1_sessions_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'upsert',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean', 'default': False, 'title': 'Upsert'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TracerSessionCreate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TracerSessionWithoutVirtualFields'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['tracer-sessions'],\n",
       "    'summary': 'Delete Tracer Sessions',\n",
       "    'description': 'Delete a specific session.',\n",
       "    'operationId': 'delete_tracer_sessions_api_v1_sessions_delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'session_ids',\n",
       "      'in': 'query',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'array',\n",
       "       'items': {'type': 'string', 'format': 'uuid'},\n",
       "       'title': 'Session Ids'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/sessions/{session_id}/metadata': {'get': {'tags': ['tracer-sessions'],\n",
       "    'summary': 'Read Tracer Sessions Runs Metadata',\n",
       "    'description': 'Given a session, a number K, and (optionally) a list of metadata keys, return the top K values for each key.',\n",
       "    'operationId': 'read_tracer_sessions_runs_metadata_api_v1_sessions__session_id__metadata_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'session_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}},\n",
       "     {'name': 'metadata_keys',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Metadata Keys'}},\n",
       "     {'name': 'start_time',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Start Time'}},\n",
       "     {'name': 'k',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 1,\n",
       "       'default': 10,\n",
       "       'title': 'K'}},\n",
       "     {'name': 'root_runs_only',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': False,\n",
       "       'title': 'Root Runs Only'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RootModel_Dict_str__list_str___'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/sessions/{session_id}/views': {'get': {'tags': ['tracer-sessions'],\n",
       "    'summary': 'Read Filter Views',\n",
       "    'description': 'Get all filter views for a session.',\n",
       "    'operationId': 'read_filter_views_api_v1_sessions__session_id__views_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'session_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}},\n",
       "     {'name': 'type',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'$ref': '#/components/schemas/FilterViewType'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Type'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/FilterView'},\n",
       "         'title': 'Response Read Filter Views Api V1 Sessions  Session Id  Views Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['tracer-sessions'],\n",
       "    'summary': 'Create Filter View',\n",
       "    'description': 'Create a new filter view.',\n",
       "    'operationId': 'create_filter_view_api_v1_sessions__session_id__views_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'session_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FilterViewCreate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FilterView'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/sessions/{session_id}/views/{view_id}': {'get': {'tags': ['tracer-sessions'],\n",
       "    'summary': 'Read Filter View',\n",
       "    'description': 'Get a specific filter view.',\n",
       "    'operationId': 'read_filter_view_api_v1_sessions__session_id__views__view_id__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'session_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}},\n",
       "     {'name': 'view_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'View Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FilterView'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['tracer-sessions'],\n",
       "    'summary': 'Update Filter View',\n",
       "    'description': 'Update a filter view.',\n",
       "    'operationId': 'update_filter_view_api_v1_sessions__session_id__views__view_id__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'session_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}},\n",
       "     {'name': 'view_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'View Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FilterViewUpdate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FilterView'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['tracer-sessions'],\n",
       "    'summary': 'Delete Filter View',\n",
       "    'description': 'Delete a specific filter view.',\n",
       "    'operationId': 'delete_filter_view_api_v1_sessions__session_id__views__view_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'session_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}},\n",
       "     {'name': 'view_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'View Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/orgs': {'get': {'tags': ['orgs'],\n",
       "    'summary': 'List Organizations',\n",
       "    'description': 'Get all orgs visible to this auth',\n",
       "    'operationId': 'list_organizations_api_v1_orgs_get',\n",
       "    'security': [{'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'skip_create',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': False,\n",
       "       'title': 'Skip Create'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/OrganizationPGSchemaSlim'},\n",
       "         'title': 'Response List Organizations Api V1 Orgs Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['orgs'],\n",
       "    'summary': 'Create Organization',\n",
       "    'operationId': 'create_organization_api_v1_orgs_post',\n",
       "    'security': [{'Bearer Auth': []}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationCreate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationPGSchemaSlim'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/orgs/current/setup': {'post': {'tags': ['orgs'],\n",
       "    'summary': 'Create Customers And Get Stripe Setup Intent',\n",
       "    'operationId': 'create_customers_and_get_stripe_setup_intent_api_v1_orgs_current_setup_post',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StripeSetupIntentResponse'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/current': {'get': {'tags': ['orgs'],\n",
       "    'summary': 'Get Organization Info',\n",
       "    'operationId': 'get_organization_info_api_v1_orgs_current_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Organization'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/current/info': {'get': {'tags': ['orgs'],\n",
       "    'summary': 'Get Current Organization Info',\n",
       "    'operationId': 'get_current_organization_info_api_v1_orgs_current_info_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationInfo'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]},\n",
       "   'patch': {'tags': ['orgs'],\n",
       "    'summary': 'Update Current Organization Info',\n",
       "    'operationId': 'update_current_organization_info_api_v1_orgs_current_info_patch',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationUpdate'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationInfo'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/current/billing': {'get': {'tags': ['orgs'],\n",
       "    'summary': 'Get Organization Billing Info',\n",
       "    'operationId': 'get_organization_billing_info_api_v1_orgs_current_billing_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationBillingInfo'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/current/dashboard': {'get': {'tags': ['orgs'],\n",
       "    'summary': 'Get Dashboard',\n",
       "    'operationId': 'get_dashboard_api_v1_orgs_current_dashboard_get',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'type',\n",
       "      'in': 'query',\n",
       "      'required': True,\n",
       "      'schema': {'$ref': '#/components/schemas/OrganizationDashboardType'}},\n",
       "     {'name': 'color_scheme',\n",
       "      'in': 'query',\n",
       "      'required': True,\n",
       "      'schema': {'anyOf': [{'$ref': '#/components/schemas/OrganizationDashboardColorScheme'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Color Scheme'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationDashboardSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/orgs/current/payment-method': {'post': {'tags': ['orgs'],\n",
       "    'summary': 'On Payment Method Created',\n",
       "    'operationId': 'on_payment_method_created_api_v1_orgs_current_payment_method_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StripePaymentInformation'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/current/business-info': {'get': {'tags': ['orgs'],\n",
       "    'summary': 'Get Company Info',\n",
       "    'operationId': 'get_company_info_api_v1_orgs_current_business_info_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StripeBusinessInfo-Output'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]},\n",
       "   'post': {'tags': ['orgs'],\n",
       "    'summary': 'Set Company Info',\n",
       "    'operationId': 'set_company_info_api_v1_orgs_current_business_info_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StripeBusinessInfo-Input'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/current/plan': {'post': {'tags': ['orgs'],\n",
       "    'summary': 'Change Payment Plan',\n",
       "    'operationId': 'change_payment_plan_api_v1_orgs_current_plan_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ChangePaymentPlanSchema'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/current/roles': {'get': {'tags': ['orgs'],\n",
       "    'summary': 'List Organization Roles',\n",
       "    'operationId': 'list_organization_roles_api_v1_orgs_current_roles_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/Role'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response List Organization Roles Api V1 Orgs Current Roles Get'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]},\n",
       "   'post': {'tags': ['orgs'],\n",
       "    'summary': 'Create Organization Roles',\n",
       "    'operationId': 'create_organization_roles_api_v1_orgs_current_roles_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateRoleRequest'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Role'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/current/roles/{role_id}': {'delete': {'tags': ['orgs'],\n",
       "    'summary': 'Delete Organization Roles',\n",
       "    'operationId': 'delete_organization_roles_api_v1_orgs_current_roles__role_id__delete',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'role_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Role Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Role'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['orgs'],\n",
       "    'summary': 'Update Organization Roles',\n",
       "    'operationId': 'update_organization_roles_api_v1_orgs_current_roles__role_id__patch',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'role_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Role Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UpdateRoleRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Role'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/orgs/permissions': {'get': {'tags': ['orgs'],\n",
       "    'summary': 'List Permissions',\n",
       "    'operationId': 'list_permissions_api_v1_orgs_permissions_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/PermissionResponse'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response List Permissions Api V1 Orgs Permissions Get'}}}}},\n",
       "    'security': [{'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/pending': {'get': {'tags': ['orgs'],\n",
       "    'summary': 'List Pending Organization Invites',\n",
       "    'description': 'Get all pending orgs visible to this auth',\n",
       "    'operationId': 'list_pending_organization_invites_api_v1_orgs_pending_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/OrganizationPGSchemaSlim'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response List Pending Organization Invites Api V1 Orgs Pending Get'}}}}},\n",
       "    'security': [{'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/current/members': {'get': {'tags': ['orgs'],\n",
       "    'summary': 'Get Current Org Members',\n",
       "    'operationId': 'get_current_org_members_api_v1_orgs_current_members_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationMembers'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]},\n",
       "   'post': {'tags': ['orgs'],\n",
       "    'summary': 'Add Member To Current Org',\n",
       "    'operationId': 'add_member_to_current_org_api_v1_orgs_current_members_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PendingIdentityCreate'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PendingIdentity'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/current/members/active': {'get': {'tags': ['orgs'],\n",
       "    'summary': 'Get Current Active Org Members',\n",
       "    'operationId': 'get_current_active_org_members_api_v1_orgs_current_members_active_get',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 500,\n",
       "       'minimum': 1,\n",
       "       'default': 50,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'emails',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'array',\n",
       "       'items': {'type': 'string'},\n",
       "       'default': [],\n",
       "       'title': 'Emails'}},\n",
       "     {'name': 'ls_user_ids',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'array',\n",
       "       'items': {'type': 'string', 'format': 'uuid'},\n",
       "       'default': [],\n",
       "       'title': 'Ls User Ids'}},\n",
       "     {'name': 'user_ids',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'array',\n",
       "       'items': {'type': 'string', 'format': 'uuid'},\n",
       "       'default': [],\n",
       "       'title': 'User Ids'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/OrgMemberIdentity'},\n",
       "         'title': 'Response Get Current Active Org Members Api V1 Orgs Current Members Active Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/orgs/current/members/pending': {'get': {'tags': ['orgs'],\n",
       "    'summary': 'Get Current Pending Org Members',\n",
       "    'operationId': 'get_current_pending_org_members_api_v1_orgs_current_members_pending_get',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 500,\n",
       "       'minimum': 1,\n",
       "       'default': 50,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'emails',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'array',\n",
       "       'items': {'type': 'string'},\n",
       "       'default': [],\n",
       "       'title': 'Emails'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/OrgPendingIdentity'},\n",
       "         'title': 'Response Get Current Pending Org Members Api V1 Orgs Current Members Pending Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/orgs/current/members/batch': {'post': {'tags': ['orgs'],\n",
       "    'summary': 'Add Members To Current Org Batch',\n",
       "    'description': 'Batch invite up to 500 users to the current org.',\n",
       "    'operationId': 'add_members_to_current_org_batch_api_v1_orgs_current_members_batch_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/PendingIdentityCreate'},\n",
       "        'type': 'array',\n",
       "        'title': 'Payloads'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/PendingIdentity'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response Add Members To Current Org Batch Api V1 Orgs Current Members Batch Post'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/current/members/basic/batch': {'post': {'tags': ['orgs'],\n",
       "    'summary': 'Add Basic Auth Members To Current Org',\n",
       "    'description': 'Batch add up to 500 users to the org and specified workspaces in basic auth mode.',\n",
       "    'operationId': 'add_basic_auth_members_to_current_org_api_v1_orgs_current_members_basic_batch_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/BasicAuthMemberCreate'},\n",
       "        'type': 'array',\n",
       "        'title': 'Payloads'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/UserWithPassword'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response Add Basic Auth Members To Current Org Api V1 Orgs Current Members Basic Batch Post'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/current/members/{identity_id}/pending': {'delete': {'tags': ['orgs'],\n",
       "    'summary': 'Delete Current Org Pending Member',\n",
       "    'description': 'When an admin deletes a pending member invite.',\n",
       "    'operationId': 'delete_current_org_pending_member_api_v1_orgs_current_members__identity_id__pending_delete',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'identity_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Identity Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/orgs/pending/{organization_id}': {'delete': {'tags': ['orgs'],\n",
       "    'summary': 'Delete Pending Organization Invite',\n",
       "    'operationId': 'delete_pending_organization_invite_api_v1_orgs_pending__organization_id__delete',\n",
       "    'security': [{'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'organization_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Organization Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/orgs/pending/{organization_id}/claim': {'post': {'tags': ['orgs'],\n",
       "    'summary': 'Claim Pending Organization Invite',\n",
       "    'operationId': 'claim_pending_organization_invite_api_v1_orgs_pending__organization_id__claim_post',\n",
       "    'security': [{'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'organization_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Organization Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Identity'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/orgs/current/members/{identity_id}': {'delete': {'tags': ['orgs'],\n",
       "    'summary': 'Remove Member From Current Org',\n",
       "    'description': 'Remove a user from the current organization.',\n",
       "    'operationId': 'remove_member_from_current_org_api_v1_orgs_current_members__identity_id__delete',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'identity_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Identity Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['orgs'],\n",
       "    'summary': 'Update Current Org Member',\n",
       "    'description': \"This is used for updating a user's role (all auth modes) or full_name/password (basic auth)\",\n",
       "    'operationId': 'update_current_org_member_api_v1_orgs_current_members__identity_id__patch',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'identity_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Identity Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrgIdentityPatch'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/orgs/members/basic': {'patch': {'tags': ['orgs'],\n",
       "    'summary': 'Update Current User',\n",
       "    'description': \"Update a user's full_name/password (basic auth only)\",\n",
       "    'operationId': 'update_current_user_api_v1_orgs_members_basic_patch',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BasicAuthUserPatch'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/ttl-settings': {'get': {'tags': ['orgs'],\n",
       "    'summary': 'List Ttl Settings',\n",
       "    'description': 'List out the configured TTL settings for a given org (org-level and tenant-level).',\n",
       "    'operationId': 'list_ttl_settings_api_v1_orgs_ttl_settings_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/TTLSettings'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response List Ttl Settings Api V1 Orgs Ttl Settings Get'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]},\n",
       "   'put': {'tags': ['orgs'],\n",
       "    'summary': 'Upsert Ttl Settings',\n",
       "    'operationId': 'upsert_ttl_settings_api_v1_orgs_ttl_settings_put',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UpsertTTLSettingsRequest'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TTLSettings'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/current/sso-settings': {'get': {'tags': ['orgs'],\n",
       "    'summary': 'Get Current Sso Settings',\n",
       "    'description': 'Get SSO provider settings for the current organization.',\n",
       "    'operationId': 'get_current_sso_settings_api_v1_orgs_current_sso_settings_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/SSOProvider'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response Get Current Sso Settings Api V1 Orgs Current Sso Settings Get'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]},\n",
       "   'post': {'tags': ['orgs'],\n",
       "    'summary': 'Create Sso Settings',\n",
       "    'description': 'Create SSO provider settings for the current organization.',\n",
       "    'operationId': 'create_sso_settings_api_v1_orgs_current_sso_settings_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SSOSettingsCreate'}}},\n",
       "     'required': True},\n",
       "    'responses': {'201': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SSOProvider'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/current/sso-settings/{id}': {'patch': {'tags': ['orgs'],\n",
       "    'summary': 'Update Sso Settings',\n",
       "    'description': 'Update SSO provider settings defaults for the current organization.',\n",
       "    'operationId': 'update_sso_settings_api_v1_orgs_current_sso_settings__id__patch',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SSOSettingsUpdate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SSOProvider'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['orgs'],\n",
       "    'summary': 'Delete Sso Settings',\n",
       "    'description': 'Delete SSO provider settings for the current organization.',\n",
       "    'operationId': 'delete_sso_settings_api_v1_orgs_current_sso_settings__id__delete',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SSOProvider'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/orgs/current/login-methods': {'patch': {'tags': ['orgs'],\n",
       "    'summary': 'Update Allowed Login Methods',\n",
       "    'description': 'Update allowed login methods for the current organization.',\n",
       "    'operationId': 'update_allowed_login_methods_api_v1_orgs_current_login_methods_patch',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AllowedLoginMethodsUpdate'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'object',\n",
       "         'title': 'Response Update Allowed Login Methods Api V1 Orgs Current Login Methods Patch'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/current/billing/usage': {'get': {'tags': ['orgs'],\n",
       "    'summary': 'Get Org Usage',\n",
       "    'operationId': 'get_org_usage_api_v1_orgs_current_billing_usage_get',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'starting_on',\n",
       "      'in': 'query',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Starting On'}},\n",
       "     {'name': 'ending_before',\n",
       "      'in': 'query',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Ending Before'}},\n",
       "     {'name': 'on_current_plan',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': True,\n",
       "       'title': 'On Current Plan'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/OrgUsage'},\n",
       "         'title': 'Response Get Org Usage Api V1 Orgs Current Billing Usage Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/orgs/current/user/login-methods': {'get': {'tags': ['orgs'],\n",
       "    'summary': 'Get Current User Login Methods',\n",
       "    'description': 'Get login methods for the current user.',\n",
       "    'operationId': 'get_current_user_login_methods_api_v1_orgs_current_user_login_methods_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/ProviderUserSlim'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response Get Current User Login Methods Api V1 Orgs Current User Login Methods Get'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/current/stripe_checkout_session': {'post': {'tags': ['orgs'],\n",
       "    'summary': 'Create Stripe Checkout Sessions Endpoint',\n",
       "    'description': 'Kick off a Stripe checkout session flow.',\n",
       "    'operationId': 'create_stripe_checkout_sessions_endpoint_api_v1_orgs_current_stripe_checkout_session_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StripeCheckoutSessionsCreate'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/current/confirm_checkout_session_completion': {'post': {'tags': ['orgs'],\n",
       "    'summary': 'Confirm Checkout Session Completion Endpoint',\n",
       "    'description': 'Complete a Stripe checkout session flow.',\n",
       "    'operationId': 'confirm_checkout_session_completion_endpoint_api_v1_orgs_current_confirm_checkout_session_completion_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StripeCheckoutSessionsConfirm'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/orgs/current/stripe_account_links': {'post': {'tags': ['orgs'],\n",
       "    'summary': 'Create Stripe Account Links Endpoint',\n",
       "    'description': 'Kick off a Stripe account link flow.',\n",
       "    'operationId': 'create_stripe_account_links_endpoint_api_v1_orgs_current_stripe_account_links_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StripeAccountLinksCreate'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/login': {'post': {'tags': ['auth'],\n",
       "    'summary': 'Login',\n",
       "    'operationId': 'login_api_v1_login_post',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BasicAuthResponse'}}}}}}},\n",
       "  '/api/v1/oauth/{provider}/callback': {'get': {'tags': ['auth'],\n",
       "    'summary': 'Oauth Provider Callback',\n",
       "    'operationId': 'oauth_provider_callback_api_v1_oauth__provider__callback_get',\n",
       "    'parameters': [{'name': 'provider',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'$ref': '#/components/schemas/OAuthProvider'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'object',\n",
       "         'title': 'Response Oauth Provider Callback Api V1 Oauth  Provider  Callback Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/oauth/{provider}/logout': {'get': {'tags': ['auth'],\n",
       "    'summary': 'Oauth Provider Logout',\n",
       "    'operationId': 'oauth_provider_logout_api_v1_oauth__provider__logout_get',\n",
       "    'parameters': [{'name': 'provider',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'$ref': '#/components/schemas/OAuthProvider'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/oauth/{provider}': {'get': {'tags': ['auth'],\n",
       "    'summary': 'Oauth Provider Auth',\n",
       "    'operationId': 'oauth_provider_auth_api_v1_oauth__provider__get',\n",
       "    'parameters': [{'name': 'provider',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'$ref': '#/components/schemas/OAuthProvider'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/oauth/{provider}/current-user': {'get': {'tags': ['auth'],\n",
       "    'summary': 'Oauth Provider Current User',\n",
       "    'operationId': 'oauth_provider_current_user_api_v1_oauth__provider__current_user_get',\n",
       "    'parameters': [{'name': 'provider',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'$ref': '#/components/schemas/OAuthProvider'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/sso/email-verification/send': {'post': {'tags': ['auth'],\n",
       "    'summary': 'Send Sso Email Confirmation',\n",
       "    'description': 'Send an email to confirm the email address for an SSO user.',\n",
       "    'operationId': 'send_sso_email_confirmation_api_v1_sso_email_verification_send_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SSOEmailVerificationSendRequest'}}},\n",
       "     'required': True},\n",
       "    'responses': {'202': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'object',\n",
       "         'title': 'Response Send Sso Email Confirmation Api V1 Sso Email Verification Send Post'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'Bearer Auth': []}]}},\n",
       "  '/api/v1/sso/email-verification/status': {'post': {'tags': ['auth'],\n",
       "    'summary': 'Check Sso Email Verification Status',\n",
       "    'description': 'Retrieve the email verification status of an SSO user.',\n",
       "    'operationId': 'check_sso_email_verification_status_api_v1_sso_email_verification_status_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SSOEmailVerificationStatusRequest'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SSOEmailVerificationStatusResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/sso/email-verification/confirm': {'post': {'tags': ['auth'],\n",
       "    'summary': 'Confirm Sso User Email',\n",
       "    'description': 'Confirm the email of an SSO user.',\n",
       "    'operationId': 'confirm_sso_user_email_api_v1_sso_email_verification_confirm_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SSOConfirmEmailRequest'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'object',\n",
       "         'title': 'Response Confirm Sso User Email Api V1 Sso Email Verification Confirm Post'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/sso/settings/{sso_login_slug}': {'get': {'tags': ['auth'],\n",
       "    'summary': 'Get Sso Settings',\n",
       "    'description': 'Get SSO provider settings from login slug.',\n",
       "    'operationId': 'get_sso_settings_api_v1_sso_settings__sso_login_slug__get',\n",
       "    'parameters': [{'name': 'sso_login_slug',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Sso Login Slug'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/SSOProviderSlim'},\n",
       "         'title': 'Response Get Sso Settings Api V1 Sso Settings  Sso Login Slug  Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/api-key': {'get': {'tags': ['api-key'],\n",
       "    'summary': 'Get Api Keys',\n",
       "    'description': \"Get the current tenant's API keys\",\n",
       "    'operationId': 'get_api_keys_api_v1_api_key_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/APIKeyGetResponse'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response Get Api Keys Api V1 Api Key Get'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]},\n",
       "   'post': {'tags': ['api-key'],\n",
       "    'summary': 'Generate Api Key',\n",
       "    'description': 'Generate an api key for the user',\n",
       "    'operationId': 'generate_api_key_api_v1_api_key_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/APIKeyCreateRequest',\n",
       "        'default': {'description': 'Default API key', 'read_only': False}}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/APIKeyCreateResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/api-key/{api_key_id}': {'delete': {'tags': ['api-key'],\n",
       "    'summary': 'Delete Api Key',\n",
       "    'description': 'Delete an api key for the user',\n",
       "    'operationId': 'delete_api_key_api_v1_api_key__api_key_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'api_key_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Api Key Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/APIKeyGetResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/api-key/current': {'get': {'tags': ['api-key'],\n",
       "    'summary': 'Get Personal Access Tokens',\n",
       "    'description': 'Get the current users PATs for this tenant',\n",
       "    'operationId': 'get_personal_access_tokens_api_v1_api_key_current_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/APIKeyGetResponse'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response Get Personal Access Tokens Api V1 Api Key Current Get'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]},\n",
       "   'post': {'tags': ['api-key'],\n",
       "    'summary': 'Generate Personal Access Token',\n",
       "    'description': 'Generate a Personal Access Token the user',\n",
       "    'operationId': 'generate_personal_access_token_api_v1_api_key_current_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/APIKeyCreateRequest',\n",
       "        'default': {'description': 'Default API key', 'read_only': False}}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/APIKeyCreateResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/api-key/current/{pat_id}': {'delete': {'tags': ['api-key'],\n",
       "    'summary': 'Delete Personal Access Token',\n",
       "    'description': 'Delete a Personal Access Token for the user',\n",
       "    'operationId': 'delete_personal_access_token_api_v1_api_key_current__pat_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'pat_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Pat Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/APIKeyGetResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/examples/count': {'get': {'tags': ['examples'],\n",
       "    'summary': 'Count Examples',\n",
       "    'description': 'Count all examples by query params',\n",
       "    'operationId': 'count_examples_api_v1_examples_count_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Id'}},\n",
       "     {'name': 'as_of',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'string'}],\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "       'default': 'latest',\n",
       "       'title': 'As Of'},\n",
       "      'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'},\n",
       "     {'name': 'metadata',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Metadata'}},\n",
       "     {'name': 'full_text_contains',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Full Text Contains'}},\n",
       "     {'name': 'splits',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Splits'}},\n",
       "     {'name': 'dataset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Dataset'}},\n",
       "     {'name': 'filter',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Filter'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'integer',\n",
       "         'title': 'Response Count Examples Api V1 Examples Count Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/examples/{example_id}': {'get': {'tags': ['examples'],\n",
       "    'summary': 'Read Example',\n",
       "    'description': 'Get a specific example.',\n",
       "    'operationId': 'read_example_api_v1_examples__example_id__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'example_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Example Id'}},\n",
       "     {'name': 'as_of',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'string'}],\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "       'default': 'latest',\n",
       "       'title': 'As Of'},\n",
       "      'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Example'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['examples'],\n",
       "    'summary': 'Update Example',\n",
       "    'description': 'Update a specific example.',\n",
       "    'operationId': 'update_example_api_v1_examples__example_id__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'example_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Example Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ExampleUpdate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['examples'],\n",
       "    'summary': 'Delete Example',\n",
       "    'description': 'Delete a specific example.',\n",
       "    'operationId': 'delete_example_api_v1_examples__example_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'example_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Example Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/examples': {'get': {'tags': ['examples'],\n",
       "    'summary': 'Read Examples',\n",
       "    'description': 'Get all examples by query params',\n",
       "    'operationId': 'read_examples_api_v1_examples_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Id'}},\n",
       "     {'name': 'as_of',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'string'}],\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "       'default': 'latest',\n",
       "       'title': 'As Of'},\n",
       "      'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'},\n",
       "     {'name': 'metadata',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Metadata'}},\n",
       "     {'name': 'full_text_contains',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Full Text Contains'}},\n",
       "     {'name': 'splits',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Splits'}},\n",
       "     {'name': 'dataset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Dataset'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 100,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'order',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'$ref': '#/components/schemas/ExampleListOrder',\n",
       "       'default': 'recent'}},\n",
       "     {'name': 'random_seed',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "       'title': 'Random Seed'}},\n",
       "     {'name': 'select',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'array',\n",
       "       'items': {'$ref': '#/components/schemas/ExampleSelect'},\n",
       "       'default': ['id',\n",
       "        'created_at',\n",
       "        'modified_at',\n",
       "        'name',\n",
       "        'dataset_id',\n",
       "        'source_run_id',\n",
       "        'metadata',\n",
       "        'inputs',\n",
       "        'outputs'],\n",
       "       'title': 'Select'}},\n",
       "     {'name': 'filter',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Filter'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/Example'},\n",
       "         'title': 'Response Read Examples Api V1 Examples Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['examples'],\n",
       "    'summary': 'Create Example',\n",
       "    'description': 'Create a new example.',\n",
       "    'operationId': 'create_example_api_v1_examples_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Example'}}}}}},\n",
       "   'delete': {'tags': ['examples'],\n",
       "    'summary': 'Delete Examples',\n",
       "    'description': 'Delete a specific set of examples.',\n",
       "    'operationId': 'delete_examples_api_v1_examples_delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'example_ids',\n",
       "      'in': 'query',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'array',\n",
       "       'items': {'type': 'string', 'format': 'uuid'},\n",
       "       'title': 'Example Ids'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/examples/bulk': {'post': {'tags': ['examples'],\n",
       "    'summary': 'Create Examples',\n",
       "    'description': 'Create a new example.',\n",
       "    'operationId': 'create_examples_api_v1_examples_bulk_post',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]},\n",
       "   'patch': {'tags': ['examples'],\n",
       "    'summary': 'Legacy Update Examples',\n",
       "    'description': 'Legacy update examples in bulk. For update involving attachments, use PATCH /v1/platform/datasets/{dataset_id}/examples instead.',\n",
       "    'operationId': 'legacy_update_examples_api_v1_examples_bulk_patch',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/ExampleUpdateWithID'},\n",
       "        'type': 'array',\n",
       "        'title': 'Example Updates'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/examples/upload/{dataset_id}': {'post': {'tags': ['examples'],\n",
       "    'summary': 'Upload Examples From Csv',\n",
       "    'description': 'Upload examples from a CSV file.\\n\\nNote: For non-csv upload, please use\\nthe POST /v1/platform/datasets/{dataset_id}/examples endpoint which provides more efficient upload.',\n",
       "    'operationId': 'upload_examples_from_csv_api_v1_examples_upload__dataset_id__post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'multipart/form-data': {'schema': {'$ref': '#/components/schemas/Body_upload_examples_from_csv_api_v1_examples_upload__dataset_id__post'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/Example'},\n",
       "         'title': 'Response Upload Examples From Csv Api V1 Examples Upload  Dataset Id  Post'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/examples/validate': {'post': {'tags': ['examples'],\n",
       "    'summary': 'Validate Example',\n",
       "    'description': 'Validate an example.',\n",
       "    'operationId': 'validate_example_api_v1_examples_validate_post',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ExampleValidationResult'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/examples/validate/bulk': {'post': {'tags': ['examples'],\n",
       "    'summary': 'Validate Examples',\n",
       "    'description': 'Validate an example.',\n",
       "    'operationId': 'validate_examples_api_v1_examples_validate_bulk_post',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/ExampleValidationResult'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response Validate Examples Api V1 Examples Validate Bulk Post'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/datasets/{dataset_id}': {'get': {'tags': ['datasets'],\n",
       "    'summary': 'Read Dataset',\n",
       "    'description': 'Get a specific dataset.',\n",
       "    'operationId': 'read_dataset_api_v1_datasets__dataset_id__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Dataset'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['datasets'],\n",
       "    'summary': 'Delete Dataset',\n",
       "    'description': 'Delete a specific dataset.',\n",
       "    'operationId': 'delete_dataset_api_v1_datasets__dataset_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['datasets'],\n",
       "    'summary': 'Update Dataset',\n",
       "    'description': 'Update a specific dataset.',\n",
       "    'operationId': 'update_dataset_api_v1_datasets__dataset_id__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetUpdate'}}}},\n",
       "    'responses': {'200': {'description': 'Dataset updated successfully',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetSchemaForUpdate'}}},\n",
       "      'headers': {'X-Updated-Examples-Count': {'description': 'Number of examples updated',\n",
       "        'schema': {'type': 'integer'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets': {'get': {'tags': ['datasets'],\n",
       "    'summary': 'Read Datasets',\n",
       "    'description': 'Get all datasets by query params and owner.',\n",
       "    'operationId': 'read_datasets_api_v1_datasets_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Id'}},\n",
       "     {'name': 'data_type',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/DataType'}},\n",
       "        {'$ref': '#/components/schemas/DataType'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Data Type'}},\n",
       "     {'name': 'name',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Name'}},\n",
       "     {'name': 'name_contains',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Name Contains'}},\n",
       "     {'name': 'metadata',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Metadata'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 100,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'sort_by',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'$ref': '#/components/schemas/SortByDatasetColumn',\n",
       "       'default': 'last_session_start_time'}},\n",
       "     {'name': 'sort_by_desc',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean', 'default': True, 'title': 'Sort By Desc'}},\n",
       "     {'name': 'tag_value_id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Tag Value Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/Dataset'},\n",
       "         'title': 'Response Read Datasets Api V1 Datasets Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['datasets'],\n",
       "    'summary': 'Create Dataset',\n",
       "    'description': 'Create a new dataset.',\n",
       "    'operationId': 'create_dataset_api_v1_datasets_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetCreate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Dataset'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/upload': {'post': {'tags': ['datasets'],\n",
       "    'summary': 'Upload Csv Dataset',\n",
       "    'description': 'Create a new dataset from a CSV file.',\n",
       "    'operationId': 'upload_csv_dataset_api_v1_datasets_upload_post',\n",
       "    'requestBody': {'content': {'multipart/form-data': {'schema': {'$ref': '#/components/schemas/Body_upload_csv_dataset_api_v1_datasets_upload_post'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Dataset'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/datasets/upload-experiment': {'post': {'tags': ['datasets'],\n",
       "    'summary': 'Upload Experiment',\n",
       "    'description': 'Upload an experiment that has already been run.',\n",
       "    'operationId': 'upload_experiment_api_v1_datasets_upload_experiment_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ExperimentResultsUpload'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ExperimentResultsUploadResult'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/datasets/{dataset_id}/versions': {'get': {'tags': ['datasets'],\n",
       "    'summary': 'Get Dataset Versions',\n",
       "    'description': 'Get dataset versions.',\n",
       "    'operationId': 'get_dataset_versions_api_v1_datasets__dataset_id__versions_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "     {'name': 'search',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Search'}},\n",
       "     {'name': 'example',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Example'}},\n",
       "     {'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 100,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/DatasetVersion'},\n",
       "         'title': 'Response Get Dataset Versions Api V1 Datasets  Dataset Id  Versions Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/{dataset_id}/versions/diff': {'get': {'tags': ['datasets'],\n",
       "    'summary': 'Diff Dataset Versions',\n",
       "    'description': 'Get diff between two dataset versions.',\n",
       "    'operationId': 'diff_dataset_versions_api_v1_datasets__dataset_id__versions_diff_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "     {'name': 'from_version',\n",
       "      'in': 'query',\n",
       "      'required': True,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'string'}],\n",
       "       'title': 'From Version'}},\n",
       "     {'name': 'to_version',\n",
       "      'in': 'query',\n",
       "      'required': True,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'string'}],\n",
       "       'title': 'To Version'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetDiffInfo'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/{dataset_id}/version': {'get': {'tags': ['datasets'],\n",
       "    'summary': 'Get Dataset Version',\n",
       "    'description': 'Get dataset version by as_of or exact tag.',\n",
       "    'operationId': 'get_dataset_version_api_v1_datasets__dataset_id__version_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "     {'name': 'as_of',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'As Of'}},\n",
       "     {'name': 'tag',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Tag'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetVersion'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/{dataset_id}/tags': {'put': {'tags': ['datasets'],\n",
       "    'summary': 'Update Dataset Version',\n",
       "    'description': 'Set a tag on a dataset version.',\n",
       "    'operationId': 'update_dataset_version_api_v1_datasets__dataset_id__tags_put',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PutDatasetVersionsSchema'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetVersion'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/{dataset_id}/openai': {'get': {'tags': ['datasets'],\n",
       "    'summary': 'Download Dataset Openai',\n",
       "    'description': 'Download a dataset as OpenAI Evals Jsonl format.',\n",
       "    'operationId': 'download_dataset_openai_api_v1_datasets__dataset_id__openai_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "     {'name': 'as_of',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "       'title': 'As Of'},\n",
       "      'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/{dataset_id}/openai_ft': {'get': {'tags': ['datasets'],\n",
       "    'summary': 'Download Dataset Openai Ft',\n",
       "    'description': 'Download a dataset as OpenAI Jsonl format.',\n",
       "    'operationId': 'download_dataset_openai_ft_api_v1_datasets__dataset_id__openai_ft_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "     {'name': 'as_of',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "       'title': 'As Of'},\n",
       "      'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/{dataset_id}/csv': {'get': {'tags': ['datasets'],\n",
       "    'summary': 'Download Dataset Csv',\n",
       "    'description': 'Download a dataset as CSV format.',\n",
       "    'operationId': 'download_dataset_csv_api_v1_datasets__dataset_id__csv_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "     {'name': 'as_of',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "       'title': 'As Of'},\n",
       "      'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/{dataset_id}/jsonl': {'get': {'tags': ['datasets'],\n",
       "    'summary': 'Download Dataset Jsonl',\n",
       "    'description': 'Download a dataset as CSV format.',\n",
       "    'operationId': 'download_dataset_jsonl_api_v1_datasets__dataset_id__jsonl_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "     {'name': 'as_of',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "       'title': 'As Of'},\n",
       "      'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/{dataset_id}/runs': {'post': {'tags': ['datasets'],\n",
       "    'summary': 'Read Examples With Runs',\n",
       "    'description': 'Fetch examples for a dataset, and fetch the runs for each example if they are associated with the given session_ids.',\n",
       "    'operationId': 'read_examples_with_runs_api_v1_datasets__dataset_id__runs_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "     {'name': 'format',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'description': \"Response format, e.g., 'csv'\",\n",
       "       'title': 'Format'},\n",
       "      'description': \"Response format, e.g., 'csv'\"}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/QueryExampleSchemaWithRuns'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'anyOf': [{'type': 'array',\n",
       "           'items': {'$ref': '#/components/schemas/ExampleWithRuns'}},\n",
       "          {'type': 'array',\n",
       "           'items': {'$ref': '#/components/schemas/ExampleWithRunsCH'}},\n",
       "          {'type': 'null'}],\n",
       "         'title': 'Response Read Examples With Runs Api V1 Datasets  Dataset Id  Runs Post'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/{dataset_id}/group/runs': {'post': {'tags': ['datasets'],\n",
       "    'summary': 'Read Examples With Runs Grouped',\n",
       "    'description': 'Fetch examples for a dataset, and fetch the runs for each example if they are associated with the given session_ids.',\n",
       "    'operationId': 'read_examples_with_runs_grouped_api_v1_datasets__dataset_id__group_runs_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/QueryGroupedExamplesWithRuns'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/GroupedExamplesWithRunsResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/{dataset_id}/runs/delta': {'post': {'tags': ['datasets'],\n",
       "    'summary': 'Read Delta',\n",
       "    'description': 'Fetch the number of regressions/improvements for each example in a dataset, between sessions[0] and sessions[1].',\n",
       "    'operationId': 'read_delta_api_v1_datasets__dataset_id__runs_delta_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/QueryFeedbackDelta'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SessionFeedbackDelta'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/{dataset_id}/share': {'get': {'tags': ['datasets'],\n",
       "    'summary': 'Read Dataset Share State',\n",
       "    'description': 'Get the state of sharing a dataset',\n",
       "    'operationId': 'read_dataset_share_state_api_v1_datasets__dataset_id__share_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'anyOf': [{'$ref': '#/components/schemas/DatasetShareSchema'},\n",
       "          {'type': 'null'}],\n",
       "         'title': 'Response Read Dataset Share State Api V1 Datasets  Dataset Id  Share Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'put': {'tags': ['datasets'],\n",
       "    'summary': 'Share Dataset',\n",
       "    'description': 'Share a dataset.',\n",
       "    'operationId': 'share_dataset_api_v1_datasets__dataset_id__share_put',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "     {'name': 'share_projects',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': False,\n",
       "       'title': 'Share Projects'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetShareSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['datasets'],\n",
       "    'summary': 'Unshare Dataset',\n",
       "    'description': 'Unshare a dataset.',\n",
       "    'operationId': 'unshare_dataset_api_v1_datasets__dataset_id__share_delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/{dataset_id}/comparative': {'get': {'tags': ['datasets'],\n",
       "    'summary': 'Read Comparative Experiments',\n",
       "    'description': 'Get all comparative experiments for a given dataset.',\n",
       "    'operationId': 'read_comparative_experiments_api_v1_datasets__dataset_id__comparative_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "     {'name': 'name',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Name'}},\n",
       "     {'name': 'name_contains',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Name Contains'}},\n",
       "     {'name': 'id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Id'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 100,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'sort_by',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'$ref': '#/components/schemas/SortByComparativeExperimentColumn',\n",
       "       'default': 'created_at'}},\n",
       "     {'name': 'sort_by_desc',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': True,\n",
       "       'title': 'Sort By Desc'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/ComparativeExperiment'},\n",
       "         'title': 'Response Read Comparative Experiments Api V1 Datasets  Dataset Id  Comparative Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/comparative': {'post': {'tags': ['datasets'],\n",
       "    'summary': 'Create Comparative Experiment',\n",
       "    'description': 'Create a comparative experiment.',\n",
       "    'operationId': 'create_comparative_experiment_api_v1_datasets_comparative_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ComparativeExperimentCreate'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ComparativeExperimentBase'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/datasets/comparative/{comparative_experiment_id}': {'delete': {'tags': ['datasets'],\n",
       "    'summary': 'Delete Comparative Experiment',\n",
       "    'description': 'Delete a specific comparative experiment.',\n",
       "    'operationId': 'delete_comparative_experiment_api_v1_datasets_comparative__comparative_experiment_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'comparative_experiment_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Comparative Experiment Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/clone': {'post': {'tags': ['datasets'],\n",
       "    'summary': 'Clone Dataset',\n",
       "    'description': 'Clone a dataset.',\n",
       "    'operationId': 'clone_dataset_api_v1_datasets_clone_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Body_clone_dataset_api_v1_datasets_clone_post'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/Example'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response Clone Dataset Api V1 Datasets Clone Post'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/datasets/{dataset_id}/splits': {'get': {'tags': ['datasets'],\n",
       "    'summary': 'Get Dataset Splits',\n",
       "    'operationId': 'get_dataset_splits_api_v1_datasets__dataset_id__splits_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "     {'name': 'as_of',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'string'}],\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "       'default': 'latest',\n",
       "       'title': 'As Of'},\n",
       "      'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'type': 'string'},\n",
       "         'title': 'Response Get Dataset Splits Api V1 Datasets  Dataset Id  Splits Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'put': {'tags': ['datasets'],\n",
       "    'summary': 'Update Dataset Splits',\n",
       "    'operationId': 'update_dataset_splits_api_v1_datasets__dataset_id__splits_put',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Body_update_dataset_splits_api_v1_datasets__dataset_id__splits_put'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'},\n",
       "         'title': 'Response Update Dataset Splits Api V1 Datasets  Dataset Id  Splits Put'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/{dataset_id}/index': {'post': {'tags': ['datasets'],\n",
       "    'summary': 'Index',\n",
       "    'description': 'Index a dataset.',\n",
       "    'operationId': 'index_api_v1_datasets__dataset_id__index_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetIndexRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['datasets'],\n",
       "    'summary': 'Remove Index',\n",
       "    'description': 'Remove an index for a dataset.',\n",
       "    'operationId': 'remove_index_api_v1_datasets__dataset_id__index_delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'get': {'tags': ['datasets'],\n",
       "    'summary': 'Get Index Info',\n",
       "    'description': 'Get index info.',\n",
       "    'operationId': 'get_index_info_api_v1_datasets__dataset_id__index_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetIndexInfo'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/{dataset_id}/index/sync': {'post': {'tags': ['datasets'],\n",
       "    'summary': 'Sync Index',\n",
       "    'description': 'Sync an index for a dataset.',\n",
       "    'operationId': 'sync_index_api_v1_datasets__dataset_id__index_sync_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/{dataset_id}/search': {'post': {'tags': ['datasets'],\n",
       "    'summary': 'Search',\n",
       "    'description': 'Search a dataset.',\n",
       "    'operationId': 'search_api_v1_datasets__dataset_id__search_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SearchDatasetRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SearchDatasetResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/{dataset_id}/generate': {'post': {'tags': ['datasets'],\n",
       "    'summary': 'Generate',\n",
       "    'description': 'Generate synthetic examples for a dataset.',\n",
       "    'operationId': 'generate_api_v1_datasets__dataset_id__generate_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/GenerateSyntheticExamplesBody'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/datasets/playground_experiment/batch': {'post': {'tags': ['datasets'],\n",
       "    'summary': 'Dataset Handler',\n",
       "    'operationId': 'dataset_handler_api_v1_datasets_playground_experiment_batch_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PlaygroundRunOverDatasetRequestSchema'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'title': 'Response Dataset Handler Api V1 Datasets Playground Experiment Batch Post'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/datasets/playground_experiment/stream': {'post': {'tags': ['datasets'],\n",
       "    'summary': 'Stream Dataset Handler',\n",
       "    'operationId': 'stream_dataset_handler_api_v1_datasets_playground_experiment_stream_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PlaygroundRunOverDatasetRequestSchema'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/datasets/studio_experiment': {'post': {'tags': ['datasets'],\n",
       "    'summary': 'Studio Experiment',\n",
       "    'operationId': 'studio_experiment_api_v1_datasets_studio_experiment_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StudioRunOverDatasetRequestSchema'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'title': 'Response Studio Experiment Api V1 Datasets Studio Experiment Post'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/runs/rules': {'get': {'tags': ['run'],\n",
       "    'summary': 'List Rules',\n",
       "    'description': 'List all run rules.',\n",
       "    'operationId': 'list_rules_api_v1_runs_rules_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'dataset_id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Dataset Id'}},\n",
       "     {'name': 'session_id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Session Id'}},\n",
       "     {'name': 'type',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'enum': ['session', 'dataset'], 'type': 'string'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Type'}},\n",
       "     {'name': 'name_contains',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Name Contains'}},\n",
       "     {'name': 'id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/RunRulesSchema'},\n",
       "         'title': 'Response List Rules Api V1 Runs Rules Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['run'],\n",
       "    'summary': 'Create Rule',\n",
       "    'description': 'Create a new run rule.',\n",
       "    'operationId': 'create_rule_api_v1_runs_rules_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunRulesCreateSchema'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunRulesSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/runs/rules/{rule_id}': {'patch': {'tags': ['run'],\n",
       "    'summary': 'Update Rule',\n",
       "    'description': 'Update a run rule.',\n",
       "    'operationId': 'update_rule_api_v1_runs_rules__rule_id__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'rule_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Rule Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunRulesCreateSchema'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunRulesSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['run'],\n",
       "    'summary': 'Delete Rule',\n",
       "    'description': 'Delete a run rule.',\n",
       "    'operationId': 'delete_rule_api_v1_runs_rules__rule_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'rule_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Rule Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/runs/rules/{rule_id}/logs': {'get': {'tags': ['run'],\n",
       "    'summary': 'List Rule Logs',\n",
       "    'description': 'List logs for a particular rule',\n",
       "    'operationId': 'list_rule_logs_api_v1_runs_rules__rule_id__logs_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'rule_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Rule Id'}},\n",
       "     {'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 1440,\n",
       "       'minimum': 100,\n",
       "       'default': 720,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'start_time',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Start Time'}},\n",
       "     {'name': 'end_time',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'End Time'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/RuleLogSchema'},\n",
       "         'title': 'Response List Rule Logs Api V1 Runs Rules  Rule Id  Logs Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/runs/rules/{rule_id}/last_applied': {'get': {'tags': ['run'],\n",
       "    'summary': 'Get Last Applied Rule',\n",
       "    'description': 'Get the last applied rule.',\n",
       "    'operationId': 'get_last_applied_rule_api_v1_runs_rules__rule_id__last_applied_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'rule_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Rule Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RuleLogSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/runs/rules/{rule_id}/trigger': {'post': {'tags': ['run'],\n",
       "    'summary': 'Trigger Rule',\n",
       "    'description': 'Trigger a run rule manually.',\n",
       "    'operationId': 'trigger_rule_api_v1_runs_rules__rule_id__trigger_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'rule_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Rule Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunRulesSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/runs/rules/trigger': {'post': {'tags': ['run'],\n",
       "    'summary': 'Trigger Rules',\n",
       "    'description': 'Trigger an array of run rules manually.',\n",
       "    'operationId': 'trigger_rules_api_v1_runs_rules_trigger_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TriggerRulesRequest'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/runs/{run_id}': {'get': {'tags': ['run'],\n",
       "    'summary': 'Read Run',\n",
       "    'description': 'Get a specific run.',\n",
       "    'operationId': 'read_run_api_v1_runs__run_id__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'run_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}},\n",
       "     {'name': 'session_id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Session Id'}},\n",
       "     {'name': 'start_time',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Start Time'}},\n",
       "     {'name': 'exclude_s3_stored_attributes',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': False,\n",
       "       'title': 'Exclude S3 Stored Attributes'}},\n",
       "     {'name': 'exclude_serialized',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': False,\n",
       "       'title': 'Exclude Serialized'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['run'],\n",
       "    'summary': 'Update Run',\n",
       "    'description': 'Update a run.',\n",
       "    'operationId': 'update_run_api_v1_runs__run_id__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'run_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/runs/{run_id}/share': {'get': {'tags': ['run'],\n",
       "    'summary': 'Read Run Share State',\n",
       "    'description': 'Get the state of sharing of a run.',\n",
       "    'operationId': 'read_run_share_state_api_v1_runs__run_id__share_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'run_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'anyOf': [{'$ref': '#/components/schemas/RunShareSchema'},\n",
       "          {'type': 'null'}],\n",
       "         'title': 'Response Read Run Share State Api V1 Runs  Run Id  Share Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'put': {'tags': ['run'],\n",
       "    'summary': 'Share Run',\n",
       "    'description': 'Share a run.',\n",
       "    'operationId': 'share_run_api_v1_runs__run_id__share_put',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'run_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunShareSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['run'],\n",
       "    'summary': 'Unshare Run',\n",
       "    'description': 'Unshare a run.',\n",
       "    'operationId': 'unshare_run_api_v1_runs__run_id__share_delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'run_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/runs/query': {'post': {'tags': ['run'],\n",
       "    'summary': 'Query Runs',\n",
       "    'operationId': 'query_runs_api_v1_runs_query_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BodyParamsForRunSchema'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ListRunsResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/runs/generate-query': {'post': {'tags': ['run'],\n",
       "    'summary': 'Generate Query For Runs',\n",
       "    'description': 'Get runs filter expression query for a given natural language query.',\n",
       "    'operationId': 'generate_query_for_runs_api_v1_runs_generate_query_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RequestBodyForRunsGenerateQuery'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ResponseBodyForRunsGenerateQuery'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/runs/stats': {'post': {'tags': ['run'],\n",
       "    'summary': 'Stats Runs',\n",
       "    'description': 'Get all runs by query in body payload.',\n",
       "    'operationId': 'stats_runs_api_v1_runs_stats_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunStatsQueryParams'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'anyOf': [{'$ref': '#/components/schemas/RunStats'},\n",
       "          {'additionalProperties': {'$ref': '#/components/schemas/RunStats'},\n",
       "           'type': 'object'}],\n",
       "         'title': 'Response Stats Runs Api V1 Runs Stats Post'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/runs/group': {'post': {'tags': ['run'],\n",
       "    'summary': 'Group Runs',\n",
       "    'description': 'Get runs grouped by an expression',\n",
       "    'operationId': 'group_runs_api_v1_runs_group_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'accept',\n",
       "      'in': 'header',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Accept'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunGroupRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/runs/group/stats': {'post': {'tags': ['run'],\n",
       "    'summary': 'Stats Group Runs',\n",
       "    'description': 'Get stats for the grouped runs.',\n",
       "    'operationId': 'stats_group_runs_api_v1_runs_group_stats_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunGroupRequest'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunGroupStats'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/runs/delete': {'post': {'tags': ['run'],\n",
       "    'summary': 'Delete Runs',\n",
       "    'description': 'Delete specific runs.',\n",
       "    'operationId': 'delete_runs_api_v1_runs_delete_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Body_delete_runs_api_v1_runs_delete_post'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/feedback/{feedback_id}': {'get': {'tags': ['feedback'],\n",
       "    'summary': 'Read Feedback',\n",
       "    'description': 'Get a specific feedback.',\n",
       "    'operationId': 'read_feedback_api_v1_feedback__feedback_id__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'feedback_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Feedback Id'}},\n",
       "     {'name': 'include_user_names',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "       'title': 'Include User Names'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['feedback'],\n",
       "    'summary': 'Update Feedback',\n",
       "    'description': 'Replace an existing feedback entry with a new, modified entry.',\n",
       "    'operationId': 'update_feedback_api_v1_feedback__feedback_id__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'feedback_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Feedback Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackUpdateSchema'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['feedback'],\n",
       "    'summary': 'Delete Feedback',\n",
       "    'description': 'Delete a feedback.',\n",
       "    'operationId': 'delete_feedback_api_v1_feedback__feedback_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'feedback_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Feedback Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/feedback': {'get': {'tags': ['feedback'],\n",
       "    'summary': 'Read Feedbacks',\n",
       "    'description': 'List all Feedback by query params.',\n",
       "    'operationId': 'read_feedbacks_api_v1_feedback_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'run',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Run'}},\n",
       "     {'name': 'key',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Key'}},\n",
       "     {'name': 'session',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Session'}},\n",
       "     {'name': 'source',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/SourceType'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Source'}},\n",
       "     {'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 100,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'user',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'User'}},\n",
       "     {'name': 'has_comment',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "       'title': 'Has Comment'}},\n",
       "     {'name': 'has_score',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "       'title': 'Has Score'}},\n",
       "     {'name': 'level',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'$ref': '#/components/schemas/FeedbackLevel'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Level'}},\n",
       "     {'name': 'max_created_at',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Max Created At'}},\n",
       "     {'name': 'min_created_at',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Min Created At'}},\n",
       "     {'name': 'include_user_names',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "       'title': 'Include User Names'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/FeedbackSchema'},\n",
       "         'title': 'Response Read Feedbacks Api V1 Feedback Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['feedback'],\n",
       "    'summary': 'Create Feedback',\n",
       "    'description': 'Create a new feedback.',\n",
       "    'operationId': 'create_feedback_api_v1_feedback_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackCreateSchema'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/feedback/eager': {'post': {'tags': ['feedback'],\n",
       "    'summary': 'Eagerly Create Feedback',\n",
       "    'description': 'Create a new feedback.\\n\\nThis method is invoked under the assumption that the run\\nis already visible in the app, thus already present in DB',\n",
       "    'operationId': 'eagerly_create_feedback_api_v1_feedback_eager_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackCreateSchema'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/feedback/tokens': {'post': {'tags': ['feedback'],\n",
       "    'summary': 'Create Feedback Ingest Token',\n",
       "    'description': 'Create a new feedback ingest token.',\n",
       "    'operationId': 'create_feedback_ingest_token_api_v1_feedback_tokens_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'anyOf': [{'$ref': '#/components/schemas/FeedbackIngestTokenCreateSchema'},\n",
       "         {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/FeedbackIngestTokenCreateSchema'}}],\n",
       "        'title': 'Feedback Ingest Token'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'anyOf': [{'$ref': '#/components/schemas/FeedbackIngestTokenSchema'},\n",
       "          {'type': 'array',\n",
       "           'items': {'$ref': '#/components/schemas/FeedbackIngestTokenSchema'}}],\n",
       "         'title': 'Response Create Feedback Ingest Token Api V1 Feedback Tokens Post'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'get': {'tags': ['feedback'],\n",
       "    'summary': 'List Feedback Ingest Tokens',\n",
       "    'description': 'List all feedback ingest tokens for a run.',\n",
       "    'operationId': 'list_feedback_ingest_tokens_api_v1_feedback_tokens_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'run_id',\n",
       "      'in': 'query',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/FeedbackIngestTokenSchema'},\n",
       "         'title': 'Response List Feedback Ingest Tokens Api V1 Feedback Tokens Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/feedback/tokens/{token}': {'get': {'tags': ['feedback'],\n",
       "    'summary': 'Create Feedback With Token Get',\n",
       "    'description': 'Create a new feedback with a token.',\n",
       "    'operationId': 'create_feedback_with_token_get_api_v1_feedback_tokens__token__get',\n",
       "    'parameters': [{'name': 'token',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Token'}},\n",
       "     {'name': 'score',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'number'},\n",
       "        {'type': 'integer'},\n",
       "        {'type': 'boolean'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Score'}},\n",
       "     {'name': 'value',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'number'},\n",
       "        {'type': 'integer'},\n",
       "        {'type': 'boolean'},\n",
       "        {'type': 'string'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Value'}},\n",
       "     {'name': 'comment',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Comment'}},\n",
       "     {'name': 'correction',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Correction'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['feedback'],\n",
       "    'summary': 'Create Feedback With Token Post',\n",
       "    'description': 'Create a new feedback with a token.',\n",
       "    'operationId': 'create_feedback_with_token_post_api_v1_feedback_tokens__token__post',\n",
       "    'parameters': [{'name': 'token',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Token'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackCreateWithTokenExtendedSchema'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/public/{share_token}/run': {'get': {'tags': ['public'],\n",
       "    'summary': 'Get Shared Run',\n",
       "    'description': 'Get the shared run.',\n",
       "    'operationId': 'get_shared_run_api_v1_public__share_token__run_get',\n",
       "    'parameters': [{'name': 'share_token',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "     {'name': 'exclude_s3_stored_attributes',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': False,\n",
       "       'title': 'Exclude S3 Stored Attributes'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunPublicSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/public/{share_token}/run/{id}': {'get': {'tags': ['public'],\n",
       "    'summary': 'Get Shared Run By Id',\n",
       "    'description': 'Get the shared run.',\n",
       "    'operationId': 'get_shared_run_by_id_api_v1_public__share_token__run__id__get',\n",
       "    'parameters': [{'name': 'id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Id'}},\n",
       "     {'name': 'share_token',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "     {'name': 'exclude_s3_stored_attributes',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': False,\n",
       "       'title': 'Exclude S3 Stored Attributes'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunPublicSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/public/{share_token}/runs/query': {'post': {'tags': ['public'],\n",
       "    'summary': 'Query Shared Runs',\n",
       "    'description': 'Get run by ids or the shared run if not specifed.',\n",
       "    'operationId': 'query_shared_runs_api_v1_public__share_token__runs_query_post',\n",
       "    'parameters': [{'name': 'share_token',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/QueryParamsForPublicRunSchema'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ListPublicRunsResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/public/{share_token}/feedbacks': {'get': {'tags': ['public'],\n",
       "    'summary': 'Read Shared Feedbacks',\n",
       "    'operationId': 'read_shared_feedbacks_api_v1_public__share_token__feedbacks_get',\n",
       "    'parameters': [{'name': 'share_token',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "     {'name': 'run',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Run'}},\n",
       "     {'name': 'key',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Key'}},\n",
       "     {'name': 'session',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Session'}},\n",
       "     {'name': 'source',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/SourceType'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Source'}},\n",
       "     {'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 100,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'user',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'User'}},\n",
       "     {'name': 'has_comment',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "       'title': 'Has Comment'}},\n",
       "     {'name': 'has_score',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "       'title': 'Has Score'}},\n",
       "     {'name': 'level',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'$ref': '#/components/schemas/FeedbackLevel'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Level'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/FeedbackSchema'},\n",
       "         'title': 'Response Read Shared Feedbacks Api V1 Public  Share Token  Feedbacks Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/public/{share_token}/datasets': {'get': {'tags': ['public'],\n",
       "    'summary': 'Read Shared Dataset',\n",
       "    'description': 'Get dataset by ids or the shared dataset if not specifed.',\n",
       "    'operationId': 'read_shared_dataset_api_v1_public__share_token__datasets_get',\n",
       "    'parameters': [{'name': 'share_token',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 100,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'sort_by',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'$ref': '#/components/schemas/SortByDatasetColumn',\n",
       "       'default': 'last_session_start_time'}},\n",
       "     {'name': 'sort_by_desc',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': True,\n",
       "       'title': 'Sort By Desc'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetPublicSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/public/{share_token}/examples/count': {'get': {'tags': ['public'],\n",
       "    'summary': 'Count Shared Examples',\n",
       "    'description': 'Count all examples by query params',\n",
       "    'operationId': 'count_shared_examples_api_v1_public__share_token__examples_count_get',\n",
       "    'parameters': [{'name': 'share_token',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "     {'name': 'id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Id'}},\n",
       "     {'name': 'as_of',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'string'}],\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "       'default': 'latest',\n",
       "       'title': 'As Of'},\n",
       "      'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'},\n",
       "     {'name': 'metadata',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Metadata'}},\n",
       "     {'name': 'filter',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Filter'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'integer',\n",
       "         'title': 'Response Count Shared Examples Api V1 Public  Share Token  Examples Count Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/public/{share_token}/examples': {'get': {'tags': ['public'],\n",
       "    'summary': 'Read Shared Examples',\n",
       "    'description': 'Get example by ids or the shared example if not specifed.',\n",
       "    'operationId': 'read_shared_examples_api_v1_public__share_token__examples_get',\n",
       "    'parameters': [{'name': 'share_token',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "     {'name': 'id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Id'}},\n",
       "     {'name': 'as_of',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'string'}],\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "       'default': 'latest',\n",
       "       'title': 'As Of'},\n",
       "      'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'},\n",
       "     {'name': 'metadata',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Metadata'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 100,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'select',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'array',\n",
       "       'items': {'$ref': '#/components/schemas/ExampleSelect'},\n",
       "       'default': ['id',\n",
       "        'created_at',\n",
       "        'modified_at',\n",
       "        'name',\n",
       "        'dataset_id',\n",
       "        'metadata',\n",
       "        'inputs',\n",
       "        'outputs',\n",
       "        'attachment_urls'],\n",
       "       'title': 'Select'}},\n",
       "     {'name': 'filter',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Filter'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/Example'},\n",
       "         'title': 'Response Read Shared Examples Api V1 Public  Share Token  Examples Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/public/{share_token}/datasets/sessions': {'get': {'tags': ['public'],\n",
       "    'summary': 'Read Shared Dataset Tracer Sessions',\n",
       "    'description': 'Get projects run on a dataset that has been shared.',\n",
       "    'operationId': 'read_shared_dataset_tracer_sessions_api_v1_public__share_token__datasets_sessions_get',\n",
       "    'parameters': [{'name': 'share_token',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "     {'name': 'id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Id'}},\n",
       "     {'name': 'name',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Name'}},\n",
       "     {'name': 'name_contains',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Name Contains'}},\n",
       "     {'name': 'dataset_version',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Dataset Version'}},\n",
       "     {'name': 'sort_by',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'$ref': '#/components/schemas/SessionSortableColumns',\n",
       "       'default': 'start_time'}},\n",
       "     {'name': 'sort_by_desc',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean', 'default': True, 'title': 'Sort By Desc'}},\n",
       "     {'name': 'sort_by_feedback_key',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Sort By Feedback Key'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 100,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'facets',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean', 'default': False, 'title': 'Facets'}},\n",
       "     {'name': 'accept',\n",
       "      'in': 'header',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Accept'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/TracerSession'},\n",
       "         'title': 'Response Read Shared Dataset Tracer Sessions Api V1 Public  Share Token  Datasets Sessions Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/public/datasets/sessions-bulk': {'get': {'tags': ['public'],\n",
       "    'summary': 'Read Shared Dataset Tracer Sessions Bulk',\n",
       "    'description': 'Get sessions from multiple datasets using share tokens.',\n",
       "    'operationId': 'read_shared_dataset_tracer_sessions_bulk_api_v1_public_datasets_sessions_bulk_get',\n",
       "    'parameters': [{'name': 'share_tokens',\n",
       "      'in': 'query',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'array',\n",
       "       'items': {'type': 'string'},\n",
       "       'title': 'Share Tokens'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/TracerSession'},\n",
       "         'title': 'Response Read Shared Dataset Tracer Sessions Bulk Api V1 Public Datasets Sessions Bulk Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/public/{share_token}/examples/runs': {'post': {'tags': ['public'],\n",
       "    'summary': 'Read Shared Dataset Examples With Runs',\n",
       "    'description': 'Get examples with associated runs from sessions in a dataset that has been shared.',\n",
       "    'operationId': 'read_shared_dataset_examples_with_runs_api_v1_public__share_token__examples_runs_post',\n",
       "    'parameters': [{'name': 'share_token',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/QueryExampleSchemaWithRuns'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'anyOf': [{'type': 'array',\n",
       "           'items': {'$ref': '#/components/schemas/PublicExampleWithRuns'}},\n",
       "          {'type': 'array',\n",
       "           'items': {'$ref': '#/components/schemas/ExampleWithRunsCH'}}],\n",
       "         'title': 'Response Read Shared Dataset Examples With Runs Api V1 Public  Share Token  Examples Runs Post'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/public/{share_token}/datasets/runs/delta': {'post': {'tags': ['public'],\n",
       "    'summary': 'Read Shared Delta',\n",
       "    'description': 'Fetch the number of regressions/improvements for each example in a dataset, between sessions[0] and sessions[1].',\n",
       "    'operationId': 'read_shared_delta_api_v1_public__share_token__datasets_runs_delta_post',\n",
       "    'parameters': [{'name': 'share_token',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/QueryFeedbackDelta'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SessionFeedbackDelta'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/public/{share_token}/datasets/runs/query': {'post': {'tags': ['public'],\n",
       "    'summary': 'Query Shared Dataset Runs',\n",
       "    'description': 'Get runs in projects run over a dataset that has been shared.',\n",
       "    'operationId': 'query_shared_dataset_runs_api_v1_public__share_token__datasets_runs_query_post',\n",
       "    'parameters': [{'name': 'share_token',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BodyParamsForRunSchema'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ListPublicDatasetRunsResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/public/{share_token}/datasets/runs/generate-query': {'post': {'tags': ['public'],\n",
       "    'summary': 'Generate Query For Shared Dataset Runs',\n",
       "    'description': 'Get runs in projects run over a dataset that has been shared.',\n",
       "    'operationId': 'generate_query_for_shared_dataset_runs_api_v1_public__share_token__datasets_runs_generate_query_post',\n",
       "    'parameters': [{'name': 'share_token',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RequestBodyForRunsGenerateQuery'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ResponseBodyForRunsGenerateQuery'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/public/{share_token}/datasets/runs/stats': {'post': {'tags': ['public'],\n",
       "    'summary': 'Stats Shared Dataset Runs',\n",
       "    'description': 'Get run stats in projects run over a dataset that has been shared.',\n",
       "    'operationId': 'stats_shared_dataset_runs_api_v1_public__share_token__datasets_runs_stats_post',\n",
       "    'parameters': [{'name': 'share_token',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunStatsQueryParams'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunStats'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/public/{share_token}/datasets/runs/{run_id}': {'get': {'tags': ['public'],\n",
       "    'summary': 'Read Shared Dataset Run',\n",
       "    'description': 'Get runs in projects run over a dataset that has been shared.',\n",
       "    'operationId': 'read_shared_dataset_run_api_v1_public__share_token__datasets_runs__run_id__get',\n",
       "    'parameters': [{'name': 'run_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}},\n",
       "     {'name': 'share_token',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "     {'name': 'exclude_s3_stored_attributes',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': False,\n",
       "       'title': 'Exclude S3 Stored Attributes'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunPublicDatasetSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/public/{share_token}/datasets/feedback': {'get': {'tags': ['public'],\n",
       "    'summary': 'Read Shared Dataset Feedback',\n",
       "    'description': 'Get feedback for runs in projects run over a dataset that has been shared.',\n",
       "    'operationId': 'read_shared_dataset_feedback_api_v1_public__share_token__datasets_feedback_get',\n",
       "    'parameters': [{'name': 'share_token',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "     {'name': 'run',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Run'}},\n",
       "     {'name': 'key',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Key'}},\n",
       "     {'name': 'session',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Session'}},\n",
       "     {'name': 'source',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/SourceType'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Source'}},\n",
       "     {'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 100,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'user',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'User'}},\n",
       "     {'name': 'has_comment',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "       'title': 'Has Comment'}},\n",
       "     {'name': 'has_score',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "       'title': 'Has Score'}},\n",
       "     {'name': 'level',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'$ref': '#/components/schemas/FeedbackLevel'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Level'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/FeedbackSchema'},\n",
       "         'title': 'Response Read Shared Dataset Feedback Api V1 Public  Share Token  Datasets Feedback Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/public/{share_token}/datasets/comparative': {'get': {'tags': ['public'],\n",
       "    'summary': 'Read Shared Comparative Experiments',\n",
       "    'description': 'Get all comparative experiments for a given dataset.',\n",
       "    'operationId': 'read_shared_comparative_experiments_api_v1_public__share_token__datasets_comparative_get',\n",
       "    'parameters': [{'name': 'share_token',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "     {'name': 'name',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Name'}},\n",
       "     {'name': 'name_contains',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Name Contains'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 100,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'sort_by',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'$ref': '#/components/schemas/SortByComparativeExperimentColumn',\n",
       "       'default': 'created_at'}},\n",
       "     {'name': 'sort_by_desc',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': True,\n",
       "       'title': 'Sort By Desc'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/PublicComparativeExperiment'},\n",
       "         'title': 'Response Read Shared Comparative Experiments Api V1 Public  Share Token  Datasets Comparative Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/public/schemas/{version}/message.json': {'get': {'tags': ['public'],\n",
       "    'summary': 'Get Message Json Schema',\n",
       "    'operationId': 'get_message_json_schema_api_v1_public_schemas__version__message_json_get',\n",
       "    'parameters': [{'name': 'version',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Version'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/public/schemas/{version}/tooldef.json': {'get': {'tags': ['public'],\n",
       "    'summary': 'Get Tool Def Json Schema',\n",
       "    'operationId': 'get_tool_def_json_schema_api_v1_public_schemas__version__tooldef_json_get',\n",
       "    'parameters': [{'name': 'version',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Version'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/annotation-queues': {'get': {'tags': ['annotation-queues'],\n",
       "    'summary': 'Get Annotation Queues',\n",
       "    'operationId': 'get_annotation_queues_api_v1_annotation_queues_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'ids',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Ids'}},\n",
       "     {'name': 'name',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Name'}},\n",
       "     {'name': 'name_contains',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Name Contains'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 100,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'tag_value_id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Tag Value Id'}},\n",
       "     {'name': 'dataset_id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Dataset Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/AnnotationQueueSchemaWithSize'},\n",
       "         'title': 'Response Get Annotation Queues Api V1 Annotation Queues Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['annotation-queues'],\n",
       "    'summary': 'Create Annotation Queue',\n",
       "    'operationId': 'create_annotation_queue_api_v1_annotation_queues_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueCreateSchema'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/annotation-queues/populate': {'post': {'tags': ['annotation-queues'],\n",
       "    'summary': 'Populate Annotation Queue',\n",
       "    'description': 'Populate annotation queue with runs from an experiment.',\n",
       "    'operationId': 'populate_annotation_queue_api_v1_annotation_queues_populate_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PopulateAnnotationQueueSchema'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/annotation-queues/{queue_id}': {'delete': {'tags': ['annotation-queues'],\n",
       "    'summary': 'Delete Annotation Queue',\n",
       "    'operationId': 'delete_annotation_queue_api_v1_annotation_queues__queue_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'queue_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['annotation-queues'],\n",
       "    'summary': 'Update Annotation Queue',\n",
       "    'operationId': 'update_annotation_queue_api_v1_annotation_queues__queue_id__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'queue_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueUpdateSchema'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'get': {'tags': ['annotation-queues'],\n",
       "    'summary': 'Get Annotation Queue',\n",
       "    'operationId': 'get_annotation_queue_api_v1_annotation_queues__queue_id__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'queue_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueSchemaWithRubric'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/annotation-queues/{queue_id}/runs': {'post': {'tags': ['annotation-queues'],\n",
       "    'summary': 'Add Runs To Annotation Queue',\n",
       "    'operationId': 'add_runs_to_annotation_queue_api_v1_annotation_queues__queue_id__runs_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'queue_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'type': 'array',\n",
       "        'items': {'type': 'string', 'format': 'uuid'},\n",
       "        'title': 'Run Ids'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/AnnotationQueueRunSchema'},\n",
       "         'title': 'Response Add Runs To Annotation Queue Api V1 Annotation Queues  Queue Id  Runs Post'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'get': {'tags': ['annotation-queues'],\n",
       "    'summary': 'Get Runs From Annotation Queue',\n",
       "    'operationId': 'get_runs_from_annotation_queue_api_v1_annotation_queues__queue_id__runs_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'queue_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 100,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'archived',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "       'title': 'Archived'}},\n",
       "     {'name': 'include_stats',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "       'title': 'Include Stats'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/RunSchemaWithAnnotationQueueInfo'},\n",
       "         'title': 'Response Get Runs From Annotation Queue Api V1 Annotation Queues  Queue Id  Runs Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/annotation-queues/{queue_id}/export': {'post': {'tags': ['annotation-queues'],\n",
       "    'summary': 'Export Annotation Queue Archived Runs',\n",
       "    'operationId': 'export_annotation_queue_archived_runs_api_v1_annotation_queues__queue_id__export_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'queue_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ExportAnnotationQueueRunsRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/annotation-queues/{queue_id}/run/{index}': {'get': {'tags': ['annotation-queues'],\n",
       "    'summary': 'Get Run From Annotation Queue',\n",
       "    'operationId': 'get_run_from_annotation_queue_api_v1_annotation_queues__queue_id__run__index__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'queue_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}},\n",
       "     {'name': 'index',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'integer', 'title': 'Index'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunSchemaWithAnnotationQueueInfo'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/annotation-queues/{run_id}/queues': {'get': {'tags': ['annotation-queues'],\n",
       "    'summary': 'Get Annotation Queues For Run',\n",
       "    'operationId': 'get_annotation_queues_for_run_api_v1_annotation_queues__run_id__queues_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'run_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/AnnotationQueueSchema'},\n",
       "         'title': 'Response Get Annotation Queues For Run Api V1 Annotation Queues  Run Id  Queues Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'patch': {'tags': ['annotation-queues'],\n",
       "    'summary': 'Update Run In Annotation Queue',\n",
       "    'operationId': 'update_run_in_annotation_queue_api_v1_annotation_queues__queue_id__runs__queue_run_id__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'queue_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}},\n",
       "     {'name': 'queue_run_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Queue Run Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueRunUpdateSchema'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['annotation-queues'],\n",
       "    'summary': 'Delete Run From Annotation Queue',\n",
       "    'operationId': 'delete_run_from_annotation_queue_api_v1_annotation_queues__queue_id__runs__queue_run_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'queue_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}},\n",
       "     {'name': 'queue_run_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Queue Run Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/annotation-queues/{queue_id}/runs/delete': {'post': {'tags': ['annotation-queues'],\n",
       "    'summary': 'Delete Runs From Annotation Queue',\n",
       "    'operationId': 'delete_runs_from_annotation_queue_api_v1_annotation_queues__queue_id__runs_delete_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'queue_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueBulkDeleteRunsRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/annotation-queues/{queue_id}/total_size': {'get': {'tags': ['annotation-queues'],\n",
       "    'summary': 'Get Total Size From Annotation Queue',\n",
       "    'operationId': 'get_total_size_from_annotation_queue_api_v1_annotation_queues__queue_id__total_size_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'queue_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueSizeSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/annotation-queues/{queue_id}/total_archived': {'get': {'tags': ['annotation-queues'],\n",
       "    'summary': 'Get Total Archived From Annotation Queue',\n",
       "    'operationId': 'get_total_archived_from_annotation_queue_api_v1_annotation_queues__queue_id__total_archived_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'queue_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}},\n",
       "     {'name': 'start_time',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Start Time'}},\n",
       "     {'name': 'end_time',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'End Time'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueSizeSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/annotation-queues/{queue_id}/size': {'get': {'tags': ['annotation-queues'],\n",
       "    'summary': 'Get Size From Annotation Queue',\n",
       "    'operationId': 'get_size_from_annotation_queue_api_v1_annotation_queues__queue_id__size_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'queue_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueSizeSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/annotation-queues/status/{annotation_queue_run_id}': {'post': {'tags': ['annotation-queues'],\n",
       "    'summary': 'Create Identity Annotation Queue Run Status',\n",
       "    'operationId': 'create_identity_annotation_queue_run_status_api_v1_annotation_queues_status__annotation_queue_run_id__post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'annotation_queue_run_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Annotation Queue Run Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/IdentityAnnotationQueueRunStatusCreateSchema'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/ace/execute': {'post': {'tags': ['ace'],\n",
       "    'summary': 'Execute',\n",
       "    'description': 'Execute some custom code for testing purposes.',\n",
       "    'operationId': 'execute_api_v1_ace_execute_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Body_execute_api_v1_ace_execute_post'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'object',\n",
       "         'title': 'Response Execute Api V1 Ace Execute Post'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/bulk-exports': {'get': {'tags': ['bulk-exports'],\n",
       "    'summary': 'Get Bulk Exports',\n",
       "    'description': \"Get the current workspace's bulk exports\",\n",
       "    'operationId': 'get_bulk_exports_api_v1_bulk_exports_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/BulkExport'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response Get Bulk Exports Api V1 Bulk Exports Get'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]},\n",
       "   'post': {'tags': ['bulk-exports'],\n",
       "    'summary': 'Create Bulk Export',\n",
       "    'description': 'Create a new bulk export',\n",
       "    'operationId': 'create_bulk_export_api_v1_bulk_exports_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BulkExportCreate'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BulkExport'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/bulk-exports/destinations': {'get': {'tags': ['bulk-exports'],\n",
       "    'summary': 'Get Bulk Export Destinations',\n",
       "    'description': \"Get the current workspace's bulk export destinations\",\n",
       "    'operationId': 'get_bulk_export_destinations_api_v1_bulk_exports_destinations_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/BulkExportDestination'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response Get Bulk Export Destinations Api V1 Bulk Exports Destinations Get'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]},\n",
       "   'post': {'tags': ['bulk-exports'],\n",
       "    'summary': 'Create Bulk Export Destination',\n",
       "    'description': 'Create a new bulk export destination',\n",
       "    'operationId': 'create_bulk_export_destination_api_v1_bulk_exports_destinations_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BulkExportDestinationCreate'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BulkExportDestination'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/bulk-exports/{bulk_export_id}': {'get': {'tags': ['bulk-exports'],\n",
       "    'summary': 'Get Bulk Export',\n",
       "    'description': 'Get a single bulk export by ID',\n",
       "    'operationId': 'get_bulk_export_api_v1_bulk_exports__bulk_export_id__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'bulk_export_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Bulk Export Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BulkExport'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['bulk-exports'],\n",
       "    'summary': 'Cancel Bulk Export',\n",
       "    'description': 'Cancel a bulk export by ID',\n",
       "    'operationId': 'cancel_bulk_export_api_v1_bulk_exports__bulk_export_id__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'bulk_export_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Bulk Export Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BulkExportUpdate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BulkExport'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/bulk-exports/destinations/{destination_id}': {'get': {'tags': ['bulk-exports'],\n",
       "    'summary': 'Get Bulk Export Destination',\n",
       "    'description': 'Get a single bulk export destination by ID',\n",
       "    'operationId': 'get_bulk_export_destination_api_v1_bulk_exports_destinations__destination_id__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'destination_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Destination Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BulkExportDestination'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/bulk-exports/{bulk_export_id}/runs': {'get': {'tags': ['bulk-exports'],\n",
       "    'summary': 'Get Bulk Export Runs',\n",
       "    'description': \"Get a bulk export's runs\",\n",
       "    'operationId': 'get_bulk_export_runs_api_v1_bulk_exports__bulk_export_id__runs_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'bulk_export_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Bulk Export Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/BulkExportRun'},\n",
       "         'title': 'Response Get Bulk Export Runs Api V1 Bulk Exports  Bulk Export Id  Runs Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/bulk-exports/{bulk_export_id}/runs/{run_id}': {'get': {'tags': ['bulk-exports'],\n",
       "    'summary': 'Get Bulk Export Run',\n",
       "    'description': \"Get a single bulk export's run by ID\",\n",
       "    'operationId': 'get_bulk_export_run_api_v1_bulk_exports__bulk_export_id__runs__run_id__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'bulk_export_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Bulk Export Id'}},\n",
       "     {'name': 'run_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BulkExportRun'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/tenants': {'get': {'tags': ['tenant'],\n",
       "    'summary': 'List Tenants',\n",
       "    'description': 'Get all tenants visible to this auth',\n",
       "    'operationId': 'list_tenants_api_v1_tenants_get',\n",
       "    'security': [{'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'skip_create',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean', 'default': False, 'title': 'Skip Create'}},\n",
       "     {'name': 'include_deleted',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': False,\n",
       "       'title': 'Include Deleted'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/TenantForUser'},\n",
       "         'title': 'Response List Tenants Api V1 Tenants Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['tenant'],\n",
       "    'summary': 'Create Tenant',\n",
       "    'description': 'Create a new organization and corresponding workspace.',\n",
       "    'operationId': 'create_tenant_api_v1_tenants_post',\n",
       "    'security': [{'Bearer Auth': []}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantCreate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/app__schemas__Tenant'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/info': {'get': {'tags': ['info'],\n",
       "    'summary': 'Get Server Info',\n",
       "    'description': 'Get information about the current deployment of LangSmith.',\n",
       "    'operationId': 'get_server_info_api_v1_info_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/InfoGetResponse'}}}}}}},\n",
       "  '/api/v1/info/health': {'get': {'tags': ['info'],\n",
       "    'summary': 'Get Health Info',\n",
       "    'description': 'Get health information about the current deployment of LangSmith.',\n",
       "    'operationId': 'get_health_info_api_v1_info_health_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HealthInfoGetResponse'}}}}}}},\n",
       "  '/api/v1/feedback-configs': {'get': {'tags': ['feedback-configs'],\n",
       "    'summary': 'List Feedback Configs Endpoint',\n",
       "    'operationId': 'list_feedback_configs_endpoint_api_v1_feedback_configs_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'key',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string'},\n",
       "         'maxItems': 50},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Key'}},\n",
       "     {'name': 'read_after_write',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': False,\n",
       "       'title': 'Read After Write'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/FeedbackConfigSchema'},\n",
       "         'title': 'Response List Feedback Configs Endpoint Api V1 Feedback Configs Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['feedback-configs'],\n",
       "    'summary': 'Create Feedback Config Endpoint',\n",
       "    'operationId': 'create_feedback_config_endpoint_api_v1_feedback_configs_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateFeedbackConfigSchema'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackConfigSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['feedback-configs'],\n",
       "    'summary': 'Update Feedback Config Endpoint',\n",
       "    'operationId': 'update_feedback_config_endpoint_api_v1_feedback_configs_patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UpdateFeedbackConfigSchema'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackConfigSchema'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/model-price-map': {'get': {'tags': ['model-price-map'],\n",
       "    'summary': 'Read Model Price Map',\n",
       "    'operationId': 'read_model_price_map_api_v1_model_price_map_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]},\n",
       "   'post': {'tags': ['model-price-map'],\n",
       "    'summary': 'Create New Model Price',\n",
       "    'operationId': 'create_new_model_price_api_v1_model_price_map_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ModelPriceMapCreateSchema'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/model-price-map/{id}': {'put': {'tags': ['model-price-map'],\n",
       "    'summary': 'Update Model Price',\n",
       "    'operationId': 'update_model_price_api_v1_model_price_map__id__put',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ModelPriceMapUpdateSchema'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['model-price-map'],\n",
       "    'summary': 'Delete Model Price',\n",
       "    'operationId': 'delete_model_price_api_v1_model_price_map__id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/usage-limits': {'get': {'tags': ['usage-limits'],\n",
       "    'summary': 'List Usage Limits',\n",
       "    'description': 'List out the configured usage limits for a given tenant.',\n",
       "    'operationId': 'list_usage_limits_api_v1_usage_limits_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/UsageLimit'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response List Usage Limits Api V1 Usage Limits Get'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]},\n",
       "   'put': {'tags': ['usage-limits'],\n",
       "    'summary': 'Upsert Usage Limit',\n",
       "    'description': 'Create a new usage limit.',\n",
       "    'operationId': 'upsert_usage_limit_api_v1_usage_limits_put',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UpsertUsageLimit'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UsageLimit'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/usage-limits/org': {'get': {'tags': ['usage-limits'],\n",
       "    'summary': 'List Org Usage Limits',\n",
       "    'description': 'List out the configured usage limits for a given organization.',\n",
       "    'operationId': 'list_org_usage_limits_api_v1_usage_limits_org_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/UsageLimit'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response List Org Usage Limits Api V1 Usage Limits Org Get'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/usage-limits/{usage_limit_id}': {'delete': {'tags': ['usage-limits'],\n",
       "    'summary': 'Delete Usage Limit',\n",
       "    'description': 'Delete a specific usage limit.',\n",
       "    'operationId': 'delete_usage_limit_api_v1_usage_limits__usage_limit_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'usage_limit_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Usage Limit Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/ttl-settings': {'get': {'tags': ['ttl-settings'],\n",
       "    'summary': 'List Ttl Settings',\n",
       "    'description': 'List out the configured TTL settings for a given tenant.',\n",
       "    'operationId': 'list_ttl_settings_api_v1_ttl_settings_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/TTLSettings'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response List Ttl Settings Api V1 Ttl Settings Get'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]},\n",
       "   'put': {'tags': ['ttl-settings'],\n",
       "    'summary': 'Upsert Ttl Settings',\n",
       "    'operationId': 'upsert_ttl_settings_api_v1_ttl_settings_put',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UpsertTTLSettingsRequest'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TTLSettings'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/prompts/invoke_prompt': {'post': {'tags': ['prompts'],\n",
       "    'summary': 'Invoke Prompt',\n",
       "    'operationId': 'invoke_prompt_api_v1_prompts_invoke_prompt_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/InvokePromptPayload'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/prompts/canvas': {'post': {'tags': ['prompts'],\n",
       "    'summary': 'Prompt Canvas',\n",
       "    'operationId': 'prompt_canvas_api_v1_prompts_canvas_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PlaygroundPromptCanvasPayload'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/prompt-webhooks': {'get': {'tags': ['prompt-webhooks'],\n",
       "    'summary': 'List Prompt Webhooks',\n",
       "    'description': 'List all prompt webhooks for the current tenant.',\n",
       "    'operationId': 'list_prompt_webhooks_api_v1_prompt_webhooks_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/PromptWebhook'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response List Prompt Webhooks Api V1 Prompt Webhooks Get'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]},\n",
       "   'post': {'tags': ['prompt-webhooks'],\n",
       "    'summary': 'Create Prompt Webhook',\n",
       "    'description': 'Create a new prompt webhook.',\n",
       "    'operationId': 'create_prompt_webhook_api_v1_prompt_webhooks_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptWebhookCreate'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptWebhook'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/prompt-webhooks/{webhook_id}': {'get': {'tags': ['prompt-webhooks'],\n",
       "    'summary': 'Get Prompt Webhook',\n",
       "    'description': 'Get a specific prompt webhook.',\n",
       "    'operationId': 'get_prompt_webhook_api_v1_prompt_webhooks__webhook_id__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'webhook_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Webhook Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptWebhook'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['prompt-webhooks'],\n",
       "    'summary': 'Update Prompt Webhook',\n",
       "    'description': 'Update a specific prompt webhook.',\n",
       "    'operationId': 'update_prompt_webhook_api_v1_prompt_webhooks__webhook_id__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'webhook_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Webhook Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptWebhookUpdate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptWebhook'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['prompt-webhooks'],\n",
       "    'summary': 'Delete Prompt Webhook',\n",
       "    'description': 'Delete a specific prompt webhook.',\n",
       "    'operationId': 'delete_prompt_webhook_api_v1_prompt_webhooks__webhook_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'webhook_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Webhook Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/prompt-webhooks/test': {'post': {'tags': ['prompt-webhooks'],\n",
       "    'summary': 'Test Prompt Webhook',\n",
       "    'description': 'Test a specific prompt webhook.',\n",
       "    'operationId': 'test_prompt_webhook_api_v1_prompt_webhooks_test_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptWebhookTest'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'additionalProperties': {'type': 'string'},\n",
       "         'type': 'object',\n",
       "         'title': 'Response Test Prompt Webhook Api V1 Prompt Webhooks Test Post'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/workspaces': {'get': {'tags': ['workspaces'],\n",
       "    'summary': 'List Workspaces',\n",
       "    'description': 'Get all workspaces visible to this auth in the current org. Does not create a new workspace/org.',\n",
       "    'operationId': 'list_workspaces_api_v1_workspaces_get',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'include_deleted',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': False,\n",
       "       'title': 'Include Deleted'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/TenantForUser'},\n",
       "         'title': 'Response List Workspaces Api V1 Workspaces Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['workspaces'],\n",
       "    'summary': 'Create Workspace',\n",
       "    'description': 'Create a new workspace.',\n",
       "    'operationId': 'create_workspace_api_v1_workspaces_post',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/WorkspaceCreate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/app__schemas__Tenant'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/workspaces/{workspace_id}': {'patch': {'tags': ['workspaces'],\n",
       "    'summary': 'Patch Workspace',\n",
       "    'operationId': 'patch_workspace_api_v1_workspaces__workspace_id__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'workspace_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Workspace Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/WorkspacePatch'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/app__schemas__Tenant'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['workspaces'],\n",
       "    'summary': 'Delete Workspace',\n",
       "    'operationId': 'delete_workspace_api_v1_workspaces__workspace_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'workspace_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Workspace Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/workspaces/pending': {'get': {'tags': ['workspaces'],\n",
       "    'summary': 'List Pending Workspace Invites',\n",
       "    'description': 'Get all workspaces visible to this auth',\n",
       "    'operationId': 'list_pending_workspace_invites_api_v1_workspaces_pending_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/app__schemas__Tenant'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response List Pending Workspace Invites Api V1 Workspaces Pending Get'}}}}},\n",
       "    'security': [{'Bearer Auth': []}]}},\n",
       "  '/api/v1/workspaces/pending/{id}': {'delete': {'tags': ['workspaces'],\n",
       "    'summary': 'Delete Pending Workspace Invite',\n",
       "    'operationId': 'delete_pending_workspace_invite_api_v1_workspaces_pending__id__delete',\n",
       "    'security': [{'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/workspaces/pending/{workspace_id}/claim': {'post': {'tags': ['workspaces'],\n",
       "    'summary': 'Claim Pending Workspace Invite',\n",
       "    'operationId': 'claim_pending_workspace_invite_api_v1_workspaces_pending__workspace_id__claim_post',\n",
       "    'deprecated': True,\n",
       "    'security': [{'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'workspace_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Workspace Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/workspaces/current/stats': {'get': {'tags': ['workspaces'],\n",
       "    'summary': 'Get Current Workspace Stats',\n",
       "    'operationId': 'get_current_workspace_stats_api_v1_workspaces_current_stats_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'tag_value_id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Tag Value Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantStats'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/workspaces/current/members': {'get': {'tags': ['workspaces'],\n",
       "    'summary': 'Get Current Workspace Members',\n",
       "    'operationId': 'get_current_workspace_members_api_v1_workspaces_current_members_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantMembers'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]},\n",
       "   'post': {'tags': ['workspaces'],\n",
       "    'summary': 'Add Member To Current Workspace',\n",
       "    'description': 'Add an existing organization member to the current workspace.',\n",
       "    'operationId': 'add_member_to_current_workspace_api_v1_workspaces_current_members_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/IdentityCreate'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Identity'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/workspaces/current/members/active': {'get': {'tags': ['workspaces'],\n",
       "    'summary': 'Get Current Active Workspace Members',\n",
       "    'operationId': 'get_current_active_workspace_members_api_v1_workspaces_current_members_active_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 500,\n",
       "       'minimum': 1,\n",
       "       'default': 50,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'emails',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'array',\n",
       "       'items': {'type': 'string'},\n",
       "       'default': [],\n",
       "       'title': 'Emails'}},\n",
       "     {'name': 'ls_user_ids',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'array',\n",
       "       'items': {'type': 'string', 'format': 'uuid'},\n",
       "       'default': [],\n",
       "       'title': 'Ls User Ids'}},\n",
       "     {'name': 'user_ids',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'array',\n",
       "       'items': {'type': 'string', 'format': 'uuid'},\n",
       "       'default': [],\n",
       "       'title': 'User Ids'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/MemberIdentity'},\n",
       "         'title': 'Response Get Current Active Workspace Members Api V1 Workspaces Current Members Active Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/workspaces/current/members/pending': {'get': {'tags': ['workspaces'],\n",
       "    'summary': 'Get Current Pending Workspace Members',\n",
       "    'operationId': 'get_current_pending_workspace_members_api_v1_workspaces_current_members_pending_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 500,\n",
       "       'minimum': 1,\n",
       "       'default': 50,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'emails',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'array',\n",
       "       'items': {'type': 'string'},\n",
       "       'default': [],\n",
       "       'title': 'Emails'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/PendingIdentity'},\n",
       "         'title': 'Response Get Current Pending Workspace Members Api V1 Workspaces Current Members Pending Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/workspaces/current/members/batch': {'post': {'tags': ['workspaces'],\n",
       "    'summary': 'Add Members To Current Workspace Batch',\n",
       "    'description': 'Batch invite up to 500 users to the current workspace and organization.',\n",
       "    'operationId': 'add_members_to_current_workspace_batch_api_v1_workspaces_current_members_batch_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/PendingIdentityCreate'},\n",
       "        'type': 'array',\n",
       "        'title': 'Payloads'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/PendingIdentity'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response Add Members To Current Workspace Batch Api V1 Workspaces Current Members Batch Post'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Tenant ID': []},\n",
       "     {'Bearer Auth': []},\n",
       "     {'Organization ID': []}]}},\n",
       "  '/api/v1/workspaces/current/shared': {'get': {'tags': ['workspaces'],\n",
       "    'summary': 'Get Shared Tokens',\n",
       "    'description': 'List all shared entities and their tokens by the workspace.',\n",
       "    'operationId': 'get_shared_tokens_api_v1_workspaces_current_shared_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 50,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantShareTokensResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['workspaces'],\n",
       "    'summary': 'Bulk Unshare Entities',\n",
       "    'description': 'Bulk unshare entities by share tokens for the workspace.',\n",
       "    'operationId': 'bulk_unshare_entities_api_v1_workspaces_current_shared_delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantBulkUnshareRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/workspaces/current/members/{identity_id}': {'delete': {'tags': ['workspaces'],\n",
       "    'summary': 'Delete Current Workspace Member',\n",
       "    'operationId': 'delete_current_workspace_member_api_v1_workspaces_current_members__identity_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'identity_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Identity Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['workspaces'],\n",
       "    'summary': 'Patch Current Workspace Member',\n",
       "    'operationId': 'patch_current_workspace_member_api_v1_workspaces_current_members__identity_id__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'identity_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Identity Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/IdentityPatch'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/workspaces/current/members/{identity_id}/pending': {'delete': {'tags': ['workspaces'],\n",
       "    'summary': 'Delete Current Workspace Pending Member',\n",
       "    'operationId': 'delete_current_workspace_pending_member_api_v1_workspaces_current_members__identity_id__pending_delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'identity_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Identity Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/workspaces/current/usage_limits': {'get': {'tags': ['workspaces'],\n",
       "    'summary': 'Get Current Workspace Usage Limits Info',\n",
       "    'operationId': 'get_current_workspace_usage_limits_info_api_v1_workspaces_current_usage_limits_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantUsageLimitInfo'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/workspaces/current/secrets': {'get': {'tags': ['workspaces'],\n",
       "    'summary': 'List Current Workspace Secrets',\n",
       "    'operationId': 'list_current_workspace_secrets_api_v1_workspaces_current_secrets_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/SecretKey'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response List Current Workspace Secrets Api V1 Workspaces Current Secrets Get'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]},\n",
       "   'post': {'tags': ['workspaces'],\n",
       "    'summary': 'Upsert Current Workspace Secrets',\n",
       "    'operationId': 'upsert_current_workspace_secrets_api_v1_workspaces_current_secrets_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/SecretUpsert'},\n",
       "        'type': 'array',\n",
       "        'title': 'Secrets'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/workspaces/current/tag-keys': {'get': {'tags': ['workspaces'],\n",
       "    'summary': 'List Tag Keys',\n",
       "    'operationId': 'list_tag_keys_api_v1_workspaces_current_tag_keys_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/TagKey'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response List Tag Keys Api V1 Workspaces Current Tag Keys Get'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]},\n",
       "   'post': {'tags': ['workspaces'],\n",
       "    'summary': 'Create Tag Key',\n",
       "    'operationId': 'create_tag_key_api_v1_workspaces_current_tag_keys_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TagKeyCreate'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TagKey'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/workspaces/current/tag-keys/{tag_key_id}': {'patch': {'tags': ['workspaces'],\n",
       "    'summary': 'Update Tag Key',\n",
       "    'operationId': 'update_tag_key_api_v1_workspaces_current_tag_keys__tag_key_id__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'tag_key_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Tag Key Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TagKeyUpdate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TagKey'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'get': {'tags': ['workspaces'],\n",
       "    'summary': 'Get Tag Key',\n",
       "    'operationId': 'get_tag_key_api_v1_workspaces_current_tag_keys__tag_key_id__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'tag_key_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Tag Key Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TagKey'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['workspaces'],\n",
       "    'summary': 'Delete Tag Key',\n",
       "    'operationId': 'delete_tag_key_api_v1_workspaces_current_tag_keys__tag_key_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'tag_key_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Tag Key Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/workspaces/current/tag-keys/{tag_key_id}/tag-values': {'post': {'tags': ['workspaces'],\n",
       "    'summary': 'Create Tag Value',\n",
       "    'operationId': 'create_tag_value_api_v1_workspaces_current_tag_keys__tag_key_id__tag_values_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'tag_key_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Tag Key Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TagValueCreate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TagValue'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'get': {'tags': ['workspaces'],\n",
       "    'summary': 'List Tag Values',\n",
       "    'operationId': 'list_tag_values_api_v1_workspaces_current_tag_keys__tag_key_id__tag_values_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'tag_key_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Tag Key Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/TagValue'},\n",
       "         'title': 'Response List Tag Values Api V1 Workspaces Current Tag Keys  Tag Key Id  Tag Values Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/workspaces/current/tag-keys/{tag_key_id}/tag-values/{tag_value_id}': {'get': {'tags': ['workspaces'],\n",
       "    'summary': 'Get Tag Value',\n",
       "    'operationId': 'get_tag_value_api_v1_workspaces_current_tag_keys__tag_key_id__tag_values__tag_value_id__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'tag_key_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Tag Key Id'}},\n",
       "     {'name': 'tag_value_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Tag Value Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TagValue'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['workspaces'],\n",
       "    'summary': 'Update Tag Value',\n",
       "    'operationId': 'update_tag_value_api_v1_workspaces_current_tag_keys__tag_key_id__tag_values__tag_value_id__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'tag_key_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Tag Key Id'}},\n",
       "     {'name': 'tag_value_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Tag Value Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TagValueUpdate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TagValue'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['workspaces'],\n",
       "    'summary': 'Delete Tag Value',\n",
       "    'operationId': 'delete_tag_value_api_v1_workspaces_current_tag_keys__tag_key_id__tag_values__tag_value_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'tag_key_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Tag Key Id'}},\n",
       "     {'name': 'tag_value_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Tag Value Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/workspaces/current/taggings': {'post': {'tags': ['workspaces'],\n",
       "    'summary': 'Create Tagging',\n",
       "    'operationId': 'create_tagging_api_v1_workspaces_current_taggings_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TaggingCreate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Tagging'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'get': {'tags': ['workspaces'],\n",
       "    'summary': 'List Taggings',\n",
       "    'operationId': 'list_taggings_api_v1_workspaces_current_taggings_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'tag_value_id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Tag Value Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/TaggingsResponse'},\n",
       "         'title': 'Response List Taggings Api V1 Workspaces Current Taggings Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/workspaces/current/taggings/{tagging_id}': {'delete': {'tags': ['workspaces'],\n",
       "    'summary': 'Delete Tagging',\n",
       "    'operationId': 'delete_tagging_api_v1_workspaces_current_taggings__tagging_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'tagging_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Tagging Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/workspaces/current/tags': {'get': {'tags': ['workspaces'],\n",
       "    'summary': 'List Tags',\n",
       "    'operationId': 'list_tags_api_v1_workspaces_current_tags_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/TagKeyWithValues'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response List Tags Api V1 Workspaces Current Tags Get'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/workspaces/current/tags/resource': {'get': {'tags': ['workspaces'],\n",
       "    'summary': 'List Tags For Resource',\n",
       "    'operationId': 'list_tags_for_resource_api_v1_workspaces_current_tags_resource_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'resource_type',\n",
       "      'in': 'query',\n",
       "      'required': True,\n",
       "      'schema': {'$ref': '#/components/schemas/ResourceType'}},\n",
       "     {'name': 'resource_id',\n",
       "      'in': 'query',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Resource Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/TagKeyWithValuesAndTaggings'},\n",
       "         'title': 'Response List Tags For Resource Api V1 Workspaces Current Tags Resource Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/workspaces/current/tags/resources': {'post': {'tags': ['workspaces'],\n",
       "    'summary': 'List Tags For Resources',\n",
       "    'operationId': 'list_tags_for_resources_api_v1_workspaces_current_tags_resources_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/ListTagsForResourceRequest'},\n",
       "        'type': 'array',\n",
       "        'title': 'Resources'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'additionalProperties': {'items': {'$ref': '#/components/schemas/TagKeyWithValuesAndTaggings'},\n",
       "          'type': 'array'},\n",
       "         'propertyNames': {'format': 'uuid'},\n",
       "         'type': 'object',\n",
       "         'title': 'Response List Tags For Resources Api V1 Workspaces Current Tags Resources Post'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/playground-settings': {'get': {'tags': ['playground-settings'],\n",
       "    'summary': 'List Playground Settings',\n",
       "    'description': 'Get all playground settings for this tenant id.',\n",
       "    'operationId': 'list_playground_settings_api_v1_playground_settings_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/PlaygroundSettingsResponse'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response List Playground Settings Api V1 Playground Settings Get'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]},\n",
       "   'post': {'tags': ['playground-settings'],\n",
       "    'summary': 'Create Playground Settings',\n",
       "    'description': 'Create playground settings.',\n",
       "    'operationId': 'create_playground_settings_api_v1_playground_settings_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PlaygroundSettingsCreateRequest'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PlaygroundSettingsResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/playground-settings/{playground_settings_id}': {'patch': {'tags': ['playground-settings'],\n",
       "    'summary': 'Update Playground Settings',\n",
       "    'description': 'Update playground settings.',\n",
       "    'operationId': 'update_playground_settings_api_v1_playground_settings__playground_settings_id__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'playground_settings_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Playground Settings Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PlaygroundSettingsUpdateRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PlaygroundSettingsResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['playground-settings'],\n",
       "    'summary': 'Delete Playground Settings',\n",
       "    'description': 'Delete playground settings.',\n",
       "    'operationId': 'delete_playground_settings_api_v1_playground_settings__playground_settings_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'playground_settings_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Playground Settings Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/service-accounts': {'get': {'tags': ['service-accounts'],\n",
       "    'summary': 'Get Service Accounts',\n",
       "    'description': \"Get the current organization's service accounts.\",\n",
       "    'operationId': 'get_service_accounts_api_v1_service_accounts_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/ServiceAccount'},\n",
       "         'type': 'array',\n",
       "         'title': 'Response Get Service Accounts Api V1 Service Accounts Get'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]},\n",
       "   'post': {'tags': ['service-accounts'],\n",
       "    'summary': 'Create Service Account',\n",
       "    'description': 'Create a service account',\n",
       "    'operationId': 'create_service_account_api_v1_service_accounts_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ServiceAccountCreateRequest'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ServiceAccountCreateResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/service-accounts/{service_account_id}': {'delete': {'tags': ['service-accounts'],\n",
       "    'summary': 'Delete Service Account',\n",
       "    'description': 'Delete a service account',\n",
       "    'operationId': 'delete_service_account_api_v1_service_accounts__service_account_id__delete',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'service_account_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Service Account Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ServiceAccountDeleteResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/charts/section/clone': {'post': {'tags': ['charts'],\n",
       "    'summary': 'Clone Section',\n",
       "    'description': 'Clone a dashboard.',\n",
       "    'operationId': 'clone_section_api_v1_charts_section_clone_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsSectionsCloneRequest'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsSectionResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/charts/section': {'get': {'tags': ['charts'],\n",
       "    'summary': 'Read Sections',\n",
       "    'description': 'Get all sections for the tenant.',\n",
       "    'operationId': 'read_sections_api_v1_charts_section_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 100,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'title_contains',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Title Contains'}},\n",
       "     {'name': 'ids',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Ids'}},\n",
       "     {'name': 'sort_by',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'default': 'created_at',\n",
       "       'title': 'Sort By'}},\n",
       "     {'name': 'sort_by_desc',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "       'default': True,\n",
       "       'title': 'Sort By Desc'}},\n",
       "     {'name': 'tag_value_id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Tag Value Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/CustomChartsSectionResponse'},\n",
       "         'title': 'Response Read Sections Api V1 Charts Section Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['charts'],\n",
       "    'summary': 'Create Section',\n",
       "    'description': 'Create a new section.',\n",
       "    'operationId': 'create_section_api_v1_charts_section_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsSectionCreate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsSectionResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/charts': {'post': {'tags': ['charts'],\n",
       "    'summary': 'Read Charts',\n",
       "    'description': 'Get all charts for the tenant.',\n",
       "    'operationId': 'read_charts_api_v1_charts_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsRequest'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/charts/preview': {'post': {'tags': ['charts'],\n",
       "    'summary': 'Read Chart Preview',\n",
       "    'description': 'Get a preview for a chart without actually creating it.',\n",
       "    'operationId': 'read_chart_preview_api_v1_charts_preview_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartPreviewRequest'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SingleCustomChartResponseBase'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/charts/create': {'post': {'tags': ['charts'],\n",
       "    'summary': 'Create Chart',\n",
       "    'description': 'Create a new chart.',\n",
       "    'operationId': 'create_chart_api_v1_charts_create_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartCreate'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/charts/{chart_id}': {'post': {'tags': ['charts'],\n",
       "    'summary': 'Read Single Chart',\n",
       "    'description': 'Get a single chart by ID.',\n",
       "    'operationId': 'read_single_chart_api_v1_charts__chart_id__post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'chart_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Chart Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SingleCustomChartResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['charts'],\n",
       "    'summary': 'Update Chart',\n",
       "    'description': 'Update a chart.',\n",
       "    'operationId': 'update_chart_api_v1_charts__chart_id__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'chart_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Chart Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartUpdate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['charts'],\n",
       "    'summary': 'Delete Chart',\n",
       "    'description': 'Delete a chart.',\n",
       "    'operationId': 'delete_chart_api_v1_charts__chart_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'chart_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Chart Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/charts/section/{section_id}': {'post': {'tags': ['charts'],\n",
       "    'summary': 'Read Single Section',\n",
       "    'description': 'Get a single section by ID.',\n",
       "    'operationId': 'read_single_section_api_v1_charts_section__section_id__post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'section_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Section Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsSectionRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsSection'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['charts'],\n",
       "    'summary': 'Update Section',\n",
       "    'description': 'Update a section.',\n",
       "    'operationId': 'update_section_api_v1_charts_section__section_id__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'section_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Section Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsSectionUpdate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsSectionResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['charts'],\n",
       "    'summary': 'Delete Section',\n",
       "    'description': 'Delete a section.',\n",
       "    'operationId': 'delete_section_api_v1_charts_section__section_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'section_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Section Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/org-charts/section': {'get': {'tags': ['charts'],\n",
       "    'summary': 'Org Read Sections',\n",
       "    'description': 'Get all sections for the tenant.',\n",
       "    'operationId': 'org_read_sections_api_v1_org_charts_section_get',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 100,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'title_contains',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Title Contains'}},\n",
       "     {'name': 'ids',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Ids'}},\n",
       "     {'name': 'sort_by',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'default': 'created_at',\n",
       "       'title': 'Sort By'}},\n",
       "     {'name': 'sort_by_desc',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "       'default': True,\n",
       "       'title': 'Sort By Desc'}},\n",
       "     {'name': 'tag_value_id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Tag Value Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/CustomChartsSectionResponse'},\n",
       "         'title': 'Response Org Read Sections Api V1 Org Charts Section Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['charts'],\n",
       "    'summary': 'Org Create Section',\n",
       "    'description': 'Create a new section.',\n",
       "    'operationId': 'org_create_section_api_v1_org_charts_section_post',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsSectionCreate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsSectionResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/org-charts': {'post': {'tags': ['charts'],\n",
       "    'summary': 'Org Read Charts',\n",
       "    'description': 'Get all charts for the tenant.',\n",
       "    'operationId': 'org_read_charts_api_v1_org_charts_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsRequest'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/org-charts/preview': {'post': {'tags': ['charts'],\n",
       "    'summary': 'Org Read Chart Preview',\n",
       "    'description': 'Get a preview for a chart without actually creating it.',\n",
       "    'operationId': 'org_read_chart_preview_api_v1_org_charts_preview_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartPreviewRequest'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SingleCustomChartResponseBase'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/org-charts/create': {'post': {'tags': ['charts'],\n",
       "    'summary': 'Org Create Chart',\n",
       "    'description': 'Create a new chart.',\n",
       "    'operationId': 'org_create_chart_api_v1_org_charts_create_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartCreate'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}]}},\n",
       "  '/api/v1/org-charts/{chart_id}': {'post': {'tags': ['charts'],\n",
       "    'summary': 'Org Read Single Chart',\n",
       "    'description': 'Get a single chart by ID.',\n",
       "    'operationId': 'org_read_single_chart_api_v1_org_charts__chart_id__post',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'chart_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Chart Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SingleCustomChartResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['charts'],\n",
       "    'summary': 'Org Update Chart',\n",
       "    'description': 'Update a chart.',\n",
       "    'operationId': 'org_update_chart_api_v1_org_charts__chart_id__patch',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'chart_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Chart Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartUpdate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['charts'],\n",
       "    'summary': 'Org Delete Chart',\n",
       "    'description': 'Delete a chart.',\n",
       "    'operationId': 'org_delete_chart_api_v1_org_charts__chart_id__delete',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'chart_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Chart Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/org-charts/section/{section_id}': {'post': {'tags': ['charts'],\n",
       "    'summary': 'Org Read Single Section',\n",
       "    'description': 'Get a single section by ID.',\n",
       "    'operationId': 'org_read_single_section_api_v1_org_charts_section__section_id__post',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'section_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Section Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsRequestBase'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsSection'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['charts'],\n",
       "    'summary': 'Org Update Section',\n",
       "    'description': 'Update a section.',\n",
       "    'operationId': 'org_update_section_api_v1_org_charts_section__section_id__patch',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'section_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Section Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsSectionUpdate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsSectionResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['charts'],\n",
       "    'summary': 'Org Delete Section',\n",
       "    'description': 'Delete a section.',\n",
       "    'operationId': 'org_delete_section_api_v1_org_charts_section__section_id__delete',\n",
       "    'security': [{'API Key': []},\n",
       "     {'Organization ID': []},\n",
       "     {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'section_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Section Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/ok': {'get': {'summary': 'Ok',\n",
       "    'operationId': 'ok_api_v1_ok_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}}}}},\n",
       "  '/api/v1/repos': {'get': {'tags': ['repos'],\n",
       "    'summary': 'List Repos',\n",
       "    'description': 'Get all repos.',\n",
       "    'operationId': 'list_repos_api_v1_repos_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'with_latest_manifest',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': False,\n",
       "       'title': 'With Latest Manifest'}},\n",
       "     {'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 20,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'tenant_handle',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Tenant Handle'}},\n",
       "     {'name': 'tenant_id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Tenant Id'}},\n",
       "     {'name': 'query',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Query'}},\n",
       "     {'name': 'has_commits',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "       'title': 'Has Commits'}},\n",
       "     {'name': 'tags',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Tags'}},\n",
       "     {'name': 'is_archived',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'enum': ['true', 'allow', 'false'],\n",
       "         'type': 'string'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Is Archived'}},\n",
       "     {'name': 'is_public',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'enum': ['true', 'false'], 'type': 'string'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Is Public'}},\n",
       "     {'name': 'upstream_repo_owner',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Upstream Repo Owner'}},\n",
       "     {'name': 'upstream_repo_handle',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Upstream Repo Handle'}},\n",
       "     {'name': 'tag_value_id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Tag Value Id'}},\n",
       "     {'name': 'sort_field',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Sort Field'}},\n",
       "     {'name': 'sort_direction',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'const': 'asc', 'type': 'string'},\n",
       "        {'const': 'desc', 'type': 'string'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Sort Direction'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ListReposResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['repos'],\n",
       "    'summary': 'Create Repo',\n",
       "    'description': 'Create a repo.',\n",
       "    'operationId': 'create_repo_api_v1_repos_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateRepoRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateRepoResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/repos/{owner}/{repo}': {'get': {'tags': ['repos'],\n",
       "    'summary': 'Get Repo',\n",
       "    'description': 'Get a repo.',\n",
       "    'operationId': 'get_repo_api_v1_repos__owner___repo__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'owner',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "     {'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/GetRepoResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['repos'],\n",
       "    'summary': 'Update Repo',\n",
       "    'description': 'Update a repo.',\n",
       "    'operationId': 'update_repo_api_v1_repos__owner___repo__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'owner',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "     {'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UpdateRepoRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateRepoResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['repos'],\n",
       "    'summary': 'Delete Repo',\n",
       "    'description': 'Delete a repo.',\n",
       "    'operationId': 'delete_repo_api_v1_repos__owner___repo__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'owner',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "     {'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/repos/{owner}/{repo}/fork': {'post': {'tags': ['repos'],\n",
       "    'summary': 'Fork Repo',\n",
       "    'description': 'Fork a repo.',\n",
       "    'operationId': 'fork_repo_api_v1_repos__owner___repo__fork_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'owner',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "     {'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ForkRepoRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/GetRepoResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/repos/tags': {'get': {'tags': ['repos'],\n",
       "    'summary': 'List Repo Tags',\n",
       "    'description': 'Get all repo tags.',\n",
       "    'operationId': 'list_repo_tags_api_v1_repos_tags_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 20,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}},\n",
       "     {'name': 'tenant_handle',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Tenant Handle'}},\n",
       "     {'name': 'tenant_id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Tenant Id'}},\n",
       "     {'name': 'query',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Query'}},\n",
       "     {'name': 'has_commits',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "       'title': 'Has Commits'}},\n",
       "     {'name': 'tags',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Tags'}},\n",
       "     {'name': 'is_archived',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'enum': ['true', 'allow', 'false'],\n",
       "         'type': 'string'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Is Archived'}},\n",
       "     {'name': 'is_public',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'enum': ['true', 'false'], 'type': 'string'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Is Public'}},\n",
       "     {'name': 'upstream_repo_owner',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Upstream Repo Owner'}},\n",
       "     {'name': 'upstream_repo_handle',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Upstream Repo Handle'}},\n",
       "     {'name': 'tag_value_id',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'}},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Tag Value Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ListTagsResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/repos/optimize-job': {'post': {'tags': ['repos'],\n",
       "    'summary': 'Optimize Prompt Job',\n",
       "    'description': 'Optimize prompt',\n",
       "    'operationId': 'optimize_prompt_job_api_v1_repos_optimize_job_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OptimizePromptJobRequest'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OptimizePromptResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/likes/{owner}/{repo}': {'post': {'tags': ['likes'],\n",
       "    'summary': 'Like Repo',\n",
       "    'description': 'Like a repo.',\n",
       "    'operationId': 'like_repo_api_v1_likes__owner___repo__post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'owner',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "     {'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/LikeRepoRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/LikeRepoResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/commits/{owner}/{repo}': {'get': {'tags': ['commits'],\n",
       "    'summary': 'List Commits',\n",
       "    'description': 'Get all commits.',\n",
       "    'operationId': 'list_commits_api_v1_commits__owner___repo__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'owner',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "     {'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}},\n",
       "     {'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 20,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ListCommitsResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['commits'],\n",
       "    'summary': 'Create Commit',\n",
       "    'description': 'Upload a repo.',\n",
       "    'operationId': 'create_commit_api_v1_commits__owner___repo__post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'owner',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "     {'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateRepoCommitRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateRepoCommitResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/commits/{owner}/{repo}/{commit}': {'get': {'tags': ['commits'],\n",
       "    'summary': 'Get Commit',\n",
       "    'description': 'Download a repo.',\n",
       "    'operationId': 'get_commit_api_v1_commits__owner___repo___commit__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'owner',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "     {'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}},\n",
       "     {'name': 'commit',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Commit'}},\n",
       "     {'name': 'get_examples',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean',\n",
       "       'default': False,\n",
       "       'title': 'Get Examples'}},\n",
       "     {'name': 'is_view',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'boolean', 'default': False, 'title': 'Is View'}},\n",
       "     {'name': 'include_model',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "       'default': False,\n",
       "       'title': 'Include Model'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CommitManifestResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/settings': {'get': {'tags': ['settings'],\n",
       "    'summary': 'Get Settings',\n",
       "    'description': 'Get settings.',\n",
       "    'operationId': 'get_settings_api_v1_settings_get',\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/app__hub__crud__tenants__Tenant'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/settings/handle': {'post': {'tags': ['settings'],\n",
       "    'summary': 'Set Tenant Handle',\n",
       "    'description': 'Set tenant handle.',\n",
       "    'operationId': 'set_tenant_handle_api_v1_settings_handle_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SetTenantHandleRequest'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/app__hub__crud__tenants__Tenant'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/events': {'post': {'tags': ['events'],\n",
       "    'summary': 'Create Event',\n",
       "    'operationId': 'create_event_api_v1_events_post',\n",
       "    'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateEventRequest'}}},\n",
       "     'required': True},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}},\n",
       "  '/api/v1/comments/{owner}/{repo}': {'post': {'tags': ['comments'],\n",
       "    'summary': 'Create Comment',\n",
       "    'operationId': 'create_comment_api_v1_comments__owner___repo__post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'owner',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "     {'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateCommentRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'get': {'tags': ['comments'],\n",
       "    'summary': 'Get Comments',\n",
       "    'operationId': 'get_comments_api_v1_comments__owner___repo__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'owner',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "     {'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}},\n",
       "     {'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 20,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ListCommentsResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/comments/{owner}/{repo}/{parent_comment_id}': {'get': {'tags': ['comments'],\n",
       "    'summary': 'Get Sub Comments',\n",
       "    'operationId': 'get_sub_comments_api_v1_comments__owner___repo___parent_comment_id__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'owner',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "     {'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}},\n",
       "     {'name': 'parent_comment_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Parent Comment Id'}},\n",
       "     {'name': 'limit',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'maximum': 100,\n",
       "       'minimum': 1,\n",
       "       'default': 20,\n",
       "       'title': 'Limit'}},\n",
       "     {'name': 'offset',\n",
       "      'in': 'query',\n",
       "      'required': False,\n",
       "      'schema': {'type': 'integer',\n",
       "       'minimum': 0,\n",
       "       'default': 0,\n",
       "       'title': 'Offset'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ListCommentsResponse'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['comments'],\n",
       "    'summary': 'Create Sub Comment',\n",
       "    'operationId': 'create_sub_comment_api_v1_comments__owner___repo___parent_comment_id__post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'owner',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "     {'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}},\n",
       "     {'name': 'parent_comment_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Parent Comment Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateCommentRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Comment'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/comments/{owner}/{repo}/{parent_comment_id}/like': {'post': {'tags': ['comments'],\n",
       "    'summary': 'Like Comment',\n",
       "    'operationId': 'like_comment_api_v1_comments__owner___repo___parent_comment_id__like_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'owner',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "     {'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}},\n",
       "     {'name': 'parent_comment_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Parent Comment Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'object',\n",
       "         'title': 'Response Like Comment Api V1 Comments  Owner   Repo   Parent Comment Id  Like Post'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['comments'],\n",
       "    'summary': 'Unlike Comment',\n",
       "    'operationId': 'unlike_comment_api_v1_comments__owner___repo___parent_comment_id__like_delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'owner',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "     {'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}},\n",
       "     {'name': 'parent_comment_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Parent Comment Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'object',\n",
       "         'title': 'Response Unlike Comment Api V1 Comments  Owner   Repo   Parent Comment Id  Like Delete'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/repos/{owner}/{repo}/tags': {'get': {'tags': ['tags'],\n",
       "    'summary': 'Get Tags',\n",
       "    'operationId': 'get_tags_api_v1_repos__owner___repo__tags_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/RepoTag'},\n",
       "         'title': 'Response Get Tags Api V1 Repos  Owner   Repo  Tags Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['tags'],\n",
       "    'summary': 'Create Tag',\n",
       "    'operationId': 'create_tag_api_v1_repos__owner___repo__tags_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RepoTagRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RepoTag'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/repos/{owner}/{repo}/tags/{tag_name}': {'get': {'tags': ['tags'],\n",
       "    'summary': 'Get Tag',\n",
       "    'operationId': 'get_tag_api_v1_repos__owner___repo__tags__tag_name__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}},\n",
       "     {'name': 'tag_name',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Tag Name'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RepoTag'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['tags'],\n",
       "    'summary': 'Update Tag',\n",
       "    'operationId': 'update_tag_api_v1_repos__owner___repo__tags__tag_name__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}},\n",
       "     {'name': 'tag_name',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Tag Name'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RepoUpdateTagRequest'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RepoTag'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['tags'],\n",
       "    'summary': 'Delete Tag',\n",
       "    'operationId': 'delete_tag_api_v1_repos__owner___repo__tags__tag_name__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}},\n",
       "     {'name': 'tag_name',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Tag Name'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/repos/{owner}/{repo}/optimization-jobs': {'get': {'tags': ['optimization-jobs'],\n",
       "    'summary': 'List Jobs',\n",
       "    'description': 'List all prompt optimization jobs.',\n",
       "    'operationId': 'list_jobs_api_v1_repos__owner___repo__optimization_jobs_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/PromptOptimizationJob'},\n",
       "         'title': 'Response List Jobs Api V1 Repos  Owner   Repo  Optimization Jobs Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['optimization-jobs'],\n",
       "    'summary': 'Create Job',\n",
       "    'description': 'Create a new prompt optimization job.',\n",
       "    'operationId': 'create_job_api_v1_repos__owner___repo__optimization_jobs_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'repo',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'title': 'Repo'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptOptimizationJobCreate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptOptimizationJob'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/repos/{owner}/{repo}/optimization-jobs/{job_id}': {'get': {'tags': ['optimization-jobs'],\n",
       "    'summary': 'Get Job',\n",
       "    'description': 'Get a specific optimization job.',\n",
       "    'operationId': 'get_job_api_v1_repos__owner___repo__optimization_jobs__job_id__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'job_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Job Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptOptimizationJobWithLogs'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'patch': {'tags': ['optimization-jobs'],\n",
       "    'summary': 'Update Job',\n",
       "    'description': 'Replace an existing prompt optimization job with a new, modified job.',\n",
       "    'operationId': 'update_job_api_v1_repos__owner___repo__optimization_jobs__job_id__patch',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'job_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Job Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptOptimizationJobUpdate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptOptimizationJob'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['optimization-jobs'],\n",
       "    'summary': 'Delete Job',\n",
       "    'description': 'Delete a prompt optimization job.',\n",
       "    'operationId': 'delete_job_api_v1_repos__owner___repo__optimization_jobs__job_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'job_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Job Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/repos/{owner}/{repo}/optimization-jobs/{job_id}/logs': {'get': {'tags': ['optimization-jobs'],\n",
       "    'summary': 'List Job Logs',\n",
       "    'description': 'List all logs for a specific prompt optimization job.',\n",
       "    'operationId': 'list_job_logs_api_v1_repos__owner___repo__optimization_jobs__job_id__logs_get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'job_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Job Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'$ref': '#/components/schemas/PromptOptimizationJobLog'},\n",
       "         'title': 'Response List Job Logs Api V1 Repos  Owner   Repo  Optimization Jobs  Job Id  Logs Get'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'post': {'tags': ['optimization-jobs'],\n",
       "    'summary': 'Create Log',\n",
       "    'description': 'Create a new log entry for a prompt optimization job.',\n",
       "    'operationId': 'create_log_api_v1_repos__owner___repo__optimization_jobs__job_id__logs_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'job_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Job Id'}}],\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptOptimizationJobLogCreate'}}}},\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptOptimizationJobLog'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/api/v1/repos/{owner}/{repo}/optimization-jobs/{job_id}/logs/{log_id}': {'get': {'tags': ['optimization-jobs'],\n",
       "    'summary': 'Get Log',\n",
       "    'description': 'Get a specific prompt optimization job log.',\n",
       "    'operationId': 'get_log_api_v1_repos__owner___repo__optimization_jobs__job_id__logs__log_id__get',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'log_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Log Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptOptimizationJobLog'}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}},\n",
       "   'delete': {'tags': ['optimization-jobs'],\n",
       "    'summary': 'Delete Log',\n",
       "    'description': 'Delete a prompt optimization job log.',\n",
       "    'operationId': 'delete_log_api_v1_repos__owner___repo__optimization_jobs__job_id__logs__log_id__delete',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}],\n",
       "    'parameters': [{'name': 'log_id',\n",
       "      'in': 'path',\n",
       "      'required': True,\n",
       "      'schema': {'type': 'string', 'format': 'uuid', 'title': 'Log Id'}}],\n",
       "    'responses': {'200': {'description': 'Successful Response',\n",
       "      'content': {'application/json': {'schema': {}}}},\n",
       "     '422': {'description': 'Validation Error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}},\n",
       "  '/feedback/batch': {'post': {'description': 'Ingests a batch of feedback objects in a single JSON array payload.',\n",
       "    'consumes': ['application/json'],\n",
       "    'produces': ['application/json'],\n",
       "    'tags': ['feedback'],\n",
       "    'summary': 'Ingest Feedback (Batch JSON)',\n",
       "    'parameters': [],\n",
       "    'responses': {'202': {'description': 'Feedback batch ingested',\n",
       "      'content': {'application/json': {'schema': {'type': 'object',\n",
       "         'additionalProperties': {'allOf': [{'type': 'string'},\n",
       "           {'type': 'object',\n",
       "            'properties': {'message': {'type': 'string'}}}]}}}}},\n",
       "     '400': {'description': 'Bad Request',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '403': {'description': 'Forbidden',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '409': {'description': 'Conflict',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '422': {'description': 'Unprocessable Entity',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '429': {'description': 'Too Many Requests',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}}},\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'type': 'array',\n",
       "        'items': {'$ref': '#/components/schemas/feedback.FeedbackCreateSchema'}}}}}}},\n",
       "  '/runs': {'post': {'description': 'Queues a single run for ingestion. The request body must be a JSON-encoded run object that follows the Run schema.',\n",
       "    'consumes': ['application/json'],\n",
       "    'produces': ['application/json'],\n",
       "    'tags': ['runs'],\n",
       "    'summary': 'Create a Run',\n",
       "    'parameters': [],\n",
       "    'responses': {'202': {'description': 'Run created',\n",
       "      'content': {'application/json': {'schema': {'type': 'object',\n",
       "         'additionalProperties': {'allOf': [{'type': 'string'},\n",
       "           {'type': 'object',\n",
       "            'properties': {'message': {'type': 'string'}}}]}}}}},\n",
       "     '400': {'description': 'Bad Request',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '403': {'description': 'Forbidden',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '409': {'description': 'Conflict',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '422': {'description': 'Unprocessable Entity',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '429': {'description': 'Too Many Requests',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}}},\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.Run'}}}}}},\n",
       "  '/runs/batch': {'post': {'description': 'Ingests a batch of runs in a single JSON payload. The payload must have `post` and/or `patch` arrays containing run objects.\\nPrefer this endpoint over singleâ€‘run ingestion when submitting hundreds of runs, but `/runs/multipart` offers better handling for very large fields and attachments.',\n",
       "    'consumes': ['application/json'],\n",
       "    'produces': ['application/json'],\n",
       "    'tags': ['runs'],\n",
       "    'summary': 'Ingest Runs (Batch JSON)',\n",
       "    'parameters': [],\n",
       "    'responses': {'202': {'description': 'Runs batch ingested',\n",
       "      'content': {'application/json': {'schema': {'type': 'object',\n",
       "         'additionalProperties': {'allOf': [{'type': 'string'},\n",
       "           {'type': 'object',\n",
       "            'properties': {'message': {'type': 'string'}}}]}}}}},\n",
       "     '400': {'description': 'Bad Request',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '403': {'description': 'Forbidden',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '409': {'description': 'Conflict',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '422': {'description': 'Unprocessable Entity',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '429': {'description': 'Too Many Requests',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}}},\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'type': 'object',\n",
       "        'properties': {'patch': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/runs.Run'}},\n",
       "         'post': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/runs.Run'}}}}}}}}},\n",
       "  '/runs/multipart': {'post': {'description': 'Ingests multiple runs, feedback objects, and binary attachments in a single `multipart/form-data` request.\\n**Partâ€‘name pattern**: `<event>.<run_id>[.<field>]` where `event` âˆˆ {`post`, `patch`, `feedback`, `attachment`}.\\n* `post|patch.<run_id>` â€“\\xa0JSON run payload.\\n* `post|patch.<run_id>.<field>` â€“ outâ€‘ofâ€‘band run data (`inputs`, `outputs`, `events`, `error`, `extra`, `serialized`).\\n* `feedback.<run_id>` â€“ JSON feedback payload (must include `trace_id`).\\n* `attachment.<run_id>.<filename>` â€“ arbitrary binary attachment stored in S3.\\n**Headers**: every part must set `Content-Type` **and** either a `Content-Length` header or `length` parameter. Perâ€‘part `Content-Encoding` is **not** allowed; the topâ€‘level request may be `Content-Encoding: zstd`.\\n**Best performance** for highâ€‘volume ingestion.',\n",
       "    'consumes': ['multipart/form-data'],\n",
       "    'produces': ['application/json'],\n",
       "    'tags': ['runs'],\n",
       "    'summary': 'Ingest Runs (Multipart)',\n",
       "    'parameters': [],\n",
       "    'responses': {'202': {'description': 'Accepted',\n",
       "      'content': {'application/json': {'schema': {'type': 'object',\n",
       "         'additionalProperties': {'type': 'string'}}}}},\n",
       "     '400': {'description': 'Bad Request',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '403': {'description': 'Forbidden',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '409': {'description': 'Conflict',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '422': {'description': 'Unprocessable Entity',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '429': {'description': 'Too Many Requests',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}}},\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'multipart/form-data': {'schema': {'type': 'object',\n",
       "        'properties': {'post.{run_id}': {'type': 'string',\n",
       "          'format': 'binary',\n",
       "          'description': 'Run to create (JSON)'},\n",
       "         'patch.{run_id}': {'type': 'string',\n",
       "          'format': 'binary',\n",
       "          'description': 'Run to update (JSON)'},\n",
       "         'post.{run_id}.inputs': {'type': 'string',\n",
       "          'format': 'binary',\n",
       "          'description': 'Large inputs object (JSON) stored outâ€‘ofâ€‘band'},\n",
       "         'patch.{run_id}.outputs': {'type': 'string',\n",
       "          'format': 'binary',\n",
       "          'description': 'Large outputs object (JSON) stored outâ€‘ofâ€‘band'},\n",
       "         'feedback.{run_id}': {'type': 'string',\n",
       "          'format': 'binary',\n",
       "          'description': 'Feedback object (JSON) â€“ must include trace_id'},\n",
       "         'attachment.{run_id}.{filename}': {'type': 'file',\n",
       "          'format': 'binary',\n",
       "          'description': 'Binary attachment linked to run {run_id}'}},\n",
       "        'required': []}}}}}},\n",
       "  '/runs/{run_id}': {'patch': {'description': 'Updates a run identified by its ID. The body should contain only the fields to be changed; unknown fields are ignored.',\n",
       "    'consumes': ['application/json'],\n",
       "    'produces': ['application/json'],\n",
       "    'tags': ['runs'],\n",
       "    'summary': 'Update a Run',\n",
       "    'parameters': [{'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'description': 'Run ID',\n",
       "      'name': 'run_id',\n",
       "      'in': 'path',\n",
       "      'required': True}],\n",
       "    'responses': {'202': {'description': 'Run updated',\n",
       "      'content': {'application/json': {'schema': {'type': 'object',\n",
       "         'additionalProperties': {'allOf': [{'type': 'string'},\n",
       "           {'type': 'object',\n",
       "            'properties': {'message': {'type': 'string'}}}]}}}}},\n",
       "     '400': {'description': 'Bad Request',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '403': {'description': 'Forbidden',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '404': {'description': 'Not Found',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '409': {'description': 'Conflict',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '422': {'description': 'Unprocessable Entity',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}},\n",
       "     '429': {'description': 'Too Many Requests',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.ErrorResponse'}}}}},\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/runs.Run'}}}}}},\n",
       "  '/v1/platform/alerts/{session_id}': {'post': {'description': 'Creates a new alert rule. The request body must be a JSON-encoded alert rule object that follows the CreateAlertRuleRequest schema.',\n",
       "    'consumes': ['application/json'],\n",
       "    'produces': ['application/json'],\n",
       "    'tags': ['alert_rules'],\n",
       "    'summary': 'Create an alert rule',\n",
       "    'parameters': [{'type': 'string',\n",
       "      'description': 'LangSmith API Key',\n",
       "      'name': 'X-API-Key',\n",
       "      'in': 'header',\n",
       "      'required': True},\n",
       "     {'type': 'string',\n",
       "      'description': 'Tenant ID',\n",
       "      'name': 'X-Tenant-ID',\n",
       "      'in': 'header',\n",
       "      'required': True},\n",
       "     {'type': 'string',\n",
       "      'description': 'Session ID',\n",
       "      'name': 'session_id',\n",
       "      'in': 'path',\n",
       "      'required': True}],\n",
       "    'responses': {'201': {'description': 'Alert rule created',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.AlertRuleResponse'}}}},\n",
       "     '400': {'description': 'Bad request',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}},\n",
       "     '403': {'description': 'Forbidden',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}},\n",
       "     '429': {'description': 'Alert Rule Limit Reached',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}},\n",
       "     '500': {'description': 'Internal server error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}},\n",
       "     '503': {'description': 'Service unavailable',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}}},\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.CreateAlertRuleRequest'}}}}}},\n",
       "  '/v1/platform/alerts/{session_id}/test': {'post': {'description': 'Tests an alert action which will fire a notification to all configured recipients if the configuration is valid.',\n",
       "    'produces': ['application/json'],\n",
       "    'tags': ['alert_rules'],\n",
       "    'summary': 'Test an alert action to determine if configuration is valid',\n",
       "    'parameters': [{'type': 'string',\n",
       "      'description': 'LangSmith API Key',\n",
       "      'name': 'X-API-Key',\n",
       "      'in': 'header',\n",
       "      'required': True},\n",
       "     {'type': 'string',\n",
       "      'description': 'Tenant ID',\n",
       "      'name': 'X-Tenant-ID',\n",
       "      'in': 'header',\n",
       "      'required': True},\n",
       "     {'type': 'string',\n",
       "      'description': 'Session ID',\n",
       "      'name': 'session_id',\n",
       "      'in': 'path',\n",
       "      'required': True},\n",
       "     {'type': 'string',\n",
       "      'description': 'Alert rule ID',\n",
       "      'name': 'alert_rule_id',\n",
       "      'in': 'path',\n",
       "      'required': True}],\n",
       "    'responses': {'200': {'description': 'Alert action fired successfully',\n",
       "      'content': {'application/json': {'schema': {'type': 'object',\n",
       "         'additionalProperties': {'allOf': [{'type': 'string'},\n",
       "           {'type': 'object',\n",
       "            'properties': {'message': {'type': 'string'}}}]}}}}},\n",
       "     '400': {'description': 'Bad request',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}},\n",
       "     '403': {'description': 'Forbidden',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}},\n",
       "     '500': {'description': 'Internal server error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}},\n",
       "     '503': {'description': 'Service unavailable',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}}}}},\n",
       "  '/v1/platform/alerts/{session_id}/{alert_rule_id}': {'get': {'description': 'Gets an alert rule.',\n",
       "    'produces': ['application/json'],\n",
       "    'tags': ['alert_rules'],\n",
       "    'summary': 'Get an alert rule',\n",
       "    'parameters': [{'type': 'string',\n",
       "      'description': 'LangSmith API Key',\n",
       "      'name': 'X-API-Key',\n",
       "      'in': 'header',\n",
       "      'required': True},\n",
       "     {'type': 'string',\n",
       "      'description': 'Tenant ID',\n",
       "      'name': 'X-Tenant-ID',\n",
       "      'in': 'header',\n",
       "      'required': True},\n",
       "     {'type': 'string',\n",
       "      'description': 'Session ID',\n",
       "      'name': 'session_id',\n",
       "      'in': 'path',\n",
       "      'required': True},\n",
       "     {'type': 'string',\n",
       "      'description': 'Alert rule ID',\n",
       "      'name': 'alert_rule_id',\n",
       "      'in': 'path',\n",
       "      'required': True}],\n",
       "    'responses': {'200': {'description': 'Alert rule',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.AlertRuleResponse'}}}},\n",
       "     '400': {'description': 'Bad request',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}},\n",
       "     '403': {'description': 'Forbidden',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}},\n",
       "     '404': {'description': 'Not found',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}},\n",
       "     '500': {'description': 'Internal server error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}},\n",
       "     '503': {'description': 'Service unavailable',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}}}},\n",
       "   'delete': {'description': 'Deletes an alert rule',\n",
       "    'produces': ['application/json'],\n",
       "    'tags': ['alert_rules'],\n",
       "    'summary': 'Delete an alert rule',\n",
       "    'parameters': [{'type': 'string',\n",
       "      'description': 'LangSmith API Key',\n",
       "      'name': 'X-API-Key',\n",
       "      'in': 'header',\n",
       "      'required': True},\n",
       "     {'type': 'string',\n",
       "      'description': 'Tenant ID',\n",
       "      'name': 'X-Tenant-ID',\n",
       "      'in': 'header',\n",
       "      'required': True},\n",
       "     {'type': 'string',\n",
       "      'description': 'Session ID',\n",
       "      'name': 'session_id',\n",
       "      'in': 'path',\n",
       "      'required': True},\n",
       "     {'type': 'string',\n",
       "      'description': 'Alert rule ID',\n",
       "      'name': 'alert_rule_id',\n",
       "      'in': 'path',\n",
       "      'required': True}],\n",
       "    'responses': {'200': {'description': 'Alert rule deleted',\n",
       "      'content': {'application/json': {'schema': {'type': 'object',\n",
       "         'additionalProperties': {'allOf': [{'type': 'string'},\n",
       "           {'type': 'object',\n",
       "            'properties': {'message': {'type': 'string'}}}]}}}}},\n",
       "     '400': {'description': 'Bad request',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}},\n",
       "     '403': {'description': 'Forbidden',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}},\n",
       "     '404': {'description': 'Not found',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}},\n",
       "     '500': {'description': 'Internal server error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}},\n",
       "     '503': {'description': 'Service unavailable',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}}}},\n",
       "   'patch': {'description': 'Updates an alert rule.',\n",
       "    'produces': ['application/json'],\n",
       "    'tags': ['alert_rules'],\n",
       "    'summary': 'Update an alert rule',\n",
       "    'parameters': [{'type': 'string',\n",
       "      'description': 'LangSmith API Key',\n",
       "      'name': 'X-API-Key',\n",
       "      'in': 'header',\n",
       "      'required': True},\n",
       "     {'type': 'string',\n",
       "      'description': 'Tenant ID',\n",
       "      'name': 'X-Tenant-ID',\n",
       "      'in': 'header',\n",
       "      'required': True},\n",
       "     {'type': 'string',\n",
       "      'description': 'Session ID',\n",
       "      'name': 'session_id',\n",
       "      'in': 'path',\n",
       "      'required': True},\n",
       "     {'type': 'string',\n",
       "      'description': 'Alert rule ID',\n",
       "      'name': 'alert_rule_id',\n",
       "      'in': 'path',\n",
       "      'required': True}],\n",
       "    'responses': {'200': {'description': 'Alert rule updated',\n",
       "      'content': {'application/json': {'schema': {'type': 'object',\n",
       "         'additionalProperties': {'allOf': [{'type': 'string'},\n",
       "           {'type': 'object',\n",
       "            'properties': {'message': {'type': 'string'}}}]}}}}},\n",
       "     '400': {'description': 'Bad request',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}},\n",
       "     '403': {'description': 'Forbidden',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}},\n",
       "     '404': {'description': 'Not found',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}},\n",
       "     '500': {'description': 'Internal server error',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}},\n",
       "     '503': {'description': 'Service unavailable',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.ErrorResponse'}}}}},\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'application/json': {'schema': {'$ref': '#/components/schemas/alerts.UpdateAlertRuleRequest'}}}}}},\n",
       "  '/v1/platform/datasets/{dataset_id}/examples': {'post': {'description': 'This endpoint allows clients to upload examples to a specified dataset by sending a multipart/form-data POST request.\\nEach form part contains either JSON-encoded data or binary attachment files associated with an example.',\n",
       "    'consumes': ['multipart/form-data'],\n",
       "    'produces': ['application/json'],\n",
       "    'tags': ['examples'],\n",
       "    'summary': 'Upload Examples',\n",
       "    'parameters': [{'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'description': 'Dataset ID',\n",
       "      'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True}],\n",
       "    'responses': {'201': {'description': 'Created',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/examples.ExamplesCreatedResponse'}}}},\n",
       "     '400': {'description': 'Bad Request',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/examples.ErrorResponse'}}}},\n",
       "     '403': {'description': 'Forbidden',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/examples.ErrorResponse'}}}},\n",
       "     '409': {'description': 'Conflict',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/examples.ErrorResponse'}}}},\n",
       "     '422': {'description': 'Unprocessable Entity',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/examples.ErrorResponse'}}}}},\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'multipart/form-data': {'schema': {'type': 'object',\n",
       "        'properties': {'{example_id}': {'type': 'string',\n",
       "          'format': 'binary',\n",
       "          'description': \"The Example info as JSON. Can have fields 'metadata', 'split', 'use_source_run_io', 'source_run_id', 'created_at', 'modified_at'\"},\n",
       "         '{example_id}.inputs': {'type': 'string',\n",
       "          'format': 'binary',\n",
       "          'description': 'The Example inputs as JSON'},\n",
       "         '{example_id}.outputs': {'type': 'string',\n",
       "          'format': 'binary',\n",
       "          'description': 'THe Example outputs as JSON'},\n",
       "         '{example_id}.attachments.{name}': {'type': 'string',\n",
       "          'format': 'binary',\n",
       "          'description': 'File attachment named {name}'}},\n",
       "        'required': ['{example_id}', '{example_id}.inputs']}}}}},\n",
       "   'patch': {'description': 'This endpoint allows clients to update existing examples in a specified dataset by sending a multipart/form-data PATCH request.\\nEach form part contains either JSON-encoded data or binary attachment files to update an example.',\n",
       "    'consumes': ['multipart/form-data'],\n",
       "    'produces': ['application/json'],\n",
       "    'tags': ['examples'],\n",
       "    'summary': 'Update Examples',\n",
       "    'parameters': [{'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'description': 'Dataset ID',\n",
       "      'name': 'dataset_id',\n",
       "      'in': 'path',\n",
       "      'required': True}],\n",
       "    'responses': {'201': {'description': 'Created',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/examples.ExamplesUpdatedResponse'}}}},\n",
       "     '400': {'description': 'Bad Request',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/examples.ErrorResponse'}}}},\n",
       "     '403': {'description': 'Forbidden',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/examples.ErrorResponse'}}}},\n",
       "     '404': {'description': 'Not Found',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/examples.ErrorResponse'}}}},\n",
       "     '409': {'description': 'Conflict',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/examples.ErrorResponse'}}}},\n",
       "     '422': {'description': 'Unprocessable Entity',\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/examples.ErrorResponse'}}}}},\n",
       "    'requestBody': {'required': True,\n",
       "     'content': {'multipart/form-data': {'schema': {'type': 'object',\n",
       "        'properties': {'{example_id}': {'type': 'string',\n",
       "          'format': 'binary',\n",
       "          'description': \"The Example update info as JSON. Can have fields 'metadata', 'split'\"},\n",
       "         '{example_id}.inputs': {'type': 'string',\n",
       "          'format': 'binary',\n",
       "          'description': 'The updated Example inputs as JSON'},\n",
       "         '{example_id}.outputs': {'type': 'string',\n",
       "          'format': 'binary',\n",
       "          'description': 'The updated Example outputs as JSON'},\n",
       "         '{example_id}.attachments_operations': {'type': 'string',\n",
       "          'format': 'binary',\n",
       "          'description': 'JSON describing attachment operations (retain, rename)'},\n",
       "         '{example_id}.attachment.{name}': {'type': 'string',\n",
       "          'format': 'binary',\n",
       "          'description': 'New file attachment named {name}'}},\n",
       "        'required': ['{example_id}']}}}}}}},\n",
       " 'components': {'schemas': {'AIMessage': {'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "       {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "        'type': 'array'}],\n",
       "      'title': 'Content'},\n",
       "     'additional_kwargs': {'type': 'object', 'title': 'Additional Kwargs'},\n",
       "     'response_metadata': {'type': 'object', 'title': 'Response Metadata'},\n",
       "     'type': {'type': 'string',\n",
       "      'const': 'ai',\n",
       "      'title': 'Type',\n",
       "      'default': 'ai'},\n",
       "     'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "     'example': {'type': 'boolean', 'title': 'Example', 'default': False},\n",
       "     'tool_calls': {'items': {'$ref': '#/components/schemas/ToolCall'},\n",
       "      'type': 'array',\n",
       "      'title': 'Tool Calls',\n",
       "      'default': []},\n",
       "     'invalid_tool_calls': {'items': {'$ref': '#/components/schemas/InvalidToolCall'},\n",
       "      'type': 'array',\n",
       "      'title': 'Invalid Tool Calls',\n",
       "      'default': []},\n",
       "     'usage_metadata': {'anyOf': [{'$ref': '#/components/schemas/UsageMetadata'},\n",
       "       {'type': 'null'}]}},\n",
       "    'additionalProperties': True,\n",
       "    'type': 'object',\n",
       "    'required': ['content'],\n",
       "    'title': 'AIMessage',\n",
       "    'description': 'Message from an AI.\\n\\nAIMessage is returned from a chat model as a response to a prompt.\\n\\nThis message represents the output of the model and consists of both\\nthe raw output as returned by the model together standardized fields\\n(e.g., tool calls, usage metadata) added by the LangChain framework.'},\n",
       "   'AIMessageChunk': {'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "       {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "        'type': 'array'}],\n",
       "      'title': 'Content'},\n",
       "     'additional_kwargs': {'type': 'object', 'title': 'Additional Kwargs'},\n",
       "     'response_metadata': {'type': 'object', 'title': 'Response Metadata'},\n",
       "     'type': {'type': 'string',\n",
       "      'const': 'AIMessageChunk',\n",
       "      'title': 'Type',\n",
       "      'default': 'AIMessageChunk'},\n",
       "     'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "     'example': {'type': 'boolean', 'title': 'Example', 'default': False},\n",
       "     'tool_calls': {'items': {'$ref': '#/components/schemas/ToolCall'},\n",
       "      'type': 'array',\n",
       "      'title': 'Tool Calls',\n",
       "      'default': []},\n",
       "     'invalid_tool_calls': {'items': {'$ref': '#/components/schemas/InvalidToolCall'},\n",
       "      'type': 'array',\n",
       "      'title': 'Invalid Tool Calls',\n",
       "      'default': []},\n",
       "     'usage_metadata': {'anyOf': [{'$ref': '#/components/schemas/UsageMetadata'},\n",
       "       {'type': 'null'}]},\n",
       "     'tool_call_chunks': {'items': {'$ref': '#/components/schemas/ToolCallChunk'},\n",
       "      'type': 'array',\n",
       "      'title': 'Tool Call Chunks',\n",
       "      'default': []}},\n",
       "    'additionalProperties': True,\n",
       "    'type': 'object',\n",
       "    'required': ['content'],\n",
       "    'title': 'AIMessageChunk',\n",
       "    'description': 'Message chunk from an AI.'},\n",
       "   'APIFeedbackSource': {'properties': {'type': {'type': 'string',\n",
       "      'title': 'Type',\n",
       "      'default': 'api'},\n",
       "     'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Metadata'}},\n",
       "    'type': 'object',\n",
       "    'title': 'APIFeedbackSource',\n",
       "    'description': 'API feedback source.'},\n",
       "   'APIKeyCreateRequest': {'properties': {'description': {'type': 'string',\n",
       "      'title': 'Description',\n",
       "      'default': 'Default API key'},\n",
       "     'read_only': {'type': 'boolean', 'title': 'Read Only', 'default': False}},\n",
       "    'type': 'object',\n",
       "    'title': 'APIKeyCreateRequest',\n",
       "    'description': 'API key POST schema.'},\n",
       "   'APIKeyCreateResponse': {'properties': {'created_at': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Created At'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'short_key': {'type': 'string', 'title': 'Short Key'},\n",
       "     'description': {'type': 'string', 'title': 'Description'},\n",
       "     'read_only': {'type': 'boolean', 'title': 'Read Only', 'default': False},\n",
       "     'last_used_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Last Used At'},\n",
       "     'key': {'type': 'string', 'title': 'Key'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id', 'short_key', 'description', 'key'],\n",
       "    'title': 'APIKeyCreateResponse',\n",
       "    'description': 'API key POST schema.'},\n",
       "   'APIKeyGetResponse': {'properties': {'created_at': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Created At'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'short_key': {'type': 'string', 'title': 'Short Key'},\n",
       "     'description': {'type': 'string', 'title': 'Description'},\n",
       "     'read_only': {'type': 'boolean', 'title': 'Read Only', 'default': False},\n",
       "     'last_used_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Last Used At'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id', 'short_key', 'description'],\n",
       "    'title': 'APIKeyGetResponse',\n",
       "    'description': 'API key GET schema.'},\n",
       "   'AccessScope': {'type': 'string',\n",
       "    'enum': ['organization', 'workspace'],\n",
       "    'title': 'AccessScope'},\n",
       "   'AllowedLoginMethodsUpdate': {'properties': {'sso_only': {'type': 'boolean',\n",
       "      'title': 'Sso Only'}},\n",
       "    'type': 'object',\n",
       "    'required': ['sso_only'],\n",
       "    'title': 'AllowedLoginMethodsUpdate'},\n",
       "   'AnnotationQueueBulkDeleteRunsRequest': {'properties': {'delete_all': {'type': 'boolean',\n",
       "      'title': 'Delete All',\n",
       "      'default': False},\n",
       "     'run_ids': {'anyOf': [{'items': {'type': 'string', 'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Run Ids'},\n",
       "     'exclude_run_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Exclude Run Ids'}},\n",
       "    'type': 'object',\n",
       "    'title': 'AnnotationQueueBulkDeleteRunsRequest'},\n",
       "   'AnnotationQueueCreateSchema': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'default_dataset': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Default Dataset'},\n",
       "     'num_reviewers_per_item': {'anyOf': [{'type': 'integer'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Num Reviewers Per Item',\n",
       "      'default': 1},\n",
       "     'enable_reservations': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Enable Reservations',\n",
       "      'default': True},\n",
       "     'reservation_minutes': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Reservation Minutes',\n",
       "      'default': 1},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'rubric_items': {'anyOf': [{'items': {'$ref': '#/components/schemas/AnnotationQueueRubricItemSchema'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Rubric Items'},\n",
       "     'rubric_instructions': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Rubric Instructions'},\n",
       "     'session_ids': {'anyOf': [{'items': {'type': 'string', 'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Session Ids'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name'],\n",
       "    'title': 'AnnotationQueueCreateSchema',\n",
       "    'description': 'AnnotationQueue schema.'},\n",
       "   'AnnotationQueueRubricItemSchema': {'properties': {'feedback_key': {'type': 'string',\n",
       "      'title': 'Feedback Key'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'value_descriptions': {'anyOf': [{'additionalProperties': {'type': 'string'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Value Descriptions'},\n",
       "     'score_descriptions': {'anyOf': [{'additionalProperties': {'type': 'string'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Score Descriptions'}},\n",
       "    'type': 'object',\n",
       "    'required': ['feedback_key'],\n",
       "    'title': 'AnnotationQueueRubricItemSchema'},\n",
       "   'AnnotationQueueRunSchema': {'properties': {'run_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Run Id'},\n",
       "     'queue_id': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'},\n",
       "     'last_reviewed_time': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Last Reviewed Time'},\n",
       "     'added_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Added At'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['run_id', 'queue_id', 'id'],\n",
       "    'title': 'AnnotationQueueRunSchema'},\n",
       "   'AnnotationQueueRunUpdateSchema': {'properties': {'last_reviewed_time': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Last Reviewed Time'},\n",
       "     'added_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Added At'}},\n",
       "    'type': 'object',\n",
       "    'title': 'AnnotationQueueRunUpdateSchema'},\n",
       "   'AnnotationQueueSchema': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'default_dataset': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Default Dataset'},\n",
       "     'num_reviewers_per_item': {'anyOf': [{'type': 'integer'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Num Reviewers Per Item',\n",
       "      'default': 1},\n",
       "     'enable_reservations': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Enable Reservations',\n",
       "      'default': True},\n",
       "     'reservation_minutes': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Reservation Minutes',\n",
       "      'default': 1},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'tenant_id': {'type': 'string', 'format': 'uuid', 'title': 'Tenant Id'},\n",
       "     'source_rule_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Source Rule Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name', 'id', 'tenant_id'],\n",
       "    'title': 'AnnotationQueueSchema',\n",
       "    'description': 'AnnotationQueue schema.'},\n",
       "   'AnnotationQueueSchemaWithRubric': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'default_dataset': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Default Dataset'},\n",
       "     'num_reviewers_per_item': {'anyOf': [{'type': 'integer'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Num Reviewers Per Item',\n",
       "      'default': 1},\n",
       "     'enable_reservations': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Enable Reservations',\n",
       "      'default': True},\n",
       "     'reservation_minutes': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Reservation Minutes',\n",
       "      'default': 1},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'tenant_id': {'type': 'string', 'format': 'uuid', 'title': 'Tenant Id'},\n",
       "     'source_rule_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Source Rule Id'},\n",
       "     'rubric_items': {'anyOf': [{'items': {'$ref': '#/components/schemas/AnnotationQueueRubricItemSchema'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Rubric Items'},\n",
       "     'rubric_instructions': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Rubric Instructions'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name', 'id', 'tenant_id'],\n",
       "    'title': 'AnnotationQueueSchemaWithRubric',\n",
       "    'description': 'AnnotationQueue schema with rubric.'},\n",
       "   'AnnotationQueueSchemaWithSize': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'default_dataset': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Default Dataset'},\n",
       "     'num_reviewers_per_item': {'anyOf': [{'type': 'integer'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Num Reviewers Per Item',\n",
       "      'default': 1},\n",
       "     'enable_reservations': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Enable Reservations',\n",
       "      'default': True},\n",
       "     'reservation_minutes': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Reservation Minutes',\n",
       "      'default': 1},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'tenant_id': {'type': 'string', 'format': 'uuid', 'title': 'Tenant Id'},\n",
       "     'source_rule_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Source Rule Id'},\n",
       "     'total_runs': {'type': 'integer', 'title': 'Total Runs'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name', 'id', 'tenant_id', 'total_runs'],\n",
       "    'title': 'AnnotationQueueSchemaWithSize',\n",
       "    'description': 'AnnotationQueue schema with size.'},\n",
       "   'AnnotationQueueSizeSchema': {'properties': {'size': {'type': 'integer',\n",
       "      'title': 'Size'}},\n",
       "    'type': 'object',\n",
       "    'required': ['size'],\n",
       "    'title': 'AnnotationQueueSizeSchema',\n",
       "    'description': 'Size of an Annotation Queue'},\n",
       "   'AnnotationQueueUpdateSchema': {'properties': {'name': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'default_dataset': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Default Dataset'},\n",
       "     'num_reviewers_per_item': {'anyOf': [{'type': 'integer'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Num Reviewers Per Item',\n",
       "      'default': 1},\n",
       "     'enable_reservations': {'type': 'boolean',\n",
       "      'title': 'Enable Reservations',\n",
       "      'default': True},\n",
       "     'reservation_minutes': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Reservation Minutes'},\n",
       "     'rubric_items': {'anyOf': [{'items': {'$ref': '#/components/schemas/AnnotationQueueRubricItemSchema'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Rubric Items'},\n",
       "     'rubric_instructions': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Rubric Instructions'}},\n",
       "    'type': 'object',\n",
       "    'title': 'AnnotationQueueUpdateSchema',\n",
       "    'description': 'AnnotationQueue update schema.'},\n",
       "   'AppFeedbackSource': {'properties': {'type': {'type': 'string',\n",
       "      'title': 'Type',\n",
       "      'default': 'app'},\n",
       "     'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Metadata'}},\n",
       "    'type': 'object',\n",
       "    'title': 'AppFeedbackSource',\n",
       "    'description': 'Feedback from the LangChainPlus App.'},\n",
       "   'Artifact': {'properties': {'id': {'type': 'string', 'title': 'Id'},\n",
       "     'contents': {'items': {'$ref': '#/components/schemas/ArtifactContent'},\n",
       "      'type': 'array',\n",
       "      'title': 'Contents'},\n",
       "     'current_content_index': {'type': 'integer',\n",
       "      'title': 'Current Content Index'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id', 'contents', 'current_content_index'],\n",
       "    'title': 'Artifact'},\n",
       "   'ArtifactContent': {'properties': {'index': {'type': 'integer',\n",
       "      'title': 'Index'},\n",
       "     'content': {'type': 'string', 'title': 'Content'}},\n",
       "    'type': 'object',\n",
       "    'required': ['index', 'content'],\n",
       "    'title': 'ArtifactContent'},\n",
       "   'AttachmentsOperations': {'properties': {'rename': {'additionalProperties': {'type': 'string'},\n",
       "      'type': 'object',\n",
       "      'title': 'Rename',\n",
       "      'description': 'Mapping of old attachment names to new names'},\n",
       "     'retain': {'items': {'type': 'string'},\n",
       "      'type': 'array',\n",
       "      'title': 'Retain',\n",
       "      'description': 'List of attachment names to keep'}},\n",
       "    'type': 'object',\n",
       "    'title': 'AttachmentsOperations'},\n",
       "   'AuthProvider': {'type': 'string',\n",
       "    'enum': ['email',\n",
       "     'supabase:non-sso',\n",
       "     'supabase:sso',\n",
       "     'oidc',\n",
       "     'custom-oidc'],\n",
       "    'title': 'AuthProvider'},\n",
       "   'AutoEvalFeedbackSource': {'properties': {'type': {'type': 'string',\n",
       "      'title': 'Type',\n",
       "      'default': 'auto_eval'},\n",
       "     'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Metadata'}},\n",
       "    'type': 'object',\n",
       "    'title': 'AutoEvalFeedbackSource',\n",
       "    'description': 'Auto eval feedback source.'},\n",
       "   'BasicAuthMemberCreate': {'properties': {'user_id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'User Id'},\n",
       "     'ls_user_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Ls User Id'},\n",
       "     'email': {'type': 'string', 'title': 'Email'},\n",
       "     'read_only': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Read Only'},\n",
       "     'role_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Role Id'},\n",
       "     'password': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Password'},\n",
       "     'full_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Full Name'},\n",
       "     'workspace_role_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Workspace Role Id'},\n",
       "     'workspace_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Workspace Ids'}},\n",
       "    'type': 'object',\n",
       "    'required': ['email'],\n",
       "    'title': 'BasicAuthMemberCreate'},\n",
       "   'BasicAuthResponse': {'properties': {'access_token': {'type': 'string',\n",
       "      'title': 'Access Token'}},\n",
       "    'type': 'object',\n",
       "    'required': ['access_token'],\n",
       "    'title': 'BasicAuthResponse'},\n",
       "   'BasicAuthUserPatch': {'properties': {'password': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Password'},\n",
       "     'full_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Full Name'}},\n",
       "    'type': 'object',\n",
       "    'title': 'BasicAuthUserPatch'},\n",
       "   'BatchIngestConfig': {'properties': {'use_multipart_endpoint': {'type': 'boolean',\n",
       "      'title': 'Use Multipart Endpoint',\n",
       "      'default': True},\n",
       "     'scale_up_qsize_trigger': {'type': 'integer',\n",
       "      'title': 'Scale Up Qsize Trigger',\n",
       "      'default': 1000},\n",
       "     'scale_up_nthreads_limit': {'type': 'integer',\n",
       "      'title': 'Scale Up Nthreads Limit',\n",
       "      'default': 16},\n",
       "     'scale_down_nempty_trigger': {'type': 'integer',\n",
       "      'title': 'Scale Down Nempty Trigger',\n",
       "      'default': 4},\n",
       "     'size_limit': {'type': 'integer', 'title': 'Size Limit', 'default': 100},\n",
       "     'size_limit_bytes': {'type': 'integer',\n",
       "      'title': 'Size Limit Bytes',\n",
       "      'default': 20971520}},\n",
       "    'type': 'object',\n",
       "    'title': 'BatchIngestConfig',\n",
       "    'description': 'Batch ingest config.'},\n",
       "   'BodyParamsForRunSchema': {'properties': {'id': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Id'},\n",
       "     'trace': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Trace'},\n",
       "     'parent_run': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Parent Run'},\n",
       "     'run_type': {'anyOf': [{'$ref': '#/components/schemas/RunTypeEnum'},\n",
       "       {'type': 'null'}]},\n",
       "     'session': {'anyOf': [{'items': {'type': 'string', 'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Session'},\n",
       "     'reference_example': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Reference Example'},\n",
       "     'execution_order': {'anyOf': [{'type': 'integer',\n",
       "        'maximum': 1.0,\n",
       "        'minimum': 1.0},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Execution Order'},\n",
       "     'start_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'End Time'},\n",
       "     'error': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Error'},\n",
       "     'query': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Query'},\n",
       "     'filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Filter'},\n",
       "     'trace_filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Trace Filter'},\n",
       "     'tree_filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Tree Filter'},\n",
       "     'is_root': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Is Root'},\n",
       "     'data_source_type': {'anyOf': [{'$ref': '#/components/schemas/RunsFilterDataSourceTypeEnum'},\n",
       "       {'type': 'null'}]},\n",
       "     'skip_pagination': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Skip Pagination'},\n",
       "     'search_filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Search Filter'},\n",
       "     'use_experimental_search': {'type': 'boolean',\n",
       "      'title': 'Use Experimental Search',\n",
       "      'default': False},\n",
       "     'cursor': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Cursor'},\n",
       "     'limit': {'type': 'integer',\n",
       "      'maximum': 100.0,\n",
       "      'minimum': 1.0,\n",
       "      'title': 'Limit',\n",
       "      'default': 100},\n",
       "     'select': {'items': {'$ref': '#/components/schemas/RunSelect'},\n",
       "      'type': 'array',\n",
       "      'title': 'Select',\n",
       "      'default': ['id',\n",
       "       'name',\n",
       "       'run_type',\n",
       "       'start_time',\n",
       "       'end_time',\n",
       "       'status',\n",
       "       'error',\n",
       "       'extra',\n",
       "       'events',\n",
       "       'inputs',\n",
       "       'outputs',\n",
       "       'parent_run_id',\n",
       "       'manifest_id',\n",
       "       'manifest_s3_id',\n",
       "       'manifest',\n",
       "       'session_id',\n",
       "       'serialized',\n",
       "       'reference_example_id',\n",
       "       'reference_dataset_id',\n",
       "       'total_tokens',\n",
       "       'prompt_tokens',\n",
       "       'completion_tokens',\n",
       "       'total_cost',\n",
       "       'prompt_cost',\n",
       "       'completion_cost',\n",
       "       'price_model_id',\n",
       "       'first_token_time',\n",
       "       'trace_id',\n",
       "       'dotted_order',\n",
       "       'last_queued_at',\n",
       "       'feedback_stats',\n",
       "       'parent_run_ids',\n",
       "       'tags',\n",
       "       'in_dataset',\n",
       "       'app_path',\n",
       "       'share_token',\n",
       "       'trace_tier',\n",
       "       'trace_first_received_at',\n",
       "       'ttl_seconds',\n",
       "       'trace_upgrade',\n",
       "       'thread_id']},\n",
       "     'order': {'$ref': '#/components/schemas/RunDateOrder', 'default': 'desc'},\n",
       "     'skip_prev_cursor': {'type': 'boolean',\n",
       "      'title': 'Skip Prev Cursor',\n",
       "      'default': False}},\n",
       "    'type': 'object',\n",
       "    'title': 'BodyParamsForRunSchema',\n",
       "    'description': 'Query params for run endpoints.'},\n",
       "   'Body_clone_dataset_api_v1_datasets_clone_post': {'properties': {'target_dataset_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Target Dataset Id'},\n",
       "     'source_dataset_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Source Dataset Id'},\n",
       "     'as_of': {'anyOf': [{'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'string'}],\n",
       "        'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'As Of'},\n",
       "     'examples': {'items': {'type': 'string', 'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'title': 'Examples',\n",
       "      'default': []}},\n",
       "    'type': 'object',\n",
       "    'required': ['target_dataset_id', 'source_dataset_id'],\n",
       "    'title': 'Body_clone_dataset_api_v1_datasets_clone_post'},\n",
       "   'Body_delete_runs_api_v1_runs_delete_post': {'properties': {'session_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Session Id'},\n",
       "     'trace_ids': {'items': {'type': 'string', 'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'title': 'Trace Ids'}},\n",
       "    'type': 'object',\n",
       "    'required': ['session_id', 'trace_ids'],\n",
       "    'title': 'Body_delete_runs_api_v1_runs_delete_post'},\n",
       "   'Body_execute_api_v1_ace_execute_post': {'properties': {'args': {'items': {},\n",
       "      'type': 'array',\n",
       "      'title': 'Args'},\n",
       "     'code': {'type': 'string', 'title': 'Code'}},\n",
       "    'type': 'object',\n",
       "    'required': ['args', 'code'],\n",
       "    'title': 'Body_execute_api_v1_ace_execute_post'},\n",
       "   'Body_update_dataset_splits_api_v1_datasets__dataset_id__splits_put': {'properties': {'split_name': {'type': 'string',\n",
       "      'title': 'Split Name'},\n",
       "     'examples': {'items': {'type': 'string', 'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'title': 'Examples'},\n",
       "     'remove': {'type': 'boolean', 'title': 'Remove', 'default': False}},\n",
       "    'type': 'object',\n",
       "    'required': ['split_name', 'examples'],\n",
       "    'title': 'Body_update_dataset_splits_api_v1_datasets__dataset_id__splits_put'},\n",
       "   'Body_upload_csv_dataset_api_v1_datasets_upload_post': {'properties': {'file': {'type': 'string',\n",
       "      'format': 'binary',\n",
       "      'title': 'File'},\n",
       "     'input_keys': {'items': {'type': 'string'},\n",
       "      'type': 'array',\n",
       "      'title': 'Input Keys'},\n",
       "     'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'data_type': {'$ref': '#/components/schemas/DataType', 'default': 'kv'},\n",
       "     'output_keys': {'items': {'type': 'string'},\n",
       "      'type': 'array',\n",
       "      'title': 'Output Keys',\n",
       "      'default': []},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'}},\n",
       "    'type': 'object',\n",
       "    'required': ['file', 'input_keys'],\n",
       "    'title': 'Body_upload_csv_dataset_api_v1_datasets_upload_post'},\n",
       "   'Body_upload_examples_from_csv_api_v1_examples_upload__dataset_id__post': {'properties': {'file': {'type': 'string',\n",
       "      'format': 'binary',\n",
       "      'title': 'File'},\n",
       "     'input_keys': {'items': {'type': 'string'},\n",
       "      'type': 'array',\n",
       "      'title': 'Input Keys'},\n",
       "     'output_keys': {'items': {'type': 'string'},\n",
       "      'type': 'array',\n",
       "      'title': 'Output Keys'}},\n",
       "    'type': 'object',\n",
       "    'required': ['file', 'input_keys'],\n",
       "    'title': 'Body_upload_examples_from_csv_api_v1_examples_upload__dataset_id__post'},\n",
       "   'BulkExport': {'properties': {'bulk_export_destination_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Bulk Export Destination Id'},\n",
       "     'session_id': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'},\n",
       "     'start_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'End Time'},\n",
       "     'filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Filter'},\n",
       "     'format': {'$ref': '#/components/schemas/BulkExportFormat',\n",
       "      'default': 'Parquet'},\n",
       "     'compression': {'$ref': '#/components/schemas/BulkExportCompression',\n",
       "      'default': 'gzip'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'tenant_id': {'type': 'string', 'format': 'uuid', 'title': 'Tenant Id'},\n",
       "     'status': {'$ref': '#/components/schemas/BulkExportStatus'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'finished_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Finished At'}},\n",
       "    'type': 'object',\n",
       "    'required': ['bulk_export_destination_id',\n",
       "     'session_id',\n",
       "     'start_time',\n",
       "     'end_time',\n",
       "     'id',\n",
       "     'tenant_id',\n",
       "     'status',\n",
       "     'created_at',\n",
       "     'updated_at',\n",
       "     'finished_at'],\n",
       "    'title': 'BulkExport'},\n",
       "   'BulkExportCompression': {'type': 'string',\n",
       "    'enum': ['none', 'gzip', 'snappy'],\n",
       "    'title': 'BulkExportCompression'},\n",
       "   'BulkExportCreate': {'properties': {'bulk_export_destination_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Bulk Export Destination Id'},\n",
       "     'session_id': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'},\n",
       "     'start_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'End Time'},\n",
       "     'filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Filter'},\n",
       "     'format': {'$ref': '#/components/schemas/BulkExportFormat',\n",
       "      'default': 'Parquet'},\n",
       "     'compression': {'$ref': '#/components/schemas/BulkExportCompression',\n",
       "      'default': 'gzip'}},\n",
       "    'type': 'object',\n",
       "    'required': ['bulk_export_destination_id',\n",
       "     'session_id',\n",
       "     'start_time',\n",
       "     'end_time'],\n",
       "    'title': 'BulkExportCreate'},\n",
       "   'BulkExportDestination': {'properties': {'destination_type': {'$ref': '#/components/schemas/BulkExportDestinationType',\n",
       "      'default': 's3'},\n",
       "     'display_name': {'type': 'string',\n",
       "      'minLength': 1,\n",
       "      'pattern': \"^[a-zA-Z0-9\\\\-_ ']+$\",\n",
       "      'title': 'Display Name'},\n",
       "     'config': {'$ref': '#/components/schemas/BulkExportDestinationS3Config'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'tenant_id': {'type': 'string', 'format': 'uuid', 'title': 'Tenant Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'credentials_keys': {'items': {'type': 'string'},\n",
       "      'type': 'array',\n",
       "      'title': 'Credentials Keys'}},\n",
       "    'type': 'object',\n",
       "    'required': ['display_name',\n",
       "     'config',\n",
       "     'id',\n",
       "     'tenant_id',\n",
       "     'created_at',\n",
       "     'updated_at',\n",
       "     'credentials_keys'],\n",
       "    'title': 'BulkExportDestination'},\n",
       "   'BulkExportDestinationCreate': {'properties': {'destination_type': {'$ref': '#/components/schemas/BulkExportDestinationType',\n",
       "      'default': 's3'},\n",
       "     'display_name': {'type': 'string',\n",
       "      'minLength': 1,\n",
       "      'pattern': \"^[a-zA-Z0-9\\\\-_ ']+$\",\n",
       "      'title': 'Display Name'},\n",
       "     'config': {'$ref': '#/components/schemas/BulkExportDestinationS3Config'},\n",
       "     'credentials': {'$ref': '#/components/schemas/BulkExportDestinationS3Credentials'}},\n",
       "    'type': 'object',\n",
       "    'required': ['display_name', 'config', 'credentials'],\n",
       "    'title': 'BulkExportDestinationCreate'},\n",
       "   'BulkExportDestinationS3Config': {'properties': {'endpoint_url': {'anyOf': [{'type': 'string',\n",
       "        'maxLength': 2048},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Endpoint Url'},\n",
       "     'prefix': {'type': 'string',\n",
       "      'maxLength': 2048,\n",
       "      'title': 'Prefix',\n",
       "      'default': ''},\n",
       "     'bucket_name': {'anyOf': [{'type': 'string',\n",
       "        'maxLength': 63,\n",
       "        'minLength': 3},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Bucket Name'},\n",
       "     'region': {'anyOf': [{'type': 'string', 'minLength': 1},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Region'}},\n",
       "    'type': 'object',\n",
       "    'title': 'BulkExportDestinationS3Config'},\n",
       "   'BulkExportDestinationS3Credentials': {'properties': {'access_key_id': {'type': 'string',\n",
       "      'maxLength': 255,\n",
       "      'minLength': 1,\n",
       "      'title': 'Access Key Id'},\n",
       "     'secret_access_key': {'type': 'string',\n",
       "      'maxLength': 2048,\n",
       "      'minLength': 1,\n",
       "      'title': 'Secret Access Key'}},\n",
       "    'type': 'object',\n",
       "    'required': ['access_key_id', 'secret_access_key'],\n",
       "    'title': 'BulkExportDestinationS3Credentials'},\n",
       "   'BulkExportDestinationType': {'type': 'string',\n",
       "    'enum': ['s3'],\n",
       "    'title': 'BulkExportDestinationType'},\n",
       "   'BulkExportFormat': {'type': 'string',\n",
       "    'enum': ['Parquet'],\n",
       "    'title': 'BulkExportFormat'},\n",
       "   'BulkExportRun': {'properties': {'bulk_export_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Bulk Export Id'},\n",
       "     'metadata': {'$ref': '#/components/schemas/BulkExportRunMetadata'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'status': {'$ref': '#/components/schemas/BulkExportRunStatus'},\n",
       "     'retry_number': {'type': 'integer',\n",
       "      'title': 'Retry Number',\n",
       "      'default': 0},\n",
       "     'errors': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Errors'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'finished_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Finished At'}},\n",
       "    'type': 'object',\n",
       "    'required': ['bulk_export_id',\n",
       "     'metadata',\n",
       "     'id',\n",
       "     'status',\n",
       "     'created_at',\n",
       "     'updated_at',\n",
       "     'finished_at'],\n",
       "    'title': 'BulkExportRun'},\n",
       "   'BulkExportRunMetadata': {'properties': {'prefix': {'type': 'string',\n",
       "      'title': 'Prefix'},\n",
       "     'start_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'End Time'},\n",
       "     'result': {'anyOf': [{'$ref': '#/components/schemas/BulkExportRunProgress'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'required': ['prefix', 'start_time', 'end_time'],\n",
       "    'title': 'BulkExportRunMetadata'},\n",
       "   'BulkExportRunProgress': {'properties': {'rows_written': {'type': 'integer',\n",
       "      'title': 'Rows Written'},\n",
       "     'exported_files': {'items': {'type': 'string'},\n",
       "      'type': 'array',\n",
       "      'title': 'Exported Files'},\n",
       "     'export_path': {'type': 'string', 'title': 'Export Path'},\n",
       "     'latest_cursor': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Latest Cursor'}},\n",
       "    'type': 'object',\n",
       "    'required': ['rows_written',\n",
       "     'exported_files',\n",
       "     'export_path',\n",
       "     'latest_cursor'],\n",
       "    'title': 'BulkExportRunProgress'},\n",
       "   'BulkExportRunStatus': {'type': 'string',\n",
       "    'enum': ['Cancelled',\n",
       "     'Completed',\n",
       "     'Created',\n",
       "     'Failed',\n",
       "     'TimedOut',\n",
       "     'Running'],\n",
       "    'title': 'BulkExportRunStatus'},\n",
       "   'BulkExportStatus': {'type': 'string',\n",
       "    'enum': ['Cancelled',\n",
       "     'Completed',\n",
       "     'Created',\n",
       "     'Failed',\n",
       "     'TimedOut',\n",
       "     'Running'],\n",
       "    'title': 'BulkExportStatus'},\n",
       "   'BulkExportUpdate': {'properties': {'status': {'type': 'string',\n",
       "      'const': 'Cancelled',\n",
       "      'title': 'Status'}},\n",
       "    'type': 'object',\n",
       "    'required': ['status'],\n",
       "    'title': 'BulkExportUpdate'},\n",
       "   'ChangePaymentPlanReq': {'type': 'string',\n",
       "    'enum': ['disabled',\n",
       "     'developer',\n",
       "     'plus',\n",
       "     'startup',\n",
       "     'partner',\n",
       "     'premier',\n",
       "     'free'],\n",
       "    'title': 'ChangePaymentPlanReq',\n",
       "    'description': 'Enum for payment plans that the user can change to. Developer plans are permanent and enterprise plans will be changed manually.'},\n",
       "   'ChangePaymentPlanSchema': {'properties': {'tier': {'$ref': '#/components/schemas/ChangePaymentPlanReq'}},\n",
       "    'type': 'object',\n",
       "    'required': ['tier'],\n",
       "    'title': 'ChangePaymentPlanSchema',\n",
       "    'description': 'Change payment plan schema.'},\n",
       "   'ChatMessage': {'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "       {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "        'type': 'array'}],\n",
       "      'title': 'Content'},\n",
       "     'additional_kwargs': {'type': 'object', 'title': 'Additional Kwargs'},\n",
       "     'response_metadata': {'type': 'object', 'title': 'Response Metadata'},\n",
       "     'type': {'type': 'string',\n",
       "      'const': 'chat',\n",
       "      'title': 'Type',\n",
       "      'default': 'chat'},\n",
       "     'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "     'role': {'type': 'string', 'title': 'Role'}},\n",
       "    'additionalProperties': True,\n",
       "    'type': 'object',\n",
       "    'required': ['content', 'role'],\n",
       "    'title': 'ChatMessage',\n",
       "    'description': 'Message that can be assigned an arbitrary speaker (i.e. role).'},\n",
       "   'ChatMessageChunk': {'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "       {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "        'type': 'array'}],\n",
       "      'title': 'Content'},\n",
       "     'additional_kwargs': {'type': 'object', 'title': 'Additional Kwargs'},\n",
       "     'response_metadata': {'type': 'object', 'title': 'Response Metadata'},\n",
       "     'type': {'type': 'string',\n",
       "      'const': 'ChatMessageChunk',\n",
       "      'title': 'Type',\n",
       "      'default': 'ChatMessageChunk'},\n",
       "     'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "     'role': {'type': 'string', 'title': 'Role'}},\n",
       "    'additionalProperties': True,\n",
       "    'type': 'object',\n",
       "    'required': ['content', 'role'],\n",
       "    'title': 'ChatMessageChunk',\n",
       "    'description': 'Chat Message chunk.'},\n",
       "   'CodeEvaluatorTopLevel': {'properties': {'code': {'type': 'string',\n",
       "      'title': 'Code'}},\n",
       "    'type': 'object',\n",
       "    'required': ['code'],\n",
       "    'title': 'CodeEvaluatorTopLevel'},\n",
       "   'Comment': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'comment_by': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Comment By'},\n",
       "     'comment_on': {'type': 'string', 'format': 'uuid', 'title': 'Comment On'},\n",
       "     'parent_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Parent Id'},\n",
       "     'content': {'type': 'string', 'title': 'Content'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'comment_by_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Comment By Name'},\n",
       "     'num_sub_comments': {'type': 'integer', 'title': 'Num Sub Comments'},\n",
       "     'num_likes': {'type': 'integer', 'title': 'Num Likes'},\n",
       "     'liked_by_auth_user': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Liked By Auth User'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id',\n",
       "     'comment_on',\n",
       "     'content',\n",
       "     'created_at',\n",
       "     'updated_at',\n",
       "     'num_sub_comments',\n",
       "     'num_likes'],\n",
       "    'title': 'Comment'},\n",
       "   'CommitManifestResponse': {'properties': {'commit_hash': {'type': 'string',\n",
       "      'title': 'Commit Hash'},\n",
       "     'manifest': {'type': 'object', 'title': 'Manifest'},\n",
       "     'examples': {'anyOf': [{'items': {'$ref': '#/components/schemas/RepoExampleResponse'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Examples'}},\n",
       "    'type': 'object',\n",
       "    'required': ['commit_hash', 'manifest'],\n",
       "    'title': 'CommitManifestResponse',\n",
       "    'description': 'Response model for get_commit_manifest.'},\n",
       "   'CommitWithLookups': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'manifest': {'type': 'object', 'title': 'Manifest'},\n",
       "     'repo_id': {'type': 'string', 'format': 'uuid', 'title': 'Repo Id'},\n",
       "     'parent_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Parent Id'},\n",
       "     'commit_hash': {'type': 'string', 'title': 'Commit Hash'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'example_run_ids': {'items': {'type': 'string', 'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'title': 'Example Run Ids'},\n",
       "     'num_downloads': {'type': 'integer', 'title': 'Num Downloads'},\n",
       "     'num_views': {'type': 'integer', 'title': 'Num Views'},\n",
       "     'parent_commit_hash': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Parent Commit Hash'},\n",
       "     'full_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Full Name'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id',\n",
       "     'manifest',\n",
       "     'repo_id',\n",
       "     'commit_hash',\n",
       "     'created_at',\n",
       "     'updated_at',\n",
       "     'example_run_ids',\n",
       "     'num_downloads',\n",
       "     'num_views'],\n",
       "    'title': 'CommitWithLookups',\n",
       "    'description': 'All database fields for commits, plus helpful computed fields and user info\\nfor private prompts.'},\n",
       "   'ComparativeExperiment': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'tenant_id': {'type': 'string', 'format': 'uuid', 'title': 'Tenant Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'modified_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Modified At'},\n",
       "     'reference_dataset_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Reference Dataset Id'},\n",
       "     'extra': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Extra'},\n",
       "     'experiments_info': {'items': {'$ref': '#/components/schemas/SimpleExperimentInfo'},\n",
       "      'type': 'array',\n",
       "      'title': 'Experiments Info'},\n",
       "     'feedback_stats': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Feedback Stats'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id',\n",
       "     'tenant_id',\n",
       "     'created_at',\n",
       "     'modified_at',\n",
       "     'reference_dataset_id',\n",
       "     'experiments_info'],\n",
       "    'title': 'ComparativeExperiment',\n",
       "    'description': 'ComparativeExperiment schema.'},\n",
       "   'ComparativeExperimentBase': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'tenant_id': {'type': 'string', 'format': 'uuid', 'title': 'Tenant Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'modified_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Modified At'},\n",
       "     'reference_dataset_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Reference Dataset Id'},\n",
       "     'extra': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Extra'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id',\n",
       "     'tenant_id',\n",
       "     'created_at',\n",
       "     'modified_at',\n",
       "     'reference_dataset_id'],\n",
       "    'title': 'ComparativeExperimentBase',\n",
       "    'description': 'ComparativeExperiment schema.'},\n",
       "   'ComparativeExperimentCreate': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'experiment_ids': {'items': {'type': 'string', 'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'title': 'Experiment Ids'},\n",
       "     'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'modified_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Modified At'},\n",
       "     'reference_dataset_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Reference Dataset Id'},\n",
       "     'extra': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Extra'}},\n",
       "    'type': 'object',\n",
       "    'required': ['experiment_ids', 'reference_dataset_id'],\n",
       "    'title': 'ComparativeExperimentCreate',\n",
       "    'description': 'Create class for ComparativeExperiment.'},\n",
       "   'ConfiguredBy': {'type': 'string',\n",
       "    'enum': ['system', 'user'],\n",
       "    'title': 'ConfiguredBy'},\n",
       "   'CreateCommentRequest': {'properties': {'content': {'type': 'string',\n",
       "      'title': 'Content'}},\n",
       "    'type': 'object',\n",
       "    'required': ['content'],\n",
       "    'title': 'CreateCommentRequest'},\n",
       "   'CreateEventRequest': {'properties': {'event_type': {'type': 'string',\n",
       "      'enum': ['playground-view', 'playground-run'],\n",
       "      'title': 'Event Type'},\n",
       "     'owner': {'type': 'string', 'title': 'Owner'},\n",
       "     'repo': {'type': 'string', 'title': 'Repo'},\n",
       "     'commit': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Commit'}},\n",
       "    'type': 'object',\n",
       "    'required': ['event_type', 'owner', 'repo'],\n",
       "    'title': 'CreateEventRequest'},\n",
       "   'CreateFeedbackConfigSchema': {'properties': {'feedback_key': {'type': 'string',\n",
       "      'title': 'Feedback Key'},\n",
       "     'feedback_config': {'$ref': '#/components/schemas/FeedbackConfig'},\n",
       "     'is_lower_score_better': {'anyOf': [{'type': 'boolean'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Is Lower Score Better',\n",
       "      'default': False}},\n",
       "    'type': 'object',\n",
       "    'required': ['feedback_key', 'feedback_config'],\n",
       "    'title': 'CreateFeedbackConfigSchema'},\n",
       "   'CreateRepoCommitRequest': {'properties': {'manifest': {'type': 'object',\n",
       "      'title': 'Manifest'},\n",
       "     'parent_commit': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Parent Commit'},\n",
       "     'example_run_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Example Run Ids'},\n",
       "     'skip_webhooks': {'anyOf': [{'type': 'boolean'},\n",
       "       {'items': {'type': 'string', 'format': 'uuid'}, 'type': 'array'}],\n",
       "      'title': 'Skip Webhooks',\n",
       "      'default': False}},\n",
       "    'type': 'object',\n",
       "    'required': ['manifest'],\n",
       "    'title': 'CreateRepoCommitRequest'},\n",
       "   'CreateRepoCommitResponse': {'properties': {'commit': {'$ref': '#/components/schemas/CommitWithLookups'}},\n",
       "    'type': 'object',\n",
       "    'required': ['commit'],\n",
       "    'title': 'CreateRepoCommitResponse'},\n",
       "   'CreateRepoRequest': {'properties': {'repo_handle': {'type': 'string',\n",
       "      'title': 'Repo Handle'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'readme': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Readme'},\n",
       "     'is_public': {'type': 'boolean', 'title': 'Is Public'},\n",
       "     'tags': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Tags'}},\n",
       "    'type': 'object',\n",
       "    'required': ['repo_handle', 'is_public'],\n",
       "    'title': 'CreateRepoRequest',\n",
       "    'description': 'Fields to create a repo'},\n",
       "   'CreateRepoResponse': {'properties': {'repo': {'$ref': '#/components/schemas/RepoWithLookups'}},\n",
       "    'type': 'object',\n",
       "    'required': ['repo'],\n",
       "    'title': 'CreateRepoResponse'},\n",
       "   'CreateRoleRequest': {'properties': {'display_name': {'type': 'string',\n",
       "      'title': 'Display Name'},\n",
       "     'description': {'type': 'string', 'title': 'Description'},\n",
       "     'permissions': {'items': {'type': 'string'},\n",
       "      'type': 'array',\n",
       "      'title': 'Permissions'}},\n",
       "    'type': 'object',\n",
       "    'required': ['display_name', 'description', 'permissions'],\n",
       "    'title': 'CreateRoleRequest'},\n",
       "   'CustomChartCreate': {'properties': {'title': {'type': 'string',\n",
       "      'title': 'Title'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'index': {'anyOf': [{'type': 'integer', 'maximum': 100.0, 'minimum': 0.0},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Index'},\n",
       "     'chart_type': {'$ref': '#/components/schemas/CustomChartType'},\n",
       "     'series': {'items': {'$ref': '#/components/schemas/CustomChartSeriesCreate'},\n",
       "      'type': 'array',\n",
       "      'title': 'Series'},\n",
       "     'section_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Section Id'},\n",
       "     'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Metadata'},\n",
       "     'common_filters': {'anyOf': [{'$ref': '#/components/schemas/CustomChartSeriesFilters'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'required': ['title', 'chart_type', 'series'],\n",
       "    'title': 'CustomChartCreate'},\n",
       "   'CustomChartCreatePreview': {'properties': {'series': {'items': {'$ref': '#/components/schemas/CustomChartSeries'},\n",
       "      'type': 'array',\n",
       "      'title': 'Series'},\n",
       "     'common_filters': {'anyOf': [{'$ref': '#/components/schemas/CustomChartSeriesFilters'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'required': ['series'],\n",
       "    'title': 'CustomChartCreatePreview'},\n",
       "   'CustomChartMetric': {'type': 'string',\n",
       "    'enum': ['run_count',\n",
       "     'latency_p50',\n",
       "     'latency_p99',\n",
       "     'latency_avg',\n",
       "     'first_token_p50',\n",
       "     'first_token_p99',\n",
       "     'total_tokens',\n",
       "     'prompt_tokens',\n",
       "     'completion_tokens',\n",
       "     'median_tokens',\n",
       "     'completion_tokens_p50',\n",
       "     'prompt_tokens_p50',\n",
       "     'tokens_p99',\n",
       "     'completion_tokens_p99',\n",
       "     'prompt_tokens_p99',\n",
       "     'feedback',\n",
       "     'feedback_score_avg',\n",
       "     'feedback_values',\n",
       "     'total_cost',\n",
       "     'prompt_cost',\n",
       "     'completion_cost',\n",
       "     'error_rate',\n",
       "     'streaming_rate',\n",
       "     'cost_p50',\n",
       "     'cost_p99'],\n",
       "    'title': 'CustomChartMetric',\n",
       "    'description': 'Metrics you can chart. Feedback metrics are not available for organization-scoped charts.'},\n",
       "   'CustomChartPreviewRequest': {'properties': {'bucket_info': {'$ref': '#/components/schemas/CustomChartsRequestBase'},\n",
       "     'chart': {'$ref': '#/components/schemas/CustomChartCreatePreview'}},\n",
       "    'type': 'object',\n",
       "    'required': ['bucket_info', 'chart'],\n",
       "    'title': 'CustomChartPreviewRequest'},\n",
       "   'CustomChartResponse': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'title': {'type': 'string', 'title': 'Title'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'index': {'type': 'integer', 'title': 'Index'},\n",
       "     'chart_type': {'$ref': '#/components/schemas/CustomChartType'},\n",
       "     'section_id': {'type': 'string', 'format': 'uuid', 'title': 'Section Id'},\n",
       "     'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Metadata'},\n",
       "     'series': {'anyOf': [{'items': {'$ref': '#/components/schemas/CustomChartSeries'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Series'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id', 'title', 'index', 'chart_type', 'section_id', 'series'],\n",
       "    'title': 'CustomChartResponse'},\n",
       "   'CustomChartSeries': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'},\n",
       "     'filters': {'anyOf': [{'$ref': '#/components/schemas/CustomChartSeriesFilters'},\n",
       "       {'type': 'null'}]},\n",
       "     'metric': {'$ref': '#/components/schemas/CustomChartMetric'},\n",
       "     'feedback_key': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Feedback Key'},\n",
       "     'workspace_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Workspace Id'},\n",
       "     'project_metric': {'anyOf': [{'$ref': '#/components/schemas/HostProjectChartMetric'},\n",
       "       {'type': 'null'}]},\n",
       "     'id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'string'}],\n",
       "      'title': 'Id'},\n",
       "     'group_by': {'anyOf': [{'$ref': '#/components/schemas/RunStatsGroupBySeriesResponse'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'required': ['name', 'metric', 'id'],\n",
       "    'title': 'CustomChartSeries'},\n",
       "   'CustomChartSeriesCreate': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'},\n",
       "     'filters': {'anyOf': [{'$ref': '#/components/schemas/CustomChartSeriesFilters'},\n",
       "       {'type': 'null'}]},\n",
       "     'metric': {'$ref': '#/components/schemas/CustomChartMetric'},\n",
       "     'feedback_key': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Feedback Key'},\n",
       "     'workspace_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Workspace Id'},\n",
       "     'project_metric': {'anyOf': [{'$ref': '#/components/schemas/HostProjectChartMetric'},\n",
       "       {'type': 'null'}]},\n",
       "     'group_by': {'anyOf': [{'$ref': '#/components/schemas/RunStatsGroupBy'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'required': ['name', 'metric'],\n",
       "    'title': 'CustomChartSeriesCreate'},\n",
       "   'CustomChartSeriesFilters': {'properties': {'filter': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Filter'},\n",
       "     'trace_filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Trace Filter'},\n",
       "     'tree_filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Tree Filter'},\n",
       "     'session': {'anyOf': [{'items': {'type': 'string', 'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Session'}},\n",
       "    'type': 'object',\n",
       "    'title': 'CustomChartSeriesFilters'},\n",
       "   'CustomChartSeriesUpdate': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'},\n",
       "     'filters': {'anyOf': [{'$ref': '#/components/schemas/CustomChartSeriesFilters'},\n",
       "       {'type': 'null'}]},\n",
       "     'metric': {'$ref': '#/components/schemas/CustomChartMetric'},\n",
       "     'feedback_key': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Feedback Key'},\n",
       "     'workspace_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Workspace Id'},\n",
       "     'project_metric': {'anyOf': [{'$ref': '#/components/schemas/HostProjectChartMetric'},\n",
       "       {'type': 'null'}]},\n",
       "     'group_by': {'anyOf': [{'$ref': '#/components/schemas/RunStatsGroupBy'},\n",
       "       {'type': 'null'}]},\n",
       "     'id': {'anyOf': [{'type': 'string', 'format': 'uuid'}, {'type': 'null'}],\n",
       "      'title': 'Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name', 'metric'],\n",
       "    'title': 'CustomChartSeriesUpdate'},\n",
       "   'CustomChartType': {'type': 'string',\n",
       "    'enum': ['line', 'bar'],\n",
       "    'title': 'CustomChartType',\n",
       "    'description': 'Enum for custom chart types.'},\n",
       "   'CustomChartUpdate': {'properties': {'title': {'anyOf': [{'type': 'string'},\n",
       "       {'$ref': '#/components/schemas/Missing'}],\n",
       "      'title': 'Title',\n",
       "      'default': {'__missing__': '__missing__'}},\n",
       "     'description': {'anyOf': [{'type': 'string'},\n",
       "       {'$ref': '#/components/schemas/Missing'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Description',\n",
       "      'default': {'__missing__': '__missing__'}},\n",
       "     'index': {'anyOf': [{'type': 'integer'},\n",
       "       {'$ref': '#/components/schemas/Missing'}],\n",
       "      'title': 'Index',\n",
       "      'default': {'__missing__': '__missing__'},\n",
       "      'ge': 0,\n",
       "      'le': 100},\n",
       "     'chart_type': {'anyOf': [{'$ref': '#/components/schemas/CustomChartType'},\n",
       "       {'$ref': '#/components/schemas/Missing'}],\n",
       "      'title': 'Chart Type',\n",
       "      'default': {'__missing__': '__missing__'}},\n",
       "     'series': {'anyOf': [{'items': {'$ref': '#/components/schemas/CustomChartSeriesUpdate'},\n",
       "        'type': 'array'},\n",
       "       {'$ref': '#/components/schemas/Missing'}],\n",
       "      'title': 'Series',\n",
       "      'default': {'__missing__': '__missing__'}},\n",
       "     'section_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'$ref': '#/components/schemas/Missing'}],\n",
       "      'title': 'Section Id',\n",
       "      'default': {'__missing__': '__missing__'}},\n",
       "     'metadata': {'anyOf': [{'type': 'object'},\n",
       "       {'$ref': '#/components/schemas/Missing'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Metadata',\n",
       "      'default': {'__missing__': '__missing__'}},\n",
       "     'common_filters': {'anyOf': [{'$ref': '#/components/schemas/CustomChartSeriesFilters'},\n",
       "       {'$ref': '#/components/schemas/Missing'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Common Filters',\n",
       "      'default': {'__missing__': '__missing__'}}},\n",
       "    'type': 'object',\n",
       "    'title': 'CustomChartUpdate'},\n",
       "   'CustomChartsDataPoint': {'properties': {'series_id': {'type': 'string',\n",
       "      'title': 'Series Id'},\n",
       "     'timestamp': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Timestamp'},\n",
       "     'value': {'anyOf': [{'type': 'integer'},\n",
       "       {'type': 'number'},\n",
       "       {'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Value'},\n",
       "     'group': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Group'}},\n",
       "    'type': 'object',\n",
       "    'required': ['series_id', 'timestamp', 'value'],\n",
       "    'title': 'CustomChartsDataPoint'},\n",
       "   'CustomChartsRequest': {'properties': {'timezone': {'type': 'string',\n",
       "      'title': 'Timezone',\n",
       "      'default': 'UTC'},\n",
       "     'start_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'End Time'},\n",
       "     'stride': {'$ref': '#/components/schemas/TimedeltaInput',\n",
       "      'default': {'days': 0, 'minutes': 15, 'hours': 0}},\n",
       "     'omit_data': {'type': 'boolean', 'title': 'Omit Data', 'default': False},\n",
       "     'after_index': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'After Index'},\n",
       "     'tag_value_id': {'anyOf': [{'items': {'type': 'string', 'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Tag Value Id'}},\n",
       "    'type': 'object',\n",
       "    'title': 'CustomChartsRequest'},\n",
       "   'CustomChartsRequestBase': {'properties': {'timezone': {'type': 'string',\n",
       "      'title': 'Timezone',\n",
       "      'default': 'UTC'},\n",
       "     'start_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'End Time'},\n",
       "     'stride': {'$ref': '#/components/schemas/TimedeltaInput',\n",
       "      'default': {'days': 0, 'minutes': 15, 'hours': 0}},\n",
       "     'omit_data': {'type': 'boolean', 'title': 'Omit Data', 'default': False}},\n",
       "    'type': 'object',\n",
       "    'title': 'CustomChartsRequestBase'},\n",
       "   'CustomChartsResponse': {'properties': {'sections': {'items': {'$ref': '#/components/schemas/CustomChartsSection'},\n",
       "      'type': 'array',\n",
       "      'title': 'Sections'}},\n",
       "    'type': 'object',\n",
       "    'required': ['sections'],\n",
       "    'title': 'CustomChartsResponse'},\n",
       "   'CustomChartsSection': {'properties': {'title': {'type': 'string',\n",
       "      'title': 'Title'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'index': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Index'},\n",
       "     'id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'string'}],\n",
       "      'title': 'Id'},\n",
       "     'session_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Session Id'},\n",
       "     'charts': {'items': {'$ref': '#/components/schemas/SingleCustomChartResponse'},\n",
       "      'type': 'array',\n",
       "      'title': 'Charts'},\n",
       "     'sub_sections': {'anyOf': [{'items': {'$ref': '#/components/schemas/SingleCustomChartSubSectionResponse'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Sub Sections'}},\n",
       "    'type': 'object',\n",
       "    'required': ['title', 'id', 'charts'],\n",
       "    'title': 'CustomChartsSection'},\n",
       "   'CustomChartsSectionCreate': {'properties': {'title': {'type': 'string',\n",
       "      'title': 'Title'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'index': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Index'}},\n",
       "    'type': 'object',\n",
       "    'required': ['title'],\n",
       "    'title': 'CustomChartsSectionCreate'},\n",
       "   'CustomChartsSectionRequest': {'properties': {'timezone': {'type': 'string',\n",
       "      'title': 'Timezone',\n",
       "      'default': 'UTC'},\n",
       "     'start_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'End Time'},\n",
       "     'stride': {'$ref': '#/components/schemas/TimedeltaInput',\n",
       "      'default': {'days': 0, 'minutes': 15, 'hours': 0}},\n",
       "     'omit_data': {'type': 'boolean', 'title': 'Omit Data', 'default': False},\n",
       "     'group_by': {'anyOf': [{'$ref': '#/components/schemas/RunStatsGroupBy'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'title': 'CustomChartsSectionRequest'},\n",
       "   'CustomChartsSectionResponse': {'properties': {'title': {'type': 'string',\n",
       "      'title': 'Title'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'index': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Index'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'chart_count': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Chart Count'},\n",
       "     'created_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Created At'},\n",
       "     'modified_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Modified At'}},\n",
       "    'type': 'object',\n",
       "    'required': ['title', 'id'],\n",
       "    'title': 'CustomChartsSectionResponse'},\n",
       "   'CustomChartsSectionUpdate': {'properties': {'title': {'anyOf': [{'type': 'string'},\n",
       "       {'$ref': '#/components/schemas/Missing'}],\n",
       "      'title': 'Title',\n",
       "      'default': {'__missing__': '__missing__'}},\n",
       "     'description': {'anyOf': [{'type': 'string'},\n",
       "       {'$ref': '#/components/schemas/Missing'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Description',\n",
       "      'default': {'__missing__': '__missing__'}},\n",
       "     'index': {'anyOf': [{'type': 'integer'},\n",
       "       {'$ref': '#/components/schemas/Missing'}],\n",
       "      'title': 'Index',\n",
       "      'default': {'__missing__': '__missing__'}}},\n",
       "    'type': 'object',\n",
       "    'title': 'CustomChartsSectionUpdate'},\n",
       "   'CustomChartsSectionsCloneRequest': {'properties': {'section_id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Section Id'},\n",
       "     'session_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Session Id'}},\n",
       "    'type': 'object',\n",
       "    'title': 'CustomChartsSectionsCloneRequest'},\n",
       "   'CustomerVisiblePlanInfo': {'properties': {'tier': {'$ref': '#/components/schemas/PaymentPlanTier'},\n",
       "     'started_on': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Started On'},\n",
       "     'ends_on': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Ends On'}},\n",
       "    'type': 'object',\n",
       "    'required': ['tier', 'started_on'],\n",
       "    'title': 'CustomerVisiblePlanInfo',\n",
       "    'description': 'Customer visible plan information.'},\n",
       "   'DataType': {'type': 'string',\n",
       "    'enum': ['kv', 'llm', 'chat'],\n",
       "    'title': 'DataType',\n",
       "    'description': 'Enum for dataset data types.'},\n",
       "   'Dataset': {'properties': {'name': {'type': 'string', 'title': 'Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'inputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Inputs Schema Definition'},\n",
       "     'outputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Outputs Schema Definition'},\n",
       "     'externally_managed': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Externally Managed',\n",
       "      'default': False},\n",
       "     'transformations': {'anyOf': [{'items': {'$ref': '#/components/schemas/DatasetTransformation'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Transformations'},\n",
       "     'data_type': {'anyOf': [{'$ref': '#/components/schemas/DataType'},\n",
       "       {'type': 'null'}],\n",
       "      'default': 'kv'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'tenant_id': {'type': 'string', 'format': 'uuid', 'title': 'Tenant Id'},\n",
       "     'example_count': {'type': 'integer', 'title': 'Example Count'},\n",
       "     'session_count': {'type': 'integer', 'title': 'Session Count'},\n",
       "     'modified_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Modified At'},\n",
       "     'last_session_start_time': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Last Session Start Time'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name',\n",
       "     'id',\n",
       "     'tenant_id',\n",
       "     'example_count',\n",
       "     'session_count',\n",
       "     'modified_at'],\n",
       "    'title': 'Dataset',\n",
       "    'description': 'Dataset schema.'},\n",
       "   'DatasetCreate': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'inputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Inputs Schema Definition'},\n",
       "     'outputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Outputs Schema Definition'},\n",
       "     'externally_managed': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Externally Managed',\n",
       "      'default': False},\n",
       "     'transformations': {'anyOf': [{'items': {'$ref': '#/components/schemas/DatasetTransformation'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Transformations'},\n",
       "     'id': {'anyOf': [{'type': 'string', 'format': 'uuid'}, {'type': 'null'}],\n",
       "      'title': 'Id'},\n",
       "     'extra': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Extra'},\n",
       "     'data_type': {'$ref': '#/components/schemas/DataType', 'default': 'kv'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name'],\n",
       "    'title': 'DatasetCreate',\n",
       "    'description': 'Create class for Dataset.'},\n",
       "   'DatasetDiffInfo': {'properties': {'examples_modified': {'items': {'type': 'string',\n",
       "       'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'title': 'Examples Modified'},\n",
       "     'examples_added': {'items': {'type': 'string', 'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'title': 'Examples Added'},\n",
       "     'examples_removed': {'items': {'type': 'string', 'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'title': 'Examples Removed'}},\n",
       "    'type': 'object',\n",
       "    'required': ['examples_modified', 'examples_added', 'examples_removed'],\n",
       "    'title': 'DatasetDiffInfo',\n",
       "    'description': 'Dataset diff schema.'},\n",
       "   'DatasetIndexInfo': {'properties': {'dataset_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Dataset Id'},\n",
       "     'tag': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Tag',\n",
       "      'default': 'latest'},\n",
       "     'last_updated_version': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Last Updated Version'}},\n",
       "    'type': 'object',\n",
       "    'required': ['dataset_id'],\n",
       "    'title': 'DatasetIndexInfo',\n",
       "    'description': 'Dataset schema for serving.'},\n",
       "   'DatasetIndexRequest': {'properties': {'tag': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Tag',\n",
       "      'default': 'latest'}},\n",
       "    'type': 'object',\n",
       "    'title': 'DatasetIndexRequest',\n",
       "    'description': 'Dataset schema for serving.'},\n",
       "   'DatasetPublicSchema': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'inputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Inputs Schema Definition'},\n",
       "     'outputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Outputs Schema Definition'},\n",
       "     'externally_managed': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Externally Managed',\n",
       "      'default': False},\n",
       "     'transformations': {'anyOf': [{'items': {'$ref': '#/components/schemas/DatasetTransformation'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Transformations'},\n",
       "     'data_type': {'anyOf': [{'$ref': '#/components/schemas/DataType'},\n",
       "       {'type': 'null'}],\n",
       "      'default': 'kv'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'example_count': {'type': 'integer', 'title': 'Example Count'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name', 'id', 'example_count'],\n",
       "    'title': 'DatasetPublicSchema',\n",
       "    'description': \"Public schema for datasets.\\n\\nDoesn't currently include session counts/stats\\nsince public test project sharing is not yet shipped\"},\n",
       "   'DatasetSchemaForUpdate': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'inputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Inputs Schema Definition'},\n",
       "     'outputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Outputs Schema Definition'},\n",
       "     'externally_managed': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Externally Managed',\n",
       "      'default': False},\n",
       "     'transformations': {'anyOf': [{'items': {'$ref': '#/components/schemas/DatasetTransformation'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Transformations'},\n",
       "     'data_type': {'anyOf': [{'$ref': '#/components/schemas/DataType'},\n",
       "       {'type': 'null'}],\n",
       "      'default': 'kv'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'tenant_id': {'type': 'string', 'format': 'uuid', 'title': 'Tenant Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name', 'id', 'tenant_id'],\n",
       "    'title': 'DatasetSchemaForUpdate'},\n",
       "   'DatasetShareSchema': {'properties': {'dataset_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Dataset Id'},\n",
       "     'share_token': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Share Token'}},\n",
       "    'type': 'object',\n",
       "    'required': ['dataset_id', 'share_token'],\n",
       "    'title': 'DatasetShareSchema'},\n",
       "   'DatasetTransformation': {'properties': {'path': {'items': {'type': 'string'},\n",
       "      'type': 'array',\n",
       "      'title': 'Path'},\n",
       "     'transformation_type': {'$ref': '#/components/schemas/DatasetTransformationType'}},\n",
       "    'type': 'object',\n",
       "    'required': ['path', 'transformation_type'],\n",
       "    'title': 'DatasetTransformation'},\n",
       "   'DatasetTransformationType': {'type': 'string',\n",
       "    'enum': ['remove_system_messages',\n",
       "     'convert_to_openai_message',\n",
       "     'convert_to_openai_tool',\n",
       "     'remove_extra_fields',\n",
       "     'extract_tools_from_run'],\n",
       "    'title': 'DatasetTransformationType',\n",
       "    'description': 'Enum for dataset data types.'},\n",
       "   'DatasetUpdate': {'properties': {'name': {'anyOf': [{'type': 'string'},\n",
       "       {'$ref': '#/components/schemas/Missing'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Name',\n",
       "      'default': {'__missing__': '__missing__'}},\n",
       "     'description': {'anyOf': [{'type': 'string'},\n",
       "       {'$ref': '#/components/schemas/Missing'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Description',\n",
       "      'default': {'__missing__': '__missing__'}},\n",
       "     'inputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "       {'$ref': '#/components/schemas/Missing'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Inputs Schema Definition',\n",
       "      'default': {'__missing__': '__missing__'}},\n",
       "     'outputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "       {'$ref': '#/components/schemas/Missing'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Outputs Schema Definition',\n",
       "      'default': {'__missing__': '__missing__'}},\n",
       "     'patch_examples': {'anyOf': [{'additionalProperties': {'$ref': '#/components/schemas/ExampleUpdate'},\n",
       "        'propertyNames': {'format': 'uuid'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Patch Examples'},\n",
       "     'transformations': {'anyOf': [{'items': {'$ref': '#/components/schemas/DatasetTransformation'},\n",
       "        'type': 'array'},\n",
       "       {'$ref': '#/components/schemas/Missing'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Transformations',\n",
       "      'default': {'__missing__': '__missing__'}}},\n",
       "    'type': 'object',\n",
       "    'title': 'DatasetUpdate',\n",
       "    'description': 'Update class for Dataset.'},\n",
       "   'DatasetVersion': {'properties': {'tags': {'anyOf': [{'items': {'type': 'string'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Tags'},\n",
       "     'as_of': {'type': 'string', 'format': 'date-time', 'title': 'As Of'}},\n",
       "    'type': 'object',\n",
       "    'required': ['as_of'],\n",
       "    'title': 'DatasetVersion',\n",
       "    'description': 'Dataset version schema.'},\n",
       "   'DemoConfig': {'properties': {'message_index': {'type': 'integer',\n",
       "      'title': 'Message Index'},\n",
       "     'metaprompt': {'type': 'object', 'title': 'Metaprompt'},\n",
       "     'examples': {'items': {'type': 'object'},\n",
       "      'type': 'array',\n",
       "      'title': 'Examples'},\n",
       "     'overall_feedback': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Overall Feedback'}},\n",
       "    'type': 'object',\n",
       "    'required': ['message_index',\n",
       "     'metaprompt',\n",
       "     'examples',\n",
       "     'overall_feedback'],\n",
       "    'title': 'DemoConfig'},\n",
       "   'EPromptOptimizationAlgorithm': {'type': 'string',\n",
       "    'enum': ['promptim', 'demo'],\n",
       "    'title': 'EPromptOptimizationAlgorithm'},\n",
       "   'EPromptOptimizationJobLogType': {'type': 'string',\n",
       "    'enum': ['info', 'result', 'error', 'link'],\n",
       "    'title': 'EPromptOptimizationJobLogType'},\n",
       "   'EPromptOptimizationJobStatus': {'type': 'string',\n",
       "    'enum': ['created', 'running', 'successful', 'failed'],\n",
       "    'title': 'EPromptOptimizationJobStatus'},\n",
       "   'EPromptWebhookTrigger': {'type': 'string',\n",
       "    'enum': ['commit'],\n",
       "    'title': 'EPromptWebhookTrigger',\n",
       "    'description': 'Valid trigger types for prompt webhooks.'},\n",
       "   'EvaluatorStructuredOutput': {'properties': {'hub_ref': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Hub Ref'},\n",
       "     'prompt': {'anyOf': [{'items': {'prefixItems': [{'type': 'string'},\n",
       "          {'type': 'string'}],\n",
       "         'type': 'array',\n",
       "         'maxItems': 2,\n",
       "         'minItems': 2},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Prompt'},\n",
       "     'template_format': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Template Format'},\n",
       "     'schema': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Schema'},\n",
       "     'variable_mapping': {'anyOf': [{'additionalProperties': {'type': 'string'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Variable Mapping'},\n",
       "     'model': {'type': 'object', 'title': 'Model'}},\n",
       "    'type': 'object',\n",
       "    'required': ['model'],\n",
       "    'title': 'EvaluatorStructuredOutput',\n",
       "    'description': 'Evaluator structured output schema.'},\n",
       "   'EvaluatorTopLevel': {'properties': {'structured': {'$ref': '#/components/schemas/EvaluatorStructuredOutput'}},\n",
       "    'type': 'object',\n",
       "    'required': ['structured'],\n",
       "    'title': 'EvaluatorTopLevel'},\n",
       "   'Example': {'properties': {'outputs': {'anyOf': [{'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Outputs'},\n",
       "     'dataset_id': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'},\n",
       "     'source_run_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Source Run Id'},\n",
       "     'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Metadata'},\n",
       "     'inputs': {'type': 'object', 'title': 'Inputs'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'name': {'type': 'string', 'title': 'Name'},\n",
       "     'modified_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Modified At'},\n",
       "     'attachment_urls': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Attachment Urls'}},\n",
       "    'type': 'object',\n",
       "    'required': ['dataset_id', 'inputs', 'id', 'name'],\n",
       "    'title': 'Example',\n",
       "    'description': 'Example schema.'},\n",
       "   'ExampleListOrder': {'type': 'string',\n",
       "    'enum': ['recent', 'random', 'recently_created'],\n",
       "    'title': 'ExampleListOrder'},\n",
       "   'ExampleSelect': {'type': 'string',\n",
       "    'enum': ['id',\n",
       "     'created_at',\n",
       "     'modified_at',\n",
       "     'name',\n",
       "     'dataset_id',\n",
       "     'source_run_id',\n",
       "     'metadata',\n",
       "     'inputs',\n",
       "     'outputs',\n",
       "     'attachment_urls'],\n",
       "    'title': 'ExampleSelect'},\n",
       "   'ExampleUpdate': {'properties': {'dataset_id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Dataset Id'},\n",
       "     'inputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Inputs'},\n",
       "     'outputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Outputs'},\n",
       "     'attachments_operations': {'anyOf': [{'$ref': '#/components/schemas/AttachmentsOperations'},\n",
       "       {'type': 'null'}]},\n",
       "     'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Metadata'},\n",
       "     'split': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "       {'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Split'},\n",
       "     'overwrite': {'type': 'boolean', 'title': 'Overwrite', 'default': False}},\n",
       "    'type': 'object',\n",
       "    'title': 'ExampleUpdate',\n",
       "    'description': 'Update class for Example.'},\n",
       "   'ExampleUpdateWithID': {'properties': {'dataset_id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Dataset Id'},\n",
       "     'inputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Inputs'},\n",
       "     'outputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Outputs'},\n",
       "     'attachments_operations': {'anyOf': [{'$ref': '#/components/schemas/AttachmentsOperations'},\n",
       "       {'type': 'null'}]},\n",
       "     'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Metadata'},\n",
       "     'split': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "       {'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Split'},\n",
       "     'overwrite': {'type': 'boolean', 'title': 'Overwrite', 'default': False},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id'],\n",
       "    'title': 'ExampleUpdateWithID',\n",
       "    'description': 'Bulk update class for Example (includes example id).'},\n",
       "   'ExampleValidationResult': {'properties': {'dataset_id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Dataset Id'},\n",
       "     'inputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Inputs'},\n",
       "     'outputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Outputs'},\n",
       "     'created_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Created At'},\n",
       "     'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Metadata'},\n",
       "     'source_run_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Source Run Id'},\n",
       "     'split': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "       {'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Split',\n",
       "      'default': 'base'},\n",
       "     'id': {'anyOf': [{'type': 'string', 'format': 'uuid'}, {'type': 'null'}],\n",
       "      'title': 'Id'},\n",
       "     'use_source_run_io': {'type': 'boolean',\n",
       "      'title': 'Use Source Run Io',\n",
       "      'default': False},\n",
       "     'overwrite': {'type': 'boolean', 'title': 'Overwrite', 'default': False}},\n",
       "    'type': 'object',\n",
       "    'title': 'ExampleValidationResult',\n",
       "    'description': 'Validation result for Example, combining fields from Create/Base/Update schemas.'},\n",
       "   'ExampleWithRuns': {'properties': {'outputs': {'anyOf': [{'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Outputs'},\n",
       "     'dataset_id': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'},\n",
       "     'source_run_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Source Run Id'},\n",
       "     'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Metadata'},\n",
       "     'inputs': {'type': 'object', 'title': 'Inputs'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'name': {'type': 'string', 'title': 'Name'},\n",
       "     'modified_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Modified At'},\n",
       "     'attachment_urls': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Attachment Urls'},\n",
       "     'runs': {'items': {'$ref': '#/components/schemas/RunSchema'},\n",
       "      'type': 'array',\n",
       "      'title': 'Runs'}},\n",
       "    'type': 'object',\n",
       "    'required': ['dataset_id', 'inputs', 'id', 'name', 'runs'],\n",
       "    'title': 'ExampleWithRuns',\n",
       "    'description': 'Example schema with list of runs.'},\n",
       "   'ExampleWithRunsCH': {'properties': {'outputs': {'anyOf': [{'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Outputs'},\n",
       "     'dataset_id': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'},\n",
       "     'source_run_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Source Run Id'},\n",
       "     'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Metadata'},\n",
       "     'inputs': {'type': 'object', 'title': 'Inputs'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'name': {'type': 'string', 'title': 'Name'},\n",
       "     'modified_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Modified At'},\n",
       "     'attachment_urls': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Attachment Urls'},\n",
       "     'runs': {'items': {'$ref': '#/components/schemas/RunSchemaComparisonView'},\n",
       "      'type': 'array',\n",
       "      'title': 'Runs'}},\n",
       "    'type': 'object',\n",
       "    'required': ['dataset_id', 'inputs', 'id', 'name', 'runs'],\n",
       "    'title': 'ExampleWithRunsCH',\n",
       "    'description': 'Example schema with list of runs.'},\n",
       "   'ExampleWithRunsGroup': {'properties': {'filter': {'type': 'string',\n",
       "      'title': 'Filter'},\n",
       "     'count': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Count'},\n",
       "     'total_tokens': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Total Tokens'},\n",
       "     'total_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Total Cost'},\n",
       "     'min_start_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Min Start Time'},\n",
       "     'max_start_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Max Start Time'},\n",
       "     'latency_p50': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'Latency P50'},\n",
       "     'latency_p99': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'Latency P99'},\n",
       "     'feedback_stats': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Feedback Stats'},\n",
       "     'group_key': {'title': 'Group Key'},\n",
       "     'examples': {'anyOf': [{'items': {'$ref': '#/components/schemas/ExampleWithRuns'},\n",
       "        'type': 'array'},\n",
       "       {'items': {'$ref': '#/components/schemas/ExampleWithRunsCH'},\n",
       "        'type': 'array'}],\n",
       "      'title': 'Examples'},\n",
       "     'prompt_tokens': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Prompt Tokens'},\n",
       "     'completion_tokens': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Completion Tokens'},\n",
       "     'prompt_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Prompt Cost'},\n",
       "     'completion_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Completion Cost'},\n",
       "     'error_rate': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'Error Rate'}},\n",
       "    'type': 'object',\n",
       "    'required': ['filter', 'group_key', 'examples'],\n",
       "    'title': 'ExampleWithRunsGroup',\n",
       "    'description': 'Group of examples with runs.'},\n",
       "   'ExperimentResultRow': {'properties': {'row_id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Row Id'},\n",
       "     'inputs': {'type': 'object', 'title': 'Inputs'},\n",
       "     'expected_outputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Expected Outputs'},\n",
       "     'actual_outputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Actual Outputs'},\n",
       "     'evaluation_scores': {'anyOf': [{'items': {'$ref': '#/components/schemas/FeedbackCreateCoreSchema'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Evaluation Scores'},\n",
       "     'start_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'End Time'},\n",
       "     'run_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Run Name'},\n",
       "     'error': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Error'},\n",
       "     'run_metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Run Metadata'}},\n",
       "    'type': 'object',\n",
       "    'required': ['inputs', 'start_time', 'end_time'],\n",
       "    'title': 'ExperimentResultRow',\n",
       "    'description': 'Class for a single row in the uploaded experiment results.'},\n",
       "   'ExperimentResultsUpload': {'properties': {'experiment_name': {'type': 'string',\n",
       "      'title': 'Experiment Name'},\n",
       "     'experiment_description': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Experiment Description'},\n",
       "     'dataset_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Dataset Id'},\n",
       "     'dataset_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Dataset Name'},\n",
       "     'dataset_description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Dataset Description'},\n",
       "     'summary_experiment_scores': {'anyOf': [{'items': {'$ref': '#/components/schemas/FeedbackCreateCoreSchema'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Summary Experiment Scores'},\n",
       "     'results': {'items': {'$ref': '#/components/schemas/ExperimentResultRow'},\n",
       "      'type': 'array',\n",
       "      'title': 'Results'},\n",
       "     'experiment_start_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Experiment Start Time'},\n",
       "     'experiment_end_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Experiment End Time'},\n",
       "     'experiment_metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Experiment Metadata'}},\n",
       "    'type': 'object',\n",
       "    'required': ['experiment_name',\n",
       "     'results',\n",
       "     'experiment_start_time',\n",
       "     'experiment_end_time'],\n",
       "    'title': 'ExperimentResultsUpload',\n",
       "    'description': 'Class for uploading the results of an already-run experiment.'},\n",
       "   'ExperimentResultsUploadResult': {'properties': {'dataset': {'$ref': '#/components/schemas/Dataset'},\n",
       "     'experiment': {'$ref': '#/components/schemas/TracerSession'}},\n",
       "    'type': 'object',\n",
       "    'required': ['dataset', 'experiment'],\n",
       "    'title': 'ExperimentResultsUploadResult',\n",
       "    'description': 'Class for uploading the results of an already-run experiment.'},\n",
       "   'ExportAnnotationQueueRunsRequest': {'properties': {'start_time': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'End Time'}},\n",
       "    'type': 'object',\n",
       "    'title': 'ExportAnnotationQueueRunsRequest',\n",
       "    'description': 'Export annotation queue runs request schema.'},\n",
       "   'FeedbackCategory': {'properties': {'value': {'type': 'number',\n",
       "      'title': 'Value'},\n",
       "     'label': {'anyOf': [{'type': 'string', 'minLength': 1}, {'type': 'null'}],\n",
       "      'title': 'Label'}},\n",
       "    'type': 'object',\n",
       "    'required': ['value'],\n",
       "    'title': 'FeedbackCategory',\n",
       "    'description': 'Specific value and label pair for feedback'},\n",
       "   'FeedbackConfig': {'properties': {'type': {'$ref': '#/components/schemas/FeedbackType'},\n",
       "     'min': {'anyOf': [{'type': 'number'}, {'type': 'null'}], 'title': 'Min'},\n",
       "     'max': {'anyOf': [{'type': 'number'}, {'type': 'null'}], 'title': 'Max'},\n",
       "     'categories': {'anyOf': [{'items': {'$ref': '#/components/schemas/FeedbackCategory'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Categories'}},\n",
       "    'type': 'object',\n",
       "    'required': ['type'],\n",
       "    'title': 'FeedbackConfig'},\n",
       "   'FeedbackConfigSchema': {'properties': {'feedback_key': {'type': 'string',\n",
       "      'title': 'Feedback Key'},\n",
       "     'feedback_config': {'$ref': '#/components/schemas/FeedbackConfig'},\n",
       "     'tenant_id': {'type': 'string', 'format': 'uuid', 'title': 'Tenant Id'},\n",
       "     'modified_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Modified At'},\n",
       "     'is_lower_score_better': {'anyOf': [{'type': 'boolean'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Is Lower Score Better'}},\n",
       "    'type': 'object',\n",
       "    'required': ['feedback_key',\n",
       "     'feedback_config',\n",
       "     'tenant_id',\n",
       "     'modified_at'],\n",
       "    'title': 'FeedbackConfigSchema'},\n",
       "   'FeedbackCreateCoreSchema': {'properties': {'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'modified_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Modified At'},\n",
       "     'key': {'type': 'string', 'maxLength': 180, 'title': 'Key'},\n",
       "     'score': {'anyOf': [{'type': 'number'},\n",
       "       {'type': 'integer'},\n",
       "       {'type': 'boolean'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Score'},\n",
       "     'value': {'anyOf': [{'type': 'number'},\n",
       "       {'type': 'integer'},\n",
       "       {'type': 'boolean'},\n",
       "       {'type': 'string'},\n",
       "       {'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Value'},\n",
       "     'comment': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Comment'},\n",
       "     'correction': {'anyOf': [{'type': 'object'},\n",
       "       {'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Correction'},\n",
       "     'feedback_group_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Feedback Group Id'},\n",
       "     'comparative_experiment_id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Comparative Experiment Id'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'feedback_source': {'anyOf': [{'$ref': '#/components/schemas/AppFeedbackSource'},\n",
       "       {'$ref': '#/components/schemas/APIFeedbackSource'},\n",
       "       {'$ref': '#/components/schemas/ModelFeedbackSource'},\n",
       "       {'$ref': '#/components/schemas/AutoEvalFeedbackSource'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Feedback Source'},\n",
       "     'feedback_config': {'anyOf': [{'$ref': '#/components/schemas/FeedbackConfig'},\n",
       "       {'type': 'null'}]},\n",
       "     'extra': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Extra'}},\n",
       "    'type': 'object',\n",
       "    'required': ['key'],\n",
       "    'title': 'FeedbackCreateCoreSchema',\n",
       "    'description': 'Schema used for creating feedback without run id or session id.'},\n",
       "   'FeedbackCreateSchema': {'properties': {'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'modified_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Modified At'},\n",
       "     'key': {'type': 'string', 'maxLength': 180, 'title': 'Key'},\n",
       "     'score': {'anyOf': [{'type': 'number'},\n",
       "       {'type': 'integer'},\n",
       "       {'type': 'boolean'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Score'},\n",
       "     'value': {'anyOf': [{'type': 'number'},\n",
       "       {'type': 'integer'},\n",
       "       {'type': 'boolean'},\n",
       "       {'type': 'string'},\n",
       "       {'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Value'},\n",
       "     'comment': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Comment'},\n",
       "     'correction': {'anyOf': [{'type': 'object'},\n",
       "       {'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Correction'},\n",
       "     'feedback_group_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Feedback Group Id'},\n",
       "     'comparative_experiment_id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Comparative Experiment Id'},\n",
       "     'run_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Run Id'},\n",
       "     'session_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Session Id'},\n",
       "     'trace_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Trace Id'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'feedback_source': {'anyOf': [{'$ref': '#/components/schemas/AppFeedbackSource'},\n",
       "       {'$ref': '#/components/schemas/APIFeedbackSource'},\n",
       "       {'$ref': '#/components/schemas/ModelFeedbackSource'},\n",
       "       {'$ref': '#/components/schemas/AutoEvalFeedbackSource'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Feedback Source'},\n",
       "     'feedback_config': {'anyOf': [{'$ref': '#/components/schemas/FeedbackConfig'},\n",
       "       {'type': 'null'}]},\n",
       "     'error': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Error'}},\n",
       "    'type': 'object',\n",
       "    'required': ['key'],\n",
       "    'title': 'FeedbackCreateSchema',\n",
       "    'description': 'Schema used for creating feedback.'},\n",
       "   'FeedbackCreateWithTokenExtendedSchema': {'properties': {'score': {'anyOf': [{'type': 'number'},\n",
       "       {'type': 'integer'},\n",
       "       {'type': 'boolean'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Score'},\n",
       "     'value': {'anyOf': [{'type': 'number'},\n",
       "       {'type': 'integer'},\n",
       "       {'type': 'boolean'},\n",
       "       {'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Value'},\n",
       "     'comment': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Comment'},\n",
       "     'correction': {'anyOf': [{'type': 'object'},\n",
       "       {'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Correction'},\n",
       "     'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Metadata'}},\n",
       "    'type': 'object',\n",
       "    'title': 'FeedbackCreateWithTokenExtendedSchema',\n",
       "    'description': 'Feedback create schema with token.'},\n",
       "   'FeedbackDelta': {'properties': {'improved_examples': {'items': {'type': 'string',\n",
       "       'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'title': 'Improved Examples'},\n",
       "     'regressed_examples': {'items': {'type': 'string', 'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'title': 'Regressed Examples'}},\n",
       "    'type': 'object',\n",
       "    'required': ['improved_examples', 'regressed_examples'],\n",
       "    'title': 'FeedbackDelta',\n",
       "    'description': 'Feedback key with number of improvements and regressions.'},\n",
       "   'FeedbackIngestTokenCreateSchema': {'properties': {'expires_in': {'anyOf': [{'$ref': '#/components/schemas/TimedeltaInput'},\n",
       "       {'type': 'null'}]},\n",
       "     'expires_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Expires At'},\n",
       "     'run_id': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'},\n",
       "     'feedback_key': {'type': 'string', 'title': 'Feedback Key'},\n",
       "     'feedback_config': {'anyOf': [{'$ref': '#/components/schemas/FeedbackConfig'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'required': ['run_id', 'feedback_key'],\n",
       "    'title': 'FeedbackIngestTokenCreateSchema',\n",
       "    'description': 'Feedback ingest token create schema.'},\n",
       "   'FeedbackIngestTokenSchema': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'url': {'type': 'string', 'title': 'Url'},\n",
       "     'expires_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Expires At'},\n",
       "     'feedback_key': {'type': 'string', 'title': 'Feedback Key'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id', 'url', 'expires_at', 'feedback_key'],\n",
       "    'title': 'FeedbackIngestTokenSchema',\n",
       "    'description': 'Feedback ingest token schema.'},\n",
       "   'FeedbackLevel': {'type': 'string',\n",
       "    'enum': ['run', 'session'],\n",
       "    'title': 'FeedbackLevel',\n",
       "    'description': 'Enum for feedback levels.'},\n",
       "   'FeedbackSchema': {'properties': {'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'modified_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Modified At'},\n",
       "     'key': {'type': 'string', 'title': 'Key'},\n",
       "     'score': {'anyOf': [{'type': 'number'},\n",
       "       {'type': 'integer'},\n",
       "       {'type': 'boolean'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Score'},\n",
       "     'value': {'anyOf': [{'type': 'number'},\n",
       "       {'type': 'integer'},\n",
       "       {'type': 'boolean'},\n",
       "       {'type': 'string'},\n",
       "       {'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Value'},\n",
       "     'comment': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Comment'},\n",
       "     'correction': {'anyOf': [{'type': 'object'},\n",
       "       {'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Correction'},\n",
       "     'feedback_group_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Feedback Group Id'},\n",
       "     'comparative_experiment_id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Comparative Experiment Id'},\n",
       "     'run_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Run Id'},\n",
       "     'session_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Session Id'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'trace_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Trace Id'},\n",
       "     'start_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Start Time'},\n",
       "     'feedback_source': {'anyOf': [{'$ref': '#/components/schemas/FeedbackSource'},\n",
       "       {'type': 'null'}]},\n",
       "     'extra': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Extra'}},\n",
       "    'type': 'object',\n",
       "    'required': ['key', 'id'],\n",
       "    'title': 'FeedbackSchema',\n",
       "    'description': 'Schema for getting feedback.'},\n",
       "   'FeedbackSource': {'properties': {'type': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Type'},\n",
       "     'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Metadata'},\n",
       "     'user_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'User Id'},\n",
       "     'user_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'User Name'}},\n",
       "    'type': 'object',\n",
       "    'title': 'FeedbackSource',\n",
       "    'description': 'The feedback source loaded from the database.'},\n",
       "   'FeedbackType': {'type': 'string',\n",
       "    'enum': ['continuous', 'categorical', 'freeform'],\n",
       "    'title': 'FeedbackType',\n",
       "    'description': 'Enum for feedback types.'},\n",
       "   'FeedbackUpdateSchema': {'properties': {'score': {'anyOf': [{'type': 'number'},\n",
       "       {'type': 'integer'},\n",
       "       {'type': 'boolean'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Score'},\n",
       "     'value': {'anyOf': [{'type': 'number'},\n",
       "       {'type': 'integer'},\n",
       "       {'type': 'boolean'},\n",
       "       {'type': 'string'},\n",
       "       {'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Value'},\n",
       "     'comment': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Comment'},\n",
       "     'correction': {'anyOf': [{'type': 'object'},\n",
       "       {'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Correction'},\n",
       "     'feedback_config': {'anyOf': [{'$ref': '#/components/schemas/FeedbackConfig'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'title': 'FeedbackUpdateSchema',\n",
       "    'description': 'Schema used for updating feedback'},\n",
       "   'FilterView': {'properties': {'filter_string': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Filter String'},\n",
       "     'trace_filter_string': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Trace Filter String'},\n",
       "     'tree_filter_string': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Tree Filter String'},\n",
       "     'display_name': {'type': 'string', 'title': 'Display Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'type': {'$ref': '#/components/schemas/FilterViewType',\n",
       "      'default': 'runs'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'session_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Session Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'}},\n",
       "    'type': 'object',\n",
       "    'required': ['display_name', 'id', 'created_at', 'updated_at'],\n",
       "    'title': 'FilterView'},\n",
       "   'FilterViewCreate': {'properties': {'filter_string': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Filter String'},\n",
       "     'trace_filter_string': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Trace Filter String'},\n",
       "     'tree_filter_string': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Tree Filter String'},\n",
       "     'display_name': {'type': 'string', 'title': 'Display Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'type': {'$ref': '#/components/schemas/FilterViewType',\n",
       "      'default': 'runs'}},\n",
       "    'type': 'object',\n",
       "    'required': ['display_name'],\n",
       "    'title': 'FilterViewCreate'},\n",
       "   'FilterViewType': {'type': 'string',\n",
       "    'enum': ['runs', 'threads'],\n",
       "    'title': 'FilterViewType'},\n",
       "   'FilterViewUpdate': {'properties': {'filter_string': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Filter String'},\n",
       "     'display_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Display Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'trace_filter_string': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Trace Filter String'},\n",
       "     'tree_filter_string': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Tree Filter String'},\n",
       "     'type': {'anyOf': [{'$ref': '#/components/schemas/FilterViewType'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'title': 'FilterViewUpdate'},\n",
       "   'ForkRepoRequest': {'properties': {'repo_handle': {'type': 'string',\n",
       "      'title': 'Repo Handle'},\n",
       "     'readme': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Readme'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'tags': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Tags'},\n",
       "     'is_public': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Is Public'}},\n",
       "    'type': 'object',\n",
       "    'required': ['repo_handle'],\n",
       "    'title': 'ForkRepoRequest',\n",
       "    'description': 'Fields to fork a repo'},\n",
       "   'FunctionMessage': {'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "       {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "        'type': 'array'}],\n",
       "      'title': 'Content'},\n",
       "     'additional_kwargs': {'type': 'object', 'title': 'Additional Kwargs'},\n",
       "     'response_metadata': {'type': 'object', 'title': 'Response Metadata'},\n",
       "     'type': {'type': 'string',\n",
       "      'const': 'function',\n",
       "      'title': 'Type',\n",
       "      'default': 'function'},\n",
       "     'name': {'type': 'string', 'title': 'Name'},\n",
       "     'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'}},\n",
       "    'additionalProperties': True,\n",
       "    'type': 'object',\n",
       "    'required': ['content', 'name'],\n",
       "    'title': 'FunctionMessage',\n",
       "    'description': 'Message for passing the result of executing a tool back to a model.\\n\\nFunctionMessage are an older version of the ToolMessage schema, and\\ndo not contain the tool_call_id field.\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.'},\n",
       "   'FunctionMessageChunk': {'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "       {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "        'type': 'array'}],\n",
       "      'title': 'Content'},\n",
       "     'additional_kwargs': {'type': 'object', 'title': 'Additional Kwargs'},\n",
       "     'response_metadata': {'type': 'object', 'title': 'Response Metadata'},\n",
       "     'type': {'type': 'string',\n",
       "      'const': 'FunctionMessageChunk',\n",
       "      'title': 'Type',\n",
       "      'default': 'FunctionMessageChunk'},\n",
       "     'name': {'type': 'string', 'title': 'Name'},\n",
       "     'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'}},\n",
       "    'additionalProperties': True,\n",
       "    'type': 'object',\n",
       "    'required': ['content', 'name'],\n",
       "    'title': 'FunctionMessageChunk',\n",
       "    'description': 'Function Message chunk.'},\n",
       "   'GenerateSyntheticExamplesBody': {'properties': {'example_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Example Ids'},\n",
       "     'num_examples': {'type': 'integer', 'title': 'Num Examples'}},\n",
       "    'type': 'object',\n",
       "    'required': ['num_examples'],\n",
       "    'title': 'GenerateSyntheticExamplesBody'},\n",
       "   'GetRepoResponse': {'properties': {'repo': {'$ref': '#/components/schemas/RepoWithLookups'}},\n",
       "    'type': 'object',\n",
       "    'required': ['repo'],\n",
       "    'title': 'GetRepoResponse'},\n",
       "   'GroupExampleRunsByField': {'type': 'string',\n",
       "    'enum': ['run_metadata', 'example_metadata'],\n",
       "    'title': 'GroupExampleRunsByField'},\n",
       "   'GroupedExamplesWithRunsResponse': {'properties': {'groups': {'items': {'$ref': '#/components/schemas/ExampleWithRunsGroup'},\n",
       "      'type': 'array',\n",
       "      'title': 'Groups'}},\n",
       "    'type': 'object',\n",
       "    'required': ['groups'],\n",
       "    'title': 'GroupedExamplesWithRunsResponse',\n",
       "    'description': 'Grouped examples with runs.'},\n",
       "   'HTTPValidationError': {'properties': {'detail': {'items': {'$ref': '#/components/schemas/ValidationError'},\n",
       "      'type': 'array',\n",
       "      'title': 'Detail'}},\n",
       "    'type': 'object',\n",
       "    'title': 'HTTPValidationError'},\n",
       "   'HealthInfoGetResponse': {'properties': {'clickhouse_disk_free_pct': {'type': 'number',\n",
       "      'title': 'Clickhouse Disk Free Pct'}},\n",
       "    'type': 'object',\n",
       "    'required': ['clickhouse_disk_free_pct'],\n",
       "    'title': 'HealthInfoGetResponse',\n",
       "    'description': 'The LangSmith server info.'},\n",
       "   'Highlight': {'properties': {'prompt_chunk_start_index': {'type': 'integer',\n",
       "      'title': 'Prompt Chunk Start Index'},\n",
       "     'prompt_chunk_end_index': {'type': 'integer',\n",
       "      'title': 'Prompt Chunk End Index'},\n",
       "     'prompt_chunk': {'type': 'string', 'title': 'Prompt Chunk'},\n",
       "     'highlight_text': {'type': 'string', 'title': 'Highlight Text'}},\n",
       "    'type': 'object',\n",
       "    'required': ['prompt_chunk_start_index',\n",
       "     'prompt_chunk_end_index',\n",
       "     'prompt_chunk',\n",
       "     'highlight_text'],\n",
       "    'title': 'Highlight'},\n",
       "   'HostProjectChartMetric': {'type': 'string',\n",
       "    'enum': ['memory_usage', 'cpu_usage', 'restart_count'],\n",
       "    'title': 'HostProjectChartMetric',\n",
       "    'description': 'LGP Metrics you can chart.'},\n",
       "   'HumanMessage': {'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "       {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "        'type': 'array'}],\n",
       "      'title': 'Content'},\n",
       "     'additional_kwargs': {'type': 'object', 'title': 'Additional Kwargs'},\n",
       "     'response_metadata': {'type': 'object', 'title': 'Response Metadata'},\n",
       "     'type': {'type': 'string',\n",
       "      'const': 'human',\n",
       "      'title': 'Type',\n",
       "      'default': 'human'},\n",
       "     'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "     'example': {'type': 'boolean', 'title': 'Example', 'default': False}},\n",
       "    'additionalProperties': True,\n",
       "    'type': 'object',\n",
       "    'required': ['content'],\n",
       "    'title': 'HumanMessage',\n",
       "    'description': 'Message from a human.\\n\\nHumanMessages are messages that are passed in from a human to the model.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Instantiate a chat model and invoke it with the messages\\n        model = ...\\n        print(model.invoke(messages))'},\n",
       "   'HumanMessageChunk': {'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "       {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "        'type': 'array'}],\n",
       "      'title': 'Content'},\n",
       "     'additional_kwargs': {'type': 'object', 'title': 'Additional Kwargs'},\n",
       "     'response_metadata': {'type': 'object', 'title': 'Response Metadata'},\n",
       "     'type': {'type': 'string',\n",
       "      'const': 'HumanMessageChunk',\n",
       "      'title': 'Type',\n",
       "      'default': 'HumanMessageChunk'},\n",
       "     'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "     'example': {'type': 'boolean', 'title': 'Example', 'default': False}},\n",
       "    'additionalProperties': True,\n",
       "    'type': 'object',\n",
       "    'required': ['content'],\n",
       "    'title': 'HumanMessageChunk',\n",
       "    'description': 'Human Message chunk.'},\n",
       "   'Identity': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'organization_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Organization Id'},\n",
       "     'tenant_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Tenant Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'user_id': {'type': 'string', 'format': 'uuid', 'title': 'User Id'},\n",
       "     'ls_user_id': {'type': 'string', 'format': 'uuid', 'title': 'Ls User Id'},\n",
       "     'read_only': {'type': 'boolean', 'title': 'Read Only'},\n",
       "     'role_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Role Id'},\n",
       "     'role_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Role Name'},\n",
       "     'access_scope': {'$ref': '#/components/schemas/AccessScope',\n",
       "      'default': 'workspace'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id',\n",
       "     'organization_id',\n",
       "     'created_at',\n",
       "     'user_id',\n",
       "     'ls_user_id',\n",
       "     'read_only'],\n",
       "    'title': 'Identity'},\n",
       "   'IdentityAnnotationQueueRunStatusCreateSchema': {'properties': {'status': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Status'},\n",
       "     'override_added_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Override Added At'}},\n",
       "    'type': 'object',\n",
       "    'title': 'IdentityAnnotationQueueRunStatusCreateSchema',\n",
       "    'description': 'Identity annotation queue run status create schema.'},\n",
       "   'IdentityCreate': {'properties': {'user_id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'User Id'},\n",
       "     'org_identity_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Org Identity Id'},\n",
       "     'read_only': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Read Only'},\n",
       "     'role_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Role Id'}},\n",
       "    'type': 'object',\n",
       "    'title': 'IdentityCreate'},\n",
       "   'IdentityPatch': {'properties': {'read_only': {'anyOf': [{'type': 'boolean'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Read Only'},\n",
       "     'role_id': {'type': 'string', 'format': 'uuid', 'title': 'Role Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['role_id'],\n",
       "    'title': 'IdentityPatch'},\n",
       "   'InfoGetResponse': {'properties': {'version': {'type': 'string',\n",
       "      'title': 'Version'},\n",
       "     'license_expiration_time': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'License Expiration Time'},\n",
       "     'batch_ingest_config': {'$ref': '#/components/schemas/BatchIngestConfig'},\n",
       "     'instance_flags': {'type': 'object', 'title': 'Instance Flags'}},\n",
       "    'type': 'object',\n",
       "    'required': ['version'],\n",
       "    'title': 'InfoGetResponse',\n",
       "    'description': 'The LangSmith server info.'},\n",
       "   'InputTokenDetails': {'properties': {'audio': {'type': 'integer',\n",
       "      'title': 'Audio'},\n",
       "     'cache_creation': {'type': 'integer', 'title': 'Cache Creation'},\n",
       "     'cache_read': {'type': 'integer', 'title': 'Cache Read'}},\n",
       "    'type': 'object',\n",
       "    'title': 'InputTokenDetails',\n",
       "    'description': 'Breakdown of input token counts.\\n\\nDoes *not* need to sum to full input token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"cache_creation\": 200,\\n            \"cache_read\": 100,\\n        }\\n\\n.. versionadded:: 0.3.9'},\n",
       "   'InvalidToolCall': {'properties': {'name': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'args': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Args'},\n",
       "     'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "     'error': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Error'},\n",
       "     'type': {'type': 'string',\n",
       "      'const': 'invalid_tool_call',\n",
       "      'title': 'Type'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name', 'args', 'id', 'error'],\n",
       "    'title': 'InvalidToolCall',\n",
       "    'description': 'Allowance for errors made by LLM.\\n\\nHere we add an `error` key to surface errors made during generation\\n(e.g., invalid JSON arguments.)'},\n",
       "   'InvokePromptPayload': {'properties': {'messages': {'items': {'prefixItems': [{'type': 'string'},\n",
       "        {'type': 'string'}],\n",
       "       'type': 'array',\n",
       "       'maxItems': 2,\n",
       "       'minItems': 2},\n",
       "      'type': 'array',\n",
       "      'title': 'Messages'},\n",
       "     'template_format': {'type': 'string', 'title': 'Template Format'},\n",
       "     'inputs': {'type': 'object', 'title': 'Inputs'}},\n",
       "    'type': 'object',\n",
       "    'required': ['messages', 'template_format', 'inputs'],\n",
       "    'title': 'InvokePromptPayload'},\n",
       "   'LikeRepoRequest': {'properties': {'like': {'type': 'boolean',\n",
       "      'title': 'Like'}},\n",
       "    'type': 'object',\n",
       "    'required': ['like'],\n",
       "    'title': 'LikeRepoRequest'},\n",
       "   'LikeRepoResponse': {'properties': {'likes': {'type': 'integer',\n",
       "      'title': 'Likes'}},\n",
       "    'type': 'object',\n",
       "    'required': ['likes'],\n",
       "    'title': 'LikeRepoResponse'},\n",
       "   'ListCommentsResponse': {'properties': {'comments': {'items': {'$ref': '#/components/schemas/Comment'},\n",
       "      'type': 'array',\n",
       "      'title': 'Comments'},\n",
       "     'total': {'type': 'integer', 'title': 'Total'}},\n",
       "    'type': 'object',\n",
       "    'required': ['comments', 'total'],\n",
       "    'title': 'ListCommentsResponse'},\n",
       "   'ListCommitsResponse': {'properties': {'commits': {'items': {'$ref': '#/components/schemas/CommitWithLookups'},\n",
       "      'type': 'array',\n",
       "      'title': 'Commits'},\n",
       "     'total': {'type': 'integer', 'title': 'Total'}},\n",
       "    'type': 'object',\n",
       "    'required': ['commits', 'total'],\n",
       "    'title': 'ListCommitsResponse'},\n",
       "   'ListPublicDatasetRunsResponse': {'properties': {'runs': {'items': {'$ref': '#/components/schemas/RunPublicDatasetSchema'},\n",
       "      'type': 'array',\n",
       "      'title': 'Runs'},\n",
       "     'cursors': {'additionalProperties': {'anyOf': [{'type': 'string'},\n",
       "        {'type': 'null'}]},\n",
       "      'type': 'object',\n",
       "      'title': 'Cursors'},\n",
       "     'parsed_query': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Parsed Query'}},\n",
       "    'type': 'object',\n",
       "    'required': ['runs', 'cursors'],\n",
       "    'title': 'ListPublicDatasetRunsResponse'},\n",
       "   'ListPublicRunsResponse': {'properties': {'runs': {'items': {'$ref': '#/components/schemas/RunPublicSchema'},\n",
       "      'type': 'array',\n",
       "      'title': 'Runs'},\n",
       "     'cursors': {'additionalProperties': {'anyOf': [{'type': 'string'},\n",
       "        {'type': 'null'}]},\n",
       "      'type': 'object',\n",
       "      'title': 'Cursors'},\n",
       "     'parsed_query': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Parsed Query'}},\n",
       "    'type': 'object',\n",
       "    'required': ['runs', 'cursors'],\n",
       "    'title': 'ListPublicRunsResponse'},\n",
       "   'ListReposResponse': {'properties': {'repos': {'items': {'$ref': '#/components/schemas/RepoWithLookups'},\n",
       "      'type': 'array',\n",
       "      'title': 'Repos'},\n",
       "     'total': {'type': 'integer', 'title': 'Total'}},\n",
       "    'type': 'object',\n",
       "    'required': ['repos', 'total'],\n",
       "    'title': 'ListReposResponse'},\n",
       "   'ListRunsResponse': {'properties': {'runs': {'items': {'$ref': '#/components/schemas/RunSchema'},\n",
       "      'type': 'array',\n",
       "      'title': 'Runs'},\n",
       "     'cursors': {'additionalProperties': {'anyOf': [{'type': 'string'},\n",
       "        {'type': 'null'}]},\n",
       "      'type': 'object',\n",
       "      'title': 'Cursors'},\n",
       "     'search_cursors': {'anyOf': [{'additionalProperties': {'anyOf': [{},\n",
       "          {'type': 'null'}]},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Search Cursors'},\n",
       "     'parsed_query': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Parsed Query'}},\n",
       "    'type': 'object',\n",
       "    'required': ['runs', 'cursors'],\n",
       "    'title': 'ListRunsResponse'},\n",
       "   'ListTagsForResourceRequest': {'properties': {'resource_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Resource Id'},\n",
       "     'resource_type': {'$ref': '#/components/schemas/ResourceType'}},\n",
       "    'type': 'object',\n",
       "    'required': ['resource_id', 'resource_type'],\n",
       "    'title': 'ListTagsForResourceRequest'},\n",
       "   'ListTagsResponse': {'properties': {'tags': {'items': {'$ref': '#/components/schemas/TagCount'},\n",
       "      'type': 'array',\n",
       "      'title': 'Tags'}},\n",
       "    'type': 'object',\n",
       "    'required': ['tags'],\n",
       "    'title': 'ListTagsResponse'},\n",
       "   'MemberIdentity': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'organization_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Organization Id'},\n",
       "     'tenant_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Tenant Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'user_id': {'type': 'string', 'format': 'uuid', 'title': 'User Id'},\n",
       "     'ls_user_id': {'type': 'string', 'format': 'uuid', 'title': 'Ls User Id'},\n",
       "     'read_only': {'type': 'boolean', 'title': 'Read Only'},\n",
       "     'role_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Role Id'},\n",
       "     'role_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Role Name'},\n",
       "     'access_scope': {'$ref': '#/components/schemas/AccessScope',\n",
       "      'default': 'workspace'},\n",
       "     'email': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Email'},\n",
       "     'full_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Full Name'},\n",
       "     'avatar_url': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Avatar Url'},\n",
       "     'linked_login_methods': {'items': {'$ref': '#/components/schemas/ProviderUserSlim'},\n",
       "      'type': 'array',\n",
       "      'title': 'Linked Login Methods',\n",
       "      'default': []},\n",
       "     'org_role_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Org Role Id'},\n",
       "     'org_role_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Org Role Name'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id',\n",
       "     'organization_id',\n",
       "     'created_at',\n",
       "     'user_id',\n",
       "     'ls_user_id',\n",
       "     'read_only'],\n",
       "    'title': 'MemberIdentity'},\n",
       "   'Missing': {'properties': {'__missing__': {'type': 'string',\n",
       "      'const': '__missing__',\n",
       "      'title': 'Missing'}},\n",
       "    'type': 'object',\n",
       "    'required': ['__missing__'],\n",
       "    'title': 'Missing'},\n",
       "   'ModelFeedbackSource': {'properties': {'type': {'type': 'string',\n",
       "      'title': 'Type',\n",
       "      'default': 'model'},\n",
       "     'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Metadata'}},\n",
       "    'type': 'object',\n",
       "    'title': 'ModelFeedbackSource',\n",
       "    'description': 'Model feedback source.'},\n",
       "   'ModelPriceMapCreateSchema': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'},\n",
       "     'start_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Start Time'},\n",
       "     'match_path': {'items': {'type': 'string'},\n",
       "      'type': 'array',\n",
       "      'title': 'Match Path',\n",
       "      'default': ['model',\n",
       "       'model_name',\n",
       "       'model_id',\n",
       "       'model_path',\n",
       "       'endpoint_name']},\n",
       "     'match_pattern': {'type': 'string', 'title': 'Match Pattern'},\n",
       "     'prompt_cost': {'anyOf': [{'type': 'number'}, {'type': 'string'}],\n",
       "      'title': 'Prompt Cost'},\n",
       "     'completion_cost': {'anyOf': [{'type': 'number'}, {'type': 'string'}],\n",
       "      'title': 'Completion Cost'},\n",
       "     'prompt_cost_details': {'anyOf': [{'additionalProperties': {'anyOf': [{'type': 'number'},\n",
       "          {'type': 'string'}]},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Prompt Cost Details'},\n",
       "     'completion_cost_details': {'anyOf': [{'additionalProperties': {'anyOf': [{'type': 'number'},\n",
       "          {'type': 'string'}]},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Completion Cost Details'},\n",
       "     'provider': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Provider'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name', 'match_pattern', 'prompt_cost', 'completion_cost'],\n",
       "    'title': 'ModelPriceMapCreateSchema',\n",
       "    'description': 'Model price map create schema.'},\n",
       "   'ModelPriceMapUpdateSchema': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'},\n",
       "     'start_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Start Time'},\n",
       "     'match_path': {'items': {'type': 'string'},\n",
       "      'type': 'array',\n",
       "      'title': 'Match Path',\n",
       "      'default': ['model',\n",
       "       'model_name',\n",
       "       'model_id',\n",
       "       'model_path',\n",
       "       'endpoint_name']},\n",
       "     'match_pattern': {'type': 'string', 'title': 'Match Pattern'},\n",
       "     'prompt_cost': {'anyOf': [{'type': 'number'}, {'type': 'string'}],\n",
       "      'title': 'Prompt Cost'},\n",
       "     'completion_cost': {'anyOf': [{'type': 'number'}, {'type': 'string'}],\n",
       "      'title': 'Completion Cost'},\n",
       "     'prompt_cost_details': {'anyOf': [{'additionalProperties': {'anyOf': [{'type': 'number'},\n",
       "          {'type': 'string'}]},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Prompt Cost Details'},\n",
       "     'completion_cost_details': {'anyOf': [{'additionalProperties': {'anyOf': [{'type': 'number'},\n",
       "          {'type': 'string'}]},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Completion Cost Details'},\n",
       "     'provider': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Provider'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name', 'match_pattern', 'prompt_cost', 'completion_cost'],\n",
       "    'title': 'ModelPriceMapUpdateSchema',\n",
       "    'description': 'Model price map update schema.'},\n",
       "   'OAuthProvider': {'type': 'string',\n",
       "    'enum': ['custom-oidc'],\n",
       "    'title': 'OAuthProvider'},\n",
       "   'OptimizePromptJobRequest': {'properties': {'algorithm': {'$ref': '#/components/schemas/EPromptOptimizationAlgorithm'},\n",
       "     'config': {'anyOf': [{'$ref': '#/components/schemas/PromptimConfig'},\n",
       "       {'$ref': '#/components/schemas/DemoConfig'}],\n",
       "      'title': 'Config'},\n",
       "     'prompt_name': {'type': 'string', 'title': 'Prompt Name'}},\n",
       "    'type': 'object',\n",
       "    'required': ['algorithm', 'config', 'prompt_name'],\n",
       "    'title': 'OptimizePromptJobRequest',\n",
       "    'description': 'Request to optimize a prompt.'},\n",
       "   'OptimizePromptResponse': {'properties': {'optimization_job_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Optimization Job Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['optimization_job_id'],\n",
       "    'title': 'OptimizePromptResponse',\n",
       "    'description': 'Response from optimizing a prompt.'},\n",
       "   'OrgIdentityPatch': {'properties': {'password': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Password'},\n",
       "     'full_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Full Name'},\n",
       "     'role_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Role Id'}},\n",
       "    'type': 'object',\n",
       "    'title': 'OrgIdentityPatch'},\n",
       "   'OrgMemberIdentity': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'organization_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Organization Id'},\n",
       "     'tenant_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Tenant Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'user_id': {'type': 'string', 'format': 'uuid', 'title': 'User Id'},\n",
       "     'ls_user_id': {'type': 'string', 'format': 'uuid', 'title': 'Ls User Id'},\n",
       "     'read_only': {'type': 'boolean', 'title': 'Read Only'},\n",
       "     'role_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Role Id'},\n",
       "     'role_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Role Name'},\n",
       "     'access_scope': {'$ref': '#/components/schemas/AccessScope',\n",
       "      'default': 'workspace'},\n",
       "     'email': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Email'},\n",
       "     'full_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Full Name'},\n",
       "     'avatar_url': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Avatar Url'},\n",
       "     'linked_login_methods': {'items': {'$ref': '#/components/schemas/ProviderUserSlim'},\n",
       "      'type': 'array',\n",
       "      'title': 'Linked Login Methods',\n",
       "      'default': []},\n",
       "     'org_role_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Org Role Id'},\n",
       "     'org_role_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Org Role Name'},\n",
       "     'tenant_ids': {'items': {'type': 'string', 'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'title': 'Tenant Ids',\n",
       "      'default': []}},\n",
       "    'type': 'object',\n",
       "    'required': ['id',\n",
       "     'organization_id',\n",
       "     'created_at',\n",
       "     'user_id',\n",
       "     'ls_user_id',\n",
       "     'read_only'],\n",
       "    'title': 'OrgMemberIdentity'},\n",
       "   'OrgPendingIdentity': {'properties': {'email': {'type': 'string',\n",
       "      'title': 'Email'},\n",
       "     'read_only': {'type': 'boolean', 'title': 'Read Only', 'default': False},\n",
       "     'role_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Role Id'},\n",
       "     'workspace_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Workspace Ids'},\n",
       "     'workspace_role_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Workspace Role Id'},\n",
       "     'password': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Password'},\n",
       "     'full_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Full Name'},\n",
       "     'access_scope': {'$ref': '#/components/schemas/AccessScope',\n",
       "      'default': 'workspace'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'user_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'User Id'},\n",
       "     'tenant_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Tenant Id'},\n",
       "     'organization_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Organization Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'role_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Role Name'},\n",
       "     'org_role_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Org Role Id'},\n",
       "     'org_role_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Org Role Name'},\n",
       "     'tenant_ids': {'items': {'type': 'string', 'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'title': 'Tenant Ids',\n",
       "      'default': []}},\n",
       "    'type': 'object',\n",
       "    'required': ['email', 'id', 'created_at'],\n",
       "    'title': 'OrgPendingIdentity'},\n",
       "   'OrgUsage': {'properties': {'customer_id': {'type': 'string',\n",
       "      'title': 'Customer Id'},\n",
       "     'billable_metric_id': {'type': 'string', 'title': 'Billable Metric Id'},\n",
       "     'billable_metric_name': {'type': 'string',\n",
       "      'title': 'Billable Metric Name'},\n",
       "     'start_timestamp': {'type': 'string', 'title': 'Start Timestamp'},\n",
       "     'end_timestamp': {'type': 'string', 'title': 'End Timestamp'},\n",
       "     'value': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'Value'},\n",
       "     'groups': {'anyOf': [{'additionalProperties': {'type': 'number'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Groups'}},\n",
       "    'type': 'object',\n",
       "    'required': ['customer_id',\n",
       "     'billable_metric_id',\n",
       "     'billable_metric_name',\n",
       "     'start_timestamp',\n",
       "     'end_timestamp',\n",
       "     'value',\n",
       "     'groups'],\n",
       "    'title': 'OrgUsage'},\n",
       "   'Organization': {'properties': {'id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Id'},\n",
       "     'display_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Display Name'},\n",
       "     'config': {'$ref': '#/components/schemas/OrganizationConfig'},\n",
       "     'connected_to_stripe': {'type': 'boolean',\n",
       "      'title': 'Connected To Stripe'},\n",
       "     'connected_to_metronome': {'type': 'boolean',\n",
       "      'title': 'Connected To Metronome'},\n",
       "     'is_personal': {'type': 'boolean', 'title': 'Is Personal'},\n",
       "     'tier': {'anyOf': [{'$ref': '#/components/schemas/PaymentPlanTier'},\n",
       "       {'type': 'null'}]},\n",
       "     'payment_method': {'anyOf': [{'$ref': '#/components/schemas/StripePaymentMethodInfo'},\n",
       "       {'type': 'null'}]},\n",
       "     'has_cancelled': {'type': 'boolean', 'title': 'Has Cancelled'},\n",
       "     'end_of_billing_period': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'End Of Billing Period'},\n",
       "     'current_plan': {'anyOf': [{'$ref': '#/components/schemas/CustomerVisiblePlanInfo'},\n",
       "       {'type': 'null'}]},\n",
       "     'upcoming_plan': {'anyOf': [{'$ref': '#/components/schemas/CustomerVisiblePlanInfo'},\n",
       "       {'type': 'null'}]},\n",
       "     'reached_max_workspaces': {'type': 'boolean',\n",
       "      'title': 'Reached Max Workspaces',\n",
       "      'default': False},\n",
       "     'permissions': {'items': {'type': 'string'},\n",
       "      'type': 'array',\n",
       "      'title': 'Permissions',\n",
       "      'default': []},\n",
       "     'marketplace_payouts_enabled': {'type': 'boolean',\n",
       "      'title': 'Marketplace Payouts Enabled',\n",
       "      'default': False},\n",
       "     'wallet': {'anyOf': [{'$ref': '#/components/schemas/Wallet'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'required': ['config',\n",
       "     'connected_to_stripe',\n",
       "     'connected_to_metronome',\n",
       "     'is_personal',\n",
       "     'has_cancelled'],\n",
       "    'title': 'Organization',\n",
       "    'description': 'Information about an organization.'},\n",
       "   'OrganizationBillingInfo': {'properties': {'id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Id'},\n",
       "     'display_name': {'type': 'string', 'title': 'Display Name'},\n",
       "     'config': {'$ref': '#/components/schemas/OrganizationConfig'},\n",
       "     'connected_to_stripe': {'type': 'boolean',\n",
       "      'title': 'Connected To Stripe'},\n",
       "     'connected_to_metronome': {'type': 'boolean',\n",
       "      'title': 'Connected To Metronome'},\n",
       "     'is_personal': {'type': 'boolean', 'title': 'Is Personal'},\n",
       "     'tier': {'anyOf': [{'$ref': '#/components/schemas/PaymentPlanTier'},\n",
       "       {'type': 'null'}]},\n",
       "     'payment_method': {'anyOf': [{'$ref': '#/components/schemas/StripePaymentMethodInfo'},\n",
       "       {'type': 'null'}]},\n",
       "     'end_of_billing_period': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'End Of Billing Period'},\n",
       "     'current_plan': {'anyOf': [{'$ref': '#/components/schemas/CustomerVisiblePlanInfo'},\n",
       "       {'type': 'null'}]},\n",
       "     'upcoming_plan': {'anyOf': [{'$ref': '#/components/schemas/CustomerVisiblePlanInfo'},\n",
       "       {'type': 'null'}]},\n",
       "     'reached_max_workspaces': {'type': 'boolean',\n",
       "      'title': 'Reached Max Workspaces',\n",
       "      'default': False},\n",
       "     'disabled': {'type': 'boolean', 'title': 'Disabled', 'default': False}},\n",
       "    'type': 'object',\n",
       "    'required': ['display_name',\n",
       "     'config',\n",
       "     'connected_to_stripe',\n",
       "     'connected_to_metronome',\n",
       "     'is_personal'],\n",
       "    'title': 'OrganizationBillingInfo',\n",
       "    'description': \"Information about an organization's billing configuration.\"},\n",
       "   'OrganizationConfig': {'properties': {'max_identities': {'type': 'integer',\n",
       "      'title': 'Max Identities',\n",
       "      'default': 5},\n",
       "     'max_workspaces': {'type': 'integer',\n",
       "      'title': 'Max Workspaces',\n",
       "      'default': 1},\n",
       "     'can_use_rbac': {'type': 'boolean',\n",
       "      'title': 'Can Use Rbac',\n",
       "      'default': False},\n",
       "     'can_add_seats': {'type': 'boolean',\n",
       "      'title': 'Can Add Seats',\n",
       "      'default': True},\n",
       "     'startup_plan_approval_date': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Startup Plan Approval Date'},\n",
       "     'partner_plan_approval_date': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Partner Plan Approval Date'},\n",
       "     'premier_plan_approval_date': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Premier Plan Approval Date'},\n",
       "     'can_disable_public_sharing': {'type': 'boolean',\n",
       "      'title': 'Can Disable Public Sharing',\n",
       "      'default': False},\n",
       "     'can_serve_datasets': {'type': 'boolean',\n",
       "      'title': 'Can Serve Datasets',\n",
       "      'default': False},\n",
       "     'can_use_langgraph_cloud': {'type': 'boolean',\n",
       "      'title': 'Can Use Langgraph Cloud',\n",
       "      'default': False},\n",
       "     'max_langgraph_cloud_deployments': {'type': 'integer',\n",
       "      'title': 'Max Langgraph Cloud Deployments',\n",
       "      'default': 3},\n",
       "     'max_free_langgraph_cloud_deployments': {'type': 'integer',\n",
       "      'title': 'Max Free Langgraph Cloud Deployments',\n",
       "      'default': 0},\n",
       "     'can_use_saml_sso': {'type': 'boolean',\n",
       "      'title': 'Can Use Saml Sso',\n",
       "      'default': False},\n",
       "     'can_use_bulk_export': {'type': 'boolean',\n",
       "      'title': 'Can Use Bulk Export',\n",
       "      'default': False},\n",
       "     'use_python_playground_service': {'type': 'boolean',\n",
       "      'title': 'Use Python Playground Service',\n",
       "      'default': False},\n",
       "     'show_updated_sidenav': {'type': 'boolean',\n",
       "      'title': 'Show Updated Sidenav',\n",
       "      'default': False},\n",
       "     'show_updated_resource_tags': {'type': 'boolean',\n",
       "      'title': 'Show Updated Resource Tags',\n",
       "      'default': False},\n",
       "     'kv_dataset_message_support': {'type': 'boolean',\n",
       "      'title': 'Kv Dataset Message Support',\n",
       "      'default': True},\n",
       "     'show_playground_prompt_canvas': {'type': 'boolean',\n",
       "      'title': 'Show Playground Prompt Canvas',\n",
       "      'default': False},\n",
       "     'allow_custom_iframes': {'type': 'boolean',\n",
       "      'title': 'Allow Custom Iframes',\n",
       "      'default': False},\n",
       "     'enable_langgraph_pricing': {'type': 'boolean',\n",
       "      'title': 'Enable Langgraph Pricing',\n",
       "      'default': False},\n",
       "     'enable_thread_view_playground': {'type': 'boolean',\n",
       "      'title': 'Enable Thread View Playground',\n",
       "      'default': False},\n",
       "     'enable_org_usage_charts': {'type': 'boolean',\n",
       "      'title': 'Enable Org Usage Charts',\n",
       "      'default': False},\n",
       "     'enable_select_all_traces': {'type': 'boolean',\n",
       "      'title': 'Enable Select All Traces',\n",
       "      'default': False},\n",
       "     'use_exact_search_for_prompts': {'type': 'boolean',\n",
       "      'title': 'Use Exact Search For Prompts',\n",
       "      'default': False},\n",
       "     'langgraph_deploy_own_cloud_enabled': {'type': 'boolean',\n",
       "      'title': 'Langgraph Deploy Own Cloud Enabled',\n",
       "      'default': False},\n",
       "     'prompt_optimization_jobs_enabled': {'type': 'boolean',\n",
       "      'title': 'Prompt Optimization Jobs Enabled',\n",
       "      'default': False},\n",
       "     'enable_k8s_vanilla_platform': {'type': 'boolean',\n",
       "      'title': 'Enable K8S Vanilla Platform',\n",
       "      'default': False},\n",
       "     'demo_lgp_new_graph_enabled': {'type': 'boolean',\n",
       "      'title': 'Demo Lgp New Graph Enabled',\n",
       "      'default': False},\n",
       "     'datadog_rum_session_sample_rate': {'type': 'integer',\n",
       "      'title': 'Datadog Rum Session Sample Rate',\n",
       "      'default': 20},\n",
       "     'langgraph_remote_reconciler_enabled': {'type': 'boolean',\n",
       "      'title': 'Langgraph Remote Reconciler Enabled',\n",
       "      'default': False},\n",
       "     'langsmith_alerts_poc_enabled': {'type': 'boolean',\n",
       "      'title': 'Langsmith Alerts Poc Enabled',\n",
       "      'default': True},\n",
       "     'tenant_skip_topk_facets': {'type': 'boolean',\n",
       "      'title': 'Tenant Skip Topk Facets',\n",
       "      'default': False},\n",
       "     'lgp_templates_enabled': {'type': 'boolean',\n",
       "      'title': 'Lgp Templates Enabled',\n",
       "      'default': False},\n",
       "     'langsmith_alerts_legacy_poc_enabled': {'type': 'boolean',\n",
       "      'title': 'Langsmith Alerts Legacy Poc Enabled',\n",
       "      'default': False},\n",
       "     'langsmith_experimental_search_enabled': {'type': 'boolean',\n",
       "      'title': 'Langsmith Experimental Search Enabled',\n",
       "      'default': False},\n",
       "     'enable_align_evaluators': {'type': 'boolean',\n",
       "      'title': 'Enable Align Evaluators',\n",
       "      'default': False},\n",
       "     'max_prompt_webhooks': {'type': 'integer',\n",
       "      'title': 'Max Prompt Webhooks',\n",
       "      'default': 1},\n",
       "     'playground_evaluator_strategy': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Playground Evaluator Strategy',\n",
       "      'default': 'sync'},\n",
       "     'enable_monthly_usage_charts': {'type': 'boolean',\n",
       "      'title': 'Enable Monthly Usage Charts',\n",
       "      'default': False},\n",
       "     'enable_studio_experiments': {'type': 'boolean',\n",
       "      'title': 'Enable Studio Experiments',\n",
       "      'default': False},\n",
       "     'enable_lgp_metrics_charts': {'type': 'boolean',\n",
       "      'title': 'Enable Lgp Metrics Charts',\n",
       "      'default': False}},\n",
       "    'type': 'object',\n",
       "    'title': 'OrganizationConfig',\n",
       "    'description': 'Organization level configuration. May include any field that exists in tenant config and additional fields.'},\n",
       "   'OrganizationCreate': {'properties': {'display_name': {'type': 'string',\n",
       "      'minLength': 1,\n",
       "      'pattern': '^[a-zA-Z0-9\\\\-_ ]+$',\n",
       "      'title': 'Display Name'},\n",
       "     'is_personal': {'type': 'boolean', 'title': 'Is Personal'}},\n",
       "    'type': 'object',\n",
       "    'required': ['display_name', 'is_personal'],\n",
       "    'title': 'OrganizationCreate',\n",
       "    'description': 'Create organization schema.'},\n",
       "   'OrganizationDashboardColorScheme': {'type': 'string',\n",
       "    'enum': ['light', 'dark'],\n",
       "    'title': 'OrganizationDashboardColorScheme',\n",
       "    'description': 'Enum for acceptable color schemes of dashboards.'},\n",
       "   'OrganizationDashboardSchema': {'properties': {'embeddable_url': {'type': 'string',\n",
       "      'title': 'Embeddable Url'}},\n",
       "    'type': 'object',\n",
       "    'required': ['embeddable_url'],\n",
       "    'title': 'OrganizationDashboardSchema',\n",
       "    'description': 'Organization dashboard for usage or invoices.'},\n",
       "   'OrganizationDashboardType': {'type': 'string',\n",
       "    'enum': ['invoices', 'usage', 'credits'],\n",
       "    'title': 'OrganizationDashboardType',\n",
       "    'description': 'Enum for acceptable types of dashboards.'},\n",
       "   'OrganizationInfo': {'properties': {'id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Id'},\n",
       "     'display_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Display Name'},\n",
       "     'config': {'$ref': '#/components/schemas/OrganizationConfig'},\n",
       "     'is_personal': {'type': 'boolean', 'title': 'Is Personal'},\n",
       "     'tier': {'anyOf': [{'$ref': '#/components/schemas/PaymentPlanTier'},\n",
       "       {'type': 'null'}]},\n",
       "     'reached_max_workspaces': {'type': 'boolean',\n",
       "      'title': 'Reached Max Workspaces',\n",
       "      'default': False},\n",
       "     'permissions': {'items': {'type': 'string'},\n",
       "      'type': 'array',\n",
       "      'title': 'Permissions',\n",
       "      'default': []},\n",
       "     'disabled': {'type': 'boolean', 'title': 'Disabled', 'default': False},\n",
       "     'sso_only': {'type': 'boolean', 'title': 'Sso Only', 'default': False},\n",
       "     'sso_login_slug': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Sso Login Slug'},\n",
       "     'public_sharing_disabled': {'type': 'boolean',\n",
       "      'title': 'Public Sharing Disabled',\n",
       "      'default': False},\n",
       "     'marketplace_payouts_enabled': {'type': 'boolean',\n",
       "      'title': 'Marketplace Payouts Enabled',\n",
       "      'default': False},\n",
       "     'wallet': {'anyOf': [{'$ref': '#/components/schemas/Wallet'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'required': ['config', 'is_personal'],\n",
       "    'title': 'OrganizationInfo',\n",
       "    'description': 'Information about an organization.'},\n",
       "   'OrganizationMembers': {'properties': {'organization_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Organization Id'},\n",
       "     'members': {'items': {'$ref': '#/components/schemas/OrgMemberIdentity'},\n",
       "      'type': 'array',\n",
       "      'title': 'Members'},\n",
       "     'pending': {'items': {'$ref': '#/components/schemas/OrgPendingIdentity'},\n",
       "      'type': 'array',\n",
       "      'title': 'Pending'}},\n",
       "    'type': 'object',\n",
       "    'required': ['organization_id', 'members', 'pending'],\n",
       "    'title': 'OrganizationMembers',\n",
       "    'description': 'Organization members schema.'},\n",
       "   'OrganizationPGSchemaSlim': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'display_name': {'type': 'string', 'title': 'Display Name'},\n",
       "     'created_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Created At'},\n",
       "     'created_by_user_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Created By User Id'},\n",
       "     'modified_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Modified At'},\n",
       "     'is_personal': {'type': 'boolean', 'title': 'Is Personal'},\n",
       "     'disabled': {'type': 'boolean', 'title': 'Disabled'},\n",
       "     'sso_login_slug': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Sso Login Slug'},\n",
       "     'sso_only': {'type': 'boolean', 'title': 'Sso Only', 'default': False},\n",
       "     'public_sharing_disabled': {'type': 'boolean',\n",
       "      'title': 'Public Sharing Disabled',\n",
       "      'default': False}},\n",
       "    'type': 'object',\n",
       "    'required': ['id', 'display_name', 'is_personal', 'disabled'],\n",
       "    'title': 'OrganizationPGSchemaSlim',\n",
       "    'description': 'Schema for an organization in postgres for list views.'},\n",
       "   'OrganizationUpdate': {'properties': {'display_name': {'type': 'string',\n",
       "      'minLength': 1,\n",
       "      'pattern': '^[a-zA-Z0-9\\\\-_ ]+$',\n",
       "      'title': 'Display Name'},\n",
       "     'public_sharing_disabled': {'anyOf': [{'type': 'boolean'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Public Sharing Disabled'},\n",
       "     'unshare_all': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Unshare All'}},\n",
       "    'type': 'object',\n",
       "    'title': 'OrganizationUpdate',\n",
       "    'description': 'Update organization schema.'},\n",
       "   'OutputTokenDetails': {'properties': {'audio': {'type': 'integer',\n",
       "      'title': 'Audio'},\n",
       "     'reasoning': {'type': 'integer', 'title': 'Reasoning'}},\n",
       "    'type': 'object',\n",
       "    'title': 'OutputTokenDetails',\n",
       "    'description': 'Breakdown of output token counts.\\n\\nDoes *not* need to sum to full output token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"reasoning\": 200,\\n        }\\n\\n.. versionadded:: 0.3.9'},\n",
       "   'PagerdutySeverity': {'type': 'string',\n",
       "    'enum': ['critical', 'warning', 'error', 'info'],\n",
       "    'title': 'PagerdutySeverity',\n",
       "    'description': 'Enum for severity.'},\n",
       "   'PaymentPlanTier': {'type': 'string',\n",
       "    'enum': ['no_plan',\n",
       "     'developer',\n",
       "     'plus',\n",
       "     'enterprise',\n",
       "     'developer_legacy',\n",
       "     'plus_legacy',\n",
       "     'free',\n",
       "     'enterprise_legacy',\n",
       "     'startup',\n",
       "     'partner',\n",
       "     'premier'],\n",
       "    'title': 'PaymentPlanTier'},\n",
       "   'PendingIdentity': {'properties': {'email': {'type': 'string',\n",
       "      'title': 'Email'},\n",
       "     'read_only': {'type': 'boolean', 'title': 'Read Only', 'default': False},\n",
       "     'role_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Role Id'},\n",
       "     'workspace_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Workspace Ids'},\n",
       "     'workspace_role_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Workspace Role Id'},\n",
       "     'password': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Password'},\n",
       "     'full_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Full Name'},\n",
       "     'access_scope': {'$ref': '#/components/schemas/AccessScope',\n",
       "      'default': 'workspace'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'user_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'User Id'},\n",
       "     'tenant_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Tenant Id'},\n",
       "     'organization_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Organization Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'role_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Role Name'},\n",
       "     'org_role_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Org Role Id'},\n",
       "     'org_role_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Org Role Name'}},\n",
       "    'type': 'object',\n",
       "    'required': ['email', 'id', 'created_at'],\n",
       "    'title': 'PendingIdentity'},\n",
       "   'PendingIdentityCreate': {'properties': {'email': {'type': 'string',\n",
       "      'title': 'Email'},\n",
       "     'read_only': {'type': 'boolean', 'title': 'Read Only', 'default': False},\n",
       "     'role_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Role Id'},\n",
       "     'workspace_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Workspace Ids'},\n",
       "     'workspace_role_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Workspace Role Id'},\n",
       "     'password': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Password'},\n",
       "     'full_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Full Name'}},\n",
       "    'type': 'object',\n",
       "    'required': ['email'],\n",
       "    'title': 'PendingIdentityCreate'},\n",
       "   'PermissionResponse': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'},\n",
       "     'description': {'type': 'string', 'title': 'Description'},\n",
       "     'access_scope': {'$ref': '#/components/schemas/AccessScope'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name', 'description', 'access_scope'],\n",
       "    'title': 'PermissionResponse'},\n",
       "   'PlaygroundPromptCanvasPayload': {'properties': {'messages': {'items': {'oneOf': [{'$ref': '#/components/schemas/AIMessage'},\n",
       "        {'$ref': '#/components/schemas/HumanMessage'},\n",
       "        {'$ref': '#/components/schemas/ChatMessage'},\n",
       "        {'$ref': '#/components/schemas/SystemMessage'},\n",
       "        {'$ref': '#/components/schemas/FunctionMessage'},\n",
       "        {'$ref': '#/components/schemas/ToolMessage'},\n",
       "        {'$ref': '#/components/schemas/AIMessageChunk'},\n",
       "        {'$ref': '#/components/schemas/HumanMessageChunk'},\n",
       "        {'$ref': '#/components/schemas/ChatMessageChunk'},\n",
       "        {'$ref': '#/components/schemas/SystemMessageChunk'},\n",
       "        {'$ref': '#/components/schemas/FunctionMessageChunk'},\n",
       "        {'$ref': '#/components/schemas/ToolMessageChunk'}]},\n",
       "      'type': 'array',\n",
       "      'title': 'Messages'},\n",
       "     'highlighted': {'anyOf': [{'$ref': '#/components/schemas/Highlight'},\n",
       "       {'type': 'null'}]},\n",
       "     'artifact': {'anyOf': [{'$ref': '#/components/schemas/Artifact'},\n",
       "       {'type': 'null'}]},\n",
       "     'artifact_length': {'anyOf': [{'type': 'string',\n",
       "        'enum': ['shortest', 'short', 'long', 'longest']},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Artifact Length'},\n",
       "     'reading_level': {'anyOf': [{'type': 'string',\n",
       "        'enum': ['child', 'teenager', 'college', 'phd']},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Reading Level'},\n",
       "     'custom_action': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Custom Action'},\n",
       "     'template_format': {'type': 'string',\n",
       "      'enum': ['f-string', 'mustache'],\n",
       "      'title': 'Template Format'},\n",
       "     'secrets': {'additionalProperties': {'type': 'string'},\n",
       "      'type': 'object',\n",
       "      'title': 'Secrets'}},\n",
       "    'type': 'object',\n",
       "    'required': ['messages', 'template_format', 'secrets'],\n",
       "    'title': 'PlaygroundPromptCanvasPayload'},\n",
       "   'PlaygroundRunOverDatasetRequestSchema': {'properties': {'manifest': {'title': 'Manifest'},\n",
       "     'secrets': {'additionalProperties': {'type': 'string'},\n",
       "      'type': 'object',\n",
       "      'title': 'Secrets'},\n",
       "     'run_id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Run Id'},\n",
       "     'repo_id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Repo Id'},\n",
       "     'tools': {'anyOf': [{'items': {}, 'type': 'array'}, {'type': 'null'}],\n",
       "      'title': 'Tools'},\n",
       "     'tool_choice': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Tool Choice'},\n",
       "     'parallel_tool_calls': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Parallel Tool Calls'},\n",
       "     'options': {'$ref': '#/components/schemas/RunnableConfig'},\n",
       "     'project_name': {'type': 'string', 'title': 'Project Name'},\n",
       "     'repo_handle': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Repo Handle'},\n",
       "     'owner': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Owner'},\n",
       "     'commit': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Commit'},\n",
       "     'evaluator_rules': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Evaluator Rules'},\n",
       "     'requests_per_second': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Requests Per Second'},\n",
       "     'use_or_fallback_to_workspace_secrets': {'type': 'boolean',\n",
       "      'title': 'Use Or Fallback To Workspace Secrets',\n",
       "      'default': False},\n",
       "     'dataset_id': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'},\n",
       "     'dataset_splits': {'anyOf': [{'items': {'type': 'string'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Dataset Splits'},\n",
       "     'repetitions': {'type': 'integer',\n",
       "      'maximum': 30.0,\n",
       "      'minimum': 1.0,\n",
       "      'title': 'Repetitions',\n",
       "      'default': 1}},\n",
       "    'type': 'object',\n",
       "    'required': ['manifest',\n",
       "     'secrets',\n",
       "     'options',\n",
       "     'project_name',\n",
       "     'dataset_id'],\n",
       "    'title': 'PlaygroundRunOverDatasetRequestSchema'},\n",
       "   'PlaygroundSavedOptions': {'properties': {'requests_per_second': {'anyOf': [{'type': 'integer'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Requests Per Second'}},\n",
       "    'type': 'object',\n",
       "    'title': 'PlaygroundSavedOptions'},\n",
       "   'PlaygroundSettingsCreateRequest': {'properties': {'name': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'settings': {'type': 'object', 'title': 'Settings'},\n",
       "     'options': {'anyOf': [{'$ref': '#/components/schemas/PlaygroundSavedOptions'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'required': ['settings'],\n",
       "    'title': 'PlaygroundSettingsCreateRequest'},\n",
       "   'PlaygroundSettingsResponse': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'settings': {'type': 'object', 'title': 'Settings'},\n",
       "     'options': {'anyOf': [{'$ref': '#/components/schemas/PlaygroundSavedOptions'},\n",
       "       {'type': 'null'}]},\n",
       "     'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id', 'settings', 'created_at', 'updated_at'],\n",
       "    'title': 'PlaygroundSettingsResponse'},\n",
       "   'PlaygroundSettingsUpdateRequest': {'properties': {'name': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'settings': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Settings'},\n",
       "     'options': {'anyOf': [{'$ref': '#/components/schemas/PlaygroundSavedOptions'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'title': 'PlaygroundSettingsUpdateRequest'},\n",
       "   'PopulateAnnotationQueueSchema': {'properties': {'queue_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Queue Id'},\n",
       "     'session_ids': {'items': {'type': 'string', 'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'title': 'Session Ids'}},\n",
       "    'type': 'object',\n",
       "    'required': ['queue_id', 'session_ids'],\n",
       "    'title': 'PopulateAnnotationQueueSchema'},\n",
       "   'PromptOptimizationJob': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'repo_id': {'type': 'string', 'format': 'uuid', 'title': 'Repo Id'},\n",
       "     'status': {'$ref': '#/components/schemas/EPromptOptimizationJobStatus'},\n",
       "     'tenant_id': {'type': 'string', 'format': 'uuid', 'title': 'Tenant Id'},\n",
       "     'algorithm': {'$ref': '#/components/schemas/EPromptOptimizationAlgorithm'},\n",
       "     'config': {'anyOf': [{'$ref': '#/components/schemas/PromptimConfig'},\n",
       "       {'$ref': '#/components/schemas/DemoConfig'}],\n",
       "      'title': 'Config'},\n",
       "     'results': {'items': {'$ref': '#/components/schemas/PromptOptimizationResult'},\n",
       "      'type': 'array',\n",
       "      'title': 'Results'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id',\n",
       "     'repo_id',\n",
       "     'status',\n",
       "     'tenant_id',\n",
       "     'algorithm',\n",
       "     'config',\n",
       "     'created_at',\n",
       "     'updated_at'],\n",
       "    'title': 'PromptOptimizationJob'},\n",
       "   'PromptOptimizationJobCreate': {'properties': {'algorithm': {'$ref': '#/components/schemas/EPromptOptimizationAlgorithm'},\n",
       "     'config': {'anyOf': [{'$ref': '#/components/schemas/PromptimConfig'},\n",
       "       {'$ref': '#/components/schemas/DemoConfig'}],\n",
       "      'title': 'Config'}},\n",
       "    'type': 'object',\n",
       "    'required': ['algorithm', 'config'],\n",
       "    'title': 'PromptOptimizationJobCreate'},\n",
       "   'PromptOptimizationJobLog': {'properties': {'log_type': {'$ref': '#/components/schemas/EPromptOptimizationJobLogType'},\n",
       "     'message': {'type': 'string', 'title': 'Message'},\n",
       "     'data': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Data'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'job_id': {'type': 'string', 'format': 'uuid', 'title': 'Job Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'}},\n",
       "    'type': 'object',\n",
       "    'required': ['log_type', 'message', 'id', 'job_id', 'created_at'],\n",
       "    'title': 'PromptOptimizationJobLog'},\n",
       "   'PromptOptimizationJobLogCreate': {'properties': {'log_type': {'$ref': '#/components/schemas/EPromptOptimizationJobLogType'},\n",
       "     'message': {'type': 'string', 'title': 'Message'},\n",
       "     'data': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Data'}},\n",
       "    'type': 'object',\n",
       "    'required': ['log_type', 'message'],\n",
       "    'title': 'PromptOptimizationJobLogCreate'},\n",
       "   'PromptOptimizationJobUpdate': {'properties': {'status': {'anyOf': [{'$ref': '#/components/schemas/EPromptOptimizationJobStatus'},\n",
       "       {'type': 'null'}]},\n",
       "     'result': {'anyOf': [{'$ref': '#/components/schemas/PromptOptimizationResult'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'title': 'PromptOptimizationJobUpdate'},\n",
       "   'PromptOptimizationJobWithLogs': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'repo_id': {'type': 'string', 'format': 'uuid', 'title': 'Repo Id'},\n",
       "     'status': {'$ref': '#/components/schemas/EPromptOptimizationJobStatus'},\n",
       "     'tenant_id': {'type': 'string', 'format': 'uuid', 'title': 'Tenant Id'},\n",
       "     'algorithm': {'$ref': '#/components/schemas/EPromptOptimizationAlgorithm'},\n",
       "     'config': {'anyOf': [{'$ref': '#/components/schemas/PromptimConfig'},\n",
       "       {'$ref': '#/components/schemas/DemoConfig'}],\n",
       "      'title': 'Config'},\n",
       "     'results': {'items': {'$ref': '#/components/schemas/PromptOptimizationResult'},\n",
       "      'type': 'array',\n",
       "      'title': 'Results'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'logs': {'items': {'$ref': '#/components/schemas/PromptOptimizationJobLog'},\n",
       "      'type': 'array',\n",
       "      'title': 'Logs'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id',\n",
       "     'repo_id',\n",
       "     'status',\n",
       "     'tenant_id',\n",
       "     'algorithm',\n",
       "     'config',\n",
       "     'created_at',\n",
       "     'updated_at',\n",
       "     'logs'],\n",
       "    'title': 'PromptOptimizationJobWithLogs'},\n",
       "   'PromptOptimizationResult': {'properties': {'timestamp': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Timestamp'},\n",
       "     'x': {'type': 'number', 'title': 'X'},\n",
       "     'y': {'type': 'number', 'title': 'Y'}},\n",
       "    'type': 'object',\n",
       "    'required': ['timestamp', 'x', 'y'],\n",
       "    'title': 'PromptOptimizationResult'},\n",
       "   'PromptWebhook': {'properties': {'url': {'type': 'string',\n",
       "      'minLength': 1,\n",
       "      'format': 'uri',\n",
       "      'title': 'Url'},\n",
       "     'headers': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Headers'},\n",
       "     'include_prompts': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Include Prompts'},\n",
       "     'exclude_prompts': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Exclude Prompts'},\n",
       "     'triggers': {'items': {'$ref': '#/components/schemas/EPromptWebhookTrigger'},\n",
       "      'type': 'array',\n",
       "      'title': 'Triggers'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'tenant_id': {'type': 'string', 'format': 'uuid', 'title': 'Tenant Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'}},\n",
       "    'type': 'object',\n",
       "    'required': ['url', 'id', 'tenant_id', 'created_at', 'updated_at'],\n",
       "    'title': 'PromptWebhook',\n",
       "    'description': 'Schema for a prompt webhook.'},\n",
       "   'PromptWebhookBase': {'properties': {'url': {'type': 'string',\n",
       "      'minLength': 1,\n",
       "      'format': 'uri',\n",
       "      'title': 'Url'},\n",
       "     'headers': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Headers'},\n",
       "     'include_prompts': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Include Prompts'},\n",
       "     'exclude_prompts': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Exclude Prompts'},\n",
       "     'triggers': {'items': {'$ref': '#/components/schemas/EPromptWebhookTrigger'},\n",
       "      'type': 'array',\n",
       "      'title': 'Triggers'}},\n",
       "    'type': 'object',\n",
       "    'required': ['url'],\n",
       "    'title': 'PromptWebhookBase',\n",
       "    'description': 'Base schema for prompt webhooks.'},\n",
       "   'PromptWebhookCreate': {'properties': {'url': {'type': 'string',\n",
       "      'minLength': 1,\n",
       "      'format': 'uri',\n",
       "      'title': 'Url'},\n",
       "     'headers': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Headers'},\n",
       "     'include_prompts': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Include Prompts'},\n",
       "     'exclude_prompts': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Exclude Prompts'},\n",
       "     'triggers': {'items': {'$ref': '#/components/schemas/EPromptWebhookTrigger'},\n",
       "      'type': 'array',\n",
       "      'title': 'Triggers'},\n",
       "     'id': {'anyOf': [{'type': 'string', 'format': 'uuid'}, {'type': 'null'}],\n",
       "      'title': 'Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['url'],\n",
       "    'title': 'PromptWebhookCreate',\n",
       "    'description': 'Schema for creating a prompt webhook.'},\n",
       "   'PromptWebhookPayload': {'properties': {'prompt_id': {'type': 'string',\n",
       "      'title': 'Prompt Id'},\n",
       "     'prompt_name': {'type': 'string', 'title': 'Prompt Name'},\n",
       "     'manifest': {'type': 'object', 'title': 'Manifest'},\n",
       "     'commit_hash': {'type': 'string', 'title': 'Commit Hash'},\n",
       "     'created_at': {'type': 'string', 'title': 'Created At'},\n",
       "     'created_by': {'type': 'string', 'title': 'Created By'}},\n",
       "    'type': 'object',\n",
       "    'required': ['prompt_id',\n",
       "     'prompt_name',\n",
       "     'manifest',\n",
       "     'commit_hash',\n",
       "     'created_at',\n",
       "     'created_by'],\n",
       "    'title': 'PromptWebhookPayload'},\n",
       "   'PromptWebhookTest': {'properties': {'webhook': {'$ref': '#/components/schemas/PromptWebhookBase'},\n",
       "     'payload': {'$ref': '#/components/schemas/PromptWebhookPayload'}},\n",
       "    'type': 'object',\n",
       "    'required': ['webhook', 'payload'],\n",
       "    'title': 'PromptWebhookTest',\n",
       "    'description': 'Schema for testing a prompt webhook.'},\n",
       "   'PromptWebhookUpdate': {'properties': {'include_prompts': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Include Prompts'},\n",
       "     'exclude_prompts': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Exclude Prompts'},\n",
       "     'url': {'anyOf': [{'type': 'string', 'minLength': 1, 'format': 'uri'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Url'},\n",
       "     'headers': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Headers'},\n",
       "     'triggers': {'anyOf': [{'items': {'$ref': '#/components/schemas/EPromptWebhookTrigger'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Triggers'}},\n",
       "    'type': 'object',\n",
       "    'title': 'PromptWebhookUpdate',\n",
       "    'description': 'Schema for updating a prompt webhook.'},\n",
       "   'PromptimConfig': {'properties': {'message_index': {'type': 'integer',\n",
       "      'title': 'Message Index'},\n",
       "     'task_description': {'type': 'string', 'title': 'Task Description'},\n",
       "     'dataset_name': {'type': 'string', 'title': 'Dataset Name'},\n",
       "     'train_split': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Train Split'},\n",
       "     'dev_split': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Dev Split'},\n",
       "     'test_split': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Test Split'},\n",
       "     'evaluators': {'items': {'type': 'string', 'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'title': 'Evaluators'},\n",
       "     'num_epochs': {'type': 'integer', 'title': 'Num Epochs'},\n",
       "     'auto_commit': {'type': 'boolean', 'title': 'Auto Commit'}},\n",
       "    'type': 'object',\n",
       "    'required': ['message_index',\n",
       "     'task_description',\n",
       "     'dataset_name',\n",
       "     'train_split',\n",
       "     'dev_split',\n",
       "     'test_split',\n",
       "     'evaluators',\n",
       "     'num_epochs',\n",
       "     'auto_commit'],\n",
       "    'title': 'PromptimConfig'},\n",
       "   'ProviderUserSlim': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'provider': {'anyOf': [{'$ref': '#/components/schemas/AuthProvider'},\n",
       "       {'type': 'null'}]},\n",
       "     'ls_user_id': {'type': 'string', 'format': 'uuid', 'title': 'Ls User Id'},\n",
       "     'saml_provider_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Saml Provider Id'},\n",
       "     'provider_user_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Provider User Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'email': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Email'},\n",
       "     'full_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Full Name'},\n",
       "     'email_confirmed_at': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Email Confirmed At'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id', 'ls_user_id', 'created_at', 'updated_at'],\n",
       "    'title': 'ProviderUserSlim'},\n",
       "   'PublicComparativeExperiment': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'modified_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Modified At'},\n",
       "     'extra': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Extra'},\n",
       "     'experiments_info': {'items': {'$ref': '#/components/schemas/SimpleExperimentInfo'},\n",
       "      'type': 'array',\n",
       "      'title': 'Experiments Info'},\n",
       "     'feedback_stats': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Feedback Stats'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id', 'created_at', 'modified_at', 'experiments_info'],\n",
       "    'title': 'PublicComparativeExperiment',\n",
       "    'description': 'Publicly-shared ComparativeExperiment schema.'},\n",
       "   'PublicExampleWithRuns': {'properties': {'outputs': {'anyOf': [{'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Outputs'},\n",
       "     'dataset_id': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'},\n",
       "     'source_run_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Source Run Id'},\n",
       "     'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Metadata'},\n",
       "     'inputs': {'type': 'object', 'title': 'Inputs'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'name': {'type': 'string', 'title': 'Name'},\n",
       "     'modified_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Modified At'},\n",
       "     'attachment_urls': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Attachment Urls'},\n",
       "     'runs': {'items': {'$ref': '#/components/schemas/RunPublicDatasetSchema'},\n",
       "      'type': 'array',\n",
       "      'title': 'Runs'}},\n",
       "    'type': 'object',\n",
       "    'required': ['dataset_id', 'inputs', 'id', 'name', 'runs'],\n",
       "    'title': 'PublicExampleWithRuns',\n",
       "    'description': 'Schema for an example in a publicly-shared dataset with list of runs.'},\n",
       "   'PutDatasetVersionsSchema': {'properties': {'as_of': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'string'}],\n",
       "      'title': 'As Of',\n",
       "      'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'},\n",
       "     'tag': {'type': 'string', 'title': 'Tag'}},\n",
       "    'type': 'object',\n",
       "    'required': ['as_of', 'tag'],\n",
       "    'title': 'PutDatasetVersionsSchema'},\n",
       "   'QueryExampleSchemaWithRuns': {'properties': {'session_ids': {'items': {'type': 'string',\n",
       "       'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'title': 'Session Ids'},\n",
       "     'offset': {'type': 'integer',\n",
       "      'minimum': 0.0,\n",
       "      'title': 'Offset',\n",
       "      'default': 0},\n",
       "     'limit': {'type': 'integer',\n",
       "      'minimum': 1.0,\n",
       "      'title': 'Limit',\n",
       "      'default': 10},\n",
       "     'preview': {'type': 'boolean', 'title': 'Preview', 'default': False},\n",
       "     'format': {'anyOf': [{'type': 'string', 'const': 'csv'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Format'},\n",
       "     'comparative_experiment_id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Comparative Experiment Id'},\n",
       "     'sort_params': {'anyOf': [{'$ref': '#/components/schemas/SortParamsForRunsComparisonView'},\n",
       "       {'type': 'null'}]},\n",
       "     'filters': {'anyOf': [{'additionalProperties': {'items': {'type': 'string'},\n",
       "         'type': 'array'},\n",
       "        'propertyNames': {'format': 'uuid'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Filters'}},\n",
       "    'type': 'object',\n",
       "    'required': ['session_ids'],\n",
       "    'title': 'QueryExampleSchemaWithRuns'},\n",
       "   'QueryFeedbackDelta': {'properties': {'baseline_session_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Baseline Session Id'},\n",
       "     'comparison_session_ids': {'items': {'type': 'string', 'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'title': 'Comparison Session Ids'},\n",
       "     'feedback_key': {'type': 'string', 'title': 'Feedback Key'},\n",
       "     'filters': {'anyOf': [{'additionalProperties': {'items': {'type': 'string'},\n",
       "         'type': 'array'},\n",
       "        'propertyNames': {'format': 'uuid'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Filters'},\n",
       "     'offset': {'type': 'integer',\n",
       "      'minimum': 0.0,\n",
       "      'title': 'Offset',\n",
       "      'default': 0},\n",
       "     'limit': {'type': 'integer',\n",
       "      'maximum': 100.0,\n",
       "      'minimum': 1.0,\n",
       "      'title': 'Limit',\n",
       "      'default': 100},\n",
       "     'comparative_experiment_id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Comparative Experiment Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['baseline_session_id',\n",
       "     'comparison_session_ids',\n",
       "     'feedback_key'],\n",
       "    'title': 'QueryFeedbackDelta'},\n",
       "   'QueryGroupedExamplesWithRuns': {'properties': {'session_ids': {'items': {'type': 'string',\n",
       "       'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'title': 'Session Ids'},\n",
       "     'offset': {'type': 'integer',\n",
       "      'minimum': 0.0,\n",
       "      'title': 'Offset',\n",
       "      'default': 0},\n",
       "     'limit': {'type': 'integer',\n",
       "      'minimum': 1.0,\n",
       "      'title': 'Limit',\n",
       "      'default': 10},\n",
       "     'preview': {'type': 'boolean', 'title': 'Preview', 'default': False},\n",
       "     'group_by': {'$ref': '#/components/schemas/GroupExampleRunsByField'},\n",
       "     'metadata_key': {'type': 'string', 'title': 'Metadata Key'},\n",
       "     'per_group_limit': {'type': 'integer',\n",
       "      'maximum': 10.0,\n",
       "      'minimum': 1.0,\n",
       "      'title': 'Per Group Limit',\n",
       "      'default': 5}},\n",
       "    'type': 'object',\n",
       "    'required': ['session_ids', 'group_by', 'metadata_key'],\n",
       "    'title': 'QueryGroupedExamplesWithRuns'},\n",
       "   'QueryParamsForPublicRunSchema': {'properties': {'id': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Id'}},\n",
       "    'type': 'object',\n",
       "    'title': 'QueryParamsForPublicRunSchema',\n",
       "    'description': 'Query params for public run endpoints.'},\n",
       "   'RepoExampleResponse': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'start_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Start Time'},\n",
       "     'inputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Inputs'},\n",
       "     'outputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Outputs'},\n",
       "     'session_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Session Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id', 'session_id'],\n",
       "    'title': 'RepoExampleResponse',\n",
       "    'description': 'Response model for example runs'},\n",
       "   'RepoTag': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'repo_id': {'type': 'string', 'format': 'uuid', 'title': 'Repo Id'},\n",
       "     'commit_id': {'type': 'string', 'format': 'uuid', 'title': 'Commit Id'},\n",
       "     'commit_hash': {'type': 'string', 'title': 'Commit Hash'},\n",
       "     'tag_name': {'type': 'string', 'title': 'Tag Name'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id',\n",
       "     'repo_id',\n",
       "     'commit_id',\n",
       "     'commit_hash',\n",
       "     'tag_name',\n",
       "     'created_at',\n",
       "     'updated_at'],\n",
       "    'title': 'RepoTag',\n",
       "    'description': 'Fields for a prompt tag'},\n",
       "   'RepoTagRequest': {'properties': {'tag_name': {'type': 'string',\n",
       "      'title': 'Tag Name'},\n",
       "     'commit_id': {'type': 'string', 'format': 'uuid', 'title': 'Commit Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['tag_name', 'commit_id'],\n",
       "    'title': 'RepoTagRequest',\n",
       "    'description': 'Fields to create a prompt tag'},\n",
       "   'RepoUpdateTagRequest': {'properties': {'commit_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Commit Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['commit_id'],\n",
       "    'title': 'RepoUpdateTagRequest',\n",
       "    'description': 'Fields to update a prompt tag'},\n",
       "   'RepoWithLookups': {'properties': {'repo_handle': {'type': 'string',\n",
       "      'title': 'Repo Handle'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'readme': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Readme'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'tenant_id': {'type': 'string', 'format': 'uuid', 'title': 'Tenant Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'is_public': {'type': 'boolean', 'title': 'Is Public'},\n",
       "     'is_archived': {'type': 'boolean', 'title': 'Is Archived'},\n",
       "     'tags': {'items': {'type': 'string'}, 'type': 'array', 'title': 'Tags'},\n",
       "     'original_repo_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Original Repo Id'},\n",
       "     'upstream_repo_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Upstream Repo Id'},\n",
       "     'owner': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Owner'},\n",
       "     'full_name': {'type': 'string', 'title': 'Full Name'},\n",
       "     'num_likes': {'type': 'integer', 'title': 'Num Likes'},\n",
       "     'num_downloads': {'type': 'integer', 'title': 'Num Downloads'},\n",
       "     'num_views': {'type': 'integer', 'title': 'Num Views'},\n",
       "     'liked_by_auth_user': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Liked By Auth User'},\n",
       "     'last_commit_hash': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Last Commit Hash'},\n",
       "     'num_commits': {'type': 'integer', 'title': 'Num Commits'},\n",
       "     'original_repo_full_name': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Original Repo Full Name'},\n",
       "     'upstream_repo_full_name': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Upstream Repo Full Name'},\n",
       "     'latest_commit_manifest': {'anyOf': [{'$ref': '#/components/schemas/CommitManifestResponse'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'required': ['repo_handle',\n",
       "     'id',\n",
       "     'tenant_id',\n",
       "     'created_at',\n",
       "     'updated_at',\n",
       "     'is_public',\n",
       "     'is_archived',\n",
       "     'tags',\n",
       "     'owner',\n",
       "     'full_name',\n",
       "     'num_likes',\n",
       "     'num_downloads',\n",
       "     'num_views',\n",
       "     'num_commits'],\n",
       "    'title': 'RepoWithLookups',\n",
       "    'description': 'All database fields for repos, plus helpful computed fields.'},\n",
       "   'RequestBodyForRunsGenerateQuery': {'properties': {'query': {'type': 'string',\n",
       "      'title': 'Query'},\n",
       "     'feedback_keys': {'items': {'$ref': '#/components/schemas/RunsGenerateQueryFeedbackKeys'},\n",
       "      'type': 'array',\n",
       "      'title': 'Feedback Keys'}},\n",
       "    'type': 'object',\n",
       "    'required': ['query'],\n",
       "    'title': 'RequestBodyForRunsGenerateQuery'},\n",
       "   'Resource': {'properties': {'tagging_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Tagging Id'},\n",
       "     'resource_name': {'type': 'string', 'title': 'Resource Name'},\n",
       "     'resource_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Resource Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['tagging_id', 'resource_name', 'resource_id'],\n",
       "    'title': 'Resource'},\n",
       "   'ResourceType': {'type': 'string',\n",
       "    'enum': ['prompt',\n",
       "     'project',\n",
       "     'queue',\n",
       "     'deployment',\n",
       "     'experiment',\n",
       "     'dataset',\n",
       "     'dashboard'],\n",
       "    'title': 'ResourceType'},\n",
       "   'ResponseBodyForRunsGenerateQuery': {'properties': {'filter': {'type': 'string',\n",
       "      'title': 'Filter'},\n",
       "     'feedback_urls': {'additionalProperties': {'type': 'string'},\n",
       "      'propertyNames': {'$ref': '#/components/schemas/RunsGenerateQueryFeedbackKeys'},\n",
       "      'type': 'object',\n",
       "      'title': 'Feedback Urls'}},\n",
       "    'type': 'object',\n",
       "    'required': ['filter', 'feedback_urls'],\n",
       "    'title': 'ResponseBodyForRunsGenerateQuery'},\n",
       "   'Role': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'name': {'type': 'string', 'title': 'Name'},\n",
       "     'display_name': {'type': 'string', 'title': 'Display Name'},\n",
       "     'description': {'type': 'string', 'title': 'Description'},\n",
       "     'organization_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Organization Id'},\n",
       "     'permissions': {'items': {'type': 'string'},\n",
       "      'type': 'array',\n",
       "      'title': 'Permissions'},\n",
       "     'access_scope': {'anyOf': [{'$ref': '#/components/schemas/AccessScope'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'required': ['id', 'name', 'display_name', 'description', 'permissions'],\n",
       "    'title': 'Role'},\n",
       "   'RootModel_Dict_str__list_str___': {'additionalProperties': {'items': {'type': 'string'},\n",
       "     'type': 'array'},\n",
       "    'type': 'object',\n",
       "    'title': 'RootModel[Dict[str, list[str]]]'},\n",
       "   'RuleLogActionOutcome': {'type': 'string',\n",
       "    'enum': ['success', 'skipped', 'error'],\n",
       "    'title': 'RuleLogActionOutcome'},\n",
       "   'RuleLogActionResponse': {'properties': {'outcome': {'$ref': '#/components/schemas/RuleLogActionOutcome'},\n",
       "     'payload': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Payload'}},\n",
       "    'type': 'object',\n",
       "    'required': ['outcome'],\n",
       "    'title': 'RuleLogActionResponse'},\n",
       "   'RuleLogSchema': {'properties': {'rule_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Rule Id'},\n",
       "     'run_id': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'},\n",
       "     'run_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Run Name'},\n",
       "     'run_type': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Run Type'},\n",
       "     'run_session_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Run Session Id'},\n",
       "     'start_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'End Time'},\n",
       "     'application_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Application Time'},\n",
       "     'add_to_annotation_queue': {'anyOf': [{'$ref': '#/components/schemas/RuleLogActionResponse'},\n",
       "       {'type': 'null'}]},\n",
       "     'add_to_dataset': {'anyOf': [{'$ref': '#/components/schemas/RuleLogActionResponse'},\n",
       "       {'type': 'null'}]},\n",
       "     'evaluators': {'anyOf': [{'$ref': '#/components/schemas/RuleLogActionResponse'},\n",
       "       {'type': 'null'}]},\n",
       "     'alerts': {'anyOf': [{'$ref': '#/components/schemas/RuleLogActionResponse'},\n",
       "       {'type': 'null'}]},\n",
       "     'webhooks': {'anyOf': [{'$ref': '#/components/schemas/RuleLogActionResponse'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'required': ['rule_id', 'run_id', 'start_time', 'end_time'],\n",
       "    'title': 'RuleLogSchema',\n",
       "    'description': 'Run rules log schema.'},\n",
       "   'RunDateOrder': {'type': 'string',\n",
       "    'enum': ['asc', 'desc'],\n",
       "    'title': 'RunDateOrder',\n",
       "    'description': 'Enum for run start date order.'},\n",
       "   'RunGroupBy': {'type': 'string',\n",
       "    'enum': ['conversation'],\n",
       "    'title': 'RunGroupBy'},\n",
       "   'RunGroupRequest': {'properties': {'session_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Session Id'},\n",
       "     'group_by': {'$ref': '#/components/schemas/RunGroupBy'},\n",
       "     'filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Filter'},\n",
       "     'start_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'End Time'},\n",
       "     'offset': {'type': 'integer',\n",
       "      'minimum': 0.0,\n",
       "      'title': 'Offset',\n",
       "      'default': 0},\n",
       "     'limit': {'type': 'integer',\n",
       "      'maximum': 100.0,\n",
       "      'minimum': 1.0,\n",
       "      'title': 'Limit',\n",
       "      'default': 10}},\n",
       "    'type': 'object',\n",
       "    'required': ['session_id', 'group_by'],\n",
       "    'title': 'RunGroupRequest'},\n",
       "   'RunGroupStats': {'properties': {'run_count': {'type': 'integer',\n",
       "      'title': 'Run Count'},\n",
       "     'latency_p50': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'Latency P50'},\n",
       "     'latency_p99': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'Latency P99'},\n",
       "     'first_token_p50': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'First Token P50'},\n",
       "     'first_token_p99': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'First Token P99'},\n",
       "     'total_tokens': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Total Tokens'},\n",
       "     'prompt_tokens': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Prompt Tokens'},\n",
       "     'completion_tokens': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Completion Tokens'},\n",
       "     'median_tokens': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Median Tokens'},\n",
       "     'completion_tokens_p50': {'anyOf': [{'type': 'integer'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Completion Tokens P50'},\n",
       "     'prompt_tokens_p50': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Prompt Tokens P50'},\n",
       "     'tokens_p99': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Tokens P99'},\n",
       "     'completion_tokens_p99': {'anyOf': [{'type': 'integer'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Completion Tokens P99'},\n",
       "     'prompt_tokens_p99': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Prompt Tokens P99'},\n",
       "     'last_run_start_time': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Last Run Start Time'},\n",
       "     'feedback_stats': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Feedback Stats'},\n",
       "     'run_facets': {'anyOf': [{'items': {'type': 'object'}, 'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Run Facets'},\n",
       "     'error_rate': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'Error Rate'},\n",
       "     'streaming_rate': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'Streaming Rate'},\n",
       "     'total_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Total Cost'},\n",
       "     'prompt_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Prompt Cost'},\n",
       "     'completion_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Completion Cost'},\n",
       "     'cost_p50': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Cost P50'},\n",
       "     'cost_p99': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Cost P99'},\n",
       "     'group_count': {'type': 'integer', 'title': 'Group Count'}},\n",
       "    'type': 'object',\n",
       "    'required': ['run_count', 'group_count'],\n",
       "    'title': 'RunGroupStats'},\n",
       "   'RunPublicDatasetSchema': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'},\n",
       "     'inputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Inputs'},\n",
       "     'inputs_preview': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Inputs Preview'},\n",
       "     'run_type': {'$ref': '#/components/schemas/RunTypeEnum'},\n",
       "     'start_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'End Time'},\n",
       "     'extra': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Extra'},\n",
       "     'error': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Error'},\n",
       "     'execution_order': {'type': 'integer',\n",
       "      'minimum': 1.0,\n",
       "      'title': 'Execution Order',\n",
       "      'default': 1},\n",
       "     'serialized': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Serialized'},\n",
       "     'outputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Outputs'},\n",
       "     'outputs_preview': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Outputs Preview'},\n",
       "     'parent_run_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Parent Run Id'},\n",
       "     'manifest_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Manifest Id'},\n",
       "     'manifest_s3_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Manifest S3 Id'},\n",
       "     'events': {'anyOf': [{'items': {'type': 'object'}, 'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Events'},\n",
       "     'tags': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Tags'},\n",
       "     'inputs_s3_urls': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Inputs S3 Urls'},\n",
       "     'outputs_s3_urls': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Outputs S3 Urls'},\n",
       "     's3_urls': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'S3 Urls'},\n",
       "     'trace_id': {'type': 'string', 'format': 'uuid', 'title': 'Trace Id'},\n",
       "     'dotted_order': {'type': 'string', 'title': 'Dotted Order'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'status': {'type': 'string', 'title': 'Status'},\n",
       "     'child_run_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Child Run Ids'},\n",
       "     'direct_child_run_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Direct Child Run Ids'},\n",
       "     'parent_run_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Parent Run Ids'},\n",
       "     'feedback_stats': {'anyOf': [{'additionalProperties': {'type': 'object'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Feedback Stats'},\n",
       "     'reference_example_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Reference Example Id'},\n",
       "     'total_tokens': {'type': 'integer',\n",
       "      'title': 'Total Tokens',\n",
       "      'default': 0},\n",
       "     'prompt_tokens': {'type': 'integer',\n",
       "      'title': 'Prompt Tokens',\n",
       "      'default': 0},\n",
       "     'completion_tokens': {'type': 'integer',\n",
       "      'title': 'Completion Tokens',\n",
       "      'default': 0},\n",
       "     'prompt_token_details': {'anyOf': [{'additionalProperties': {'type': 'integer'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Prompt Token Details'},\n",
       "     'completion_token_details': {'anyOf': [{'additionalProperties': {'type': 'integer'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Completion Token Details'},\n",
       "     'total_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Total Cost'},\n",
       "     'prompt_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Prompt Cost'},\n",
       "     'completion_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Completion Cost'},\n",
       "     'prompt_cost_details': {'anyOf': [{'additionalProperties': {'type': 'string'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Prompt Cost Details'},\n",
       "     'completion_cost_details': {'anyOf': [{'additionalProperties': {'type': 'string'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Completion Cost Details'},\n",
       "     'price_model_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Price Model Id'},\n",
       "     'first_token_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'First Token Time'},\n",
       "     'session_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Session Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name',\n",
       "     'run_type',\n",
       "     'trace_id',\n",
       "     'dotted_order',\n",
       "     'id',\n",
       "     'status',\n",
       "     'session_id'],\n",
       "    'title': 'RunPublicDatasetSchema',\n",
       "    'description': 'Schema for a run in a publicly-shared dataset.'},\n",
       "   'RunPublicSchema': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'},\n",
       "     'inputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Inputs'},\n",
       "     'inputs_preview': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Inputs Preview'},\n",
       "     'run_type': {'$ref': '#/components/schemas/RunTypeEnum'},\n",
       "     'start_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'End Time'},\n",
       "     'extra': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Extra'},\n",
       "     'error': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Error'},\n",
       "     'execution_order': {'type': 'integer',\n",
       "      'minimum': 1.0,\n",
       "      'title': 'Execution Order',\n",
       "      'default': 1},\n",
       "     'serialized': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Serialized'},\n",
       "     'outputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Outputs'},\n",
       "     'outputs_preview': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Outputs Preview'},\n",
       "     'parent_run_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Parent Run Id'},\n",
       "     'manifest_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Manifest Id'},\n",
       "     'manifest_s3_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Manifest S3 Id'},\n",
       "     'events': {'anyOf': [{'items': {'type': 'object'}, 'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Events'},\n",
       "     'tags': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Tags'},\n",
       "     'inputs_s3_urls': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Inputs S3 Urls'},\n",
       "     'outputs_s3_urls': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Outputs S3 Urls'},\n",
       "     's3_urls': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'S3 Urls'},\n",
       "     'trace_id': {'type': 'string', 'format': 'uuid', 'title': 'Trace Id'},\n",
       "     'dotted_order': {'type': 'string', 'title': 'Dotted Order'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'status': {'type': 'string', 'title': 'Status'},\n",
       "     'child_run_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Child Run Ids'},\n",
       "     'direct_child_run_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Direct Child Run Ids'},\n",
       "     'parent_run_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Parent Run Ids'},\n",
       "     'feedback_stats': {'anyOf': [{'additionalProperties': {'type': 'object'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Feedback Stats'},\n",
       "     'reference_example_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Reference Example Id'},\n",
       "     'total_tokens': {'type': 'integer',\n",
       "      'title': 'Total Tokens',\n",
       "      'default': 0},\n",
       "     'prompt_tokens': {'type': 'integer',\n",
       "      'title': 'Prompt Tokens',\n",
       "      'default': 0},\n",
       "     'completion_tokens': {'type': 'integer',\n",
       "      'title': 'Completion Tokens',\n",
       "      'default': 0},\n",
       "     'prompt_token_details': {'anyOf': [{'additionalProperties': {'type': 'integer'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Prompt Token Details'},\n",
       "     'completion_token_details': {'anyOf': [{'additionalProperties': {'type': 'integer'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Completion Token Details'},\n",
       "     'total_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Total Cost'},\n",
       "     'prompt_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Prompt Cost'},\n",
       "     'completion_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Completion Cost'},\n",
       "     'prompt_cost_details': {'anyOf': [{'additionalProperties': {'type': 'string'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Prompt Cost Details'},\n",
       "     'completion_cost_details': {'anyOf': [{'additionalProperties': {'type': 'string'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Completion Cost Details'},\n",
       "     'price_model_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Price Model Id'},\n",
       "     'first_token_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'First Token Time'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name',\n",
       "     'run_type',\n",
       "     'trace_id',\n",
       "     'dotted_order',\n",
       "     'id',\n",
       "     'status'],\n",
       "    'title': 'RunPublicSchema'},\n",
       "   'RunRulesAlertType': {'type': 'string',\n",
       "    'enum': ['pagerduty'],\n",
       "    'title': 'RunRulesAlertType',\n",
       "    'description': 'Enum for alert types.'},\n",
       "   'RunRulesCreateSchema': {'properties': {'display_name': {'type': 'string',\n",
       "      'title': 'Display Name'},\n",
       "     'session_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Session Id'},\n",
       "     'is_enabled': {'type': 'boolean', 'title': 'Is Enabled', 'default': True},\n",
       "     'dataset_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Dataset Id'},\n",
       "     'sampling_rate': {'type': 'number', 'title': 'Sampling Rate'},\n",
       "     'filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Filter'},\n",
       "     'trace_filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Trace Filter'},\n",
       "     'tree_filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Tree Filter'},\n",
       "     'backfill_from': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Backfill From'},\n",
       "     'use_corrections_dataset': {'type': 'boolean',\n",
       "      'title': 'Use Corrections Dataset',\n",
       "      'default': False},\n",
       "     'num_few_shot_examples': {'anyOf': [{'type': 'integer'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Num Few Shot Examples'},\n",
       "     'extend_only': {'type': 'boolean',\n",
       "      'title': 'Extend Only',\n",
       "      'default': False},\n",
       "     'transient': {'type': 'boolean', 'title': 'Transient', 'default': False},\n",
       "     'add_to_annotation_queue_id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Add To Annotation Queue Id'},\n",
       "     'add_to_dataset_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Add To Dataset Id'},\n",
       "     'add_to_dataset_prefer_correction': {'type': 'boolean',\n",
       "      'title': 'Add To Dataset Prefer Correction',\n",
       "      'default': False},\n",
       "     'evaluators': {'anyOf': [{'items': {'$ref': '#/components/schemas/EvaluatorTopLevel'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Evaluators'},\n",
       "     'code_evaluators': {'anyOf': [{'items': {'$ref': '#/components/schemas/CodeEvaluatorTopLevel'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Code Evaluators'},\n",
       "     'alerts': {'anyOf': [{'items': {'$ref': '#/components/schemas/RunRulesPagerdutyAlertSchema'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Alerts'},\n",
       "     'webhooks': {'anyOf': [{'items': {'$ref': '#/components/schemas/RunRulesWebhookSchema'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Webhooks'},\n",
       "     'evaluator_version': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Evaluator Version'}},\n",
       "    'type': 'object',\n",
       "    'required': ['display_name', 'sampling_rate'],\n",
       "    'title': 'RunRulesCreateSchema'},\n",
       "   'RunRulesPagerdutyAlertSchema': {'properties': {'type': {'anyOf': [{'$ref': '#/components/schemas/RunRulesAlertType'},\n",
       "       {'type': 'null'}],\n",
       "      'default': 'pagerduty'},\n",
       "     'routing_key': {'type': 'string', 'title': 'Routing Key'},\n",
       "     'summary': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Summary'},\n",
       "     'severity': {'anyOf': [{'$ref': '#/components/schemas/PagerdutySeverity'},\n",
       "       {'type': 'null'}],\n",
       "      'default': 'warning'}},\n",
       "    'type': 'object',\n",
       "    'required': ['routing_key'],\n",
       "    'title': 'RunRulesPagerdutyAlertSchema'},\n",
       "   'RunRulesSchema': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'tenant_id': {'type': 'string', 'format': 'uuid', 'title': 'Tenant Id'},\n",
       "     'is_enabled': {'type': 'boolean', 'title': 'Is Enabled', 'default': True},\n",
       "     'session_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Session Id'},\n",
       "     'session_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Session Name'},\n",
       "     'dataset_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Dataset Id'},\n",
       "     'dataset_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Dataset Name'},\n",
       "     'display_name': {'type': 'string', 'title': 'Display Name'},\n",
       "     'sampling_rate': {'type': 'number', 'title': 'Sampling Rate'},\n",
       "     'filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Filter'},\n",
       "     'trace_filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Trace Filter'},\n",
       "     'tree_filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Tree Filter'},\n",
       "     'add_to_annotation_queue_id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Add To Annotation Queue Id'},\n",
       "     'add_to_annotation_queue_name': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Add To Annotation Queue Name'},\n",
       "     'add_to_dataset_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Add To Dataset Id'},\n",
       "     'add_to_dataset_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Add To Dataset Name'},\n",
       "     'add_to_dataset_prefer_correction': {'type': 'boolean',\n",
       "      'title': 'Add To Dataset Prefer Correction',\n",
       "      'default': False},\n",
       "     'corrections_dataset_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Corrections Dataset Id'},\n",
       "     'use_corrections_dataset': {'type': 'boolean',\n",
       "      'title': 'Use Corrections Dataset',\n",
       "      'default': False},\n",
       "     'num_few_shot_examples': {'anyOf': [{'type': 'integer'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Num Few Shot Examples'},\n",
       "     'evaluators': {'anyOf': [{'items': {'$ref': '#/components/schemas/EvaluatorTopLevel'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Evaluators'},\n",
       "     'code_evaluators': {'anyOf': [{'items': {'$ref': '#/components/schemas/CodeEvaluatorTopLevel'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Code Evaluators'},\n",
       "     'alerts': {'anyOf': [{'items': {'$ref': '#/components/schemas/RunRulesPagerdutyAlertSchema'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Alerts'},\n",
       "     'webhooks': {'anyOf': [{'items': {'$ref': '#/components/schemas/RunRulesWebhookSchema'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Webhooks'},\n",
       "     'extend_only': {'type': 'boolean',\n",
       "      'title': 'Extend Only',\n",
       "      'default': False},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'backfill_from': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Backfill From'},\n",
       "     'transient': {'type': 'boolean', 'title': 'Transient', 'default': False},\n",
       "     'evaluator_version': {'type': 'integer', 'title': 'Evaluator Version'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id',\n",
       "     'tenant_id',\n",
       "     'display_name',\n",
       "     'sampling_rate',\n",
       "     'webhooks',\n",
       "     'created_at',\n",
       "     'updated_at',\n",
       "     'evaluator_version'],\n",
       "    'title': 'RunRulesSchema',\n",
       "    'description': 'Run rules schema.'},\n",
       "   'RunRulesWebhookSchema': {'properties': {'url': {'type': 'string',\n",
       "      'title': 'Url'},\n",
       "     'headers': {'anyOf': [{'additionalProperties': {'type': 'string'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Headers'}},\n",
       "    'type': 'object',\n",
       "    'required': ['url'],\n",
       "    'title': 'RunRulesWebhookSchema'},\n",
       "   'RunSchema': {'properties': {'name': {'type': 'string', 'title': 'Name'},\n",
       "     'inputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Inputs'},\n",
       "     'inputs_preview': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Inputs Preview'},\n",
       "     'run_type': {'$ref': '#/components/schemas/RunTypeEnum'},\n",
       "     'start_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'End Time'},\n",
       "     'extra': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Extra'},\n",
       "     'error': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Error'},\n",
       "     'execution_order': {'type': 'integer',\n",
       "      'minimum': 1.0,\n",
       "      'title': 'Execution Order',\n",
       "      'default': 1},\n",
       "     'serialized': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Serialized'},\n",
       "     'outputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Outputs'},\n",
       "     'outputs_preview': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Outputs Preview'},\n",
       "     'parent_run_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Parent Run Id'},\n",
       "     'manifest_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Manifest Id'},\n",
       "     'manifest_s3_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Manifest S3 Id'},\n",
       "     'events': {'anyOf': [{'items': {'type': 'object'}, 'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Events'},\n",
       "     'tags': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Tags'},\n",
       "     'inputs_s3_urls': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Inputs S3 Urls'},\n",
       "     'outputs_s3_urls': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Outputs S3 Urls'},\n",
       "     's3_urls': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'S3 Urls'},\n",
       "     'trace_id': {'type': 'string', 'format': 'uuid', 'title': 'Trace Id'},\n",
       "     'dotted_order': {'type': 'string', 'title': 'Dotted Order'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'status': {'type': 'string', 'title': 'Status'},\n",
       "     'child_run_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Child Run Ids'},\n",
       "     'direct_child_run_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Direct Child Run Ids'},\n",
       "     'parent_run_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Parent Run Ids'},\n",
       "     'feedback_stats': {'anyOf': [{'additionalProperties': {'type': 'object'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Feedback Stats'},\n",
       "     'reference_example_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Reference Example Id'},\n",
       "     'total_tokens': {'type': 'integer',\n",
       "      'title': 'Total Tokens',\n",
       "      'default': 0},\n",
       "     'prompt_tokens': {'type': 'integer',\n",
       "      'title': 'Prompt Tokens',\n",
       "      'default': 0},\n",
       "     'completion_tokens': {'type': 'integer',\n",
       "      'title': 'Completion Tokens',\n",
       "      'default': 0},\n",
       "     'prompt_token_details': {'anyOf': [{'additionalProperties': {'type': 'integer'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Prompt Token Details'},\n",
       "     'completion_token_details': {'anyOf': [{'additionalProperties': {'type': 'integer'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Completion Token Details'},\n",
       "     'total_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Total Cost'},\n",
       "     'prompt_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Prompt Cost'},\n",
       "     'completion_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Completion Cost'},\n",
       "     'prompt_cost_details': {'anyOf': [{'additionalProperties': {'type': 'string'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Prompt Cost Details'},\n",
       "     'completion_cost_details': {'anyOf': [{'additionalProperties': {'type': 'string'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Completion Cost Details'},\n",
       "     'price_model_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Price Model Id'},\n",
       "     'first_token_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'First Token Time'},\n",
       "     'session_id': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'},\n",
       "     'app_path': {'type': 'string', 'title': 'App Path'},\n",
       "     'last_queued_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Last Queued At'},\n",
       "     'in_dataset': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'In Dataset'},\n",
       "     'share_token': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Share Token'},\n",
       "     'trace_tier': {'anyOf': [{'$ref': '#/components/schemas/TraceTier'},\n",
       "       {'type': 'null'}]},\n",
       "     'trace_first_received_at': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Trace First Received At'},\n",
       "     'ttl_seconds': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Ttl Seconds'},\n",
       "     'trace_upgrade': {'type': 'boolean',\n",
       "      'title': 'Trace Upgrade',\n",
       "      'default': False},\n",
       "     'reference_dataset_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Reference Dataset Id'},\n",
       "     'thread_id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Thread Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name',\n",
       "     'run_type',\n",
       "     'trace_id',\n",
       "     'dotted_order',\n",
       "     'id',\n",
       "     'status',\n",
       "     'session_id',\n",
       "     'app_path'],\n",
       "    'title': 'RunSchema',\n",
       "    'description': 'Run schema.'},\n",
       "   'RunSchemaComparisonView': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'},\n",
       "     'inputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Inputs'},\n",
       "     'inputs_preview': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Inputs Preview'},\n",
       "     'run_type': {'$ref': '#/components/schemas/RunTypeEnum'},\n",
       "     'start_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'End Time'},\n",
       "     'extra': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Extra'},\n",
       "     'error': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Error'},\n",
       "     'execution_order': {'type': 'integer',\n",
       "      'minimum': 1.0,\n",
       "      'title': 'Execution Order',\n",
       "      'default': 1},\n",
       "     'serialized': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Serialized'},\n",
       "     'outputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Outputs'},\n",
       "     'outputs_preview': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Outputs Preview'},\n",
       "     'parent_run_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Parent Run Id'},\n",
       "     'manifest_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Manifest Id'},\n",
       "     'manifest_s3_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Manifest S3 Id'},\n",
       "     'events': {'anyOf': [{'items': {'type': 'object'}, 'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Events'},\n",
       "     'tags': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Tags'},\n",
       "     'inputs_s3_urls': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Inputs S3 Urls'},\n",
       "     'outputs_s3_urls': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Outputs S3 Urls'},\n",
       "     's3_urls': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'S3 Urls'},\n",
       "     'trace_id': {'type': 'string', 'format': 'uuid', 'title': 'Trace Id'},\n",
       "     'dotted_order': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Dotted Order'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'session_id': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'},\n",
       "     'reference_example_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Reference Example Id'},\n",
       "     'total_tokens': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Total Tokens'},\n",
       "     'prompt_tokens': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Prompt Tokens'},\n",
       "     'completion_tokens': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Completion Tokens'},\n",
       "     'total_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Total Cost'},\n",
       "     'prompt_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Prompt Cost'},\n",
       "     'completion_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Completion Cost'},\n",
       "     'status': {'type': 'string', 'title': 'Status'},\n",
       "     'feedback_stats': {'anyOf': [{'additionalProperties': {'type': 'object'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Feedback Stats'},\n",
       "     'app_path': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'App Path'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name', 'run_type', 'trace_id', 'id', 'session_id', 'status'],\n",
       "    'title': 'RunSchemaComparisonView',\n",
       "    'description': 'Run schema for comparison view.'},\n",
       "   'RunSchemaWithAnnotationQueueInfo': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'},\n",
       "     'inputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Inputs'},\n",
       "     'inputs_preview': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Inputs Preview'},\n",
       "     'run_type': {'$ref': '#/components/schemas/RunTypeEnum'},\n",
       "     'start_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'End Time'},\n",
       "     'extra': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Extra'},\n",
       "     'error': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Error'},\n",
       "     'execution_order': {'type': 'integer',\n",
       "      'minimum': 1.0,\n",
       "      'title': 'Execution Order',\n",
       "      'default': 1},\n",
       "     'serialized': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Serialized'},\n",
       "     'outputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Outputs'},\n",
       "     'outputs_preview': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Outputs Preview'},\n",
       "     'parent_run_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Parent Run Id'},\n",
       "     'manifest_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Manifest Id'},\n",
       "     'manifest_s3_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Manifest S3 Id'},\n",
       "     'events': {'anyOf': [{'items': {'type': 'object'}, 'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Events'},\n",
       "     'tags': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Tags'},\n",
       "     'inputs_s3_urls': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Inputs S3 Urls'},\n",
       "     'outputs_s3_urls': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Outputs S3 Urls'},\n",
       "     's3_urls': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'S3 Urls'},\n",
       "     'trace_id': {'type': 'string', 'format': 'uuid', 'title': 'Trace Id'},\n",
       "     'dotted_order': {'type': 'string', 'title': 'Dotted Order'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'status': {'type': 'string', 'title': 'Status'},\n",
       "     'child_run_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Child Run Ids'},\n",
       "     'direct_child_run_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Direct Child Run Ids'},\n",
       "     'parent_run_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Parent Run Ids'},\n",
       "     'feedback_stats': {'anyOf': [{'additionalProperties': {'type': 'object'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Feedback Stats'},\n",
       "     'reference_example_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Reference Example Id'},\n",
       "     'total_tokens': {'type': 'integer',\n",
       "      'title': 'Total Tokens',\n",
       "      'default': 0},\n",
       "     'prompt_tokens': {'type': 'integer',\n",
       "      'title': 'Prompt Tokens',\n",
       "      'default': 0},\n",
       "     'completion_tokens': {'type': 'integer',\n",
       "      'title': 'Completion Tokens',\n",
       "      'default': 0},\n",
       "     'prompt_token_details': {'anyOf': [{'additionalProperties': {'type': 'integer'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Prompt Token Details'},\n",
       "     'completion_token_details': {'anyOf': [{'additionalProperties': {'type': 'integer'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Completion Token Details'},\n",
       "     'total_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Total Cost'},\n",
       "     'prompt_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Prompt Cost'},\n",
       "     'completion_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Completion Cost'},\n",
       "     'prompt_cost_details': {'anyOf': [{'additionalProperties': {'type': 'string'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Prompt Cost Details'},\n",
       "     'completion_cost_details': {'anyOf': [{'additionalProperties': {'type': 'string'},\n",
       "        'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Completion Cost Details'},\n",
       "     'price_model_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Price Model Id'},\n",
       "     'first_token_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'First Token Time'},\n",
       "     'session_id': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'},\n",
       "     'app_path': {'type': 'string', 'title': 'App Path'},\n",
       "     'last_queued_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Last Queued At'},\n",
       "     'in_dataset': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'In Dataset'},\n",
       "     'share_token': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Share Token'},\n",
       "     'trace_tier': {'anyOf': [{'$ref': '#/components/schemas/TraceTier'},\n",
       "       {'type': 'null'}]},\n",
       "     'trace_first_received_at': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Trace First Received At'},\n",
       "     'ttl_seconds': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Ttl Seconds'},\n",
       "     'trace_upgrade': {'type': 'boolean',\n",
       "      'title': 'Trace Upgrade',\n",
       "      'default': False},\n",
       "     'reference_dataset_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Reference Dataset Id'},\n",
       "     'thread_id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Thread Id'},\n",
       "     'queue_run_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Queue Run Id'},\n",
       "     'last_reviewed_time': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Last Reviewed Time'},\n",
       "     'added_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Added At'},\n",
       "     'effective_added_at': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Effective Added At'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name',\n",
       "     'run_type',\n",
       "     'trace_id',\n",
       "     'dotted_order',\n",
       "     'id',\n",
       "     'status',\n",
       "     'session_id',\n",
       "     'app_path',\n",
       "     'queue_run_id'],\n",
       "    'title': 'RunSchemaWithAnnotationQueueInfo',\n",
       "    'description': 'Run schema with annotation queue info.'},\n",
       "   'RunSelect': {'type': 'string',\n",
       "    'enum': ['id',\n",
       "     'name',\n",
       "     'run_type',\n",
       "     'start_time',\n",
       "     'end_time',\n",
       "     'status',\n",
       "     'error',\n",
       "     'extra',\n",
       "     'events',\n",
       "     'inputs',\n",
       "     'inputs_preview',\n",
       "     'inputs_s3_urls',\n",
       "     'inputs_or_signed_url',\n",
       "     'outputs',\n",
       "     'outputs_preview',\n",
       "     'outputs_s3_urls',\n",
       "     'outputs_or_signed_url',\n",
       "     's3_urls',\n",
       "     'error_or_signed_url',\n",
       "     'events_or_signed_url',\n",
       "     'extra_or_signed_url',\n",
       "     'serialized_or_signed_url',\n",
       "     'parent_run_id',\n",
       "     'manifest_id',\n",
       "     'manifest_s3_id',\n",
       "     'manifest',\n",
       "     'session_id',\n",
       "     'serialized',\n",
       "     'reference_example_id',\n",
       "     'reference_dataset_id',\n",
       "     'total_tokens',\n",
       "     'prompt_tokens',\n",
       "     'completion_tokens',\n",
       "     'total_cost',\n",
       "     'prompt_cost',\n",
       "     'completion_cost',\n",
       "     'price_model_id',\n",
       "     'first_token_time',\n",
       "     'trace_id',\n",
       "     'dotted_order',\n",
       "     'last_queued_at',\n",
       "     'feedback_stats',\n",
       "     'child_run_ids',\n",
       "     'parent_run_ids',\n",
       "     'tags',\n",
       "     'in_dataset',\n",
       "     'app_path',\n",
       "     'share_token',\n",
       "     'trace_tier',\n",
       "     'trace_first_received_at',\n",
       "     'ttl_seconds',\n",
       "     'trace_upgrade',\n",
       "     'thread_id'],\n",
       "    'title': 'RunSelect',\n",
       "    'description': 'Enum for available run columns.'},\n",
       "   'RunShareSchema': {'properties': {'run_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Run Id'},\n",
       "     'share_token': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Share Token'}},\n",
       "    'type': 'object',\n",
       "    'required': ['run_id', 'share_token'],\n",
       "    'title': 'RunShareSchema'},\n",
       "   'RunStats': {'properties': {'run_count': {'type': 'integer',\n",
       "      'title': 'Run Count'},\n",
       "     'latency_p50': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'Latency P50'},\n",
       "     'latency_p99': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'Latency P99'},\n",
       "     'first_token_p50': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'First Token P50'},\n",
       "     'first_token_p99': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'First Token P99'},\n",
       "     'total_tokens': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Total Tokens'},\n",
       "     'prompt_tokens': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Prompt Tokens'},\n",
       "     'completion_tokens': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Completion Tokens'},\n",
       "     'median_tokens': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Median Tokens'},\n",
       "     'completion_tokens_p50': {'anyOf': [{'type': 'integer'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Completion Tokens P50'},\n",
       "     'prompt_tokens_p50': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Prompt Tokens P50'},\n",
       "     'tokens_p99': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Tokens P99'},\n",
       "     'completion_tokens_p99': {'anyOf': [{'type': 'integer'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Completion Tokens P99'},\n",
       "     'prompt_tokens_p99': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Prompt Tokens P99'},\n",
       "     'last_run_start_time': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Last Run Start Time'},\n",
       "     'feedback_stats': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Feedback Stats'},\n",
       "     'run_facets': {'anyOf': [{'items': {'type': 'object'}, 'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Run Facets'},\n",
       "     'error_rate': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'Error Rate'},\n",
       "     'streaming_rate': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'Streaming Rate'},\n",
       "     'total_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Total Cost'},\n",
       "     'prompt_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Prompt Cost'},\n",
       "     'completion_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Completion Cost'},\n",
       "     'cost_p50': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Cost P50'},\n",
       "     'cost_p99': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Cost P99'}},\n",
       "    'type': 'object',\n",
       "    'required': ['run_count'],\n",
       "    'title': 'RunStats'},\n",
       "   'RunStatsGroupBy': {'properties': {'attribute': {'type': 'string',\n",
       "      'enum': ['name', 'run_type', 'tag', 'metadata'],\n",
       "      'title': 'Attribute'},\n",
       "     'path': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Path'},\n",
       "     'max_groups': {'type': 'integer', 'title': 'Max Groups', 'default': 5}},\n",
       "    'type': 'object',\n",
       "    'required': ['attribute'],\n",
       "    'title': 'RunStatsGroupBy',\n",
       "    'description': 'Group by param for run stats.'},\n",
       "   'RunStatsGroupBySeriesResponse': {'properties': {'attribute': {'type': 'string',\n",
       "      'enum': ['name', 'run_type', 'tag', 'metadata'],\n",
       "      'title': 'Attribute'},\n",
       "     'path': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Path'},\n",
       "     'max_groups': {'type': 'integer', 'title': 'Max Groups', 'default': 5},\n",
       "     'set_by': {'anyOf': [{'type': 'string', 'enum': ['section', 'series']},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Set By'}},\n",
       "    'type': 'object',\n",
       "    'required': ['attribute'],\n",
       "    'title': 'RunStatsGroupBySeriesResponse',\n",
       "    'description': 'Include additional information about where the group_by param was set.'},\n",
       "   'RunStatsQueryParams': {'properties': {'id': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Id'},\n",
       "     'trace': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Trace'},\n",
       "     'parent_run': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Parent Run'},\n",
       "     'run_type': {'anyOf': [{'$ref': '#/components/schemas/RunTypeEnum'},\n",
       "       {'type': 'null'}]},\n",
       "     'session': {'anyOf': [{'items': {'type': 'string', 'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Session'},\n",
       "     'reference_example': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Reference Example'},\n",
       "     'execution_order': {'anyOf': [{'type': 'integer',\n",
       "        'maximum': 1.0,\n",
       "        'minimum': 1.0},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Execution Order'},\n",
       "     'start_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'End Time'},\n",
       "     'error': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Error'},\n",
       "     'query': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Query'},\n",
       "     'filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Filter'},\n",
       "     'trace_filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Trace Filter'},\n",
       "     'tree_filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Tree Filter'},\n",
       "     'is_root': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Is Root'},\n",
       "     'data_source_type': {'anyOf': [{'$ref': '#/components/schemas/RunsFilterDataSourceTypeEnum'},\n",
       "       {'type': 'null'}]},\n",
       "     'skip_pagination': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Skip Pagination'},\n",
       "     'search_filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Search Filter'},\n",
       "     'use_experimental_search': {'type': 'boolean',\n",
       "      'title': 'Use Experimental Search',\n",
       "      'default': False},\n",
       "     'group_by': {'anyOf': [{'$ref': '#/components/schemas/RunStatsGroupBy'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'title': 'RunStatsQueryParams',\n",
       "    'description': 'Query params for run stats.'},\n",
       "   'RunTypeEnum': {'type': 'string',\n",
       "    'enum': ['tool',\n",
       "     'chain',\n",
       "     'llm',\n",
       "     'retriever',\n",
       "     'embedding',\n",
       "     'prompt',\n",
       "     'parser'],\n",
       "    'title': 'RunTypeEnum',\n",
       "    'description': 'Enum for run types.'},\n",
       "   'RunnableConfig': {'properties': {'tags': {'items': {'type': 'string'},\n",
       "      'type': 'array',\n",
       "      'title': 'Tags'},\n",
       "     'metadata': {'type': 'object', 'title': 'Metadata'},\n",
       "     'callbacks': {'anyOf': [{'items': {}, 'type': 'array'},\n",
       "       {},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Callbacks'},\n",
       "     'run_name': {'type': 'string', 'title': 'Run Name'},\n",
       "     'max_concurrency': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Max Concurrency'},\n",
       "     'recursion_limit': {'type': 'integer', 'title': 'Recursion Limit'},\n",
       "     'configurable': {'type': 'object', 'title': 'Configurable'},\n",
       "     'run_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Run Id'}},\n",
       "    'type': 'object',\n",
       "    'title': 'RunnableConfig',\n",
       "    'description': 'Configuration for a Runnable.'},\n",
       "   'RunsFilterDataSourceTypeEnum': {'type': 'string',\n",
       "    'enum': ['current', 'historical'],\n",
       "    'title': 'RunsFilterDataSourceTypeEnum',\n",
       "    'description': 'Enum for run data source types.'},\n",
       "   'RunsGenerateQueryFeedbackKeys': {'type': 'string',\n",
       "    'enum': ['user_score',\n",
       "     'user_edited',\n",
       "     'user_removed',\n",
       "     'user_opened_run',\n",
       "     'user_selected_run',\n",
       "     'results_size',\n",
       "     'valid_filter'],\n",
       "    'title': 'RunsGenerateQueryFeedbackKeys'},\n",
       "   'SSOConfirmEmailRequest': {'properties': {'token': {'type': 'string',\n",
       "      'title': 'Token'}},\n",
       "    'type': 'object',\n",
       "    'required': ['token'],\n",
       "    'title': 'SSOConfirmEmailRequest'},\n",
       "   'SSOEmailVerificationSendRequest': {'properties': {'email': {'type': 'string',\n",
       "      'title': 'Email'},\n",
       "     'saml_provider_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Saml Provider Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['email', 'saml_provider_id'],\n",
       "    'title': 'SSOEmailVerificationSendRequest'},\n",
       "   'SSOEmailVerificationStatusRequest': {'properties': {'email': {'type': 'string',\n",
       "      'title': 'Email'},\n",
       "     'saml_provider_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Saml Provider Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['email', 'saml_provider_id'],\n",
       "    'title': 'SSOEmailVerificationStatusRequest'},\n",
       "   'SSOEmailVerificationStatusResponse': {'properties': {'email_confirmed_at': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Email Confirmed At'}},\n",
       "    'type': 'object',\n",
       "    'title': 'SSOEmailVerificationStatusResponse'},\n",
       "   'SSOProvider': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'organization_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Organization Id'},\n",
       "     'provider_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Provider Id'},\n",
       "     'default_workspace_role_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Default Workspace Role Id'},\n",
       "     'default_workspace_ids': {'items': {'type': 'string', 'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'title': 'Default Workspace Ids'},\n",
       "     'metadata_url': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Metadata Url'},\n",
       "     'metadata_xml': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Metadata Xml'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id',\n",
       "     'organization_id',\n",
       "     'provider_id',\n",
       "     'default_workspace_role_id',\n",
       "     'default_workspace_ids'],\n",
       "    'title': 'SSOProvider'},\n",
       "   'SSOProviderSlim': {'properties': {'provider_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Provider Id'},\n",
       "     'organization_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Organization Id'},\n",
       "     'organization_display_name': {'type': 'string',\n",
       "      'title': 'Organization Display Name'}},\n",
       "    'type': 'object',\n",
       "    'required': ['provider_id',\n",
       "     'organization_id',\n",
       "     'organization_display_name'],\n",
       "    'title': 'SSOProviderSlim'},\n",
       "   'SSOSettingsCreate': {'properties': {'default_workspace_role_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Default Workspace Role Id'},\n",
       "     'default_workspace_ids': {'items': {'type': 'string', 'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'title': 'Default Workspace Ids'},\n",
       "     'metadata_xml': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Metadata Xml'},\n",
       "     'metadata_url': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Metadata Url'},\n",
       "     'attribute_mapping': {'additionalProperties': {'type': 'string'},\n",
       "      'type': 'object',\n",
       "      'title': 'Attribute Mapping'}},\n",
       "    'type': 'object',\n",
       "    'required': ['default_workspace_role_id', 'default_workspace_ids'],\n",
       "    'title': 'SSOSettingsCreate'},\n",
       "   'SSOSettingsUpdate': {'properties': {'default_workspace_role_id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Default Workspace Role Id'},\n",
       "     'default_workspace_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Default Workspace Ids'},\n",
       "     'metadata_url': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Metadata Url'},\n",
       "     'metadata_xml': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Metadata Xml'}},\n",
       "    'type': 'object',\n",
       "    'title': 'SSOSettingsUpdate'},\n",
       "   'SearchDatasetRequest': {'properties': {'inputs': {'type': 'object',\n",
       "      'title': 'Inputs'},\n",
       "     'limit': {'type': 'integer',\n",
       "      'maximum': 100.0,\n",
       "      'minimum': 1.0,\n",
       "      'title': 'Limit',\n",
       "      'default': 5},\n",
       "     'debug': {'type': 'boolean', 'title': 'Debug', 'default': False},\n",
       "     'filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Filter'}},\n",
       "    'type': 'object',\n",
       "    'required': ['inputs'],\n",
       "    'title': 'SearchDatasetRequest',\n",
       "    'description': 'Dataset schema for serving.'},\n",
       "   'SearchDatasetResponse': {'properties': {'examples': {'items': {'$ref': '#/components/schemas/SearchedFewShotExample'},\n",
       "      'type': 'array',\n",
       "      'title': 'Examples'}},\n",
       "    'type': 'object',\n",
       "    'required': ['examples'],\n",
       "    'title': 'SearchDatasetResponse',\n",
       "    'description': 'Dataset schema for serving.'},\n",
       "   'SearchedFewShotExample': {'properties': {'inputs': {'type': 'object',\n",
       "      'title': 'Inputs'},\n",
       "     'outputs': {'type': 'object', 'title': 'Outputs'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'debug_info': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Debug Info'}},\n",
       "    'type': 'object',\n",
       "    'required': ['inputs', 'outputs', 'id'],\n",
       "    'title': 'SearchedFewShotExample',\n",
       "    'description': 'Dataset schema for serving.'},\n",
       "   'SecretKey': {'properties': {'key': {'type': 'string', 'title': 'Key'}},\n",
       "    'type': 'object',\n",
       "    'required': ['key'],\n",
       "    'title': 'SecretKey'},\n",
       "   'SecretUpsert': {'properties': {'key': {'type': 'string', 'title': 'Key'},\n",
       "     'value': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Value'}},\n",
       "    'type': 'object',\n",
       "    'required': ['key', 'value'],\n",
       "    'title': 'SecretUpsert'},\n",
       "   'ServiceAccount': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'name': {'type': 'string', 'title': 'Name'},\n",
       "     'organization_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Organization Id'},\n",
       "     'default_workspace_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Default Workspace Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id',\n",
       "     'created_at',\n",
       "     'updated_at',\n",
       "     'name',\n",
       "     'organization_id',\n",
       "     'default_workspace_id'],\n",
       "    'title': 'ServiceAccount'},\n",
       "   'ServiceAccountCreateRequest': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name'],\n",
       "    'title': 'ServiceAccountCreateRequest'},\n",
       "   'ServiceAccountCreateResponse': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'name': {'type': 'string', 'title': 'Name'},\n",
       "     'organization_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Organization Id'},\n",
       "     'default_workspace_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Default Workspace Id'},\n",
       "     'organization_identity_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Organization Identity Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id',\n",
       "     'created_at',\n",
       "     'updated_at',\n",
       "     'name',\n",
       "     'organization_id',\n",
       "     'default_workspace_id',\n",
       "     'organization_identity_id'],\n",
       "    'title': 'ServiceAccountCreateResponse'},\n",
       "   'ServiceAccountDeleteResponse': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'name': {'type': 'string', 'title': 'Name'},\n",
       "     'organization_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Organization Id'},\n",
       "     'default_workspace_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Default Workspace Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id',\n",
       "     'created_at',\n",
       "     'updated_at',\n",
       "     'name',\n",
       "     'organization_id',\n",
       "     'default_workspace_id'],\n",
       "    'title': 'ServiceAccountDeleteResponse'},\n",
       "   'SessionFeedbackDelta': {'properties': {'feedback_deltas': {'additionalProperties': {'$ref': '#/components/schemas/FeedbackDelta'},\n",
       "      'propertyNames': {'format': 'uuid'},\n",
       "      'type': 'object',\n",
       "      'title': 'Feedback Deltas'}},\n",
       "    'type': 'object',\n",
       "    'required': ['feedback_deltas'],\n",
       "    'title': 'SessionFeedbackDelta',\n",
       "    'description': 'List of feedback keys with number of improvements and regressions for each.'},\n",
       "   'SessionSortableColumns': {'type': 'string',\n",
       "    'enum': ['name',\n",
       "     'start_time',\n",
       "     'last_run_start_time',\n",
       "     'latency_p50',\n",
       "     'latency_p99',\n",
       "     'error_rate',\n",
       "     'feedback'],\n",
       "    'title': 'SessionSortableColumns'},\n",
       "   'SetTenantHandleRequest': {'properties': {'tenant_handle': {'type': 'string',\n",
       "      'title': 'Tenant Handle'}},\n",
       "    'type': 'object',\n",
       "    'required': ['tenant_handle'],\n",
       "    'title': 'SetTenantHandleRequest'},\n",
       "   'SimpleExperimentInfo': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'name': {'type': 'string', 'title': 'Name'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id', 'name'],\n",
       "    'title': 'SimpleExperimentInfo',\n",
       "    'description': 'Simple experiment info schema for use with comparative experiments'},\n",
       "   'SingleCustomChartResponse': {'properties': {'data': {'items': {'$ref': '#/components/schemas/CustomChartsDataPoint'},\n",
       "      'type': 'array',\n",
       "      'title': 'Data'},\n",
       "     'id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'string'}],\n",
       "      'title': 'Id'},\n",
       "     'title': {'type': 'string', 'title': 'Title'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Metadata'},\n",
       "     'index': {'type': 'integer', 'title': 'Index'},\n",
       "     'chart_type': {'$ref': '#/components/schemas/CustomChartType'},\n",
       "     'series': {'items': {'$ref': '#/components/schemas/CustomChartSeries'},\n",
       "      'type': 'array',\n",
       "      'title': 'Series'},\n",
       "     'common_filters': {'anyOf': [{'$ref': '#/components/schemas/CustomChartSeriesFilters'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'required': ['data', 'id', 'title', 'index', 'chart_type', 'series'],\n",
       "    'title': 'SingleCustomChartResponse'},\n",
       "   'SingleCustomChartResponseBase': {'properties': {'data': {'items': {'$ref': '#/components/schemas/CustomChartsDataPoint'},\n",
       "      'type': 'array',\n",
       "      'title': 'Data'}},\n",
       "    'type': 'object',\n",
       "    'required': ['data'],\n",
       "    'title': 'SingleCustomChartResponseBase'},\n",
       "   'SingleCustomChartSubSectionResponse': {'properties': {'title': {'type': 'string',\n",
       "      'title': 'Title'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'index': {'type': 'integer', 'title': 'Index'},\n",
       "     'id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'string'}],\n",
       "      'title': 'Id'},\n",
       "     'charts': {'items': {'$ref': '#/components/schemas/SingleCustomChartResponse'},\n",
       "      'type': 'array',\n",
       "      'title': 'Charts'}},\n",
       "    'type': 'object',\n",
       "    'required': ['title', 'index', 'id', 'charts'],\n",
       "    'title': 'SingleCustomChartSubSectionResponse'},\n",
       "   'SortByComparativeExperimentColumn': {'type': 'string',\n",
       "    'enum': ['name', 'created_at'],\n",
       "    'title': 'SortByComparativeExperimentColumn',\n",
       "    'description': 'Enum for available comparative experiment columns to sort by.'},\n",
       "   'SortByDatasetColumn': {'type': 'string',\n",
       "    'enum': ['name',\n",
       "     'created_at',\n",
       "     'last_session_start_time',\n",
       "     'example_count',\n",
       "     'session_count'],\n",
       "    'title': 'SortByDatasetColumn',\n",
       "    'description': 'Enum for available dataset columns to sort by.'},\n",
       "   'SortParamsForRunsComparisonView': {'properties': {'sort_by': {'type': 'string',\n",
       "      'title': 'Sort By'},\n",
       "     'sort_order': {'type': 'string',\n",
       "      'enum': ['ASC', 'DESC'],\n",
       "      'title': 'Sort Order',\n",
       "      'default': 'DESC'}},\n",
       "    'type': 'object',\n",
       "    'required': ['sort_by'],\n",
       "    'title': 'SortParamsForRunsComparisonView'},\n",
       "   'SourceType': {'type': 'string',\n",
       "    'enum': ['api', 'model', 'app', 'auto_eval'],\n",
       "    'title': 'SourceType',\n",
       "    'description': 'Enum for feedback source types.'},\n",
       "   'StripeAccountLinksCreate': {'properties': {'success_path': {'type': 'string',\n",
       "      'title': 'Success Path'}},\n",
       "    'type': 'object',\n",
       "    'required': ['success_path'],\n",
       "    'title': 'StripeAccountLinksCreate'},\n",
       "   'StripeBusinessBillingInfo': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'},\n",
       "     'address': {'anyOf': [{'$ref': '#/components/schemas/StripeCustomerAddress'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'required': ['name'],\n",
       "    'title': 'StripeBusinessBillingInfo',\n",
       "    'description': 'Stripe customer billing information.'},\n",
       "   'StripeBusinessInfo-Input': {'properties': {'company_info': {'anyOf': [{'$ref': '#/components/schemas/StripeBusinessBillingInfo'},\n",
       "       {'type': 'null'}]},\n",
       "     'tax_id': {'anyOf': [{'$ref': '#/components/schemas/StripeTaxId'},\n",
       "       {'type': 'null'}]},\n",
       "     'invoice_email': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Invoice Email'},\n",
       "     'is_business': {'type': 'boolean',\n",
       "      'title': 'Is Business',\n",
       "      'default': False}},\n",
       "    'type': 'object',\n",
       "    'title': 'StripeBusinessInfo'},\n",
       "   'StripeBusinessInfo-Output': {'properties': {'company_info': {'anyOf': [{'$ref': '#/components/schemas/StripeBusinessBillingInfo'},\n",
       "       {'type': 'null'}]},\n",
       "     'tax_id': {'anyOf': [{'$ref': '#/components/schemas/StripeTaxId'},\n",
       "       {'type': 'null'}]},\n",
       "     'invoice_email': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Invoice Email'},\n",
       "     'is_business': {'type': 'boolean',\n",
       "      'title': 'Is Business',\n",
       "      'default': False}},\n",
       "    'type': 'object',\n",
       "    'title': 'StripeBusinessInfo'},\n",
       "   'StripeCheckoutSessionsConfirm': {'properties': {'stripe_session_id': {'type': 'string',\n",
       "      'title': 'Stripe Session Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['stripe_session_id'],\n",
       "    'title': 'StripeCheckoutSessionsConfirm'},\n",
       "   'StripeCheckoutSessionsCreate': {'properties': {'amount_cents': {'type': 'integer',\n",
       "      'title': 'Amount Cents'},\n",
       "     'success_path': {'type': 'string', 'title': 'Success Path'}},\n",
       "    'type': 'object',\n",
       "    'required': ['amount_cents', 'success_path'],\n",
       "    'title': 'StripeCheckoutSessionsCreate'},\n",
       "   'StripeCustomerAddress': {'properties': {'line1': {'type': 'string',\n",
       "      'title': 'Line1'},\n",
       "     'line2': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Line2'},\n",
       "     'city': {'type': 'string', 'title': 'City'},\n",
       "     'state': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'State'},\n",
       "     'postal_code': {'type': 'string', 'title': 'Postal Code'},\n",
       "     'country': {'type': 'string', 'title': 'Country'}},\n",
       "    'type': 'object',\n",
       "    'required': ['line1', 'city', 'postal_code', 'country'],\n",
       "    'title': 'StripeCustomerAddress',\n",
       "    'description': 'Stripe customer address.'},\n",
       "   'StripeCustomerBillingInfo': {'properties': {'name': {'type': 'string',\n",
       "      'title': 'Name'},\n",
       "     'address': {'$ref': '#/components/schemas/StripeCustomerAddress'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name', 'address'],\n",
       "    'title': 'StripeCustomerBillingInfo',\n",
       "    'description': 'Stripe customer billing information.'},\n",
       "   'StripePaymentInformation': {'properties': {'billing_info': {'$ref': '#/components/schemas/StripeCustomerBillingInfo'},\n",
       "     'setup_intent': {'type': 'string', 'title': 'Setup Intent'}},\n",
       "    'type': 'object',\n",
       "    'required': ['billing_info', 'setup_intent'],\n",
       "    'title': 'StripePaymentInformation',\n",
       "    'description': 'Stripe payment information.'},\n",
       "   'StripePaymentMethodInfo': {'properties': {'brand': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Brand'},\n",
       "     'last4': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Last4'},\n",
       "     'exp_month': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Exp Month'},\n",
       "     'exp_year': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Exp Year'},\n",
       "     'email': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Email'}},\n",
       "    'type': 'object',\n",
       "    'title': 'StripePaymentMethodInfo',\n",
       "    'description': 'Stripe customer billing info.'},\n",
       "   'StripeSetupIntentResponse': {'properties': {'client_secret': {'type': 'string',\n",
       "      'title': 'Client Secret'}},\n",
       "    'type': 'object',\n",
       "    'required': ['client_secret'],\n",
       "    'title': 'StripeSetupIntentResponse',\n",
       "    'description': 'Stripe setup intent response.'},\n",
       "   'StripeTaxId': {'properties': {'value': {'type': 'string',\n",
       "      'title': 'Value'},\n",
       "     'type': {'type': 'string', 'title': 'Type'}},\n",
       "    'type': 'object',\n",
       "    'required': ['value', 'type'],\n",
       "    'title': 'StripeTaxId',\n",
       "    'description': 'Stripe tax ID.'},\n",
       "   'StudioRunOverDatasetRequestSchema': {'properties': {'project_name': {'type': 'string',\n",
       "      'title': 'Project Name'},\n",
       "     'dataset_id': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'},\n",
       "     'evaluator_rules': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Evaluator Rules'}},\n",
       "    'type': 'object',\n",
       "    'required': ['project_name', 'dataset_id'],\n",
       "    'title': 'StudioRunOverDatasetRequestSchema'},\n",
       "   'SystemMessage': {'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "       {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "        'type': 'array'}],\n",
       "      'title': 'Content'},\n",
       "     'additional_kwargs': {'type': 'object', 'title': 'Additional Kwargs'},\n",
       "     'response_metadata': {'type': 'object', 'title': 'Response Metadata'},\n",
       "     'type': {'type': 'string',\n",
       "      'const': 'system',\n",
       "      'title': 'Type',\n",
       "      'default': 'system'},\n",
       "     'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'}},\n",
       "    'additionalProperties': True,\n",
       "    'type': 'object',\n",
       "    'required': ['content'],\n",
       "    'title': 'SystemMessage',\n",
       "    'description': 'Message for priming AI behavior.\\n\\nThe system message is usually passed in as the first of a sequence\\nof input messages.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Define a chat model and invoke it with the messages\\n        print(model.invoke(messages))'},\n",
       "   'SystemMessageChunk': {'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "       {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "        'type': 'array'}],\n",
       "      'title': 'Content'},\n",
       "     'additional_kwargs': {'type': 'object', 'title': 'Additional Kwargs'},\n",
       "     'response_metadata': {'type': 'object', 'title': 'Response Metadata'},\n",
       "     'type': {'type': 'string',\n",
       "      'const': 'SystemMessageChunk',\n",
       "      'title': 'Type',\n",
       "      'default': 'SystemMessageChunk'},\n",
       "     'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'}},\n",
       "    'additionalProperties': True,\n",
       "    'type': 'object',\n",
       "    'required': ['content'],\n",
       "    'title': 'SystemMessageChunk',\n",
       "    'description': 'System Message chunk.'},\n",
       "   'TTLSettings': {'properties': {'tenant_id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Tenant Id'},\n",
       "     'default_trace_tier': {'$ref': '#/components/schemas/TraceTier'},\n",
       "     'apply_to_all_projects': {'type': 'boolean',\n",
       "      'title': 'Apply To All Projects',\n",
       "      'default': False},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'organization_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Organization Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'configured_by': {'$ref': '#/components/schemas/ConfiguredBy'}},\n",
       "    'type': 'object',\n",
       "    'required': ['default_trace_tier',\n",
       "     'id',\n",
       "     'organization_id',\n",
       "     'created_at',\n",
       "     'updated_at',\n",
       "     'configured_by'],\n",
       "    'title': 'TTLSettings',\n",
       "    'description': 'TTL settings model.'},\n",
       "   'TagCount': {'properties': {'tag': {'type': 'string', 'title': 'Tag'},\n",
       "     'count': {'type': 'integer', 'title': 'Count'}},\n",
       "    'type': 'object',\n",
       "    'required': ['tag', 'count'],\n",
       "    'title': 'TagCount'},\n",
       "   'TagKey': {'properties': {'key': {'type': 'string',\n",
       "      'maxLength': 255,\n",
       "      'minLength': 1,\n",
       "      'title': 'Key'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'}},\n",
       "    'type': 'object',\n",
       "    'required': ['key', 'id', 'created_at', 'updated_at'],\n",
       "    'title': 'TagKey'},\n",
       "   'TagKeyCreate': {'properties': {'key': {'type': 'string',\n",
       "      'maxLength': 255,\n",
       "      'minLength': 1,\n",
       "      'title': 'Key'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'}},\n",
       "    'type': 'object',\n",
       "    'required': ['key'],\n",
       "    'title': 'TagKeyCreate'},\n",
       "   'TagKeyUpdate': {'properties': {'key': {'anyOf': [{'type': 'string',\n",
       "        'maxLength': 255,\n",
       "        'minLength': 1},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Key'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'}},\n",
       "    'type': 'object',\n",
       "    'title': 'TagKeyUpdate'},\n",
       "   'TagKeyWithValues': {'properties': {'key': {'type': 'string',\n",
       "      'maxLength': 255,\n",
       "      'minLength': 1,\n",
       "      'title': 'Key'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'values': {'items': {'$ref': '#/components/schemas/TagValue'},\n",
       "      'type': 'array',\n",
       "      'title': 'Values'}},\n",
       "    'type': 'object',\n",
       "    'required': ['key', 'id', 'created_at', 'updated_at'],\n",
       "    'title': 'TagKeyWithValues'},\n",
       "   'TagKeyWithValuesAndTaggings': {'properties': {'key': {'type': 'string',\n",
       "      'maxLength': 255,\n",
       "      'minLength': 1,\n",
       "      'title': 'Key'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'values': {'items': {'$ref': '#/components/schemas/TagValueWithTaggings'},\n",
       "      'type': 'array',\n",
       "      'title': 'Values'}},\n",
       "    'type': 'object',\n",
       "    'required': ['key', 'id', 'created_at', 'updated_at'],\n",
       "    'title': 'TagKeyWithValuesAndTaggings'},\n",
       "   'TagValue': {'properties': {'value': {'type': 'string',\n",
       "      'maxLength': 255,\n",
       "      'minLength': 1,\n",
       "      'title': 'Value'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'tag_key_id': {'type': 'string', 'format': 'uuid', 'title': 'Tag Key Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'}},\n",
       "    'type': 'object',\n",
       "    'required': ['value', 'id', 'tag_key_id', 'created_at', 'updated_at'],\n",
       "    'title': 'TagValue'},\n",
       "   'TagValueCreate': {'properties': {'value': {'type': 'string',\n",
       "      'maxLength': 255,\n",
       "      'minLength': 1,\n",
       "      'title': 'Value'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'}},\n",
       "    'type': 'object',\n",
       "    'required': ['value'],\n",
       "    'title': 'TagValueCreate'},\n",
       "   'TagValueUpdate': {'properties': {'value': {'anyOf': [{'type': 'string',\n",
       "        'maxLength': 255,\n",
       "        'minLength': 1},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Value'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'}},\n",
       "    'type': 'object',\n",
       "    'title': 'TagValueUpdate'},\n",
       "   'TagValueWithTaggings': {'properties': {'value': {'type': 'string',\n",
       "      'maxLength': 255,\n",
       "      'minLength': 1,\n",
       "      'title': 'Value'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'tag_key_id': {'type': 'string', 'format': 'uuid', 'title': 'Tag Key Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'taggings': {'items': {'$ref': '#/components/schemas/Tagging'},\n",
       "      'type': 'array',\n",
       "      'title': 'Taggings'}},\n",
       "    'type': 'object',\n",
       "    'required': ['value', 'id', 'tag_key_id', 'created_at', 'updated_at'],\n",
       "    'title': 'TagValueWithTaggings'},\n",
       "   'Tagging': {'properties': {'tag_value_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Tag Value Id'},\n",
       "     'resource_type': {'$ref': '#/components/schemas/ResourceType'},\n",
       "     'resource_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Resource Id'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'}},\n",
       "    'type': 'object',\n",
       "    'required': ['tag_value_id',\n",
       "     'resource_type',\n",
       "     'resource_id',\n",
       "     'id',\n",
       "     'created_at'],\n",
       "    'title': 'Tagging'},\n",
       "   'TaggingCreate': {'properties': {'tag_value_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Tag Value Id'},\n",
       "     'resource_type': {'$ref': '#/components/schemas/ResourceType'},\n",
       "     'resource_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Resource Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['tag_value_id', 'resource_type', 'resource_id'],\n",
       "    'title': 'TaggingCreate'},\n",
       "   'TaggingsByResourceType': {'properties': {'prompts': {'items': {'$ref': '#/components/schemas/Resource'},\n",
       "      'type': 'array',\n",
       "      'title': 'Prompts',\n",
       "      'default': []},\n",
       "     'projects': {'items': {'$ref': '#/components/schemas/Resource'},\n",
       "      'type': 'array',\n",
       "      'title': 'Projects',\n",
       "      'default': []},\n",
       "     'queues': {'items': {'$ref': '#/components/schemas/Resource'},\n",
       "      'type': 'array',\n",
       "      'title': 'Queues',\n",
       "      'default': []},\n",
       "     'deployments': {'items': {'$ref': '#/components/schemas/Resource'},\n",
       "      'type': 'array',\n",
       "      'title': 'Deployments',\n",
       "      'default': []},\n",
       "     'experiments': {'items': {'$ref': '#/components/schemas/Resource'},\n",
       "      'type': 'array',\n",
       "      'title': 'Experiments',\n",
       "      'default': []},\n",
       "     'datasets': {'items': {'$ref': '#/components/schemas/Resource'},\n",
       "      'type': 'array',\n",
       "      'title': 'Datasets',\n",
       "      'default': []},\n",
       "     'dashboards': {'items': {'$ref': '#/components/schemas/Resource'},\n",
       "      'type': 'array',\n",
       "      'title': 'Dashboards',\n",
       "      'default': []}},\n",
       "    'type': 'object',\n",
       "    'title': 'TaggingsByResourceType'},\n",
       "   'TaggingsResponse': {'properties': {'tag_key': {'type': 'string',\n",
       "      'title': 'Tag Key'},\n",
       "     'tag_key_id': {'type': 'string', 'format': 'uuid', 'title': 'Tag Key Id'},\n",
       "     'tag_value': {'type': 'string', 'title': 'Tag Value'},\n",
       "     'tag_value_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Tag Value Id'},\n",
       "     'resources': {'$ref': '#/components/schemas/TaggingsByResourceType'}},\n",
       "    'type': 'object',\n",
       "    'required': ['tag_key',\n",
       "     'tag_key_id',\n",
       "     'tag_value',\n",
       "     'tag_value_id',\n",
       "     'resources'],\n",
       "    'title': 'TaggingsResponse'},\n",
       "   'TenantBulkUnshareRequest': {'properties': {'share_tokens': {'items': {'type': 'string',\n",
       "       'format': 'uuid'},\n",
       "      'type': 'array',\n",
       "      'minItems': 1,\n",
       "      'title': 'Share Tokens'}},\n",
       "    'type': 'object',\n",
       "    'title': 'TenantBulkUnshareRequest'},\n",
       "   'TenantCreate': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'organization_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Organization Id'},\n",
       "     'display_name': {'type': 'string',\n",
       "      'minLength': 1,\n",
       "      'pattern': \"^[a-zA-Z0-9\\\\-_ ']+$\",\n",
       "      'title': 'Display Name'},\n",
       "     'tenant_handle': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Tenant Handle'},\n",
       "     'is_personal': {'type': 'boolean',\n",
       "      'title': 'Is Personal',\n",
       "      'default': False}},\n",
       "    'type': 'object',\n",
       "    'required': ['display_name'],\n",
       "    'title': 'TenantCreate',\n",
       "    'description': 'Creation model for the tenant.'},\n",
       "   'TenantForUser': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'organization_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Organization Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'display_name': {'type': 'string', 'title': 'Display Name'},\n",
       "     'is_personal': {'type': 'boolean', 'title': 'Is Personal'},\n",
       "     'is_deleted': {'type': 'boolean', 'title': 'Is Deleted'},\n",
       "     'tenant_handle': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Tenant Handle'},\n",
       "     'read_only': {'type': 'boolean', 'title': 'Read Only', 'default': False},\n",
       "     'role_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Role Id'},\n",
       "     'role_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Role Name'},\n",
       "     'permissions': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Permissions'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id',\n",
       "     'created_at',\n",
       "     'display_name',\n",
       "     'is_personal',\n",
       "     'is_deleted'],\n",
       "    'title': 'TenantForUser'},\n",
       "   'TenantMembers': {'properties': {'tenant_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Tenant Id'},\n",
       "     'members': {'items': {'$ref': '#/components/schemas/MemberIdentity'},\n",
       "      'type': 'array',\n",
       "      'title': 'Members'},\n",
       "     'pending': {'items': {'$ref': '#/components/schemas/PendingIdentity'},\n",
       "      'type': 'array',\n",
       "      'title': 'Pending'}},\n",
       "    'type': 'object',\n",
       "    'required': ['tenant_id', 'members', 'pending'],\n",
       "    'title': 'TenantMembers',\n",
       "    'description': 'Tenant members schema.'},\n",
       "   'TenantShareDatasetToken': {'properties': {'type': {'type': 'string',\n",
       "      'const': 'dataset',\n",
       "      'title': 'Type'},\n",
       "     'share_token': {'type': 'string', 'title': 'Share Token'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'dataset_id': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'},\n",
       "     'dataset_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Dataset Name'}},\n",
       "    'type': 'object',\n",
       "    'required': ['type', 'share_token', 'created_at', 'dataset_id'],\n",
       "    'title': 'TenantShareDatasetToken'},\n",
       "   'TenantShareRunToken': {'properties': {'type': {'type': 'string',\n",
       "      'const': 'run',\n",
       "      'title': 'Type'},\n",
       "     'share_token': {'type': 'string', 'title': 'Share Token'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'run_id': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'},\n",
       "     'run_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Run Name'},\n",
       "     'run_type': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Run Type'},\n",
       "     'session_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Session Id'},\n",
       "     'session_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Session Name'}},\n",
       "    'type': 'object',\n",
       "    'required': ['type', 'share_token', 'created_at', 'run_id'],\n",
       "    'title': 'TenantShareRunToken'},\n",
       "   'TenantShareTokensResponse': {'properties': {'entities': {'items': {'oneOf': [{'$ref': '#/components/schemas/TenantShareRunToken'},\n",
       "        {'$ref': '#/components/schemas/TenantShareDatasetToken'}],\n",
       "       'discriminator': {'propertyName': 'type',\n",
       "        'mapping': {'dataset': '#/components/schemas/TenantShareDatasetToken',\n",
       "         'run': '#/components/schemas/TenantShareRunToken'}}},\n",
       "      'type': 'array',\n",
       "      'title': 'Entities'}},\n",
       "    'type': 'object',\n",
       "    'required': ['entities'],\n",
       "    'title': 'TenantShareTokensResponse'},\n",
       "   'TenantStats': {'properties': {'tenant_id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Tenant Id'},\n",
       "     'dataset_count': {'type': 'integer', 'title': 'Dataset Count'},\n",
       "     'tracer_session_count': {'type': 'integer',\n",
       "      'title': 'Tracer Session Count'},\n",
       "     'repo_count': {'type': 'integer', 'title': 'Repo Count'},\n",
       "     'annotation_queue_count': {'type': 'integer',\n",
       "      'title': 'Annotation Queue Count'},\n",
       "     'deployment_count': {'type': 'integer', 'title': 'Deployment Count'},\n",
       "     'dashboards_count': {'type': 'integer', 'title': 'Dashboards Count'}},\n",
       "    'type': 'object',\n",
       "    'required': ['tenant_id',\n",
       "     'dataset_count',\n",
       "     'tracer_session_count',\n",
       "     'repo_count',\n",
       "     'annotation_queue_count',\n",
       "     'deployment_count',\n",
       "     'dashboards_count'],\n",
       "    'title': 'TenantStats',\n",
       "    'description': 'Stats for a tenant.'},\n",
       "   'TenantUsageLimitInfo': {'properties': {'in_reject_set': {'type': 'boolean',\n",
       "      'title': 'In Reject Set'},\n",
       "     'usage_limit_type': {'anyOf': [{'$ref': '#/components/schemas/TenantUsageLimitType'},\n",
       "       {'type': 'null'}]},\n",
       "     'tenant_limit': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Tenant Limit'}},\n",
       "    'type': 'object',\n",
       "    'required': ['in_reject_set'],\n",
       "    'title': 'TenantUsageLimitInfo'},\n",
       "   'TenantUsageLimitType': {'type': 'string',\n",
       "    'enum': ['payload_size',\n",
       "     'events_ingested_per_hour',\n",
       "     'total_unique_traces',\n",
       "     'events_ingested_per_minute',\n",
       "     'user_defined_monthly_traces',\n",
       "     'user_defined_monthly_longlived_traces',\n",
       "     'user_defined_unknown'],\n",
       "    'title': 'TenantUsageLimitType'},\n",
       "   'TimedeltaInput': {'properties': {'days': {'type': 'integer',\n",
       "      'title': 'Days',\n",
       "      'default': 0},\n",
       "     'minutes': {'type': 'integer', 'title': 'Minutes', 'default': 0},\n",
       "     'hours': {'type': 'integer', 'title': 'Hours', 'default': 0}},\n",
       "    'type': 'object',\n",
       "    'title': 'TimedeltaInput',\n",
       "    'description': 'Timedelta input.'},\n",
       "   'ToolCall': {'properties': {'name': {'type': 'string', 'title': 'Name'},\n",
       "     'args': {'type': 'object', 'title': 'Args'},\n",
       "     'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "     'type': {'type': 'string', 'const': 'tool_call', 'title': 'Type'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name', 'args', 'id'],\n",
       "    'title': 'ToolCall',\n",
       "    'description': 'Represents a request to call a tool.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"name\": \"foo\",\\n            \"args\": {\"a\": 1},\\n            \"id\": \"123\"\\n        }\\n\\n    This represents a request to call the tool named \"foo\" with arguments {\"a\": 1}\\n    and an identifier of \"123\".'},\n",
       "   'ToolCallChunk': {'properties': {'name': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'args': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Args'},\n",
       "     'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "     'index': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Index'},\n",
       "     'type': {'type': 'string', 'const': 'tool_call_chunk', 'title': 'Type'}},\n",
       "    'type': 'object',\n",
       "    'required': ['name', 'args', 'id', 'index'],\n",
       "    'title': 'ToolCallChunk',\n",
       "    'description': 'A chunk of a tool call (e.g., as part of a stream).\\n\\nWhen merging ToolCallChunks (e.g., via AIMessageChunk.__add__),\\nall string attributes are concatenated. Chunks are only merged if their\\nvalues of `index` are equal and not None.\\n\\nExample:\\n\\n.. code-block:: python\\n\\n    left_chunks = [ToolCallChunk(name=\"foo\", args=\\'{\"a\":\\', index=0)]\\n    right_chunks = [ToolCallChunk(name=None, args=\\'1}\\', index=0)]\\n\\n    (\\n        AIMessageChunk(content=\"\", tool_call_chunks=left_chunks)\\n        + AIMessageChunk(content=\"\", tool_call_chunks=right_chunks)\\n    ).tool_call_chunks == [ToolCallChunk(name=\\'foo\\', args=\\'{\"a\":1}\\', index=0)]'},\n",
       "   'ToolMessage': {'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "       {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "        'type': 'array'}],\n",
       "      'title': 'Content'},\n",
       "     'additional_kwargs': {'type': 'object', 'title': 'Additional Kwargs'},\n",
       "     'response_metadata': {'type': 'object', 'title': 'Response Metadata'},\n",
       "     'type': {'type': 'string',\n",
       "      'const': 'tool',\n",
       "      'title': 'Type',\n",
       "      'default': 'tool'},\n",
       "     'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "     'tool_call_id': {'type': 'string', 'title': 'Tool Call Id'},\n",
       "     'artifact': {'title': 'Artifact'},\n",
       "     'status': {'type': 'string',\n",
       "      'enum': ['success', 'error'],\n",
       "      'title': 'Status',\n",
       "      'default': 'success'}},\n",
       "    'additionalProperties': True,\n",
       "    'type': 'object',\n",
       "    'required': ['content', 'tool_call_id'],\n",
       "    'title': 'ToolMessage',\n",
       "    'description': 'Message for passing the result of executing a tool back to a model.\\n\\nToolMessages contain the result of a tool invocation. Typically, the result\\nis encoded inside the `content` field.\\n\\nExample: A ToolMessage representing a result of 42 from a tool call with id\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        ToolMessage(content=\\'42\\', tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\')\\n\\n\\nExample: A ToolMessage where only part of the tool output is sent to the model\\n    and the full output is passed in to artifact.\\n\\n    .. versionadded:: 0.2.17\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        tool_output = {\\n            \"stdout\": \"From the graph we can see that the correlation between x and y is ...\",\\n            \"stderr\": None,\\n            \"artifacts\": {\"type\": \"image\", \"base64_data\": \"/9j/4gIcSU...\"},\\n        }\\n\\n        ToolMessage(\\n            content=tool_output[\"stdout\"],\\n            artifact=tool_output,\\n            tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\',\\n        )\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.'},\n",
       "   'ToolMessageChunk': {'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "       {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "        'type': 'array'}],\n",
       "      'title': 'Content'},\n",
       "     'additional_kwargs': {'type': 'object', 'title': 'Additional Kwargs'},\n",
       "     'response_metadata': {'type': 'object', 'title': 'Response Metadata'},\n",
       "     'type': {'type': 'string',\n",
       "      'const': 'ToolMessageChunk',\n",
       "      'title': 'Type',\n",
       "      'default': 'ToolMessageChunk'},\n",
       "     'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "     'tool_call_id': {'type': 'string', 'title': 'Tool Call Id'},\n",
       "     'artifact': {'title': 'Artifact'},\n",
       "     'status': {'type': 'string',\n",
       "      'enum': ['success', 'error'],\n",
       "      'title': 'Status',\n",
       "      'default': 'success'}},\n",
       "    'additionalProperties': True,\n",
       "    'type': 'object',\n",
       "    'required': ['content', 'tool_call_id'],\n",
       "    'title': 'ToolMessageChunk',\n",
       "    'description': 'Tool Message chunk.'},\n",
       "   'TraceTier': {'type': 'string',\n",
       "    'enum': ['longlived', 'shortlived'],\n",
       "    'title': 'TraceTier'},\n",
       "   'TracerSession': {'properties': {'start_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'End Time'},\n",
       "     'extra': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Extra'},\n",
       "     'name': {'type': 'string', 'title': 'Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'default_dataset_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Default Dataset Id'},\n",
       "     'reference_dataset_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Reference Dataset Id'},\n",
       "     'trace_tier': {'anyOf': [{'$ref': '#/components/schemas/TraceTier'},\n",
       "       {'type': 'null'}]},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'run_count': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Run Count'},\n",
       "     'latency_p50': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'Latency P50'},\n",
       "     'latency_p99': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'Latency P99'},\n",
       "     'first_token_p50': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'First Token P50'},\n",
       "     'first_token_p99': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'First Token P99'},\n",
       "     'total_tokens': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Total Tokens'},\n",
       "     'prompt_tokens': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Prompt Tokens'},\n",
       "     'completion_tokens': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Completion Tokens'},\n",
       "     'total_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Total Cost'},\n",
       "     'prompt_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Prompt Cost'},\n",
       "     'completion_cost': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Completion Cost'},\n",
       "     'tenant_id': {'type': 'string', 'format': 'uuid', 'title': 'Tenant Id'},\n",
       "     'last_run_start_time': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Last Run Start Time'},\n",
       "     'last_run_start_time_live': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Last Run Start Time Live'},\n",
       "     'feedback_stats': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Feedback Stats'},\n",
       "     'session_feedback_stats': {'anyOf': [{'type': 'object'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Session Feedback Stats'},\n",
       "     'run_facets': {'anyOf': [{'items': {'type': 'object'}, 'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Run Facets'},\n",
       "     'error_rate': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'Error Rate'},\n",
       "     'streaming_rate': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "      'title': 'Streaming Rate'},\n",
       "     'test_run_number': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'title': 'Test Run Number'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id', 'tenant_id'],\n",
       "    'title': 'TracerSession',\n",
       "    'description': 'TracerSession schema.'},\n",
       "   'TracerSessionCreate': {'properties': {'start_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'End Time'},\n",
       "     'extra': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Extra'},\n",
       "     'name': {'type': 'string', 'title': 'Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'default_dataset_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Default Dataset Id'},\n",
       "     'reference_dataset_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Reference Dataset Id'},\n",
       "     'trace_tier': {'anyOf': [{'$ref': '#/components/schemas/TraceTier'},\n",
       "       {'type': 'null'}]},\n",
       "     'id': {'anyOf': [{'type': 'string', 'format': 'uuid'}, {'type': 'null'}],\n",
       "      'title': 'Id'}},\n",
       "    'type': 'object',\n",
       "    'title': 'TracerSessionCreate',\n",
       "    'description': 'Create class for TracerSession.'},\n",
       "   'TracerSessionUpdate': {'properties': {'name': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'default_dataset_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Default Dataset Id'},\n",
       "     'end_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'End Time'},\n",
       "     'extra': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Extra'},\n",
       "     'trace_tier': {'anyOf': [{'$ref': '#/components/schemas/TraceTier'},\n",
       "       {'type': 'null'}]}},\n",
       "    'type': 'object',\n",
       "    'title': 'TracerSessionUpdate',\n",
       "    'description': 'Update class for TracerSession.'},\n",
       "   'TracerSessionWithoutVirtualFields': {'properties': {'start_time': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Start Time'},\n",
       "     'end_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'End Time'},\n",
       "     'extra': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "      'title': 'Extra'},\n",
       "     'name': {'type': 'string', 'title': 'Name'},\n",
       "     'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'default_dataset_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Default Dataset Id'},\n",
       "     'reference_dataset_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Reference Dataset Id'},\n",
       "     'trace_tier': {'anyOf': [{'$ref': '#/components/schemas/TraceTier'},\n",
       "       {'type': 'null'}]},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'tenant_id': {'type': 'string', 'format': 'uuid', 'title': 'Tenant Id'},\n",
       "     'last_run_start_time_live': {'anyOf': [{'type': 'string',\n",
       "        'format': 'date-time'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Last Run Start Time Live'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id', 'tenant_id'],\n",
       "    'title': 'TracerSessionWithoutVirtualFields',\n",
       "    'description': 'TracerSession schema.'},\n",
       "   'TriggerRulesRequest': {'properties': {'rule_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Rule Ids'},\n",
       "     'dataset_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Dataset Id'}},\n",
       "    'type': 'object',\n",
       "    'title': 'TriggerRulesRequest'},\n",
       "   'UpdateFeedbackConfigSchema': {'properties': {'feedback_key': {'type': 'string',\n",
       "      'title': 'Feedback Key'},\n",
       "     'feedback_config': {'anyOf': [{'$ref': '#/components/schemas/FeedbackConfig'},\n",
       "       {'type': 'null'}]},\n",
       "     'is_lower_score_better': {'anyOf': [{'type': 'boolean'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Is Lower Score Better'}},\n",
       "    'type': 'object',\n",
       "    'required': ['feedback_key'],\n",
       "    'title': 'UpdateFeedbackConfigSchema'},\n",
       "   'UpdateRepoRequest': {'properties': {'description': {'anyOf': [{'type': 'string'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Description'},\n",
       "     'readme': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Readme'},\n",
       "     'tags': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Tags'},\n",
       "     'is_public': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Is Public'},\n",
       "     'is_archived': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "      'title': 'Is Archived'}},\n",
       "    'type': 'object',\n",
       "    'title': 'UpdateRepoRequest',\n",
       "    'description': 'Fields to update a repo'},\n",
       "   'UpdateRoleRequest': {'properties': {'display_name': {'type': 'string',\n",
       "      'title': 'Display Name'},\n",
       "     'description': {'type': 'string', 'title': 'Description'},\n",
       "     'permissions': {'items': {'type': 'string'},\n",
       "      'type': 'array',\n",
       "      'title': 'Permissions'}},\n",
       "    'type': 'object',\n",
       "    'required': ['display_name', 'description', 'permissions'],\n",
       "    'title': 'UpdateRoleRequest'},\n",
       "   'UpsertTTLSettingsRequest': {'properties': {'tenant_id': {'anyOf': [{'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Tenant Id'},\n",
       "     'default_trace_tier': {'$ref': '#/components/schemas/TraceTier'},\n",
       "     'apply_to_all_projects': {'type': 'boolean',\n",
       "      'title': 'Apply To All Projects',\n",
       "      'default': False}},\n",
       "    'type': 'object',\n",
       "    'required': ['default_trace_tier'],\n",
       "    'title': 'UpsertTTLSettingsRequest',\n",
       "    'description': 'Base TTL settings model.'},\n",
       "   'UpsertUsageLimit': {'properties': {'limit_type': {'$ref': '#/components/schemas/UsageLimitType'},\n",
       "     'limit_value': {'type': 'integer', 'title': 'Limit Value'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'}},\n",
       "    'type': 'object',\n",
       "    'required': ['limit_type', 'limit_value'],\n",
       "    'title': 'UpsertUsageLimit',\n",
       "    'description': 'Request body for creating or updating a usage limit.'},\n",
       "   'UsageLimit': {'properties': {'limit_type': {'$ref': '#/components/schemas/UsageLimitType'},\n",
       "     'limit_value': {'type': 'integer', 'title': 'Limit Value'},\n",
       "     'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "     'tenant_id': {'type': 'string', 'format': 'uuid', 'title': 'Tenant Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'}},\n",
       "    'type': 'object',\n",
       "    'required': ['limit_type',\n",
       "     'limit_value',\n",
       "     'tenant_id',\n",
       "     'created_at',\n",
       "     'updated_at'],\n",
       "    'title': 'UsageLimit',\n",
       "    'description': 'Usage limit model.'},\n",
       "   'UsageLimitType': {'type': 'string',\n",
       "    'enum': ['monthly_traces', 'monthly_longlived_traces'],\n",
       "    'title': 'UsageLimitType',\n",
       "    'description': 'Type of usage limit.'},\n",
       "   'UsageMetadata': {'properties': {'input_tokens': {'type': 'integer',\n",
       "      'title': 'Input Tokens'},\n",
       "     'output_tokens': {'type': 'integer', 'title': 'Output Tokens'},\n",
       "     'total_tokens': {'type': 'integer', 'title': 'Total Tokens'},\n",
       "     'input_token_details': {'$ref': '#/components/schemas/InputTokenDetails'},\n",
       "     'output_token_details': {'$ref': '#/components/schemas/OutputTokenDetails'}},\n",
       "    'type': 'object',\n",
       "    'required': ['input_tokens', 'output_tokens', 'total_tokens'],\n",
       "    'title': 'UsageMetadata',\n",
       "    'description': 'Usage metadata for a message, such as token counts.\\n\\nThis is a standard representation of token usage that is consistent across models.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"input_tokens\": 350,\\n            \"output_tokens\": 240,\\n            \"total_tokens\": 590,\\n            \"input_token_details\": {\\n                \"audio\": 10,\\n                \"cache_creation\": 200,\\n                \"cache_read\": 100,\\n            },\\n            \"output_token_details\": {\\n                \"audio\": 10,\\n                \"reasoning\": 200,\\n            }\\n        }\\n\\n.. versionchanged:: 0.3.9\\n\\n    Added ``input_token_details`` and ``output_token_details``.'},\n",
       "   'UserWithPassword': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'ls_user_id': {'type': 'string', 'format': 'uuid', 'title': 'Ls User Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'updated_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Updated At'},\n",
       "     'email': {'type': 'string', 'title': 'Email'},\n",
       "     'full_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Full Name'},\n",
       "     'avatar_url': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Avatar Url'},\n",
       "     'password': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Password'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id', 'ls_user_id', 'created_at', 'updated_at', 'email'],\n",
       "    'title': 'UserWithPassword'},\n",
       "   'ValidationError': {'properties': {'loc': {'items': {'anyOf': [{'type': 'string'},\n",
       "        {'type': 'integer'}]},\n",
       "      'type': 'array',\n",
       "      'title': 'Location'},\n",
       "     'msg': {'type': 'string', 'title': 'Message'},\n",
       "     'type': {'type': 'string', 'title': 'Error Type'}},\n",
       "    'type': 'object',\n",
       "    'required': ['loc', 'msg', 'type'],\n",
       "    'title': 'ValidationError'},\n",
       "   'Wallet': {'properties': {'credit_balance_micros': {'type': 'integer',\n",
       "      'title': 'Credit Balance Micros'},\n",
       "     'inflight_balance_micros': {'type': 'integer',\n",
       "      'title': 'Inflight Balance Micros'}},\n",
       "    'type': 'object',\n",
       "    'required': ['credit_balance_micros', 'inflight_balance_micros'],\n",
       "    'title': 'Wallet'},\n",
       "   'WorkspaceCreate': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'display_name': {'type': 'string',\n",
       "      'minLength': 1,\n",
       "      'pattern': \"^[a-zA-Z0-9\\\\-_ '@()]+$\",\n",
       "      'title': 'Display Name'},\n",
       "     'tenant_handle': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Tenant Handle'}},\n",
       "    'type': 'object',\n",
       "    'required': ['display_name'],\n",
       "    'title': 'WorkspaceCreate',\n",
       "    'description': 'Creation model for the workspace.'},\n",
       "   'WorkspacePatch': {'properties': {'display_name': {'type': 'string',\n",
       "      'minLength': 1,\n",
       "      'pattern': \"^[a-zA-Z0-9\\\\-_ '@()]+$\",\n",
       "      'title': 'Display Name'}},\n",
       "    'type': 'object',\n",
       "    'required': ['display_name'],\n",
       "    'title': 'WorkspacePatch',\n",
       "    'description': 'Patch model for the workspace.'},\n",
       "   'app__hub__crud__tenants__Tenant': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'display_name': {'type': 'string', 'title': 'Display Name'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'tenant_handle': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Tenant Handle'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id', 'display_name', 'created_at'],\n",
       "    'title': 'Tenant'},\n",
       "   'app__schemas__Tenant': {'properties': {'id': {'type': 'string',\n",
       "      'format': 'uuid',\n",
       "      'title': 'Id'},\n",
       "     'organization_id': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "       {'type': 'null'}],\n",
       "      'title': 'Organization Id'},\n",
       "     'created_at': {'type': 'string',\n",
       "      'format': 'date-time',\n",
       "      'title': 'Created At'},\n",
       "     'display_name': {'type': 'string', 'title': 'Display Name'},\n",
       "     'is_personal': {'type': 'boolean', 'title': 'Is Personal'},\n",
       "     'is_deleted': {'type': 'boolean', 'title': 'Is Deleted'},\n",
       "     'tenant_handle': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "      'title': 'Tenant Handle'}},\n",
       "    'type': 'object',\n",
       "    'required': ['id',\n",
       "     'created_at',\n",
       "     'display_name',\n",
       "     'is_personal',\n",
       "     'is_deleted'],\n",
       "    'title': 'Tenant',\n",
       "    'description': 'Tenant schema.'},\n",
       "   'alerts.AlertAction': {'type': 'object',\n",
       "    'required': ['config', 'target'],\n",
       "    'properties': {'alert_rule_id': {'type': 'string'},\n",
       "     'config': {'type': 'object'},\n",
       "     'created_at': {'type': 'string'},\n",
       "     'id': {'type': 'string'},\n",
       "     'target': {'type': 'string', 'enum': ['pagerduty', 'webhook']},\n",
       "     'updated_at': {'type': 'string'}}},\n",
       "   'alerts.AlertActionBase': {'type': 'object',\n",
       "    'required': ['config', 'target'],\n",
       "    'properties': {'alert_rule_id': {'type': 'string'},\n",
       "     'config': {'type': 'object'},\n",
       "     'id': {'type': 'string'},\n",
       "     'target': {'type': 'string', 'enum': ['pagerduty', 'webhook']}}},\n",
       "   'alerts.AlertRule': {'type': 'object',\n",
       "    'required': ['aggregation',\n",
       "     'attribute',\n",
       "     'description',\n",
       "     'name',\n",
       "     'operator',\n",
       "     'type',\n",
       "     'window_minutes'],\n",
       "    'properties': {'aggregation': {'type': 'string',\n",
       "      'enum': ['avg', 'sum', 'pct']},\n",
       "     'attribute': {'type': 'string',\n",
       "      'enum': ['latency',\n",
       "       'error_count',\n",
       "       'feedback_score',\n",
       "       'run_latency',\n",
       "       'run_count']},\n",
       "     'created_at': {'type': 'string'},\n",
       "     'denominator_filter': {'type': 'string'},\n",
       "     'description': {'type': 'string'},\n",
       "     'filter': {'type': 'string'},\n",
       "     'id': {'type': 'string'},\n",
       "     'name': {'type': 'string'},\n",
       "     'operator': {'type': 'string', 'enum': ['gte', 'lte']},\n",
       "     'threshold': {'type': 'number'},\n",
       "     'threshold_multiplier': {'type': 'number'},\n",
       "     'threshold_window_minutes': {'type': 'integer', 'maximum': 60},\n",
       "     'type': {'type': 'string', 'enum': ['threshold', 'change']},\n",
       "     'updated_at': {'type': 'string'},\n",
       "     'window_minutes': {'description': 'max 15 minutes for alert rule',\n",
       "      'type': 'integer',\n",
       "      'maximum': 15}}},\n",
       "   'alerts.AlertRuleBase': {'type': 'object',\n",
       "    'required': ['aggregation',\n",
       "     'attribute',\n",
       "     'description',\n",
       "     'name',\n",
       "     'operator',\n",
       "     'type',\n",
       "     'window_minutes'],\n",
       "    'properties': {'aggregation': {'type': 'string',\n",
       "      'enum': ['avg', 'sum', 'pct']},\n",
       "     'attribute': {'type': 'string',\n",
       "      'enum': ['latency',\n",
       "       'error_count',\n",
       "       'feedback_score',\n",
       "       'run_latency',\n",
       "       'run_count']},\n",
       "     'denominator_filter': {'type': 'string'},\n",
       "     'description': {'type': 'string'},\n",
       "     'filter': {'type': 'string'},\n",
       "     'id': {'type': 'string'},\n",
       "     'name': {'type': 'string'},\n",
       "     'operator': {'type': 'string', 'enum': ['gte', 'lte']},\n",
       "     'threshold': {'type': 'number'},\n",
       "     'threshold_multiplier': {'type': 'number'},\n",
       "     'threshold_window_minutes': {'type': 'integer', 'maximum': 60},\n",
       "     'type': {'type': 'string', 'enum': ['threshold', 'change']},\n",
       "     'window_minutes': {'description': 'max 15 minutes for alert rule',\n",
       "      'type': 'integer',\n",
       "      'maximum': 15}}},\n",
       "   'alerts.AlertRuleResponse': {'type': 'object',\n",
       "    'properties': {'actions': {'type': 'array',\n",
       "      'items': {'$ref': '#/components/schemas/alerts.AlertAction'}},\n",
       "     'rule': {'$ref': '#/components/schemas/alerts.AlertRule'}}},\n",
       "   'alerts.CreateAlertRuleRequest': {'type': 'object',\n",
       "    'required': ['actions', 'rule'],\n",
       "    'properties': {'actions': {'type': 'array',\n",
       "      'items': {'$ref': '#/components/schemas/alerts.AlertActionBase'}},\n",
       "     'rule': {'$ref': '#/components/schemas/alerts.AlertRuleBase'}}},\n",
       "   'alerts.ErrorResponse': {'type': 'object',\n",
       "    'properties': {'error': {'type': 'string',\n",
       "      'example': 'Invalid request: missing required fields'}}},\n",
       "   'alerts.UpdateAlertRuleRequest': {'type': 'object',\n",
       "    'required': ['actions', 'rule'],\n",
       "    'properties': {'actions': {'type': 'array',\n",
       "      'items': {'$ref': '#/components/schemas/alerts.AlertActionBase'}},\n",
       "     'rule': {'$ref': '#/components/schemas/alerts.AlertRuleBase'}}},\n",
       "   'examples.ErrorResponse': {'type': 'object',\n",
       "    'properties': {'details': {'description': 'Optional error details as JSON string',\n",
       "      'type': 'string',\n",
       "      'example': '{\"field\":\"dataset_id\",\"reason\":\"required\"}'},\n",
       "     'error': {'description': 'Error message',\n",
       "      'type': 'string',\n",
       "      'example': 'Invalid request: missing required fields'}}},\n",
       "   'examples.ExamplesCreatedResponse': {'type': 'object',\n",
       "    'properties': {'count': {'type': 'integer', 'example': 1},\n",
       "     'example_ids': {'type': 'array',\n",
       "      'items': {'type': 'string'},\n",
       "      'example': ['[\"123e4567-e89b-12d3-a456-426614174000\"]']}}},\n",
       "   'examples.ExamplesUpdatedResponse': {'type': 'object',\n",
       "    'properties': {'count': {'type': 'integer', 'example': 1},\n",
       "     'example_ids': {'type': 'array',\n",
       "      'items': {'type': 'string'},\n",
       "      'example': ['[\"123e4567-e89b-12d3-a456-426614174000\"]']}}},\n",
       "   'feedback.FeedbackCategory': {'type': 'object',\n",
       "    'properties': {'label': {'type': 'string', 'minLength': 1},\n",
       "     'value': {'type': 'number'}}},\n",
       "   'feedback.FeedbackConfig': {'type': 'object',\n",
       "    'properties': {'categories': {'type': 'array',\n",
       "      'items': {'$ref': '#/components/schemas/feedback.FeedbackCategory'}},\n",
       "     'max': {'type': 'number'},\n",
       "     'min': {'type': 'number'},\n",
       "     'type': {'$ref': '#/components/schemas/feedback.FeedbackType'}}},\n",
       "   'feedback.FeedbackCreateSchema': {'type': 'object',\n",
       "    'properties': {'comment': {'type': 'string'},\n",
       "     'comparative_experiment_id': {'type': 'string'},\n",
       "     'correction': {},\n",
       "     'created_at': {'type': 'string'},\n",
       "     'error': {'type': 'boolean'},\n",
       "     'feedback_config': {'$ref': '#/components/schemas/feedback.FeedbackConfig'},\n",
       "     'feedback_group_id': {'type': 'string'},\n",
       "     'feedback_source': {'$ref': '#/components/schemas/feedback.FeedbackSource'},\n",
       "     'id': {'type': 'string'},\n",
       "     'key': {'type': 'string'},\n",
       "     'modified_at': {'type': 'string'},\n",
       "     'run_id': {'type': 'string'},\n",
       "     'score': {},\n",
       "     'session_id': {'type': 'string'},\n",
       "     'trace_id': {'type': 'string'},\n",
       "     'value': {}}},\n",
       "   'feedback.FeedbackSource': {'type': 'object',\n",
       "    'properties': {'metadata': {'type': 'object',\n",
       "      'additionalProperties': True},\n",
       "     'type': {'type': 'string'}}},\n",
       "   'feedback.FeedbackType': {'type': 'string',\n",
       "    'enum': ['continuous', 'categorical', 'freeform'],\n",
       "    'x-enum-varnames': ['FeedbackTypeContinuous',\n",
       "     'FeedbackTypeCategorical',\n",
       "     'FeedbackTypeFreeform']},\n",
       "   'runs.ErrorResponse': {'type': 'object',\n",
       "    'properties': {'details': {'description': 'Optional error details as JSON string',\n",
       "      'type': 'string',\n",
       "      'example': '{\"field\":\"dataset_id\",\"reason\":\"required\"}'},\n",
       "     'error': {'description': 'Error message',\n",
       "      'type': 'string',\n",
       "      'example': 'Invalid request: missing required fields'}}},\n",
       "   'runs.Run': {'type': 'object',\n",
       "    'properties': {'dotted_order': {'type': 'string'},\n",
       "     'end_time': {'type': 'string'},\n",
       "     'error': {'type': 'string'},\n",
       "     'events': {'type': 'array',\n",
       "      'items': {'type': 'object', 'additionalProperties': True}},\n",
       "     'extra': {'type': 'object', 'additionalProperties': True},\n",
       "     'id': {'type': 'string'},\n",
       "     'input_attachments': {'type': 'object', 'additionalProperties': True},\n",
       "     'inputs': {'type': 'object', 'additionalProperties': True},\n",
       "     'name': {'type': 'string'},\n",
       "     'output_attachments': {'type': 'object', 'additionalProperties': True},\n",
       "     'outputs': {'type': 'object', 'additionalProperties': True},\n",
       "     'parent_run_id': {'type': 'string'},\n",
       "     'reference_example_id': {'type': 'string'},\n",
       "     'run_type': {'type': 'string',\n",
       "      'enum': ['tool',\n",
       "       'chain',\n",
       "       'llm',\n",
       "       'retriever',\n",
       "       'embedding',\n",
       "       'prompt',\n",
       "       'parser']},\n",
       "     'serialized': {'type': 'object', 'additionalProperties': True},\n",
       "     'session_id': {'type': 'string'},\n",
       "     'session_name': {'type': 'string'},\n",
       "     'start_time': {'type': 'string'},\n",
       "     'status': {'type': 'string'},\n",
       "     'tags': {'type': 'array', 'items': {'type': 'string'}},\n",
       "     'trace_id': {'type': 'string'}}}},\n",
       "  'securitySchemes': {'API Key': {'type': 'apiKey',\n",
       "    'in': 'header',\n",
       "    'name': 'X-API-Key'},\n",
       "   'Tenant ID': {'type': 'apiKey', 'in': 'header', 'name': 'X-Tenant-Id'},\n",
       "   'Bearer Auth': {'type': 'http',\n",
       "    'description': 'Bearer tokens are used to authenticate from the UI. Must also specify x-tenant-id or x-organization-id (for org scoped apis).',\n",
       "    'scheme': 'bearer'},\n",
       "   'Organization ID': {'type': 'apiKey',\n",
       "    'in': 'header',\n",
       "    'name': 'X-Organization-Id'}}},\n",
       " 'definitions': {'alerts.AlertAction': {'type': 'object',\n",
       "   'required': ['config', 'target'],\n",
       "   'properties': {'alert_rule_id': {'type': 'string'},\n",
       "    'config': {'type': 'object'},\n",
       "    'created_at': {'type': 'string'},\n",
       "    'id': {'type': 'string'},\n",
       "    'target': {'type': 'string', 'enum': ['pagerduty', 'webhook']},\n",
       "    'updated_at': {'type': 'string'}}},\n",
       "  'alerts.AlertActionBase': {'type': 'object',\n",
       "   'required': ['config', 'target'],\n",
       "   'properties': {'alert_rule_id': {'type': 'string'},\n",
       "    'config': {'type': 'object'},\n",
       "    'id': {'type': 'string'},\n",
       "    'target': {'type': 'string', 'enum': ['pagerduty', 'webhook']}}},\n",
       "  'alerts.AlertRule': {'type': 'object',\n",
       "   'required': ['aggregation',\n",
       "    'attribute',\n",
       "    'description',\n",
       "    'name',\n",
       "    'operator',\n",
       "    'type',\n",
       "    'window_minutes'],\n",
       "   'properties': {'aggregation': {'type': 'string',\n",
       "     'enum': ['avg', 'sum', 'pct']},\n",
       "    'attribute': {'type': 'string',\n",
       "     'enum': ['latency',\n",
       "      'error_count',\n",
       "      'feedback_score',\n",
       "      'run_latency',\n",
       "      'run_count']},\n",
       "    'created_at': {'type': 'string'},\n",
       "    'denominator_filter': {'type': 'string'},\n",
       "    'description': {'type': 'string'},\n",
       "    'filter': {'type': 'string'},\n",
       "    'id': {'type': 'string'},\n",
       "    'name': {'type': 'string'},\n",
       "    'operator': {'type': 'string', 'enum': ['gte', 'lte']},\n",
       "    'threshold': {'type': 'number'},\n",
       "    'threshold_multiplier': {'type': 'number'},\n",
       "    'threshold_window_minutes': {'type': 'integer', 'maximum': 60},\n",
       "    'type': {'type': 'string', 'enum': ['threshold', 'change']},\n",
       "    'updated_at': {'type': 'string'},\n",
       "    'window_minutes': {'description': 'max 15 minutes for alert rule',\n",
       "     'type': 'integer',\n",
       "     'maximum': 15}}},\n",
       "  'alerts.AlertRuleBase': {'type': 'object',\n",
       "   'required': ['aggregation',\n",
       "    'attribute',\n",
       "    'description',\n",
       "    'name',\n",
       "    'operator',\n",
       "    'type',\n",
       "    'window_minutes'],\n",
       "   'properties': {'aggregation': {'type': 'string',\n",
       "     'enum': ['avg', 'sum', 'pct']},\n",
       "    'attribute': {'type': 'string',\n",
       "     'enum': ['latency',\n",
       "      'error_count',\n",
       "      'feedback_score',\n",
       "      'run_latency',\n",
       "      'run_count']},\n",
       "    'denominator_filter': {'type': 'string'},\n",
       "    'description': {'type': 'string'},\n",
       "    'filter': {'type': 'string'},\n",
       "    'id': {'type': 'string'},\n",
       "    'name': {'type': 'string'},\n",
       "    'operator': {'type': 'string', 'enum': ['gte', 'lte']},\n",
       "    'threshold': {'type': 'number'},\n",
       "    'threshold_multiplier': {'type': 'number'},\n",
       "    'threshold_window_minutes': {'type': 'integer', 'maximum': 60},\n",
       "    'type': {'type': 'string', 'enum': ['threshold', 'change']},\n",
       "    'window_minutes': {'description': 'max 15 minutes for alert rule',\n",
       "     'type': 'integer',\n",
       "     'maximum': 15}}},\n",
       "  'alerts.AlertRuleResponse': {'type': 'object',\n",
       "   'properties': {'actions': {'type': 'array',\n",
       "     'items': {'$ref': '#/components/schemas/alerts.AlertAction'}},\n",
       "    'rule': {'$ref': '#/components/schemas/alerts.AlertRule'}}},\n",
       "  'alerts.CreateAlertRuleRequest': {'type': 'object',\n",
       "   'required': ['actions', 'rule'],\n",
       "   'properties': {'actions': {'type': 'array',\n",
       "     'items': {'$ref': '#/components/schemas/alerts.AlertActionBase'}},\n",
       "    'rule': {'$ref': '#/components/schemas/alerts.AlertRuleBase'}}},\n",
       "  'alerts.ErrorResponse': {'type': 'object',\n",
       "   'properties': {'error': {'type': 'string',\n",
       "     'example': 'Invalid request: missing required fields'}}},\n",
       "  'alerts.UpdateAlertRuleRequest': {'type': 'object',\n",
       "   'required': ['actions', 'rule'],\n",
       "   'properties': {'actions': {'type': 'array',\n",
       "     'items': {'$ref': '#/components/schemas/alerts.AlertActionBase'}},\n",
       "    'rule': {'$ref': '#/components/schemas/alerts.AlertRuleBase'}}},\n",
       "  'examples.ErrorResponse': {'type': 'object',\n",
       "   'properties': {'details': {'description': 'Optional error details as JSON string',\n",
       "     'type': 'string',\n",
       "     'example': '{\"field\":\"dataset_id\",\"reason\":\"required\"}'},\n",
       "    'error': {'description': 'Error message',\n",
       "     'type': 'string',\n",
       "     'example': 'Invalid request: missing required fields'}}},\n",
       "  'examples.ExamplesCreatedResponse': {'type': 'object',\n",
       "   'properties': {'count': {'type': 'integer', 'example': 1},\n",
       "    'example_ids': {'type': 'array',\n",
       "     'items': {'type': 'string'},\n",
       "     'example': ['[\"123e4567-e89b-12d3-a456-426614174000\"]']}}},\n",
       "  'examples.ExamplesUpdatedResponse': {'type': 'object',\n",
       "   'properties': {'count': {'type': 'integer', 'example': 1},\n",
       "    'example_ids': {'type': 'array',\n",
       "     'items': {'type': 'string'},\n",
       "     'example': ['[\"123e4567-e89b-12d3-a456-426614174000\"]']}}},\n",
       "  'feedback.FeedbackCategory': {'type': 'object',\n",
       "   'properties': {'label': {'type': 'string', 'minLength': 1},\n",
       "    'value': {'type': 'number'}}},\n",
       "  'feedback.FeedbackConfig': {'type': 'object',\n",
       "   'properties': {'categories': {'type': 'array',\n",
       "     'items': {'$ref': '#/components/schemas/feedback.FeedbackCategory'}},\n",
       "    'max': {'type': 'number'},\n",
       "    'min': {'type': 'number'},\n",
       "    'type': {'$ref': '#/components/schemas/feedback.FeedbackType'}}},\n",
       "  'feedback.FeedbackCreateSchema': {'type': 'object',\n",
       "   'properties': {'comment': {'type': 'string'},\n",
       "    'comparative_experiment_id': {'type': 'string'},\n",
       "    'correction': {},\n",
       "    'created_at': {'type': 'string'},\n",
       "    'error': {'type': 'boolean'},\n",
       "    'feedback_config': {'$ref': '#/components/schemas/feedback.FeedbackConfig'},\n",
       "    'feedback_group_id': {'type': 'string'},\n",
       "    'feedback_source': {'$ref': '#/components/schemas/feedback.FeedbackSource'},\n",
       "    'id': {'type': 'string'},\n",
       "    'key': {'type': 'string'},\n",
       "    'modified_at': {'type': 'string'},\n",
       "    'run_id': {'type': 'string'},\n",
       "    'score': {},\n",
       "    'session_id': {'type': 'string'},\n",
       "    'trace_id': {'type': 'string'},\n",
       "    'value': {}}},\n",
       "  'feedback.FeedbackSource': {'type': 'object',\n",
       "   'properties': {'metadata': {'type': 'object', 'additionalProperties': True},\n",
       "    'type': {'type': 'string'}}},\n",
       "  'feedback.FeedbackType': {'type': 'string',\n",
       "   'enum': ['continuous', 'categorical', 'freeform'],\n",
       "   'x-enum-varnames': ['FeedbackTypeContinuous',\n",
       "    'FeedbackTypeCategorical',\n",
       "    'FeedbackTypeFreeform']},\n",
       "  'runs.ErrorResponse': {'type': 'object',\n",
       "   'properties': {'details': {'description': 'Optional error details as JSON string',\n",
       "     'type': 'string',\n",
       "     'example': '{\"field\":\"dataset_id\",\"reason\":\"required\"}'},\n",
       "    'error': {'description': 'Error message',\n",
       "     'type': 'string',\n",
       "     'example': 'Invalid request: missing required fields'}}},\n",
       "  'runs.Run': {'type': 'object',\n",
       "   'properties': {'dotted_order': {'type': 'string'},\n",
       "    'end_time': {'type': 'string'},\n",
       "    'error': {'type': 'string'},\n",
       "    'events': {'type': 'array',\n",
       "     'items': {'type': 'object', 'additionalProperties': True}},\n",
       "    'extra': {'type': 'object', 'additionalProperties': True},\n",
       "    'id': {'type': 'string'},\n",
       "    'input_attachments': {'type': 'object', 'additionalProperties': True},\n",
       "    'inputs': {'type': 'object', 'additionalProperties': True},\n",
       "    'name': {'type': 'string'},\n",
       "    'output_attachments': {'type': 'object', 'additionalProperties': True},\n",
       "    'outputs': {'type': 'object', 'additionalProperties': True},\n",
       "    'parent_run_id': {'type': 'string'},\n",
       "    'reference_example_id': {'type': 'string'},\n",
       "    'run_type': {'type': 'string',\n",
       "     'enum': ['tool',\n",
       "      'chain',\n",
       "      'llm',\n",
       "      'retriever',\n",
       "      'embedding',\n",
       "      'prompt',\n",
       "      'parser']},\n",
       "    'serialized': {'type': 'object', 'additionalProperties': True},\n",
       "    'session_id': {'type': 'string'},\n",
       "    'session_name': {'type': 'string'},\n",
       "    'start_time': {'type': 'string'},\n",
       "    'status': {'type': 'string'},\n",
       "    'tags': {'type': 'array', 'items': {'type': 'string'}},\n",
       "    'trace_id': {'type': 'string'}}}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d78c0128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'openapi': '3.1.0',\n",
       "  'info': {'title': 'LangSmith', 'version': '0.1.0'},\n",
       "  'paths': {'/api/v1/sessions/{session_id}/dashboard': {'post': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Get Tracing Project Prebuilt Dashboard',\n",
       "     'description': 'Get a prebuilt dashboard for a tracing project.'}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/dashboard': {'post': {'operationId': 'get_tracing_project_prebuilt_dashboard_api_v1_sessions__session_id__dashboard_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/dashboard': {'post': {'parameters': [{'name': 'session_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}},\n",
       "      {'name': 'accept',\n",
       "       'in': 'header',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Accept'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/dashboard': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsSectionRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/dashboard': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CustomChartsSection'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/dashboard': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'get': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Read Tracer Session',\n",
       "     'description': 'Get a specific session.',\n",
       "     'operationId': 'read_tracer_session_api_v1_sessions__session_id__get'}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'get': {'parameters': [{'name': 'session_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}},\n",
       "      {'name': 'include_stats',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Include Stats'}},\n",
       "      {'name': 'accept',\n",
       "       'in': 'header',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Accept'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TracerSession'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'patch': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Update Tracer Session',\n",
       "     'description': 'Create a new session.',\n",
       "     'operationId': 'update_tracer_session_api_v1_sessions__session_id__patch'}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'patch': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'session_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Session Id'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TracerSessionUpdate'}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TracerSessionWithoutVirtualFields'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'delete': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Delete Tracer Session',\n",
       "     'description': 'Delete a specific session.',\n",
       "     'operationId': 'delete_tracer_session_api_v1_sessions__session_id__delete'}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'session_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Session Id'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions': {'get': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Read Tracer Sessions',\n",
       "     'description': 'Get all sessions.',\n",
       "     'operationId': 'read_tracer_sessions_api_v1_sessions_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/sessions': {'get': {'parameters': [{'name': 'reference_free',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Reference Free'}},\n",
       "      {'name': 'reference_dataset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Reference Dataset'}},\n",
       "      {'name': 'id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Id'}},\n",
       "      {'name': 'name',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name'}},\n",
       "      {'name': 'name_contains',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name Contains'}},\n",
       "      {'name': 'dataset_version',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Dataset Version'}},\n",
       "      {'name': 'sort_by',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'$ref': '#/components/schemas/SessionSortableColumns',\n",
       "        'default': 'start_time'}},\n",
       "      {'name': 'sort_by_desc',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': True,\n",
       "        'title': 'Sort By Desc'}},\n",
       "      {'name': 'metadata',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Metadata'}},\n",
       "      {'name': 'sort_by_feedback_key',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Sort By Feedback Key'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'tag_value_id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Tag Value Id'}},\n",
       "      {'name': 'facets',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean', 'default': False, 'title': 'Facets'}},\n",
       "      {'name': 'filter',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Filter'}},\n",
       "      {'name': 'include_stats',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': True,\n",
       "        'title': 'Include Stats'}},\n",
       "      {'name': 'use_approx_stats',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Use Approx Stats'}},\n",
       "      {'name': 'accept',\n",
       "       'in': 'header',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Accept'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/TracerSession'},\n",
       "          'title': 'Response Read Tracer Sessions Api V1 Sessions Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions': {'post': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Create Tracer Session',\n",
       "     'description': 'Create a new session.',\n",
       "     'operationId': 'create_tracer_session_api_v1_sessions_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/sessions': {'post': {'parameters': [{'name': 'upsert',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Upsert'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TracerSessionCreate'}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TracerSessionWithoutVirtualFields'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions': {'delete': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Delete Tracer Sessions',\n",
       "     'description': 'Delete a specific session.',\n",
       "     'operationId': 'delete_tracer_sessions_api_v1_sessions_delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/sessions': {'delete': {'parameters': [{'name': 'session_ids',\n",
       "       'in': 'query',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'array',\n",
       "        'items': {'type': 'string', 'format': 'uuid'},\n",
       "        'title': 'Session Ids'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}},\n",
       "      '422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/metadata': {'get': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Read Tracer Sessions Runs Metadata',\n",
       "     'description': 'Given a session, a number K, and (optionally) a list of metadata keys, return the top K values for each key.'}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/metadata': {'get': {'operationId': 'read_tracer_sessions_runs_metadata_api_v1_sessions__session_id__metadata_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/metadata': {'get': {'parameters': [{'name': 'session_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}},\n",
       "      {'name': 'metadata_keys',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Metadata Keys'}},\n",
       "      {'name': 'start_time',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Start Time'}},\n",
       "      {'name': 'k',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 1,\n",
       "        'default': 10,\n",
       "        'title': 'K'}},\n",
       "      {'name': 'root_runs_only',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Root Runs Only'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/metadata': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RootModel_Dict_str__list_str___'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/metadata': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views': {'get': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Read Filter Views',\n",
       "     'description': 'Get all filter views for a session.',\n",
       "     'operationId': 'read_filter_views_api_v1_sessions__session_id__views_get'}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views': {'get': {'parameters': [{'name': 'session_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}},\n",
       "      {'name': 'type',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'$ref': '#/components/schemas/FilterViewType'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Type'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/FilterView'},\n",
       "          'title': 'Response Read Filter Views Api V1 Sessions  Session Id  Views Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views': {'post': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Create Filter View',\n",
       "     'description': 'Create a new filter view.',\n",
       "     'operationId': 'create_filter_view_api_v1_sessions__session_id__views_post'}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'session_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Session Id'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FilterViewCreate'}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FilterView'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views/{view_id}': {'get': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Read Filter View',\n",
       "     'description': 'Get a specific filter view.',\n",
       "     'operationId': 'read_filter_view_api_v1_sessions__session_id__views__view_id__get'}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views/{view_id}': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views/{view_id}': {'get': {'parameters': [{'name': 'session_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}},\n",
       "      {'name': 'view_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'View Id'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views/{view_id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FilterView'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views/{view_id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views/{view_id}': {'patch': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Update Filter View',\n",
       "     'description': 'Update a filter view.',\n",
       "     'operationId': 'update_filter_view_api_v1_sessions__session_id__views__view_id__patch'}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views/{view_id}': {'patch': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views/{view_id}': {'patch': {'parameters': [{'name': 'session_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}},\n",
       "      {'name': 'view_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'View Id'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views/{view_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FilterViewUpdate'}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views/{view_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FilterView'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views/{view_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views/{view_id}': {'delete': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Delete Filter View',\n",
       "     'description': 'Delete a specific filter view.',\n",
       "     'operationId': 'delete_filter_view_api_v1_sessions__session_id__views__view_id__delete'}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views/{view_id}': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views/{view_id}': {'delete': {'parameters': [{'name': 'session_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}},\n",
       "      {'name': 'view_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'View Id'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views/{view_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/views/{view_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'List Organizations',\n",
       "     'description': 'Get all orgs visible to this auth',\n",
       "     'operationId': 'list_organizations_api_v1_orgs_get',\n",
       "     'security': [{'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs': {'get': {'parameters': [{'name': 'skip_create',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Skip Create'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/OrganizationPGSchemaSlim'},\n",
       "          'title': 'Response List Organizations Api V1 Orgs Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Create Organization',\n",
       "     'operationId': 'create_organization_api_v1_orgs_post',\n",
       "     'security': [{'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationCreate'}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationPGSchemaSlim'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/setup': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Create Customers And Get Stripe Setup Intent',\n",
       "     'operationId': 'create_customers_and_get_stripe_setup_intent_api_v1_orgs_current_setup_post'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/setup': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StripeSetupIntentResponse'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'Get Organization Info',\n",
       "     'operationId': 'get_organization_info_api_v1_orgs_current_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/current': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Organization'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/info': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'Get Current Organization Info',\n",
       "     'operationId': 'get_current_organization_info_api_v1_orgs_current_info_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/info': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationInfo'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/info': {'patch': {'tags': ['orgs'],\n",
       "     'summary': 'Update Current Organization Info',\n",
       "     'operationId': 'update_current_organization_info_api_v1_orgs_current_info_patch'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/info': {'patch': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationUpdate'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/info': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationInfo'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/info': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/billing': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'Get Organization Billing Info',\n",
       "     'operationId': 'get_organization_billing_info_api_v1_orgs_current_billing_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/billing': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationBillingInfo'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/dashboard': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'Get Dashboard',\n",
       "     'operationId': 'get_dashboard_api_v1_orgs_current_dashboard_get',\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/dashboard': {'get': {'parameters': [{'name': 'type',\n",
       "       'in': 'query',\n",
       "       'required': True,\n",
       "       'schema': {'$ref': '#/components/schemas/OrganizationDashboardType'}},\n",
       "      {'name': 'color_scheme',\n",
       "       'in': 'query',\n",
       "       'required': True,\n",
       "       'schema': {'anyOf': [{'$ref': '#/components/schemas/OrganizationDashboardColorScheme'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Color Scheme'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/dashboard': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationDashboardSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/dashboard': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/payment-method': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'On Payment Method Created',\n",
       "     'operationId': 'on_payment_method_created_api_v1_orgs_current_payment_method_post'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/payment-method': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StripePaymentInformation'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/payment-method': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/payment-method': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/business-info': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'Get Company Info',\n",
       "     'operationId': 'get_company_info_api_v1_orgs_current_business_info_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/business-info': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StripeBusinessInfo-Output'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/business-info': {'get': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/business-info': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Set Company Info',\n",
       "     'operationId': 'set_company_info_api_v1_orgs_current_business_info_post'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/business-info': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StripeBusinessInfo-Input'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/business-info': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/business-info': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/plan': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Change Payment Plan',\n",
       "     'operationId': 'change_payment_plan_api_v1_orgs_current_plan_post'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/plan': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ChangePaymentPlanSchema'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/plan': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/plan': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'List Organization Roles',\n",
       "     'operationId': 'list_organization_roles_api_v1_orgs_current_roles_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/Role'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Organization Roles Api V1 Orgs Current Roles Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles': {'get': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Create Organization Roles',\n",
       "     'operationId': 'create_organization_roles_api_v1_orgs_current_roles_post'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateRoleRequest'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Role'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles/{role_id}': {'delete': {'tags': ['orgs'],\n",
       "     'summary': 'Delete Organization Roles',\n",
       "     'operationId': 'delete_organization_roles_api_v1_orgs_current_roles__role_id__delete',\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles/{role_id}': {'delete': {'parameters': [{'name': 'role_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Role Id'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles/{role_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Role'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles/{role_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles/{role_id}': {'patch': {'tags': ['orgs'],\n",
       "     'summary': 'Update Organization Roles',\n",
       "     'operationId': 'update_organization_roles_api_v1_orgs_current_roles__role_id__patch',\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles/{role_id}': {'patch': {'parameters': [{'name': 'role_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Role Id'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles/{role_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UpdateRoleRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles/{role_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Role'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles/{role_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/permissions': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'List Permissions',\n",
       "     'operationId': 'list_permissions_api_v1_orgs_permissions_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/permissions': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/PermissionResponse'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Permissions Api V1 Orgs Permissions Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/permissions': {'get': {'security': [{'Bearer Auth': []}]}},\n",
       "   '/api/v1/orgs/pending': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'List Pending Organization Invites',\n",
       "     'description': 'Get all pending orgs visible to this auth'}}}},\n",
       " {'paths': {'/api/v1/orgs/pending': {'get': {'operationId': 'list_pending_organization_invites_api_v1_orgs_pending_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/pending': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/OrganizationPGSchemaSlim'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Pending Organization Invites Api V1 Orgs Pending Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/pending': {'get': {'security': [{'Bearer Auth': []}]}},\n",
       "   '/api/v1/orgs/current/members': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'Get Current Org Members',\n",
       "     'operationId': 'get_current_org_members_api_v1_orgs_current_members_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationMembers'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Add Member To Current Org',\n",
       "     'operationId': 'add_member_to_current_org_api_v1_orgs_current_members_post'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PendingIdentityCreate'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PendingIdentity'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/active': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'Get Current Active Org Members',\n",
       "     'operationId': 'get_current_active_org_members_api_v1_orgs_current_members_active_get',\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/active': {'get': {'parameters': [{'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 500,\n",
       "        'minimum': 1,\n",
       "        'default': 50,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'emails',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'array',\n",
       "        'items': {'type': 'string'},\n",
       "        'default': [],\n",
       "        'title': 'Emails'}},\n",
       "      {'name': 'ls_user_ids',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'array',\n",
       "        'items': {'type': 'string', 'format': 'uuid'},\n",
       "        'default': [],\n",
       "        'title': 'Ls User Ids'}},\n",
       "      {'name': 'user_ids',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'array',\n",
       "        'items': {'type': 'string', 'format': 'uuid'},\n",
       "        'default': [],\n",
       "        'title': 'User Ids'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/active': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/OrgMemberIdentity'},\n",
       "          'title': 'Response Get Current Active Org Members Api V1 Orgs Current Members Active Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/active': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/pending': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'Get Current Pending Org Members',\n",
       "     'operationId': 'get_current_pending_org_members_api_v1_orgs_current_members_pending_get',\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/pending': {'get': {'parameters': [{'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 500,\n",
       "        'minimum': 1,\n",
       "        'default': 50,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'emails',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'array',\n",
       "        'items': {'type': 'string'},\n",
       "        'default': [],\n",
       "        'title': 'Emails'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/pending': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/OrgPendingIdentity'},\n",
       "          'title': 'Response Get Current Pending Org Members Api V1 Orgs Current Members Pending Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/pending': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/batch': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Add Members To Current Org Batch',\n",
       "     'description': 'Batch invite up to 500 users to the current org.',\n",
       "     'operationId': 'add_members_to_current_org_batch_api_v1_orgs_current_members_batch_post'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/batch': {'post': {'requestBody': {'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/PendingIdentityCreate'},\n",
       "         'type': 'array',\n",
       "         'title': 'Payloads'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/batch': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/PendingIdentity'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response Add Members To Current Org Batch Api V1 Orgs Current Members Batch Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/batch': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/basic/batch': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Add Basic Auth Members To Current Org',\n",
       "     'description': 'Batch add up to 500 users to the org and specified workspaces in basic auth mode.'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/basic/batch': {'post': {'operationId': 'add_basic_auth_members_to_current_org_api_v1_orgs_current_members_basic_batch_post'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/basic/batch': {'post': {'requestBody': {'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/BasicAuthMemberCreate'},\n",
       "         'type': 'array',\n",
       "         'title': 'Payloads'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/basic/batch': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/UserWithPassword'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response Add Basic Auth Members To Current Org Api V1 Orgs Current Members Basic Batch Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/basic/batch': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/basic/batch': {'post': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}/pending': {'delete': {'tags': ['orgs'],\n",
       "     'summary': 'Delete Current Org Pending Member',\n",
       "     'description': 'When an admin deletes a pending member invite.'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}/pending': {'delete': {'operationId': 'delete_current_org_pending_member_api_v1_orgs_current_members__identity_id__pending_delete',\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}/pending': {'delete': {'parameters': [{'name': 'identity_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Identity Id'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}/pending': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}/pending': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/pending/{organization_id}': {'delete': {'tags': ['orgs'],\n",
       "     'summary': 'Delete Pending Organization Invite',\n",
       "     'operationId': 'delete_pending_organization_invite_api_v1_orgs_pending__organization_id__delete',\n",
       "     'security': [{'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/pending/{organization_id}': {'delete': {'parameters': [{'name': 'organization_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Organization Id'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/pending/{organization_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/pending/{organization_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/pending/{organization_id}/claim': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Claim Pending Organization Invite',\n",
       "     'operationId': 'claim_pending_organization_invite_api_v1_orgs_pending__organization_id__claim_post',\n",
       "     'security': [{'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/pending/{organization_id}/claim': {'post': {'parameters': [{'name': 'organization_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Organization Id'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/pending/{organization_id}/claim': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Identity'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/pending/{organization_id}/claim': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'delete': {'tags': ['orgs'],\n",
       "     'summary': 'Remove Member From Current Org',\n",
       "     'description': 'Remove a user from the current organization.',\n",
       "     'operationId': 'remove_member_from_current_org_api_v1_orgs_current_members__identity_id__delete'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'delete': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'identity_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Identity Id'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'patch': {'tags': ['orgs'],\n",
       "     'summary': 'Update Current Org Member',\n",
       "     'description': \"This is used for updating a user's role (all auth modes) or full_name/password (basic auth)\"}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'patch': {'operationId': 'update_current_org_member_api_v1_orgs_current_members__identity_id__patch',\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'patch': {'parameters': [{'name': 'identity_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Identity Id'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrgIdentityPatch'}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/members/basic': {'patch': {'tags': ['orgs'],\n",
       "     'summary': 'Update Current User',\n",
       "     'description': \"Update a user's full_name/password (basic auth only)\",\n",
       "     'operationId': 'update_current_user_api_v1_orgs_members_basic_patch'}}}},\n",
       " {'paths': {'/api/v1/orgs/members/basic': {'patch': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BasicAuthUserPatch'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/members/basic': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/members/basic': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/ttl-settings': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'List Ttl Settings',\n",
       "     'description': 'List out the configured TTL settings for a given org (org-level and tenant-level).',\n",
       "     'operationId': 'list_ttl_settings_api_v1_orgs_ttl_settings_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/ttl-settings': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/TTLSettings'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Ttl Settings Api V1 Orgs Ttl Settings Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/ttl-settings': {'get': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/ttl-settings': {'put': {'tags': ['orgs'],\n",
       "     'summary': 'Upsert Ttl Settings',\n",
       "     'operationId': 'upsert_ttl_settings_api_v1_orgs_ttl_settings_put'}}}},\n",
       " {'paths': {'/api/v1/orgs/ttl-settings': {'put': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UpsertTTLSettingsRequest'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/ttl-settings': {'put': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TTLSettings'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/ttl-settings': {'put': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/sso-settings': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'Get Current Sso Settings',\n",
       "     'description': 'Get SSO provider settings for the current organization.',\n",
       "     'operationId': 'get_current_sso_settings_api_v1_orgs_current_sso_settings_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/sso-settings': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/SSOProvider'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response Get Current Sso Settings Api V1 Orgs Current Sso Settings Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/sso-settings': {'get': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/sso-settings': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Create Sso Settings',\n",
       "     'description': 'Create SSO provider settings for the current organization.',\n",
       "     'operationId': 'create_sso_settings_api_v1_orgs_current_sso_settings_post'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/sso-settings': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SSOSettingsCreate'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/sso-settings': {'post': {'responses': {'201': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SSOProvider'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/sso-settings': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/sso-settings/{id}': {'patch': {'tags': ['orgs'],\n",
       "     'summary': 'Update Sso Settings',\n",
       "     'description': 'Update SSO provider settings defaults for the current organization.',\n",
       "     'operationId': 'update_sso_settings_api_v1_orgs_current_sso_settings__id__patch'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/sso-settings/{id}': {'patch': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Id'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/sso-settings/{id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SSOSettingsUpdate'}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/sso-settings/{id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SSOProvider'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/sso-settings/{id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/sso-settings/{id}': {'delete': {'tags': ['orgs'],\n",
       "     'summary': 'Delete Sso Settings',\n",
       "     'description': 'Delete SSO provider settings for the current organization.',\n",
       "     'operationId': 'delete_sso_settings_api_v1_orgs_current_sso_settings__id__delete'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/sso-settings/{id}': {'delete': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Id'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/sso-settings/{id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SSOProvider'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/sso-settings/{id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/login-methods': {'patch': {'tags': ['orgs'],\n",
       "     'summary': 'Update Allowed Login Methods',\n",
       "     'description': 'Update allowed login methods for the current organization.',\n",
       "     'operationId': 'update_allowed_login_methods_api_v1_orgs_current_login_methods_patch'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/login-methods': {'patch': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AllowedLoginMethodsUpdate'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/login-methods': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'object',\n",
       "          'title': 'Response Update Allowed Login Methods Api V1 Orgs Current Login Methods Patch'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/login-methods': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/billing/usage': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'Get Org Usage',\n",
       "     'operationId': 'get_org_usage_api_v1_orgs_current_billing_usage_get',\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/billing/usage': {'get': {'parameters': [{'name': 'starting_on',\n",
       "       'in': 'query',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'date-time',\n",
       "        'title': 'Starting On'}},\n",
       "      {'name': 'ending_before',\n",
       "       'in': 'query',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'date-time',\n",
       "        'title': 'Ending Before'}},\n",
       "      {'name': 'on_current_plan',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': True,\n",
       "        'title': 'On Current Plan'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/billing/usage': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/OrgUsage'},\n",
       "          'title': 'Response Get Org Usage Api V1 Orgs Current Billing Usage Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/billing/usage': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/user/login-methods': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'Get Current User Login Methods',\n",
       "     'description': 'Get login methods for the current user.',\n",
       "     'operationId': 'get_current_user_login_methods_api_v1_orgs_current_user_login_methods_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/user/login-methods': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/ProviderUserSlim'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response Get Current User Login Methods Api V1 Orgs Current User Login Methods Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/user/login-methods': {'get': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/stripe_checkout_session': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Create Stripe Checkout Sessions Endpoint',\n",
       "     'description': 'Kick off a Stripe checkout session flow.'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/stripe_checkout_session': {'post': {'operationId': 'create_stripe_checkout_sessions_endpoint_api_v1_orgs_current_stripe_checkout_session_post'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/stripe_checkout_session': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StripeCheckoutSessionsCreate'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/stripe_checkout_session': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/stripe_checkout_session': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/stripe_checkout_session': {'post': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/confirm_checkout_session_completion': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Confirm Checkout Session Completion Endpoint',\n",
       "     'description': 'Complete a Stripe checkout session flow.'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/confirm_checkout_session_completion': {'post': {'operationId': 'confirm_checkout_session_completion_endpoint_api_v1_orgs_current_confirm_checkout_session_completion_post'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/confirm_checkout_session_completion': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StripeCheckoutSessionsConfirm'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/confirm_checkout_session_completion': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/confirm_checkout_session_completion': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/confirm_checkout_session_completion': {'post': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/stripe_account_links': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Create Stripe Account Links Endpoint',\n",
       "     'description': 'Kick off a Stripe account link flow.',\n",
       "     'operationId': 'create_stripe_account_links_endpoint_api_v1_orgs_current_stripe_account_links_post'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/stripe_account_links': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StripeAccountLinksCreate'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/stripe_account_links': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/stripe_account_links': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/stripe_account_links': {'post': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/login': {'post': {'tags': ['auth'],\n",
       "     'summary': 'Login',\n",
       "     'operationId': 'login_api_v1_login_post',\n",
       "     'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BasicAuthResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/oauth/{provider}/callback': {'get': {'tags': ['auth'],\n",
       "     'summary': 'Oauth Provider Callback',\n",
       "     'operationId': 'oauth_provider_callback_api_v1_oauth__provider__callback_get'}}}},\n",
       " {'paths': {'/api/v1/oauth/{provider}/callback': {'get': {'parameters': [{'name': 'provider',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'$ref': '#/components/schemas/OAuthProvider'}}]}}}},\n",
       " {'paths': {'/api/v1/oauth/{provider}/callback': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'object',\n",
       "          'title': 'Response Oauth Provider Callback Api V1 Oauth  Provider  Callback Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/oauth/{provider}/callback': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/oauth/{provider}/logout': {'get': {'tags': ['auth'],\n",
       "     'summary': 'Oauth Provider Logout',\n",
       "     'operationId': 'oauth_provider_logout_api_v1_oauth__provider__logout_get'}}}},\n",
       " {'paths': {'/api/v1/oauth/{provider}/logout': {'get': {'parameters': [{'name': 'provider',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'$ref': '#/components/schemas/OAuthProvider'}}]}}}},\n",
       " {'paths': {'/api/v1/oauth/{provider}/logout': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/oauth/{provider}/logout': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/oauth/{provider}': {'get': {'tags': ['auth'],\n",
       "     'summary': 'Oauth Provider Auth',\n",
       "     'operationId': 'oauth_provider_auth_api_v1_oauth__provider__get',\n",
       "     'parameters': [{'name': 'provider',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'$ref': '#/components/schemas/OAuthProvider'}}]}}}},\n",
       " {'paths': {'/api/v1/oauth/{provider}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/oauth/{provider}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/oauth/{provider}/current-user': {'get': {'tags': ['auth'],\n",
       "     'summary': 'Oauth Provider Current User',\n",
       "     'operationId': 'oauth_provider_current_user_api_v1_oauth__provider__current_user_get'}}}},\n",
       " {'paths': {'/api/v1/oauth/{provider}/current-user': {'get': {'parameters': [{'name': 'provider',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'$ref': '#/components/schemas/OAuthProvider'}}]}}}},\n",
       " {'paths': {'/api/v1/oauth/{provider}/current-user': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/oauth/{provider}/current-user': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sso/email-verification/send': {'post': {'tags': ['auth'],\n",
       "     'summary': 'Send Sso Email Confirmation',\n",
       "     'description': 'Send an email to confirm the email address for an SSO user.',\n",
       "     'operationId': 'send_sso_email_confirmation_api_v1_sso_email_verification_send_post'}}}},\n",
       " {'paths': {'/api/v1/sso/email-verification/send': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SSOEmailVerificationSendRequest'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/sso/email-verification/send': {'post': {'responses': {'202': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'object',\n",
       "          'title': 'Response Send Sso Email Confirmation Api V1 Sso Email Verification Send Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sso/email-verification/send': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/sso/email-verification/status': {'post': {'tags': ['auth'],\n",
       "     'summary': 'Check Sso Email Verification Status',\n",
       "     'description': 'Retrieve the email verification status of an SSO user.'}}}},\n",
       " {'paths': {'/api/v1/sso/email-verification/status': {'post': {'operationId': 'check_sso_email_verification_status_api_v1_sso_email_verification_status_post'}}}},\n",
       " {'paths': {'/api/v1/sso/email-verification/status': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SSOEmailVerificationStatusRequest'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/sso/email-verification/status': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SSOEmailVerificationStatusResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sso/email-verification/status': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sso/email-verification/confirm': {'post': {'tags': ['auth'],\n",
       "     'summary': 'Confirm Sso User Email',\n",
       "     'description': 'Confirm the email of an SSO user.',\n",
       "     'operationId': 'confirm_sso_user_email_api_v1_sso_email_verification_confirm_post'}}}},\n",
       " {'paths': {'/api/v1/sso/email-verification/confirm': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SSOConfirmEmailRequest'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/sso/email-verification/confirm': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'object',\n",
       "          'title': 'Response Confirm Sso User Email Api V1 Sso Email Verification Confirm Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sso/email-verification/confirm': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sso/settings/{sso_login_slug}': {'get': {'tags': ['auth'],\n",
       "     'summary': 'Get Sso Settings',\n",
       "     'description': 'Get SSO provider settings from login slug.',\n",
       "     'operationId': 'get_sso_settings_api_v1_sso_settings__sso_login_slug__get'}}}},\n",
       " {'paths': {'/api/v1/sso/settings/{sso_login_slug}': {'get': {'parameters': [{'name': 'sso_login_slug',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Sso Login Slug'}}]}}}},\n",
       " {'paths': {'/api/v1/sso/settings/{sso_login_slug}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/SSOProviderSlim'},\n",
       "          'title': 'Response Get Sso Settings Api V1 Sso Settings  Sso Login Slug  Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sso/settings/{sso_login_slug}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key': {'get': {'tags': ['api-key'],\n",
       "     'summary': 'Get Api Keys',\n",
       "     'description': \"Get the current tenant's API keys\",\n",
       "     'operationId': 'get_api_keys_api_v1_api_key_get'}}}},\n",
       " {'paths': {'/api/v1/api-key': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/APIKeyGetResponse'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response Get Api Keys Api V1 Api Key Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/api-key': {'post': {'tags': ['api-key'],\n",
       "     'summary': 'Generate Api Key',\n",
       "     'description': 'Generate an api key for the user',\n",
       "     'operationId': 'generate_api_key_api_v1_api_key_post'}}}},\n",
       " {'paths': {'/api/v1/api-key': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/APIKeyCreateRequest',\n",
       "         'default': {'description': 'Default API key',\n",
       "          'read_only': False}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/APIKeyCreateResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/api-key/{api_key_id}': {'delete': {'tags': ['api-key'],\n",
       "     'summary': 'Delete Api Key',\n",
       "     'description': 'Delete an api key for the user',\n",
       "     'operationId': 'delete_api_key_api_v1_api_key__api_key_id__delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/api-key/{api_key_id}': {'delete': {'parameters': [{'name': 'api_key_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Api Key Id'}}]}}}},\n",
       " {'paths': {'/api/v1/api-key/{api_key_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/APIKeyGetResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key/{api_key_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key/current': {'get': {'tags': ['api-key'],\n",
       "     'summary': 'Get Personal Access Tokens',\n",
       "     'description': 'Get the current users PATs for this tenant',\n",
       "     'operationId': 'get_personal_access_tokens_api_v1_api_key_current_get'}}}},\n",
       " {'paths': {'/api/v1/api-key/current': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/APIKeyGetResponse'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response Get Personal Access Tokens Api V1 Api Key Current Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key/current': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/api-key/current': {'post': {'tags': ['api-key'],\n",
       "     'summary': 'Generate Personal Access Token',\n",
       "     'description': 'Generate a Personal Access Token the user',\n",
       "     'operationId': 'generate_personal_access_token_api_v1_api_key_current_post'}}}},\n",
       " {'paths': {'/api/v1/api-key/current': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/APIKeyCreateRequest',\n",
       "         'default': {'description': 'Default API key',\n",
       "          'read_only': False}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key/current': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/APIKeyCreateResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key/current': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/api-key/current/{pat_id}': {'delete': {'tags': ['api-key'],\n",
       "     'summary': 'Delete Personal Access Token',\n",
       "     'description': 'Delete a Personal Access Token for the user',\n",
       "     'operationId': 'delete_personal_access_token_api_v1_api_key_current__pat_id__delete'}}}},\n",
       " {'paths': {'/api/v1/api-key/current/{pat_id}': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'pat_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Pat Id'}}]}}}},\n",
       " {'paths': {'/api/v1/api-key/current/{pat_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/APIKeyGetResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key/current/{pat_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/count': {'get': {'tags': ['examples'],\n",
       "     'summary': 'Count Examples',\n",
       "     'description': 'Count all examples by query params',\n",
       "     'operationId': 'count_examples_api_v1_examples_count_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/examples/count': {'get': {'parameters': [{'name': 'id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Id'}},\n",
       "      {'name': 'as_of',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'string'}],\n",
       "        'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "        'default': 'latest',\n",
       "        'title': 'As Of'},\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'},\n",
       "      {'name': 'metadata',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Metadata'}},\n",
       "      {'name': 'full_text_contains',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Full Text Contains'}},\n",
       "      {'name': 'splits',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Splits'}},\n",
       "      {'name': 'dataset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Dataset'}},\n",
       "      {'name': 'filter',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Filter'}}]}}}},\n",
       " {'paths': {'/api/v1/examples/count': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'integer',\n",
       "          'title': 'Response Count Examples Api V1 Examples Count Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/count': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'get': {'tags': ['examples'],\n",
       "     'summary': 'Read Example',\n",
       "     'description': 'Get a specific example.',\n",
       "     'operationId': 'read_example_api_v1_examples__example_id__get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'get': {'parameters': [{'name': 'example_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Example Id'}},\n",
       "      {'name': 'as_of',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'string'}],\n",
       "        'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "        'default': 'latest',\n",
       "        'title': 'As Of'},\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'}]}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Example'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'patch': {'tags': ['examples'],\n",
       "     'summary': 'Update Example',\n",
       "     'description': 'Update a specific example.',\n",
       "     'operationId': 'update_example_api_v1_examples__example_id__patch',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'patch': {'parameters': [{'name': 'example_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Example Id'}}]}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ExampleUpdate'}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'delete': {'tags': ['examples'],\n",
       "     'summary': 'Delete Example',\n",
       "     'description': 'Delete a specific example.',\n",
       "     'operationId': 'delete_example_api_v1_examples__example_id__delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'delete': {'parameters': [{'name': 'example_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Example Id'}}]}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples': {'get': {'tags': ['examples'],\n",
       "     'summary': 'Read Examples',\n",
       "     'description': 'Get all examples by query params',\n",
       "     'operationId': 'read_examples_api_v1_examples_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/examples': {'get': {'parameters': [{'name': 'id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Id'}},\n",
       "      {'name': 'as_of',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'string'}],\n",
       "        'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "        'default': 'latest',\n",
       "        'title': 'As Of'},\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'},\n",
       "      {'name': 'metadata',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Metadata'}},\n",
       "      {'name': 'full_text_contains',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Full Text Contains'}},\n",
       "      {'name': 'splits',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Splits'}},\n",
       "      {'name': 'dataset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Dataset'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'order',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'$ref': '#/components/schemas/ExampleListOrder',\n",
       "        'default': 'recent'}},\n",
       "      {'name': 'random_seed',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "        'title': 'Random Seed'}},\n",
       "      {'name': 'select',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'array',\n",
       "        'items': {'$ref': '#/components/schemas/ExampleSelect'},\n",
       "        'default': ['id',\n",
       "         'created_at',\n",
       "         'modified_at',\n",
       "         'name',\n",
       "         'dataset_id',\n",
       "         'source_run_id',\n",
       "         'metadata',\n",
       "         'inputs',\n",
       "         'outputs'],\n",
       "        'title': 'Select'}},\n",
       "      {'name': 'filter',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Filter'}}]}}}},\n",
       " {'paths': {'/api/v1/examples': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/Example'},\n",
       "          'title': 'Response Read Examples Api V1 Examples Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples': {'post': {'tags': ['examples'],\n",
       "     'summary': 'Create Example',\n",
       "     'description': 'Create a new example.',\n",
       "     'operationId': 'create_example_api_v1_examples_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/examples': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Example'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples': {'delete': {'tags': ['examples'],\n",
       "     'summary': 'Delete Examples',\n",
       "     'description': 'Delete a specific set of examples.',\n",
       "     'operationId': 'delete_examples_api_v1_examples_delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/examples': {'delete': {'parameters': [{'name': 'example_ids',\n",
       "       'in': 'query',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'array',\n",
       "        'items': {'type': 'string', 'format': 'uuid'},\n",
       "        'title': 'Example Ids'}}]}}}},\n",
       " {'paths': {'/api/v1/examples': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}},\n",
       "      '422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/bulk': {'post': {'tags': ['examples'],\n",
       "     'summary': 'Create Examples',\n",
       "     'description': 'Create a new example.',\n",
       "     'operationId': 'create_examples_api_v1_examples_bulk_post'}}}},\n",
       " {'paths': {'/api/v1/examples/bulk': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/examples/bulk': {'patch': {'tags': ['examples'],\n",
       "     'summary': 'Legacy Update Examples',\n",
       "     'description': 'Legacy update examples in bulk. For update involving attachments, use PATCH /v1/platform/datasets/{dataset_id}/examples instead.'}}}},\n",
       " {'paths': {'/api/v1/examples/bulk': {'patch': {'operationId': 'legacy_update_examples_api_v1_examples_bulk_patch'}}}},\n",
       " {'paths': {'/api/v1/examples/bulk': {'patch': {'requestBody': {'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/ExampleUpdateWithID'},\n",
       "         'type': 'array',\n",
       "         'title': 'Example Updates'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/examples/bulk': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/bulk': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/examples/upload/{dataset_id}': {'post': {'tags': ['examples'],\n",
       "     'summary': 'Upload Examples From Csv'}}}},\n",
       " {'paths': {'/api/v1/examples/upload/{dataset_id}': {'post': {'description': 'Upload examples from a CSV file.\\n\\nNote: For non-csv upload, please use\\nthe POST /v1/platform/datasets/{dataset_id}/examples endpoint which provides more efficient upload.'}}}},\n",
       " {'paths': {'/api/v1/examples/upload/{dataset_id}': {'post': {'operationId': 'upload_examples_from_csv_api_v1_examples_upload__dataset_id__post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/examples/upload/{dataset_id}': {'post': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/examples/upload/{dataset_id}': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'multipart/form-data': {'schema': {'$ref': '#/components/schemas/Body_upload_examples_from_csv_api_v1_examples_upload__dataset_id__post'}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/upload/{dataset_id}': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/Example'},\n",
       "          'title': 'Response Upload Examples From Csv Api V1 Examples Upload  Dataset Id  Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/upload/{dataset_id}': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/validate': {'post': {'tags': ['examples'],\n",
       "     'summary': 'Validate Example',\n",
       "     'description': 'Validate an example.',\n",
       "     'operationId': 'validate_example_api_v1_examples_validate_post'}}}},\n",
       " {'paths': {'/api/v1/examples/validate': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ExampleValidationResult'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/examples/validate/bulk': {'post': {'tags': ['examples'],\n",
       "     'summary': 'Validate Examples',\n",
       "     'description': 'Validate an example.',\n",
       "     'operationId': 'validate_examples_api_v1_examples_validate_bulk_post'}}}},\n",
       " {'paths': {'/api/v1/examples/validate/bulk': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/ExampleValidationResult'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response Validate Examples Api V1 Examples Validate Bulk Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/validate/bulk': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Read Dataset',\n",
       "     'description': 'Get a specific dataset.',\n",
       "     'operationId': 'read_dataset_api_v1_datasets__dataset_id__get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Dataset'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'delete': {'tags': ['datasets'],\n",
       "     'summary': 'Delete Dataset',\n",
       "     'description': 'Delete a specific dataset.',\n",
       "     'operationId': 'delete_dataset_api_v1_datasets__dataset_id__delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'delete': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'patch': {'tags': ['datasets'],\n",
       "     'summary': 'Update Dataset',\n",
       "     'description': 'Update a specific dataset.',\n",
       "     'operationId': 'update_dataset_api_v1_datasets__dataset_id__patch',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'patch': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetUpdate'}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'patch': {'responses': {'200': {'description': 'Dataset updated successfully',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetSchemaForUpdate'}}},\n",
       "       'headers': {'X-Updated-Examples-Count': {'description': 'Number of examples updated',\n",
       "         'schema': {'type': 'integer'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Read Datasets',\n",
       "     'description': 'Get all datasets by query params and owner.',\n",
       "     'operationId': 'read_datasets_api_v1_datasets_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets': {'get': {'parameters': [{'name': 'id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Id'}},\n",
       "      {'name': 'data_type',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/DataType'}},\n",
       "         {'$ref': '#/components/schemas/DataType'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Data Type'}},\n",
       "      {'name': 'name',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name'}},\n",
       "      {'name': 'name_contains',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name Contains'}},\n",
       "      {'name': 'metadata',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Metadata'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'sort_by',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'$ref': '#/components/schemas/SortByDatasetColumn',\n",
       "        'default': 'last_session_start_time'}},\n",
       "      {'name': 'sort_by_desc',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': True,\n",
       "        'title': 'Sort By Desc'}},\n",
       "      {'name': 'tag_value_id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Tag Value Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/Dataset'},\n",
       "          'title': 'Response Read Datasets Api V1 Datasets Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Create Dataset',\n",
       "     'description': 'Create a new dataset.',\n",
       "     'operationId': 'create_dataset_api_v1_datasets_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetCreate'}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Dataset'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/upload': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Upload Csv Dataset',\n",
       "     'description': 'Create a new dataset from a CSV file.',\n",
       "     'operationId': 'upload_csv_dataset_api_v1_datasets_upload_post'}}}},\n",
       " {'paths': {'/api/v1/datasets/upload': {'post': {'requestBody': {'content': {'multipart/form-data': {'schema': {'$ref': '#/components/schemas/Body_upload_csv_dataset_api_v1_datasets_upload_post'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/datasets/upload': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Dataset'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/upload': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/upload-experiment': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Upload Experiment',\n",
       "     'description': 'Upload an experiment that has already been run.',\n",
       "     'operationId': 'upload_experiment_api_v1_datasets_upload_experiment_post'}}}},\n",
       " {'paths': {'/api/v1/datasets/upload-experiment': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ExperimentResultsUpload'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/datasets/upload-experiment': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ExperimentResultsUploadResult'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/upload-experiment': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Get Dataset Versions',\n",
       "     'description': 'Get dataset versions.',\n",
       "     'operationId': 'get_dataset_versions_api_v1_datasets__dataset_id__versions_get'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'search',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Search'}},\n",
       "      {'name': 'example',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Example'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/DatasetVersion'},\n",
       "          'title': 'Response Get Dataset Versions Api V1 Datasets  Dataset Id  Versions Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions/diff': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Diff Dataset Versions',\n",
       "     'description': 'Get diff between two dataset versions.',\n",
       "     'operationId': 'diff_dataset_versions_api_v1_datasets__dataset_id__versions_diff_get'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions/diff': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions/diff': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'from_version',\n",
       "       'in': 'query',\n",
       "       'required': True,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'string'}],\n",
       "        'title': 'From Version'}},\n",
       "      {'name': 'to_version',\n",
       "       'in': 'query',\n",
       "       'required': True,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'string'}],\n",
       "        'title': 'To Version'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions/diff': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetDiffInfo'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions/diff': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/version': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Get Dataset Version',\n",
       "     'description': 'Get dataset version by as_of or exact tag.',\n",
       "     'operationId': 'get_dataset_version_api_v1_datasets__dataset_id__version_get'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/version': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/version': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'as_of',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'As Of'}},\n",
       "      {'name': 'tag',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Tag'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/version': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetVersion'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/version': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/tags': {'put': {'tags': ['datasets'],\n",
       "     'summary': 'Update Dataset Version',\n",
       "     'description': 'Set a tag on a dataset version.',\n",
       "     'operationId': 'update_dataset_version_api_v1_datasets__dataset_id__tags_put'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/tags': {'put': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/tags': {'put': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PutDatasetVersionsSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/tags': {'put': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetVersion'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/tags': {'put': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Download Dataset Openai',\n",
       "     'description': 'Download a dataset as OpenAI Evals Jsonl format.',\n",
       "     'operationId': 'download_dataset_openai_api_v1_datasets__dataset_id__openai_get'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'as_of',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "        'title': 'As Of'},\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai_ft': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Download Dataset Openai Ft',\n",
       "     'description': 'Download a dataset as OpenAI Jsonl format.',\n",
       "     'operationId': 'download_dataset_openai_ft_api_v1_datasets__dataset_id__openai_ft_get'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai_ft': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai_ft': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'as_of',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "        'title': 'As Of'},\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai_ft': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai_ft': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/csv': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Download Dataset Csv',\n",
       "     'description': 'Download a dataset as CSV format.',\n",
       "     'operationId': 'download_dataset_csv_api_v1_datasets__dataset_id__csv_get'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/csv': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/csv': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'as_of',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "        'title': 'As Of'},\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/csv': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/csv': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/jsonl': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Download Dataset Jsonl',\n",
       "     'description': 'Download a dataset as CSV format.',\n",
       "     'operationId': 'download_dataset_jsonl_api_v1_datasets__dataset_id__jsonl_get'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/jsonl': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/jsonl': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'as_of',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "        'title': 'As Of'},\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/jsonl': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/jsonl': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Read Examples With Runs',\n",
       "     'description': 'Fetch examples for a dataset, and fetch the runs for each example if they are associated with the given session_ids.'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs': {'post': {'operationId': 'read_examples_with_runs_api_v1_datasets__dataset_id__runs_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs': {'post': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'format',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'description': \"Response format, e.g., 'csv'\",\n",
       "        'title': 'Format'},\n",
       "       'description': \"Response format, e.g., 'csv'\"}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/QueryExampleSchemaWithRuns'}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs': {'post': {'responses': {'200': {'description': 'Successful Response'}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs': {'post': {'responses': {'200': {'content': {'application/json': {'schema': {'anyOf': [{'type': 'array',\n",
       "            'items': {'$ref': '#/components/schemas/ExampleWithRuns'}},\n",
       "           {'type': 'array',\n",
       "            'items': {'$ref': '#/components/schemas/ExampleWithRunsCH'}},\n",
       "           {'type': 'null'}],\n",
       "          'title': 'Response Read Examples With Runs Api V1 Datasets  Dataset Id  Runs Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/group/runs': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Read Examples With Runs Grouped',\n",
       "     'description': 'Fetch examples for a dataset, and fetch the runs for each example if they are associated with the given session_ids.'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/group/runs': {'post': {'operationId': 'read_examples_with_runs_grouped_api_v1_datasets__dataset_id__group_runs_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/group/runs': {'post': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/group/runs': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/QueryGroupedExamplesWithRuns'}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/group/runs': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/GroupedExamplesWithRunsResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/group/runs': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs/delta': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Read Delta',\n",
       "     'description': 'Fetch the number of regressions/improvements for each example in a dataset, between sessions[0] and sessions[1].'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs/delta': {'post': {'operationId': 'read_delta_api_v1_datasets__dataset_id__runs_delta_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs/delta': {'post': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs/delta': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/QueryFeedbackDelta'}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs/delta': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SessionFeedbackDelta'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs/delta': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Read Dataset Share State',\n",
       "     'description': 'Get the state of sharing a dataset',\n",
       "     'operationId': 'read_dataset_share_state_api_v1_datasets__dataset_id__share_get'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'anyOf': [{'$ref': '#/components/schemas/DatasetShareSchema'},\n",
       "           {'type': 'null'}],\n",
       "          'title': 'Response Read Dataset Share State Api V1 Datasets  Dataset Id  Share Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'put': {'tags': ['datasets'],\n",
       "     'summary': 'Share Dataset',\n",
       "     'description': 'Share a dataset.',\n",
       "     'operationId': 'share_dataset_api_v1_datasets__dataset_id__share_put',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'put': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'share_projects',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Share Projects'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'put': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetShareSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'put': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'delete': {'tags': ['datasets'],\n",
       "     'summary': 'Unshare Dataset',\n",
       "     'description': 'Unshare a dataset.',\n",
       "     'operationId': 'unshare_dataset_api_v1_datasets__dataset_id__share_delete'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/comparative': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Read Comparative Experiments',\n",
       "     'description': 'Get all comparative experiments for a given dataset.',\n",
       "     'operationId': 'read_comparative_experiments_api_v1_datasets__dataset_id__comparative_get'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/comparative': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/comparative': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'name',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name'}},\n",
       "      {'name': 'name_contains',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name Contains'}},\n",
       "      {'name': 'id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Id'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'sort_by',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'$ref': '#/components/schemas/SortByComparativeExperimentColumn',\n",
       "        'default': 'created_at'}},\n",
       "      {'name': 'sort_by_desc',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': True,\n",
       "        'title': 'Sort By Desc'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/comparative': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/ComparativeExperiment'},\n",
       "          'title': 'Response Read Comparative Experiments Api V1 Datasets  Dataset Id  Comparative Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/comparative': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/comparative': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Create Comparative Experiment',\n",
       "     'description': 'Create a comparative experiment.',\n",
       "     'operationId': 'create_comparative_experiment_api_v1_datasets_comparative_post'}}}},\n",
       " {'paths': {'/api/v1/datasets/comparative': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ComparativeExperimentCreate'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/datasets/comparative': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ComparativeExperimentBase'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/comparative': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/comparative/{comparative_experiment_id}': {'delete': {'tags': ['datasets'],\n",
       "     'summary': 'Delete Comparative Experiment',\n",
       "     'description': 'Delete a specific comparative experiment.'}}}},\n",
       " {'paths': {'/api/v1/datasets/comparative/{comparative_experiment_id}': {'delete': {'operationId': 'delete_comparative_experiment_api_v1_datasets_comparative__comparative_experiment_id__delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/comparative/{comparative_experiment_id}': {'delete': {'parameters': [{'name': 'comparative_experiment_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Comparative Experiment Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/comparative/{comparative_experiment_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/comparative/{comparative_experiment_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/clone': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Clone Dataset',\n",
       "     'description': 'Clone a dataset.',\n",
       "     'operationId': 'clone_dataset_api_v1_datasets_clone_post'}}}},\n",
       " {'paths': {'/api/v1/datasets/clone': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Body_clone_dataset_api_v1_datasets_clone_post'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/datasets/clone': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/Example'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response Clone Dataset Api V1 Datasets Clone Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/clone': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/splits': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Get Dataset Splits',\n",
       "     'operationId': 'get_dataset_splits_api_v1_datasets__dataset_id__splits_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/splits': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'as_of',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'string'}],\n",
       "        'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "        'default': 'latest',\n",
       "        'title': 'As Of'},\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/splits': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'type': 'string'},\n",
       "          'title': 'Response Get Dataset Splits Api V1 Datasets  Dataset Id  Splits Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/splits': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/splits': {'put': {'tags': ['datasets'],\n",
       "     'summary': 'Update Dataset Splits',\n",
       "     'operationId': 'update_dataset_splits_api_v1_datasets__dataset_id__splits_put',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/splits': {'put': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/splits': {'put': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Body_update_dataset_splits_api_v1_datasets__dataset_id__splits_put'}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/splits': {'put': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'},\n",
       "          'title': 'Response Update Dataset Splits Api V1 Datasets  Dataset Id  Splits Put'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/splits': {'put': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/index': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Index',\n",
       "     'description': 'Index a dataset.',\n",
       "     'operationId': 'index_api_v1_datasets__dataset_id__index_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/index': {'post': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/index': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetIndexRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/index': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/index': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/index': {'delete': {'tags': ['datasets'],\n",
       "     'summary': 'Remove Index',\n",
       "     'description': 'Remove an index for a dataset.',\n",
       "     'operationId': 'remove_index_api_v1_datasets__dataset_id__index_delete'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/index': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/index': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/index': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/index': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Get Index Info',\n",
       "     'description': 'Get index info.',\n",
       "     'operationId': 'get_index_info_api_v1_datasets__dataset_id__index_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/index': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/index': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetIndexInfo'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/index': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/index/sync': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Sync Index',\n",
       "     'description': 'Sync an index for a dataset.',\n",
       "     'operationId': 'sync_index_api_v1_datasets__dataset_id__index_sync_post'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/index/sync': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/index/sync': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/index/sync': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/search': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Search',\n",
       "     'description': 'Search a dataset.',\n",
       "     'operationId': 'search_api_v1_datasets__dataset_id__search_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/search': {'post': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/search': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SearchDatasetRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/search': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SearchDatasetResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/search': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/generate': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Generate',\n",
       "     'description': 'Generate synthetic examples for a dataset.',\n",
       "     'operationId': 'generate_api_v1_datasets__dataset_id__generate_post'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/generate': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/generate': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/GenerateSyntheticExamplesBody'}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/generate': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/generate': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/playground_experiment/batch': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Dataset Handler',\n",
       "     'operationId': 'dataset_handler_api_v1_datasets_playground_experiment_batch_post'}}}},\n",
       " {'paths': {'/api/v1/datasets/playground_experiment/batch': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PlaygroundRunOverDatasetRequestSchema'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/datasets/playground_experiment/batch': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'title': 'Response Dataset Handler Api V1 Datasets Playground Experiment Batch Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/playground_experiment/batch': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/playground_experiment/batch': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/playground_experiment/stream': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Stream Dataset Handler',\n",
       "     'operationId': 'stream_dataset_handler_api_v1_datasets_playground_experiment_stream_post'}}}},\n",
       " {'paths': {'/api/v1/datasets/playground_experiment/stream': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PlaygroundRunOverDatasetRequestSchema'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/datasets/playground_experiment/stream': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/playground_experiment/stream': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/playground_experiment/stream': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/studio_experiment': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Studio Experiment',\n",
       "     'operationId': 'studio_experiment_api_v1_datasets_studio_experiment_post'}}}},\n",
       " {'paths': {'/api/v1/datasets/studio_experiment': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StudioRunOverDatasetRequestSchema'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/datasets/studio_experiment': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'title': 'Response Studio Experiment Api V1 Datasets Studio Experiment Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/studio_experiment': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules': {'get': {'tags': ['run'],\n",
       "     'summary': 'List Rules',\n",
       "     'description': 'List all run rules.',\n",
       "     'operationId': 'list_rules_api_v1_runs_rules_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Dataset Id'}},\n",
       "      {'name': 'session_id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Session Id'}},\n",
       "      {'name': 'type',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'enum': ['session', 'dataset'], 'type': 'string'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Type'}},\n",
       "      {'name': 'name_contains',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name Contains'}},\n",
       "      {'name': 'id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Id'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/RunRulesSchema'},\n",
       "          'title': 'Response List Rules Api V1 Runs Rules Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules': {'post': {'tags': ['run'],\n",
       "     'summary': 'Create Rule',\n",
       "     'description': 'Create a new run rule.',\n",
       "     'operationId': 'create_rule_api_v1_runs_rules_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunRulesCreateSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunRulesSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}': {'patch': {'tags': ['run'],\n",
       "     'summary': 'Update Rule',\n",
       "     'description': 'Update a run rule.',\n",
       "     'operationId': 'update_rule_api_v1_runs_rules__rule_id__patch',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}': {'patch': {'parameters': [{'name': 'rule_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Rule Id'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunRulesCreateSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunRulesSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}': {'delete': {'tags': ['run'],\n",
       "     'summary': 'Delete Rule',\n",
       "     'description': 'Delete a run rule.',\n",
       "     'operationId': 'delete_rule_api_v1_runs_rules__rule_id__delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}': {'delete': {'parameters': [{'name': 'rule_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Rule Id'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/logs': {'get': {'tags': ['run'],\n",
       "     'summary': 'List Rule Logs',\n",
       "     'description': 'List logs for a particular rule',\n",
       "     'operationId': 'list_rule_logs_api_v1_runs_rules__rule_id__logs_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/logs': {'get': {'parameters': [{'name': 'rule_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Rule Id'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 1440,\n",
       "        'minimum': 100,\n",
       "        'default': 720,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'start_time',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Start Time'}},\n",
       "      {'name': 'end_time',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'End Time'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/logs': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/RuleLogSchema'},\n",
       "          'title': 'Response List Rule Logs Api V1 Runs Rules  Rule Id  Logs Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/logs': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/last_applied': {'get': {'tags': ['run'],\n",
       "     'summary': 'Get Last Applied Rule',\n",
       "     'description': 'Get the last applied rule.',\n",
       "     'operationId': 'get_last_applied_rule_api_v1_runs_rules__rule_id__last_applied_get'}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/last_applied': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'rule_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Rule Id'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/last_applied': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RuleLogSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/last_applied': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/trigger': {'post': {'tags': ['run'],\n",
       "     'summary': 'Trigger Rule',\n",
       "     'description': 'Trigger a run rule manually.',\n",
       "     'operationId': 'trigger_rule_api_v1_runs_rules__rule_id__trigger_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/trigger': {'post': {'parameters': [{'name': 'rule_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Rule Id'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/trigger': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunRulesSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/trigger': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/trigger': {'post': {'tags': ['run'],\n",
       "     'summary': 'Trigger Rules',\n",
       "     'description': 'Trigger an array of run rules manually.',\n",
       "     'operationId': 'trigger_rules_api_v1_runs_rules_trigger_post'}}}},\n",
       " {'paths': {'/api/v1/runs/rules/trigger': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TriggerRulesRequest'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/trigger': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/trigger': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}': {'get': {'tags': ['run'],\n",
       "     'summary': 'Read Run',\n",
       "     'description': 'Get a specific run.',\n",
       "     'operationId': 'read_run_api_v1_runs__run_id__get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}': {'get': {'parameters': [{'name': 'run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}},\n",
       "      {'name': 'session_id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Session Id'}},\n",
       "      {'name': 'start_time',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Start Time'}},\n",
       "      {'name': 'exclude_s3_stored_attributes',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Exclude S3 Stored Attributes'}},\n",
       "      {'name': 'exclude_serialized',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Exclude Serialized'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}': {'patch': {'tags': ['run'],\n",
       "     'summary': 'Update Run',\n",
       "     'description': 'Update a run.',\n",
       "     'operationId': 'update_run_api_v1_runs__run_id__patch',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}': {'patch': {'parameters': [{'name': 'run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'get': {'tags': ['run'],\n",
       "     'summary': 'Read Run Share State',\n",
       "     'description': 'Get the state of sharing of a run.',\n",
       "     'operationId': 'read_run_share_state_api_v1_runs__run_id__share_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'get': {'parameters': [{'name': 'run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'anyOf': [{'$ref': '#/components/schemas/RunShareSchema'},\n",
       "           {'type': 'null'}],\n",
       "          'title': 'Response Read Run Share State Api V1 Runs  Run Id  Share Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'put': {'tags': ['run'],\n",
       "     'summary': 'Share Run',\n",
       "     'description': 'Share a run.',\n",
       "     'operationId': 'share_run_api_v1_runs__run_id__share_put',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'put': {'parameters': [{'name': 'run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'put': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunShareSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'put': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'delete': {'tags': ['run'],\n",
       "     'summary': 'Unshare Run',\n",
       "     'description': 'Unshare a run.',\n",
       "     'operationId': 'unshare_run_api_v1_runs__run_id__share_delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'delete': {'parameters': [{'name': 'run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/query': {'post': {'tags': ['run'],\n",
       "     'summary': 'Query Runs',\n",
       "     'operationId': 'query_runs_api_v1_runs_query_post',\n",
       "     'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BodyParamsForRunSchema'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/runs/query': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ListRunsResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/query': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/generate-query': {'post': {'tags': ['run'],\n",
       "     'summary': 'Generate Query For Runs',\n",
       "     'description': 'Get runs filter expression query for a given natural language query.',\n",
       "     'operationId': 'generate_query_for_runs_api_v1_runs_generate_query_post'}}}},\n",
       " {'paths': {'/api/v1/runs/generate-query': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RequestBodyForRunsGenerateQuery'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/runs/generate-query': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ResponseBodyForRunsGenerateQuery'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/generate-query': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/stats': {'post': {'tags': ['run'],\n",
       "     'summary': 'Stats Runs',\n",
       "     'description': 'Get all runs by query in body payload.',\n",
       "     'operationId': 'stats_runs_api_v1_runs_stats_post'}}}},\n",
       " {'paths': {'/api/v1/runs/stats': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunStatsQueryParams'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/runs/stats': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'anyOf': [{'$ref': '#/components/schemas/RunStats'},\n",
       "           {'additionalProperties': {'$ref': '#/components/schemas/RunStats'},\n",
       "            'type': 'object'}],\n",
       "          'title': 'Response Stats Runs Api V1 Runs Stats Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/stats': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/group': {'post': {'tags': ['run'],\n",
       "     'summary': 'Group Runs',\n",
       "     'description': 'Get runs grouped by an expression',\n",
       "     'operationId': 'group_runs_api_v1_runs_group_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/group': {'post': {'parameters': [{'name': 'accept',\n",
       "       'in': 'header',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Accept'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/group': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunGroupRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/group': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}},\n",
       "      '422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/group/stats': {'post': {'tags': ['run'],\n",
       "     'summary': 'Stats Group Runs',\n",
       "     'description': 'Get stats for the grouped runs.',\n",
       "     'operationId': 'stats_group_runs_api_v1_runs_group_stats_post'}}}},\n",
       " {'paths': {'/api/v1/runs/group/stats': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunGroupRequest'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/runs/group/stats': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunGroupStats'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/group/stats': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/delete': {'post': {'tags': ['run'],\n",
       "     'summary': 'Delete Runs',\n",
       "     'description': 'Delete specific runs.',\n",
       "     'operationId': 'delete_runs_api_v1_runs_delete_post'}}}},\n",
       " {'paths': {'/api/v1/runs/delete': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Body_delete_runs_api_v1_runs_delete_post'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/runs/delete': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/delete': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'get': {'tags': ['feedback'],\n",
       "     'summary': 'Read Feedback',\n",
       "     'description': 'Get a specific feedback.',\n",
       "     'operationId': 'read_feedback_api_v1_feedback__feedback_id__get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'get': {'parameters': [{'name': 'feedback_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Feedback Id'}},\n",
       "      {'name': 'include_user_names',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Include User Names'}}]}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'patch': {'tags': ['feedback'],\n",
       "     'summary': 'Update Feedback',\n",
       "     'description': 'Replace an existing feedback entry with a new, modified entry.',\n",
       "     'operationId': 'update_feedback_api_v1_feedback__feedback_id__patch'}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'patch': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'feedback_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Feedback Id'}}]}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackUpdateSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'delete': {'tags': ['feedback'],\n",
       "     'summary': 'Delete Feedback',\n",
       "     'description': 'Delete a feedback.',\n",
       "     'operationId': 'delete_feedback_api_v1_feedback__feedback_id__delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'delete': {'parameters': [{'name': 'feedback_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Feedback Id'}}]}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback': {'get': {'tags': ['feedback'],\n",
       "     'summary': 'Read Feedbacks',\n",
       "     'description': 'List all Feedback by query params.',\n",
       "     'operationId': 'read_feedbacks_api_v1_feedback_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback': {'get': {'parameters': [{'name': 'run',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Run'}},\n",
       "      {'name': 'key',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Key'}},\n",
       "      {'name': 'session',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Session'}},\n",
       "      {'name': 'source',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/SourceType'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Source'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'user',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'User'}},\n",
       "      {'name': 'has_comment',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Has Comment'}},\n",
       "      {'name': 'has_score',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Has Score'}},\n",
       "      {'name': 'level',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'$ref': '#/components/schemas/FeedbackLevel'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Level'}},\n",
       "      {'name': 'max_created_at',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Max Created At'}},\n",
       "      {'name': 'min_created_at',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Min Created At'}},\n",
       "      {'name': 'include_user_names',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Include User Names'}}]}}}},\n",
       " {'paths': {'/api/v1/feedback': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/FeedbackSchema'},\n",
       "          'title': 'Response Read Feedbacks Api V1 Feedback Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback': {'post': {'tags': ['feedback'],\n",
       "     'summary': 'Create Feedback',\n",
       "     'description': 'Create a new feedback.',\n",
       "     'operationId': 'create_feedback_api_v1_feedback_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackCreateSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/eager': {'post': {'tags': ['feedback'],\n",
       "     'summary': 'Eagerly Create Feedback',\n",
       "     'description': 'Create a new feedback.\\n\\nThis method is invoked under the assumption that the run\\nis already visible in the app, thus already present in DB'}}}},\n",
       " {'paths': {'/api/v1/feedback/eager': {'post': {'operationId': 'eagerly_create_feedback_api_v1_feedback_eager_post',\n",
       "     'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackCreateSchema'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/feedback/eager': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/eager': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'post': {'tags': ['feedback'],\n",
       "     'summary': 'Create Feedback Ingest Token',\n",
       "     'description': 'Create a new feedback ingest token.',\n",
       "     'operationId': 'create_feedback_ingest_token_api_v1_feedback_tokens_post'}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'anyOf': [{'$ref': '#/components/schemas/FeedbackIngestTokenCreateSchema'},\n",
       "          {'type': 'array',\n",
       "           'items': {'$ref': '#/components/schemas/FeedbackIngestTokenCreateSchema'}}]}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'post': {'requestBody': {'content': {'application/json': {'schema': {'title': 'Feedback Ingest Token'}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'post': {'responses': {'200': {'description': 'Successful Response'}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'post': {'responses': {'200': {'content': {'application/json': {'schema': {'anyOf': [{'$ref': '#/components/schemas/FeedbackIngestTokenSchema'},\n",
       "           {'type': 'array',\n",
       "            'items': {'$ref': '#/components/schemas/FeedbackIngestTokenSchema'}}],\n",
       "          'title': 'Response Create Feedback Ingest Token Api V1 Feedback Tokens Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'get': {'tags': ['feedback'],\n",
       "     'summary': 'List Feedback Ingest Tokens',\n",
       "     'description': 'List all feedback ingest tokens for a run.',\n",
       "     'operationId': 'list_feedback_ingest_tokens_api_v1_feedback_tokens_get'}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'run_id',\n",
       "       'in': 'query',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}]}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/FeedbackIngestTokenSchema'},\n",
       "          'title': 'Response List Feedback Ingest Tokens Api V1 Feedback Tokens Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens/{token}': {'get': {'tags': ['feedback'],\n",
       "     'summary': 'Create Feedback With Token Get',\n",
       "     'description': 'Create a new feedback with a token.',\n",
       "     'operationId': 'create_feedback_with_token_get_api_v1_feedback_tokens__token__get'}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens/{token}': {'get': {'parameters': [{'name': 'token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Token'}},\n",
       "      {'name': 'score',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'number'},\n",
       "         {'type': 'integer'},\n",
       "         {'type': 'boolean'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Score'}},\n",
       "      {'name': 'value',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'number'},\n",
       "         {'type': 'integer'},\n",
       "         {'type': 'boolean'},\n",
       "         {'type': 'string'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Value'}},\n",
       "      {'name': 'comment',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Comment'}},\n",
       "      {'name': 'correction',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Correction'}}]}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens/{token}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens/{token}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens/{token}': {'post': {'tags': ['feedback'],\n",
       "     'summary': 'Create Feedback With Token Post',\n",
       "     'description': 'Create a new feedback with a token.',\n",
       "     'operationId': 'create_feedback_with_token_post_api_v1_feedback_tokens__token__post'}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens/{token}': {'post': {'parameters': [{'name': 'token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Token'}}]}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens/{token}': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackCreateWithTokenExtendedSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens/{token}': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens/{token}': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/run': {'get': {'tags': ['public'],\n",
       "     'summary': 'Get Shared Run',\n",
       "     'description': 'Get the shared run.',\n",
       "     'operationId': 'get_shared_run_api_v1_public__share_token__run_get'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/run': {'get': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "      {'name': 'exclude_s3_stored_attributes',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Exclude S3 Stored Attributes'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/run': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunPublicSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/run': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/run/{id}': {'get': {'tags': ['public'],\n",
       "     'summary': 'Get Shared Run By Id',\n",
       "     'description': 'Get the shared run.',\n",
       "     'operationId': 'get_shared_run_by_id_api_v1_public__share_token__run__id__get'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/run/{id}': {'get': {'parameters': [{'name': 'id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Id'}},\n",
       "      {'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "      {'name': 'exclude_s3_stored_attributes',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Exclude S3 Stored Attributes'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/run/{id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunPublicSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/run/{id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/runs/query': {'post': {'tags': ['public'],\n",
       "     'summary': 'Query Shared Runs',\n",
       "     'description': 'Get run by ids or the shared run if not specifed.',\n",
       "     'operationId': 'query_shared_runs_api_v1_public__share_token__runs_query_post'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/runs/query': {'post': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Share Token'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/runs/query': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/QueryParamsForPublicRunSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/runs/query': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ListPublicRunsResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/runs/query': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/feedbacks': {'get': {'tags': ['public'],\n",
       "     'summary': 'Read Shared Feedbacks',\n",
       "     'operationId': 'read_shared_feedbacks_api_v1_public__share_token__feedbacks_get'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/feedbacks': {'get': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "      {'name': 'run',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Run'}},\n",
       "      {'name': 'key',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Key'}},\n",
       "      {'name': 'session',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Session'}},\n",
       "      {'name': 'source',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/SourceType'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Source'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'user',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'User'}},\n",
       "      {'name': 'has_comment',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Has Comment'}},\n",
       "      {'name': 'has_score',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Has Score'}},\n",
       "      {'name': 'level',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'$ref': '#/components/schemas/FeedbackLevel'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Level'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/feedbacks': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/FeedbackSchema'},\n",
       "          'title': 'Response Read Shared Feedbacks Api V1 Public  Share Token  Feedbacks Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/feedbacks': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets': {'get': {'tags': ['public'],\n",
       "     'summary': 'Read Shared Dataset',\n",
       "     'description': 'Get dataset by ids or the shared dataset if not specifed.',\n",
       "     'operationId': 'read_shared_dataset_api_v1_public__share_token__datasets_get'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets': {'get': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'sort_by',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'$ref': '#/components/schemas/SortByDatasetColumn',\n",
       "        'default': 'last_session_start_time'}},\n",
       "      {'name': 'sort_by_desc',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': True,\n",
       "        'title': 'Sort By Desc'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetPublicSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples/count': {'get': {'tags': ['public'],\n",
       "     'summary': 'Count Shared Examples',\n",
       "     'description': 'Count all examples by query params',\n",
       "     'operationId': 'count_shared_examples_api_v1_public__share_token__examples_count_get'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples/count': {'get': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "      {'name': 'id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Id'}},\n",
       "      {'name': 'as_of',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'string'}],\n",
       "        'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "        'default': 'latest',\n",
       "        'title': 'As Of'},\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'},\n",
       "      {'name': 'metadata',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Metadata'}},\n",
       "      {'name': 'filter',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Filter'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples/count': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'integer',\n",
       "          'title': 'Response Count Shared Examples Api V1 Public  Share Token  Examples Count Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples/count': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples': {'get': {'tags': ['public'],\n",
       "     'summary': 'Read Shared Examples',\n",
       "     'description': 'Get example by ids or the shared example if not specifed.',\n",
       "     'operationId': 'read_shared_examples_api_v1_public__share_token__examples_get'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples': {'get': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "      {'name': 'id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Id'}},\n",
       "      {'name': 'as_of',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'string'}],\n",
       "        'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "        'default': 'latest',\n",
       "        'title': 'As Of'},\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'},\n",
       "      {'name': 'metadata',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Metadata'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'select',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'array',\n",
       "        'items': {'$ref': '#/components/schemas/ExampleSelect'},\n",
       "        'default': ['id',\n",
       "         'created_at',\n",
       "         'modified_at',\n",
       "         'name',\n",
       "         'dataset_id',\n",
       "         'metadata',\n",
       "         'inputs',\n",
       "         'outputs',\n",
       "         'attachment_urls'],\n",
       "        'title': 'Select'}},\n",
       "      {'name': 'filter',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Filter'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/Example'},\n",
       "          'title': 'Response Read Shared Examples Api V1 Public  Share Token  Examples Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/sessions': {'get': {'tags': ['public'],\n",
       "     'summary': 'Read Shared Dataset Tracer Sessions',\n",
       "     'description': 'Get projects run on a dataset that has been shared.'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/sessions': {'get': {'operationId': 'read_shared_dataset_tracer_sessions_api_v1_public__share_token__datasets_sessions_get'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/sessions': {'get': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "      {'name': 'id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Id'}},\n",
       "      {'name': 'name',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name'}},\n",
       "      {'name': 'name_contains',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name Contains'}},\n",
       "      {'name': 'dataset_version',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Dataset Version'}},\n",
       "      {'name': 'sort_by',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'$ref': '#/components/schemas/SessionSortableColumns',\n",
       "        'default': 'start_time'}},\n",
       "      {'name': 'sort_by_desc',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': True,\n",
       "        'title': 'Sort By Desc'}},\n",
       "      {'name': 'sort_by_feedback_key',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Sort By Feedback Key'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'facets',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean', 'default': False, 'title': 'Facets'}},\n",
       "      {'name': 'accept',\n",
       "       'in': 'header',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Accept'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/sessions': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/TracerSession'},\n",
       "          'title': 'Response Read Shared Dataset Tracer Sessions Api V1 Public  Share Token  Datasets Sessions Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/sessions': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/datasets/sessions-bulk': {'get': {'tags': ['public'],\n",
       "     'summary': 'Read Shared Dataset Tracer Sessions Bulk',\n",
       "     'description': 'Get sessions from multiple datasets using share tokens.'}}}},\n",
       " {'paths': {'/api/v1/public/datasets/sessions-bulk': {'get': {'operationId': 'read_shared_dataset_tracer_sessions_bulk_api_v1_public_datasets_sessions_bulk_get'}}}},\n",
       " {'paths': {'/api/v1/public/datasets/sessions-bulk': {'get': {'parameters': [{'name': 'share_tokens',\n",
       "       'in': 'query',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'array',\n",
       "        'items': {'type': 'string'},\n",
       "        'title': 'Share Tokens'}}]}}}},\n",
       " {'paths': {'/api/v1/public/datasets/sessions-bulk': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/TracerSession'},\n",
       "          'title': 'Response Read Shared Dataset Tracer Sessions Bulk Api V1 Public Datasets Sessions Bulk Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/datasets/sessions-bulk': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples/runs': {'post': {'tags': ['public'],\n",
       "     'summary': 'Read Shared Dataset Examples With Runs',\n",
       "     'description': 'Get examples with associated runs from sessions in a dataset that has been shared.'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples/runs': {'post': {'operationId': 'read_shared_dataset_examples_with_runs_api_v1_public__share_token__examples_runs_post'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples/runs': {'post': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Share Token'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples/runs': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/QueryExampleSchemaWithRuns'}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples/runs': {'post': {'responses': {'200': {'description': 'Successful Response'}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples/runs': {'post': {'responses': {'200': {'content': {'application/json': {'schema': {'anyOf': [{'type': 'array',\n",
       "            'items': {'$ref': '#/components/schemas/PublicExampleWithRuns'}},\n",
       "           {'type': 'array',\n",
       "            'items': {'$ref': '#/components/schemas/ExampleWithRunsCH'}}],\n",
       "          'title': 'Response Read Shared Dataset Examples With Runs Api V1 Public  Share Token  Examples Runs Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples/runs': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/delta': {'post': {'tags': ['public'],\n",
       "     'summary': 'Read Shared Delta',\n",
       "     'description': 'Fetch the number of regressions/improvements for each example in a dataset, between sessions[0] and sessions[1].'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/delta': {'post': {'operationId': 'read_shared_delta_api_v1_public__share_token__datasets_runs_delta_post'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/delta': {'post': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Share Token'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/delta': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/QueryFeedbackDelta'}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/delta': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SessionFeedbackDelta'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/delta': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/query': {'post': {'tags': ['public'],\n",
       "     'summary': 'Query Shared Dataset Runs',\n",
       "     'description': 'Get runs in projects run over a dataset that has been shared.'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/query': {'post': {'operationId': 'query_shared_dataset_runs_api_v1_public__share_token__datasets_runs_query_post'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/query': {'post': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Share Token'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/query': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BodyParamsForRunSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/query': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ListPublicDatasetRunsResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/query': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/generate-query': {'post': {'tags': ['public'],\n",
       "     'summary': 'Generate Query For Shared Dataset Runs',\n",
       "     'description': 'Get runs in projects run over a dataset that has been shared.'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/generate-query': {'post': {'operationId': 'generate_query_for_shared_dataset_runs_api_v1_public__share_token__datasets_runs_generate_query_post'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/generate-query': {'post': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Share Token'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/generate-query': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RequestBodyForRunsGenerateQuery'}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/generate-query': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ResponseBodyForRunsGenerateQuery'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/generate-query': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/stats': {'post': {'tags': ['public'],\n",
       "     'summary': 'Stats Shared Dataset Runs',\n",
       "     'description': 'Get run stats in projects run over a dataset that has been shared.'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/stats': {'post': {'operationId': 'stats_shared_dataset_runs_api_v1_public__share_token__datasets_runs_stats_post'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/stats': {'post': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Share Token'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/stats': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunStatsQueryParams'}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/stats': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunStats'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/stats': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/{run_id}': {'get': {'tags': ['public'],\n",
       "     'summary': 'Read Shared Dataset Run',\n",
       "     'description': 'Get runs in projects run over a dataset that has been shared.'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/{run_id}': {'get': {'operationId': 'read_shared_dataset_run_api_v1_public__share_token__datasets_runs__run_id__get'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/{run_id}': {'get': {'parameters': [{'name': 'run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}},\n",
       "      {'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "      {'name': 'exclude_s3_stored_attributes',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Exclude S3 Stored Attributes'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/{run_id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunPublicDatasetSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/{run_id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/feedback': {'get': {'tags': ['public'],\n",
       "     'summary': 'Read Shared Dataset Feedback',\n",
       "     'description': 'Get feedback for runs in projects run over a dataset that has been shared.'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/feedback': {'get': {'operationId': 'read_shared_dataset_feedback_api_v1_public__share_token__datasets_feedback_get'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/feedback': {'get': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "      {'name': 'run',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Run'}},\n",
       "      {'name': 'key',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Key'}},\n",
       "      {'name': 'session',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Session'}},\n",
       "      {'name': 'source',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/SourceType'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Source'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'user',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'User'}},\n",
       "      {'name': 'has_comment',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Has Comment'}},\n",
       "      {'name': 'has_score',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Has Score'}},\n",
       "      {'name': 'level',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'$ref': '#/components/schemas/FeedbackLevel'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Level'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/feedback': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/FeedbackSchema'},\n",
       "          'title': 'Response Read Shared Dataset Feedback Api V1 Public  Share Token  Datasets Feedback Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/feedback': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/comparative': {'get': {'tags': ['public'],\n",
       "     'summary': 'Read Shared Comparative Experiments',\n",
       "     'description': 'Get all comparative experiments for a given dataset.'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/comparative': {'get': {'operationId': 'read_shared_comparative_experiments_api_v1_public__share_token__datasets_comparative_get'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/comparative': {'get': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "      {'name': 'name',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name'}},\n",
       "      {'name': 'name_contains',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name Contains'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'sort_by',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'$ref': '#/components/schemas/SortByComparativeExperimentColumn',\n",
       "        'default': 'created_at'}},\n",
       "      {'name': 'sort_by_desc',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': True,\n",
       "        'title': 'Sort By Desc'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/comparative': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/PublicComparativeExperiment'},\n",
       "          'title': 'Response Read Shared Comparative Experiments Api V1 Public  Share Token  Datasets Comparative Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/comparative': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/schemas/{version}/message.json': {'get': {'tags': ['public'],\n",
       "     'summary': 'Get Message Json Schema',\n",
       "     'operationId': 'get_message_json_schema_api_v1_public_schemas__version__message_json_get'}}}},\n",
       " {'paths': {'/api/v1/public/schemas/{version}/message.json': {'get': {'parameters': [{'name': 'version',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Version'}}]}}}},\n",
       " {'paths': {'/api/v1/public/schemas/{version}/message.json': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/schemas/{version}/message.json': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/schemas/{version}/tooldef.json': {'get': {'tags': ['public'],\n",
       "     'summary': 'Get Tool Def Json Schema',\n",
       "     'operationId': 'get_tool_def_json_schema_api_v1_public_schemas__version__tooldef_json_get'}}}},\n",
       " {'paths': {'/api/v1/public/schemas/{version}/tooldef.json': {'get': {'parameters': [{'name': 'version',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Version'}}]}}}},\n",
       " {'paths': {'/api/v1/public/schemas/{version}/tooldef.json': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/schemas/{version}/tooldef.json': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues': {'get': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Get Annotation Queues',\n",
       "     'operationId': 'get_annotation_queues_api_v1_annotation_queues_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues': {'get': {'parameters': [{'name': 'ids',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Ids'}},\n",
       "      {'name': 'name',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name'}},\n",
       "      {'name': 'name_contains',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name Contains'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'tag_value_id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Tag Value Id'}},\n",
       "      {'name': 'dataset_id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/AnnotationQueueSchemaWithSize'},\n",
       "          'title': 'Response Get Annotation Queues Api V1 Annotation Queues Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues': {'post': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Create Annotation Queue',\n",
       "     'operationId': 'create_annotation_queue_api_v1_annotation_queues_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueCreateSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/populate': {'post': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Populate Annotation Queue',\n",
       "     'description': 'Populate annotation queue with runs from an experiment.',\n",
       "     'operationId': 'populate_annotation_queue_api_v1_annotation_queues_populate_post'}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/populate': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PopulateAnnotationQueueSchema'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/populate': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/populate': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'delete': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Delete Annotation Queue',\n",
       "     'operationId': 'delete_annotation_queue_api_v1_annotation_queues__queue_id__delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'delete': {'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Queue Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'patch': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Update Annotation Queue',\n",
       "     'operationId': 'update_annotation_queue_api_v1_annotation_queues__queue_id__patch',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'patch': {'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Queue Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueUpdateSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'get': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Get Annotation Queue',\n",
       "     'operationId': 'get_annotation_queue_api_v1_annotation_queues__queue_id__get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'get': {'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Queue Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueSchemaWithRubric'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs': {'post': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Add Runs To Annotation Queue',\n",
       "     'operationId': 'add_runs_to_annotation_queue_api_v1_annotation_queues__queue_id__runs_post'}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Queue Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'},\n",
       "         'title': 'Run Ids'}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/AnnotationQueueRunSchema'},\n",
       "          'title': 'Response Add Runs To Annotation Queue Api V1 Annotation Queues  Queue Id  Runs Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs': {'get': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Get Runs From Annotation Queue',\n",
       "     'operationId': 'get_runs_from_annotation_queue_api_v1_annotation_queues__queue_id__runs_get'}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs': {'get': {'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'archived',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Archived'}},\n",
       "      {'name': 'include_stats',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Include Stats'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/RunSchemaWithAnnotationQueueInfo'},\n",
       "          'title': 'Response Get Runs From Annotation Queue Api V1 Annotation Queues  Queue Id  Runs Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/export': {'post': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Export Annotation Queue Archived Runs',\n",
       "     'operationId': 'export_annotation_queue_archived_runs_api_v1_annotation_queues__queue_id__export_post'}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/export': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Queue Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/export': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ExportAnnotationQueueRunsRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/export': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/export': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/run/{index}': {'get': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Get Run From Annotation Queue',\n",
       "     'operationId': 'get_run_from_annotation_queue_api_v1_annotation_queues__queue_id__run__index__get'}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/run/{index}': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/run/{index}': {'get': {'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}},\n",
       "      {'name': 'index',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'integer', 'title': 'Index'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/run/{index}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunSchemaWithAnnotationQueueInfo'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/run/{index}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{run_id}/queues': {'get': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Get Annotation Queues For Run',\n",
       "     'operationId': 'get_annotation_queues_for_run_api_v1_annotation_queues__run_id__queues_get'}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{run_id}/queues': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{run_id}/queues': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/AnnotationQueueSchema'},\n",
       "          'title': 'Response Get Annotation Queues For Run Api V1 Annotation Queues  Run Id  Queues Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{run_id}/queues': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'patch': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Update Run In Annotation Queue',\n",
       "     'operationId': 'update_run_in_annotation_queue_api_v1_annotation_queues__queue_id__runs__queue_run_id__patch'}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'patch': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'patch': {'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}},\n",
       "      {'name': 'queue_run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Queue Run Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueRunUpdateSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'delete': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Delete Run From Annotation Queue',\n",
       "     'operationId': 'delete_run_from_annotation_queue_api_v1_annotation_queues__queue_id__runs__queue_run_id__delete'}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'delete': {'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}},\n",
       "      {'name': 'queue_run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Queue Run Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/delete': {'post': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Delete Runs From Annotation Queue',\n",
       "     'operationId': 'delete_runs_from_annotation_queue_api_v1_annotation_queues__queue_id__runs_delete_post'}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/delete': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Queue Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/delete': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueBulkDeleteRunsRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/delete': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/delete': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/total_size': {'get': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Get Total Size From Annotation Queue',\n",
       "     'operationId': 'get_total_size_from_annotation_queue_api_v1_annotation_queues__queue_id__total_size_get'}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/total_size': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Queue Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/total_size': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueSizeSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/total_size': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/total_archived': {'get': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Get Total Archived From Annotation Queue',\n",
       "     'operationId': 'get_total_archived_from_annotation_queue_api_v1_annotation_queues__queue_id__total_archived_get'}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/total_archived': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/total_archived': {'get': {'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}},\n",
       "      {'name': 'start_time',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Start Time'}},\n",
       "      {'name': 'end_time',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'End Time'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/total_archived': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueSizeSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/total_archived': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/size': {'get': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Get Size From Annotation Queue',\n",
       "     'operationId': 'get_size_from_annotation_queue_api_v1_annotation_queues__queue_id__size_get'}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/size': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Queue Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/size': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueSizeSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/size': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/status/{annotation_queue_run_id}': {'post': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Create Identity Annotation Queue Run Status',\n",
       "     'operationId': 'create_identity_annotation_queue_run_status_api_v1_annotation_queues_status__annotation_queue_run_id__post'}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/status/{annotation_queue_run_id}': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/status/{annotation_queue_run_id}': {'post': {'parameters': [{'name': 'annotation_queue_run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Annotation Queue Run Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/status/{annotation_queue_run_id}': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/IdentityAnnotationQueueRunStatusCreateSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/status/{annotation_queue_run_id}': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/status/{annotation_queue_run_id}': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/ace/execute': {'post': {'tags': ['ace'],\n",
       "     'summary': 'Execute',\n",
       "     'description': 'Execute some custom code for testing purposes.',\n",
       "     'operationId': 'execute_api_v1_ace_execute_post'}}}},\n",
       " {'paths': {'/api/v1/ace/execute': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Body_execute_api_v1_ace_execute_post'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/ace/execute': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'object',\n",
       "          'title': 'Response Execute Api V1 Ace Execute Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/ace/execute': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/bulk-exports': {'get': {'tags': ['bulk-exports'],\n",
       "     'summary': 'Get Bulk Exports',\n",
       "     'description': \"Get the current workspace's bulk exports\",\n",
       "     'operationId': 'get_bulk_exports_api_v1_bulk_exports_get'}}}},\n",
       " {'paths': {'/api/v1/bulk-exports': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/BulkExport'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response Get Bulk Exports Api V1 Bulk Exports Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/bulk-exports': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/bulk-exports': {'post': {'tags': ['bulk-exports'],\n",
       "     'summary': 'Create Bulk Export',\n",
       "     'description': 'Create a new bulk export',\n",
       "     'operationId': 'create_bulk_export_api_v1_bulk_exports_post'}}}},\n",
       " {'paths': {'/api/v1/bulk-exports': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BulkExportCreate'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/bulk-exports': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BulkExport'}}}}}}}}},\n",
       " {'paths': {'/api/v1/bulk-exports': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/destinations': {'get': {'tags': ['bulk-exports'],\n",
       "     'summary': 'Get Bulk Export Destinations',\n",
       "     'description': \"Get the current workspace's bulk export destinations\",\n",
       "     'operationId': 'get_bulk_export_destinations_api_v1_bulk_exports_destinations_get'}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/destinations': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/BulkExportDestination'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response Get Bulk Export Destinations Api V1 Bulk Exports Destinations Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/destinations': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/destinations': {'post': {'tags': ['bulk-exports'],\n",
       "     'summary': 'Create Bulk Export Destination',\n",
       "     'description': 'Create a new bulk export destination',\n",
       "     'operationId': 'create_bulk_export_destination_api_v1_bulk_exports_destinations_post'}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/destinations': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BulkExportDestinationCreate'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/destinations': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BulkExportDestination'}}}}}}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/destinations': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/{bulk_export_id}': {'get': {'tags': ['bulk-exports'],\n",
       "     'summary': 'Get Bulk Export',\n",
       "     'description': 'Get a single bulk export by ID',\n",
       "     'operationId': 'get_bulk_export_api_v1_bulk_exports__bulk_export_id__get'}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/{bulk_export_id}': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'bulk_export_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Bulk Export Id'}}]}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/{bulk_export_id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BulkExport'}}}}}}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/{bulk_export_id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/{bulk_export_id}': {'patch': {'tags': ['bulk-exports'],\n",
       "     'summary': 'Cancel Bulk Export',\n",
       "     'description': 'Cancel a bulk export by ID',\n",
       "     'operationId': 'cancel_bulk_export_api_v1_bulk_exports__bulk_export_id__patch'}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/{bulk_export_id}': {'patch': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'bulk_export_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Bulk Export Id'}}]}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/{bulk_export_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BulkExportUpdate'}}}}}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/{bulk_export_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BulkExport'}}}}}}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/{bulk_export_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/destinations/{destination_id}': {'get': {'tags': ['bulk-exports'],\n",
       "     'summary': 'Get Bulk Export Destination',\n",
       "     'description': 'Get a single bulk export destination by ID'}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/destinations/{destination_id}': {'get': {'operationId': 'get_bulk_export_destination_api_v1_bulk_exports_destinations__destination_id__get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/destinations/{destination_id}': {'get': {'parameters': [{'name': 'destination_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Destination Id'}}]}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/destinations/{destination_id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BulkExportDestination'}}}}}}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/destinations/{destination_id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/{bulk_export_id}/runs': {'get': {'tags': ['bulk-exports'],\n",
       "     'summary': 'Get Bulk Export Runs',\n",
       "     'description': \"Get a bulk export's runs\",\n",
       "     'operationId': 'get_bulk_export_runs_api_v1_bulk_exports__bulk_export_id__runs_get'}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/{bulk_export_id}/runs': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'bulk_export_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Bulk Export Id'}}]}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/{bulk_export_id}/runs': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/BulkExportRun'},\n",
       "          'title': 'Response Get Bulk Export Runs Api V1 Bulk Exports  Bulk Export Id  Runs Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/{bulk_export_id}/runs': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/{bulk_export_id}/runs/{run_id}': {'get': {'tags': ['bulk-exports'],\n",
       "     'summary': 'Get Bulk Export Run',\n",
       "     'description': \"Get a single bulk export's run by ID\",\n",
       "     'operationId': 'get_bulk_export_run_api_v1_bulk_exports__bulk_export_id__runs__run_id__get'}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/{bulk_export_id}/runs/{run_id}': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/{bulk_export_id}/runs/{run_id}': {'get': {'parameters': [{'name': 'bulk_export_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Bulk Export Id'}},\n",
       "      {'name': 'run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}]}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/{bulk_export_id}/runs/{run_id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BulkExportRun'}}}}}}}}},\n",
       " {'paths': {'/api/v1/bulk-exports/{bulk_export_id}/runs/{run_id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants': {'get': {'tags': ['tenant'],\n",
       "     'summary': 'List Tenants',\n",
       "     'description': 'Get all tenants visible to this auth',\n",
       "     'operationId': 'list_tenants_api_v1_tenants_get',\n",
       "     'security': [{'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/tenants': {'get': {'parameters': [{'name': 'skip_create',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Skip Create'}},\n",
       "      {'name': 'include_deleted',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Include Deleted'}}]}}}},\n",
       " {'paths': {'/api/v1/tenants': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/TenantForUser'},\n",
       "          'title': 'Response List Tenants Api V1 Tenants Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants': {'post': {'tags': ['tenant'],\n",
       "     'summary': 'Create Tenant',\n",
       "     'description': 'Create a new organization and corresponding workspace.',\n",
       "     'operationId': 'create_tenant_api_v1_tenants_post',\n",
       "     'security': [{'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/tenants': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantCreate'}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/app__schemas__Tenant'}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/info': {'get': {'tags': ['info'],\n",
       "     'summary': 'Get Server Info',\n",
       "     'description': 'Get information about the current deployment of LangSmith.',\n",
       "     'operationId': 'get_server_info_api_v1_info_get'}}}},\n",
       " {'paths': {'/api/v1/info': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/InfoGetResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/info/health': {'get': {'tags': ['info'],\n",
       "     'summary': 'Get Health Info',\n",
       "     'description': 'Get health information about the current deployment of LangSmith.',\n",
       "     'operationId': 'get_health_info_api_v1_info_health_get'}}}},\n",
       " {'paths': {'/api/v1/info/health': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HealthInfoGetResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'get': {'tags': ['feedback-configs'],\n",
       "     'summary': 'List Feedback Configs Endpoint',\n",
       "     'operationId': 'list_feedback_configs_endpoint_api_v1_feedback_configs_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'get': {'parameters': [{'name': 'key',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string'},\n",
       "          'maxItems': 50},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Key'}},\n",
       "      {'name': 'read_after_write',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Read After Write'}}]}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/FeedbackConfigSchema'},\n",
       "          'title': 'Response List Feedback Configs Endpoint Api V1 Feedback Configs Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'post': {'tags': ['feedback-configs'],\n",
       "     'summary': 'Create Feedback Config Endpoint',\n",
       "     'operationId': 'create_feedback_config_endpoint_api_v1_feedback_configs_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateFeedbackConfigSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackConfigSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'patch': {'tags': ['feedback-configs'],\n",
       "     'summary': 'Update Feedback Config Endpoint',\n",
       "     'operationId': 'update_feedback_config_endpoint_api_v1_feedback_configs_patch',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UpdateFeedbackConfigSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackConfigSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/model-price-map': {'get': {'tags': ['model-price-map'],\n",
       "     'summary': 'Read Model Price Map',\n",
       "     'operationId': 'read_model_price_map_api_v1_model_price_map_get',\n",
       "     'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/model-price-map': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/model-price-map': {'post': {'tags': ['model-price-map'],\n",
       "     'summary': 'Create New Model Price',\n",
       "     'operationId': 'create_new_model_price_api_v1_model_price_map_post'}}}},\n",
       " {'paths': {'/api/v1/model-price-map': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ModelPriceMapCreateSchema'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/model-price-map': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/model-price-map': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/model-price-map/{id}': {'put': {'tags': ['model-price-map'],\n",
       "     'summary': 'Update Model Price',\n",
       "     'operationId': 'update_model_price_api_v1_model_price_map__id__put',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/model-price-map/{id}': {'put': {'parameters': [{'name': 'id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Id'}}]}}}},\n",
       " {'paths': {'/api/v1/model-price-map/{id}': {'put': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ModelPriceMapUpdateSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/model-price-map/{id}': {'put': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/model-price-map/{id}': {'put': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/model-price-map/{id}': {'delete': {'tags': ['model-price-map'],\n",
       "     'summary': 'Delete Model Price',\n",
       "     'operationId': 'delete_model_price_api_v1_model_price_map__id__delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/model-price-map/{id}': {'delete': {'parameters': [{'name': 'id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Id'}}]}}}},\n",
       " {'paths': {'/api/v1/model-price-map/{id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/model-price-map/{id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/usage-limits': {'get': {'tags': ['usage-limits'],\n",
       "     'summary': 'List Usage Limits',\n",
       "     'description': 'List out the configured usage limits for a given tenant.',\n",
       "     'operationId': 'list_usage_limits_api_v1_usage_limits_get'}}}},\n",
       " {'paths': {'/api/v1/usage-limits': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/UsageLimit'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Usage Limits Api V1 Usage Limits Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/usage-limits': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/usage-limits': {'put': {'tags': ['usage-limits'],\n",
       "     'summary': 'Upsert Usage Limit',\n",
       "     'description': 'Create a new usage limit.',\n",
       "     'operationId': 'upsert_usage_limit_api_v1_usage_limits_put'}}}},\n",
       " {'paths': {'/api/v1/usage-limits': {'put': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UpsertUsageLimit'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/usage-limits': {'put': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UsageLimit'}}}}}}}}},\n",
       " {'paths': {'/api/v1/usage-limits': {'put': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/usage-limits/org': {'get': {'tags': ['usage-limits'],\n",
       "     'summary': 'List Org Usage Limits',\n",
       "     'description': 'List out the configured usage limits for a given organization.',\n",
       "     'operationId': 'list_org_usage_limits_api_v1_usage_limits_org_get'}}}},\n",
       " {'paths': {'/api/v1/usage-limits/org': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/UsageLimit'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Org Usage Limits Api V1 Usage Limits Org Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/usage-limits/org': {'get': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/usage-limits/{usage_limit_id}': {'delete': {'tags': ['usage-limits'],\n",
       "     'summary': 'Delete Usage Limit',\n",
       "     'description': 'Delete a specific usage limit.',\n",
       "     'operationId': 'delete_usage_limit_api_v1_usage_limits__usage_limit_id__delete'}}}},\n",
       " {'paths': {'/api/v1/usage-limits/{usage_limit_id}': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'usage_limit_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Usage Limit Id'}}]}}}},\n",
       " {'paths': {'/api/v1/usage-limits/{usage_limit_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/usage-limits/{usage_limit_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/ttl-settings': {'get': {'tags': ['ttl-settings'],\n",
       "     'summary': 'List Ttl Settings',\n",
       "     'description': 'List out the configured TTL settings for a given tenant.',\n",
       "     'operationId': 'list_ttl_settings_api_v1_ttl_settings_get'}}}},\n",
       " {'paths': {'/api/v1/ttl-settings': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/TTLSettings'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Ttl Settings Api V1 Ttl Settings Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/ttl-settings': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/ttl-settings': {'put': {'tags': ['ttl-settings'],\n",
       "     'summary': 'Upsert Ttl Settings',\n",
       "     'operationId': 'upsert_ttl_settings_api_v1_ttl_settings_put'}}}},\n",
       " {'paths': {'/api/v1/ttl-settings': {'put': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UpsertTTLSettingsRequest'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/ttl-settings': {'put': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TTLSettings'}}}}}}}}},\n",
       " {'paths': {'/api/v1/ttl-settings': {'put': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/prompts/invoke_prompt': {'post': {'tags': ['prompts'],\n",
       "     'summary': 'Invoke Prompt',\n",
       "     'operationId': 'invoke_prompt_api_v1_prompts_invoke_prompt_post'}}}},\n",
       " {'paths': {'/api/v1/prompts/invoke_prompt': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/InvokePromptPayload'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/prompts/invoke_prompt': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/prompts/invoke_prompt': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/prompts/canvas': {'post': {'tags': ['prompts'],\n",
       "     'summary': 'Prompt Canvas',\n",
       "     'operationId': 'prompt_canvas_api_v1_prompts_canvas_post'}}}},\n",
       " {'paths': {'/api/v1/prompts/canvas': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PlaygroundPromptCanvasPayload'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/prompts/canvas': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/prompts/canvas': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks': {'get': {'tags': ['prompt-webhooks'],\n",
       "     'summary': 'List Prompt Webhooks',\n",
       "     'description': 'List all prompt webhooks for the current tenant.',\n",
       "     'operationId': 'list_prompt_webhooks_api_v1_prompt_webhooks_get'}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/PromptWebhook'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Prompt Webhooks Api V1 Prompt Webhooks Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks': {'post': {'tags': ['prompt-webhooks'],\n",
       "     'summary': 'Create Prompt Webhook',\n",
       "     'description': 'Create a new prompt webhook.',\n",
       "     'operationId': 'create_prompt_webhook_api_v1_prompt_webhooks_post'}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptWebhookCreate'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptWebhook'}}}}}}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks/{webhook_id}': {'get': {'tags': ['prompt-webhooks'],\n",
       "     'summary': 'Get Prompt Webhook',\n",
       "     'description': 'Get a specific prompt webhook.',\n",
       "     'operationId': 'get_prompt_webhook_api_v1_prompt_webhooks__webhook_id__get'}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks/{webhook_id}': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'webhook_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Webhook Id'}}]}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks/{webhook_id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptWebhook'}}}}}}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks/{webhook_id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks/{webhook_id}': {'patch': {'tags': ['prompt-webhooks'],\n",
       "     'summary': 'Update Prompt Webhook',\n",
       "     'description': 'Update a specific prompt webhook.',\n",
       "     'operationId': 'update_prompt_webhook_api_v1_prompt_webhooks__webhook_id__patch'}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks/{webhook_id}': {'patch': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'webhook_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Webhook Id'}}]}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks/{webhook_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptWebhookUpdate'}}}}}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks/{webhook_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptWebhook'}}}}}}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks/{webhook_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks/{webhook_id}': {'delete': {'tags': ['prompt-webhooks'],\n",
       "     'summary': 'Delete Prompt Webhook',\n",
       "     'description': 'Delete a specific prompt webhook.',\n",
       "     'operationId': 'delete_prompt_webhook_api_v1_prompt_webhooks__webhook_id__delete'}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks/{webhook_id}': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'webhook_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Webhook Id'}}]}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks/{webhook_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks/{webhook_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks/test': {'post': {'tags': ['prompt-webhooks'],\n",
       "     'summary': 'Test Prompt Webhook',\n",
       "     'description': 'Test a specific prompt webhook.',\n",
       "     'operationId': 'test_prompt_webhook_api_v1_prompt_webhooks_test_post'}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks/test': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PromptWebhookTest'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks/test': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'additionalProperties': {'type': 'string'},\n",
       "          'type': 'object',\n",
       "          'title': 'Response Test Prompt Webhook Api V1 Prompt Webhooks Test Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/prompt-webhooks/test': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces': {'get': {'tags': ['workspaces'],\n",
       "     'summary': 'List Workspaces',\n",
       "     'description': 'Get all workspaces visible to this auth in the current org. Does not create a new workspace/org.',\n",
       "     'operationId': 'list_workspaces_api_v1_workspaces_get'}}}},\n",
       " {'paths': {'/api/v1/workspaces': {'get': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'include_deleted',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Include Deleted'}}]}}}},\n",
       " {'paths': {'/api/v1/workspaces': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/TenantForUser'},\n",
       "          'title': 'Response List Workspaces Api V1 Workspaces Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces': {'post': {'tags': ['workspaces'],\n",
       "     'summary': 'Create Workspace',\n",
       "     'description': 'Create a new workspace.',\n",
       "     'operationId': 'create_workspace_api_v1_workspaces_post',\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/WorkspaceCreate'}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/app__schemas__Tenant'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/{workspace_id}': {'patch': {'tags': ['workspaces'],\n",
       "     'summary': 'Patch Workspace',\n",
       "     'operationId': 'patch_workspace_api_v1_workspaces__workspace_id__patch',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/{workspace_id}': {'patch': {'parameters': [{'name': 'workspace_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Workspace Id'}}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/{workspace_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/WorkspacePatch'}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/{workspace_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/app__schemas__Tenant'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/{workspace_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/{workspace_id}': {'delete': {'tags': ['workspaces'],\n",
       "     'summary': 'Delete Workspace',\n",
       "     'operationId': 'delete_workspace_api_v1_workspaces__workspace_id__delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/{workspace_id}': {'delete': {'parameters': [{'name': 'workspace_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Workspace Id'}}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/{workspace_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/{workspace_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending': {'get': {'tags': ['workspaces'],\n",
       "     'summary': 'List Pending Workspace Invites',\n",
       "     'description': 'Get all workspaces visible to this auth',\n",
       "     'operationId': 'list_pending_workspace_invites_api_v1_workspaces_pending_get'}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/app__schemas__Tenant'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Pending Workspace Invites Api V1 Workspaces Pending Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending': {'get': {'security': [{'Bearer Auth': []}]}},\n",
       "   '/api/v1/workspaces/pending/{id}': {'delete': {'tags': ['workspaces'],\n",
       "     'summary': 'Delete Pending Workspace Invite',\n",
       "     'operationId': 'delete_pending_workspace_invite_api_v1_workspaces_pending__id__delete'}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending/{id}': {'delete': {'security': [{'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Id'}}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending/{id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending/{id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending/{workspace_id}/claim': {'post': {'tags': ['workspaces'],\n",
       "     'summary': 'Claim Pending Workspace Invite',\n",
       "     'operationId': 'claim_pending_workspace_invite_api_v1_workspaces_pending__workspace_id__claim_post',\n",
       "     'deprecated': True,\n",
       "     'security': [{'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending/{workspace_id}/claim': {'post': {'parameters': [{'name': 'workspace_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Workspace Id'}}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending/{workspace_id}/claim': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending/{workspace_id}/claim': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/stats': {'get': {'tags': ['workspaces'],\n",
       "     'summary': 'Get Current Workspace Stats',\n",
       "     'operationId': 'get_current_workspace_stats_api_v1_workspaces_current_stats_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/stats': {'get': {'parameters': [{'name': 'tag_value_id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Tag Value Id'}}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/stats': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantStats'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/stats': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members': {'get': {'tags': ['workspaces'],\n",
       "     'summary': 'Get Current Workspace Members',\n",
       "     'operationId': 'get_current_workspace_members_api_v1_workspaces_current_members_get'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantMembers'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members': {'post': {'tags': ['workspaces'],\n",
       "     'summary': 'Add Member To Current Workspace',\n",
       "     'description': 'Add an existing organization member to the current workspace.'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members': {'post': {'operationId': 'add_member_to_current_workspace_api_v1_workspaces_current_members_post',\n",
       "     'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/IdentityCreate'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Identity'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/active': {'get': {'tags': ['workspaces'],\n",
       "     'summary': 'Get Current Active Workspace Members',\n",
       "     'operationId': 'get_current_active_workspace_members_api_v1_workspaces_current_members_active_get'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/active': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/active': {'get': {'parameters': [{'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 500,\n",
       "        'minimum': 1,\n",
       "        'default': 50,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'emails',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'array',\n",
       "        'items': {'type': 'string'},\n",
       "        'default': [],\n",
       "        'title': 'Emails'}},\n",
       "      {'name': 'ls_user_ids',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'array',\n",
       "        'items': {'type': 'string', 'format': 'uuid'},\n",
       "        'default': [],\n",
       "        'title': 'Ls User Ids'}},\n",
       "      {'name': 'user_ids',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'array',\n",
       "        'items': {'type': 'string', 'format': 'uuid'},\n",
       "        'default': [],\n",
       "        'title': 'User Ids'}}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/active': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/MemberIdentity'},\n",
       "          'title': 'Response Get Current Active Workspace Members Api V1 Workspaces Current Members Active Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/active': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/pending': {'get': {'tags': ['workspaces'],\n",
       "     'summary': 'Get Current Pending Workspace Members',\n",
       "     'operationId': 'get_current_pending_workspace_members_api_v1_workspaces_current_members_pending_get'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/pending': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/pending': {'get': {'parameters': [{'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 500,\n",
       "        'minimum': 1,\n",
       "        'default': 50,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'emails',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'array',\n",
       "        'items': {'type': 'string'},\n",
       "        'default': [],\n",
       "        'title': 'Emails'}}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/pending': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/PendingIdentity'},\n",
       "          'title': 'Response Get Current Pending Workspace Members Api V1 Workspaces Current Members Pending Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/pending': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/batch': {'post': {'tags': ['workspaces'],\n",
       "     'summary': 'Add Members To Current Workspace Batch',\n",
       "     'description': 'Batch invite up to 500 users to the current workspace and organization.'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/batch': {'post': {'operationId': 'add_members_to_current_workspace_batch_api_v1_workspaces_current_members_batch_post'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/batch': {'post': {'requestBody': {'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/PendingIdentityCreate'},\n",
       "         'type': 'array',\n",
       "         'title': 'Payloads'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/batch': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/PendingIdentity'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response Add Members To Current Workspace Batch Api V1 Workspaces Current Members Batch Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/batch': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/batch': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []},\n",
       "      {'Organization ID': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/shared': {'get': {'tags': ['workspaces'],\n",
       "     'summary': 'Get Shared Tokens',\n",
       "     'description': 'List all shared entities and their tokens by the workspace.',\n",
       "     'operationId': 'get_shared_tokens_api_v1_workspaces_current_shared_get'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/shared': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/shared': {'get': {'parameters': [{'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 50,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/shared': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantShareTokensResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/shared': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/shared': {'delete': {'tags': ['workspaces'],\n",
       "     'summary': 'Bulk Unshare Entities',\n",
       "     'description': 'Bulk unshare entities by share tokens for the workspace.',\n",
       "     'operationId': 'bulk_unshare_entities_api_v1_workspaces_current_shared_delete'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/shared': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantBulkUnshareRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/shared': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/shared': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}': {'delete': {'tags': ['workspaces'],\n",
       "     'summary': 'Delete Current Workspace Member',\n",
       "     'operationId': 'delete_current_workspace_member_api_v1_workspaces_current_members__identity_id__delete'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'identity_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Identity Id'}}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}': {'patch': {'tags': ['workspaces'],\n",
       "     'summary': 'Patch Current Workspace Member',\n",
       "     'operationId': 'patch_current_workspace_member_api_v1_workspaces_current_members__identity_id__patch'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}': {'patch': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'identity_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Identity Id'}}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/IdentityPatch'}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}/pending': {'delete': {'tags': ['workspaces'],\n",
       "     'summary': 'Delete Current Workspace Pending Member',\n",
       "     'operationId': 'delete_current_workspace_pending_member_api_v1_workspaces_current_members__identity_id__pending_delete'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}/pending': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}/pending': {'delete': {'parameters': [{'name': 'identity_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Identity Id'}}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}/pending': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}/pending': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "json_splitter=RecursiveJsonSplitter(max_chunk_size=300)\n",
    "json_chunks=json_splitter.split_json(json_data)\n",
    "json_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62f82b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'openapi': '3.1.0',\n",
       " 'info': {'title': 'LangSmith', 'version': '0.1.0'},\n",
       " 'paths': {'/api/v1/sessions/{session_id}/dashboard': {'post': {'tags': ['tracer-sessions'],\n",
       "    'summary': 'Get Tracing Project Prebuilt Dashboard',\n",
       "    'description': 'Get a prebuilt dashboard for a tracing project.'}}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9debf28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paths': {'/api/v1/sessions/{session_id}/dashboard': {'post': {'operationId': 'get_tracing_project_prebuilt_dashboard_api_v1_sessions__session_id__dashboard_post',\n",
       "    'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_chunks[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9194c4",
   "metadata": {},
   "source": [
    "A **recursive JSON splitter** is a method used to **break down large or deeply nested JSON data** into smaller, more manageable chunksâ€”typically for processing with language models like GPT.\n",
    "\n",
    "This technique is especially useful when dealing with:\n",
    "\n",
    "* Large JSON documents\n",
    "* Nested dictionaries and lists\n",
    "* APIs that return complex data\n",
    "* Streaming or chunked ingestion into LLM pipelines\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ” Why \"Recursive\"?\n",
    "\n",
    "Because the splitter **recursively traverses** the structure of the JSONâ€”exploring dictionaries and lists inside dictionaries and listsâ€”until it finds atomic elements (like strings, numbers), and breaks them into chunks without losing the hierarchy.\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ§  Use Case in LLMs / LangChain\n",
    "\n",
    "LangChain and other frameworks use recursive splitting to:\n",
    "\n",
    "* **Preserve context** in nested JSON\n",
    "* Avoid hallucination by keeping chunk boundaries aligned with logical JSON blocks\n",
    "* Enable **semantic chunking** for RAG or summarization\n",
    "\n",
    "---\n",
    "\n",
    "#### âœ… Example\n",
    "\n",
    "Suppose you have the following JSON:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"patient\": {\n",
    "    \"name\": \"John\",\n",
    "    \"age\": 30,\n",
    "    \"medical_history\": [\n",
    "      {\n",
    "        \"condition\": \"Diabetes\",\n",
    "        \"medications\": [\"Metformin\", \"Insulin\"]\n",
    "      },\n",
    "      {\n",
    "        \"condition\": \"Hypertension\",\n",
    "        \"medications\": [\"Amlodipine\"]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "A **recursive JSON splitter** would:\n",
    "\n",
    "* Traverse into `\"patient\"` â†’ `\"medical_history\"` â†’ individual entries\n",
    "* Split **each condition block** into a separate chunk:\n",
    "\n",
    "  * Chunk 1: `{\"condition\": \"Diabetes\", \"medications\": [\"Metformin\", \"Insulin\"]}`\n",
    "  * Chunk 2: `{\"condition\": \"Hypertension\", \"medications\": [\"Amlodipine\"]}`\n",
    "\n",
    "This is **better than naive string chunking**, because it preserves meaning and structure.\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ”§ In LangChain\n",
    "\n",
    "If you're using LangChain's `RecursiveJsonSplitter`, it works like this:\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import RecursiveJsonSplitter\n",
    "\n",
    "splitter = RecursiveJsonSplitter(max_chunk_size=500, chunk_overlap=0)\n",
    "chunks = splitter.split_json(json_data)\n",
    "```\n",
    "\n",
    "* `max_chunk_size`: Defines the size limit per chunk (based on character count or tokens)\n",
    "* `chunk_overlap`: Optional overlap between chunks to preserve context\n",
    "* Works recursively to maintain JSON integrity\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ“Œ Summary\n",
    "\n",
    "| Feature   | Description                                                               |\n",
    "| --------- | ------------------------------------------------------------------------- |\n",
    "| Purpose   | Break down large/nested JSON into manageable chunks                       |\n",
    "| Recursive | Traverses dictionaries and lists recursively                              |\n",
    "| Benefits  | Preserves structure, avoids hallucination, better for LLMs                |\n",
    "| Used in   | LLM preprocessing, LangChain, RAG pipelines, indexing large API responses |\n",
    "\n",
    "Would you like a working Python example?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d98477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
