{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "o7F9oe3WJuXp",
      "metadata": {
        "id": "o7F9oe3WJuXp"
      },
      "source": [
        "# Lang Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6454e5e",
      "metadata": {
        "id": "f6454e5e"
      },
      "source": [
        "## Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "582fbea0",
      "metadata": {
        "id": "582fbea0"
      },
      "source": [
        "### Wikipedia API Wrapper Tool (Summary from wikipedia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "09df7eeb",
      "metadata": {
        "id": "09df7eeb"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools import WikipediaQueryRun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "27350042",
      "metadata": {
        "id": "27350042"
      },
      "outputs": [],
      "source": [
        "from langchain_community.utilities import WikipediaAPIWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "349ce79b",
      "metadata": {
        "id": "349ce79b"
      },
      "outputs": [],
      "source": [
        "api_wrapper=WikipediaAPIWrapper(top_k_results=5,doc_content_chars_max= 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fde85dee",
      "metadata": {
        "id": "fde85dee"
      },
      "outputs": [],
      "source": [
        "wiki_tool=WikipediaQueryRun(api_wrapper=api_wrapper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "98b780a7",
      "metadata": {
        "id": "98b780a7",
        "outputId": "47a97f50-8dd2-4160-f4df-6e2266c3966d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'wikipedia'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wiki_tool.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9845643a",
      "metadata": {
        "id": "9845643a",
        "outputId": "58596aef-ddd7-4cbc-8235-be789a90c934"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wiki_tool.description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e0376b73",
      "metadata": {
        "id": "e0376b73",
        "outputId": "97d249c9-27e6-4b81-c186-b568069dc4a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': {'description': 'query to look up on wikipedia',\n",
              "  'title': 'Query',\n",
              "  'type': 'string'}}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wiki_tool.args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1e4a274f",
      "metadata": {
        "id": "1e4a274f",
        "outputId": "c5df7a65-a078-4f4c-b04f-382bcb0b82df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Page: Elon Musk\\nSummary: Elon Reeve Musk ( EE-lon; born June 28, 1971) is a businessman. He is known for his leadership of Tesla, SpaceX, X (formerly Twitter), and the Department of Government Efficiency (DOGE). Musk has been considered the wealthiest person in the world since 2021; as of May 2025, Forbes estimates his net worth to be US$424.7 billion. \\nBorn to a wealthy family in Pretoria, South Africa, Musk emigrated in 1989 to Canada. He received bachelor's degrees from the University of Penn\""
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wiki_tool.run({\"query\":\"elon musk\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "740fa568",
      "metadata": {
        "id": "740fa568",
        "outputId": "5bd6bcf1-b81e-433e-cc63-0656ff181f29"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file c:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Page: Royal Challengers Bengaluru\\nSummary: The Royal Challengers Bengaluru, formerly Royal Challengers Bangalore, also known as RCB, are a professional Twenty20 cricket team based in Bengaluru, Karnataka, that competes in the Indian Premier League (IPL). Founded in 2008 by United Spirits, the team's home ground is M. Chinnaswamy Stadium. They won their first title in 2025. The team finished as the runners-up on three occasions: in 2009, 2011, and 2016. They have also qualified for the playoffs i\""
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wiki_tool.run(\"RCB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8500a32a",
      "metadata": {
        "id": "8500a32a"
      },
      "source": [
        "### Youtube Search Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a4018c56",
      "metadata": {
        "id": "a4018c56"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools import YouTubeSearchTool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "098d336c",
      "metadata": {
        "id": "098d336c"
      },
      "outputs": [],
      "source": [
        "tool=YouTubeSearchTool()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5750f96f",
      "metadata": {
        "id": "5750f96f",
        "outputId": "97210823-5815-43d1-bb6f-c38cd4ca2fc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'youtube_search'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f2d2e6ea",
      "metadata": {
        "id": "f2d2e6ea",
        "outputId": "f17e3c17-084d-4a17-edac-403b8bc30517"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'search for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool.description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "9dcb154b",
      "metadata": {
        "id": "9dcb154b",
        "outputId": "bc3614eb-e429-414a-e9c0-414978741564"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"['https://www.youtube.com/watch?v=Jj1-zb38Yfw&pp=ygUKQWdlbnRpYyBBSQ%3D%3D', 'https://www.youtube.com/watch?v=dIb-DujRNEo&pp=ygUKQWdlbnRpYyBBSQ%3D%3D']\""
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool.run(\"Agentic AI\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2814b8c",
      "metadata": {
        "id": "c2814b8c"
      },
      "source": [
        "### Tavily Search Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "d3a9b887",
      "metadata": {
        "id": "d3a9b887"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ee5261b2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b98b226a",
      "metadata": {
        "id": "b98b226a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "a9cf56f1",
      "metadata": {
        "id": "a9cf56f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\saina\\AppData\\Local\\Temp\\ipykernel_1796\\1068719361.py:1: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  tool=TavilySearchResults(tavily_api_key=TAVILY_API_KEY)\n"
          ]
        }
      ],
      "source": [
        "tool=TavilySearchResults(tavily_api_key=TAVILY_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "503163b0",
      "metadata": {
        "id": "503163b0",
        "outputId": "fdf900d7-18ee-40ac-d312-efb5eaaa67b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'title': \"Bengaluru stampede case: What we know so far on RCB's ...\",\n",
              "  'url': 'https://timesofindia.indiatimes.com/sports/cricket/ipl/top-stories/bengaluru-stampede-case-what-we-know-so-far-on-rcbs-celebrations-that-turned-catastrophic/articleshow/121670873.cms',\n",
              "  'content': \"[Follow us](https://news.google.com/publications/CAAqBwgKMM6y_Qowwu70Ag)\\n\\nRoyal Challengers Bengaluru's IPL victory celebrations turned tragic as a stampede at M Chinnaswamy Stadium resulted in 11 deaths and 75 injuries. FIRs have been filed against RCB, events organisers DNA, and Karnataka State Cricket Association for alleged negligence. The Karnataka High Court has sought a report from the government while arrests have been and officials suspended.\\n\\nRead More [...] [](https://timesofindia.indiatimes.com/city/bengaluru/celebrations-turn-tragic-bloodbath-at-rcbs-maiden-ipl-trophy-victory-day-to-remember-forever-see-pics/photostory/121646177.cms)[Celebrations turn tragic: Bloodbath at RCB’s maiden IPL trophy victory, day to remember forever | see pics Lakhs of fans had gathered around Chinnaswamy Stadium, celebrating RCB’s historic first-ever IPL title with joy and excitement.Times Of\",\n",
              "  'score': 0.8455478},\n",
              " {'title': 'Chinnaswamy Stadium Stampede: What triggered the deadly chaos ...',\n",
              "  'url': 'https://m.economictimes.com/news/bengaluru-news/chinnaswamy-stadium-stampede-what-triggered-the-chaos-that-turned-deadly-in-rcbs-victory-celebration/articleshow/121624517.cms',\n",
              "  'content': \"![Image 3](https://img.etimg.com/thumb/msid-121625936,width-300,height-225,imgsize-121910,resizemode-75/.jpg)\\n\\nRCB's IPL victory celebrations turn tragic: Stampede in Bengaluru; 11 dead, 33 injured\\n\\nThe celebrations after RCB took a heart-breaking turn when a deadly [stampede](https://m.economictimes.com/topic/stampede) near the M Chinnaswamy Stadium killed over 11 fans dead and nearly 33 others injured.\",\n",
              "  'score': 0.83710164},\n",
              " {'title': \"Several Killed as RCB's Victory Celebration Turns Deadly - YouTube\",\n",
              "  'url': 'https://www.youtube.com/watch?v=gz8chxY7elU',\n",
              "  'content': \"At least 11 people were killed and 30 injured in a stampede outside the Chinnaswamy cricket stadium in Bengaluru. The incident happened during the Royal Challengers' victory celebrations after their first IPL triumph in 18 years. Did the state government underestimate the rush? Were crowd control measures not in place? Palki Sharma tells you.\\n\\n--- [...] It was supposed to be a day of pure joy, of celebration and pride. Instead, Bengaluru is in shock today. I'm sure you've seen the news and the pictures. Bengaluru was all decked up for a massive celebration today. Their IPL team had finally won the tournament. The Royal Challengers beat Punjab Kings yesterday. It was their first IPL trophy in 18 years. Now the RCB fans are a very passionate lot. Plus they've been waiting for a win since 2008. So they packed the streets of Bengaluru in [...] soon the fan frenzy turned fatal. The exact details are not clear yet but reports say the rush led to a stampede. At least 11 people were killed, including children, and more than 30 were injured. Like I said, the exact sequence of events is unclear, but these pictures give you an idea. Uh you can see fans climbing up fences and trees. In some places, the police pushed back with force. We will show you the pictures, but as always, viewer discretion is advised. [Applause] [Music] [Applause] Such\",\n",
              "  'score': 0.83290404},\n",
              " {'title': 'RCB victory parade stampede updates: Bengaluru city chief B ...',\n",
              "  'url': 'https://www.thehindu.com/news/national/rcb-ipl-victory-parade-stampede-death-toll-virat-kohli-chinnaswamy-stadium-live/article69656707.ece',\n",
              "  'content': 'Sachin Tendulkar has offered his condolences on the loss of 11 lives in a stampede outside Bengaluru’s Chinnaswamy Stadium during RCB’s IPL victory celebrations, describing the incident as “beyond tragic”.\\n\\nOn the day the stampede broke out in Bengaluru while celebrating the victory of Royal Challengers Bengaluru (RCB) in the IPL final, killing 11 and leaving scores injured, the Namma Metro witnessed unprecedented footfall. [...] A stampede that broke out near the Chinnaswamy stadium in Bengaluru, after fans gathered to celebrate Royal Challengers Bengaluru’s IPL win, led to the [deaths of 11 persons and injuries to 33](https://www.thehindu.com/news/cities/bangalore/rcb-ipl-victory-celebrations-stampede-bengaluru-death-toll/article69656538.ece) on Wednesday (June 4, 2025). The tragedy unfolded near the gates of the stadium, where over 2 lakh fans had gathered to mark RCB’s historic first title win in 18 years. [...] In a post on X, Mr. Bommai said following the Royal Challengers Bangalore (RCB) team lifting the IPL trophy, the state government hastily organised a victory celebration event without proper planning, leading to a tragic stampede that claimed the lives of more than ten innocent people. Organising two events in a hurry without any prior preparation and allowing an overwhelming number of people to attend both clearly demonstrates the government’s complete negligence and irresponsibility.',\n",
              "  'score': 0.82492816},\n",
              " {'title': \"How did celebration of RCB's historic win in IPL spiral into chaos ...\",\n",
              "  'url': 'https://www.thehindu.com/news/national/karnataka/how-did-celebration-of-rcbs-historic-win-in-ipl-spiral-into-chaos-and-crisis-explained/article69668074.ece',\n",
              "  'content': 'A stampede during RCB’s victory celebrations in Bengaluru on June 4 claimed 11 lives and left several others with injuries, turning a moment of triumph into tragedy. Facing a backlash for mismanagement and hurried planning, the Congress government in Karnataka suspended top police officials [...] Remove [SEE ALL](https://www.thehindu.com/myaccount/?tab=bookmarks)\\n\\nPRINT\\n\\n![Image 12: Footwear left behind by fans of Royal Challenge Bengaluru (RCB) after a stampede at the victory celebrations, in Bengaluru on June 5, 2025. ](https://www.thehindu.com/theme/images/th-online/1x1_spacer.png)\\n\\nFootwear left behind by fans of Royal Challenge Bengaluru (RCB) after a stampede at the victory celebrations, in Bengaluru on June 5, 2025. | Photo Credit: SUDHAKARA JAIN\\n\\n#### The story so far',\n",
              "  'score': 0.818055}]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool.invoke({\"query\":\"what happend in RCB victory celebration?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f1f2463",
      "metadata": {
        "id": "4f1f2463"
      },
      "source": [
        "### Custom tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "fc844561",
      "metadata": {
        "id": "fc844561"
      },
      "outputs": [],
      "source": [
        "def multiply(a:int,b:int)->int:\n",
        "    return a*b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7f37c964",
      "metadata": {
        "id": "7f37c964",
        "outputId": "a03c4208-06a7-48f0-beec-4f0f98e40d80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multiply(10,20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "39fe75c0",
      "metadata": {
        "id": "39fe75c0",
        "outputId": "8a8767ab-4654-462a-c441-058752976154"
      },
      "outputs": [],
      "source": [
        "# multiply.run(10,20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a8da091",
      "metadata": {
        "id": "6a8da091"
      },
      "source": [
        "---------------------------------------------------------------------------\n",
        "AttributeError                            Traceback (most recent call last)\n",
        "Cell In[52], line 1\n",
        "----> 1 multiply.run(10,20)\n",
        "\n",
        "AttributeError: 'function' object has no attribute 'run'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "480b255d",
      "metadata": {
        "id": "480b255d",
        "outputId": "f1fa9034-1d50-4612-a949-462875a744cf"
      },
      "outputs": [],
      "source": [
        "# multiply.invoke(10,20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b0ff8c1",
      "metadata": {
        "id": "3b0ff8c1"
      },
      "source": [
        "---------------------------------------------------------------------------\n",
        "AttributeError                            Traceback (most recent call last)\n",
        "Cell In[53], line 1\n",
        "----> 1 multiply.invoke(10,20)\n",
        "\n",
        "AttributeError: 'function' object has no attribute 'invoke'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "2c3b4b97",
      "metadata": {
        "id": "2c3b4b97"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import tool\n",
        "@tool\n",
        "def multiply(a:int,b:int)->int:\n",
        "    '''this tool is for the multiplication'''\n",
        "    return a*b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "4bd8cbf7",
      "metadata": {
        "id": "4bd8cbf7",
        "outputId": "4b1f0a31-6d04-480e-a189-03b8dccc7038"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multiply.invoke({\"a\":10,\"b\":20})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "888d6268",
      "metadata": {
        "id": "888d6268",
        "outputId": "0a346cf1-97e9-434e-a961-3527af1184f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'multiply'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multiply.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "420df80b",
      "metadata": {
        "id": "420df80b",
        "outputId": "9380cbc6-e834-45d8-bba7-d84ba349bfea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'this tool is for the multiplication'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multiply.description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "365e78d7",
      "metadata": {
        "id": "365e78d7",
        "outputId": "1076e637-614f-4907-df66-c1789e10e940"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'a': {'title': 'A', 'type': 'integer'},\n",
              " 'b': {'title': 'B', 'type': 'integer'}}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multiply.args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "5941e644",
      "metadata": {
        "id": "5941e644"
      },
      "outputs": [],
      "source": [
        "def get_word_length(word:str)->int:\n",
        "    return len(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "d56fafdd",
      "metadata": {
        "id": "d56fafdd",
        "outputId": "1566e601-3088-4312-d3db-c395a7facd75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_word_length(\"Sainadh bahadursha\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "b176fc8a",
      "metadata": {
        "id": "b176fc8a",
        "outputId": "5d80649d-6e89-4189-f913-e1640286aa9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_word_length(\"narendra modi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "c1cfb06e",
      "metadata": {
        "id": "c1cfb06e"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def get_word_length(word:str)->int:\n",
        "    \"\"\"this function is calculating a length of the word\"\"\"\n",
        "    return len(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "efd94c98",
      "metadata": {
        "id": "efd94c98",
        "outputId": "54bbff7d-bfed-47f5-b1d6-6c9e7222449f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'get_word_length'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_word_length.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "d7a4cc82",
      "metadata": {
        "id": "d7a4cc82",
        "outputId": "ee26eba5-b4c2-48b2-8182-e9c6e7a9c9f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'this function is calculating a length of the word'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_word_length.description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "5bd42de8",
      "metadata": {
        "id": "5bd42de8",
        "outputId": "acc39742-b57a-4335-beba-f2cf0841ee47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'word': {'title': 'Word', 'type': 'string'}}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_word_length.args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "88d450b3",
      "metadata": {
        "id": "88d450b3",
        "outputId": "bdb847dd-6916-439b-f5f6-54953f829c24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\saina\\AppData\\Local\\Temp\\ipykernel_1796\\1704822211.py:1: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  get_word_length(\"sainadh\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_word_length(\"sainadh\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "784c9efc",
      "metadata": {
        "id": "784c9efc",
        "outputId": "42124ab2-c1f1-4778-8d47-e8e267e47845"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_word_length.invoke(\"sainadh\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ae74a74",
      "metadata": {
        "id": "8ae74a74"
      },
      "source": [
        "### Gmail tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "02d0863e",
      "metadata": {
        "id": "02d0863e"
      },
      "outputs": [],
      "source": [
        "# @tool\n",
        "# def call_gmail_api(args):\n",
        "#     \"\"\"this is my gmail api calling funtion\"\"\"\n",
        "#     pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "71b335ff",
      "metadata": {
        "id": "71b335ff"
      },
      "outputs": [],
      "source": [
        "# from langchain.agents import tool\n",
        "# import os\n",
        "# import base64\n",
        "# from email import message_from_bytes\n",
        "# from google.auth.transport.requests import Request\n",
        "# from google.oauth2.credentials import Credentials\n",
        "# from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "# from googleapiclient.discovery import build\n",
        "\n",
        "# SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']\n",
        "# from langchain.tools import tool\n",
        "# from pydantic import BaseModel, Field\n",
        "\n",
        "# class GmailArgs(BaseModel):\n",
        "#     max_results: int = Field(..., description=\"Number of unread emails to fetch\")\n",
        "\n",
        "# @tool\n",
        "# def call_gmail_api(args: GmailArgs) -> str:\n",
        "#     \"\"\"\n",
        "#     Reads unread emails from Gmail inbox using Gmail API.\n",
        "#     Args:\n",
        "#         max_results (int): Maximum number of unread emails to fetch. Default is 5.\n",
        "#     Returns:\n",
        "#         A string summary of unread emails.\n",
        "#     \"\"\"\n",
        "#     max_results = args.max_results\n",
        "\n",
        "#     try:\n",
        "#         creds = None\n",
        "#         if os.path.exists('token.json'):\n",
        "#             creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
        "#         if not creds or not creds.valid:\n",
        "#             if creds and creds.expired and creds.refresh_token:\n",
        "#                 creds.refresh(Request())\n",
        "#             else:\n",
        "#                 flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)\n",
        "#                 creds = flow.run_local_server(port=0)\n",
        "#             with open('token.json', 'w') as token:\n",
        "#                 token.write(creds.to_json())\n",
        "\n",
        "#         service = build('gmail', 'v1', credentials=creds)\n",
        "#         results = service.users().messages().list(userId='me', labelIds=['INBOX', 'UNREAD'], maxResults=max_results).execute()\n",
        "#         messages = results.get('messages', [])\n",
        "\n",
        "#         if not messages:\n",
        "#             return \"No unread emails found.\"\n",
        "\n",
        "#         summaries = []\n",
        "#         for msg in messages:\n",
        "#             msg_data = service.users().messages().get(userId='me', id=msg['id']).execute()\n",
        "#             headers = msg_data['payload']['headers']\n",
        "#             subject = next((h['value'] for h in headers if h['name'] == 'Subject'), '(No Subject)')\n",
        "#             sender = next((h['value'] for h in headers if h['name'] == 'From'), '(Unknown Sender)')\n",
        "#             snippet = msg_data.get('snippet', '')\n",
        "#             summaries.append(f\"From: {sender}\\nSubject: {subject}\\nSnippet: {snippet}\")\n",
        "\n",
        "#         return \"\\n\\n\".join(summaries)\n",
        "\n",
        "#     except Exception as e:\n",
        "#         return f\"Error accessing Gmail API: {e}\"\n",
        "\n",
        "# # @tool\n",
        "# # def call_gmail_api(max_results: int = 5) -> str:\n",
        "# #     \"\"\"\n",
        "# #     Reads unread emails from Gmail inbox using Gmail API.\n",
        "# #     Args:\n",
        "# #         max_results (int): Maximum number of unread emails to fetch. Default is 5.\n",
        "# #     Returns:\n",
        "# #         A string summary of unread emails.\n",
        "# #     \"\"\"\n",
        "# #     try:\n",
        "# #         creds = None\n",
        "# #         if os.path.exists('token.json'):\n",
        "# #             creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
        "# #         if not creds or not creds.valid:\n",
        "# #             if creds and creds.expired and creds.refresh_token:\n",
        "# #                 creds.refresh(Request())\n",
        "# #             else:\n",
        "# #                 flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)\n",
        "# #                 creds = flow.run_local_server(port=0)\n",
        "# #             with open('token.json', 'w') as token:\n",
        "# #                 token.write(creds.to_json())\n",
        "\n",
        "# #         service = build('gmail', 'v1', credentials=creds)\n",
        "# #         results = service.users().messages().list(userId='me', labelIds=['INBOX', 'UNREAD'], maxResults=max_results).execute()\n",
        "# #         messages = results.get('messages', [])\n",
        "\n",
        "# #         if not messages:\n",
        "# #             return \"No unread emails found.\"\n",
        "\n",
        "# #         summaries = []\n",
        "# #         for msg in messages:\n",
        "# #             msg_data = service.users().messages().get(userId='me', id=msg['id']).execute()\n",
        "# #             headers = msg_data['payload']['headers']\n",
        "# #             subject = next((h['value'] for h in headers if h['name'] == 'Subject'), '(No Subject)')\n",
        "# #             sender = next((h['value'] for h in headers if h['name'] == 'From'), '(Unknown Sender)')\n",
        "# #             snippet = msg_data.get('snippet', '')\n",
        "# #             summaries.append(f\"From: {sender}\\nSubject: {subject}\\nSnippet: {snippet}\")\n",
        "\n",
        "# #         return \"\\n\\n\".join(summaries)\n",
        "\n",
        "# #     except Exception as e:\n",
        "# #         return f\"Error accessing Gmail API: {e}\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "6eee951c",
      "metadata": {
        "id": "6eee951c",
        "outputId": "f89f26fd-0835-4a7f-d7ec-3de2f111481a"
      },
      "outputs": [],
      "source": [
        "# # from langchain.agents import initialize_agent\n",
        "# # from langchain.agents.agent_types import AgentType\n",
        "# # from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# # # Register the tool\n",
        "# # tools = [call_gmail_api]\n",
        "\n",
        "# # llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# # agent = initialize_agent(\n",
        "# #     tools=tools,\n",
        "# #     llm=llm,\n",
        "# #     agent_type=AgentType.OPENAI_FUNCTIONS,\n",
        "# #     verbose=True,\n",
        "# # )\n",
        "\n",
        "# # # Example query\n",
        "# # response = agent.run(\"Read my last 3 unread emails.\")\n",
        "# # print(response)\n",
        "\n",
        "# from langchain.agents import initialize_agent, AgentType\n",
        "# from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# tools = [call_gmail_api]\n",
        "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# agent = initialize_agent(\n",
        "#     tools=tools,\n",
        "#     llm=llm,\n",
        "#     agent_type=AgentType.OPENAI_FUNCTIONS,  # Requires structured input\n",
        "#     verbose=True,\n",
        "# )\n",
        "\n",
        "# # Test\n",
        "# response = agent.run(\"Get my last 3 unread emails.\")\n",
        "# print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e677c1ba",
      "metadata": {
        "id": "e677c1ba"
      },
      "source": [
        "## Langgraph Intro 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "f5ef2219",
      "metadata": {
        "id": "f5ef2219"
      },
      "outputs": [],
      "source": [
        "def function1(input1):\n",
        "    return input1 + \" from first function\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "3e85c2f7",
      "metadata": {
        "id": "3e85c2f7"
      },
      "outputs": [],
      "source": [
        "def function2(input2):\n",
        "    return input2 + \" Bahadursha from second function\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "37b6edbc",
      "metadata": {
        "id": "37b6edbc"
      },
      "outputs": [],
      "source": [
        "def function3(input3):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "9851a3ef",
      "metadata": {
        "id": "9851a3ef",
        "outputId": "af639098-380c-469d-8910-dff99ad0cced"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Sainadh from first function'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "function1(\"Sainadh\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "e030fa62",
      "metadata": {
        "id": "e030fa62",
        "outputId": "e02d9c96-888a-4de5-aa33-b31a94fd520c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Bahadursha Bahadursha from second function'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "function2(\"Bahadursha\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "36a9e3dc",
      "metadata": {
        "id": "36a9e3dc"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "1975fb71",
      "metadata": {
        "id": "1975fb71"
      },
      "outputs": [],
      "source": [
        "workflow1 = Graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "2acc4344",
      "metadata": {
        "id": "2acc4344",
        "outputId": "c8d89e42-7502-466e-bba9-5f5e29b98d66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94ae2450>"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow1.add_node(\"fun1\",function1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "0eb9b0a9",
      "metadata": {
        "id": "0eb9b0a9",
        "outputId": "69600744-a866-491d-e520-623dddc0aa42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94ae2450>"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow1.add_node(\"fun2\",function2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "4de9ba38",
      "metadata": {
        "id": "4de9ba38",
        "outputId": "02700687-e4ab-4897-fda5-7f7e5a5fc19c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94ae2450>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow1.add_edge(\"fun1\",\"fun2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "67deaa83",
      "metadata": {
        "id": "67deaa83",
        "outputId": "22fef9fd-4ca7-4c0e-dac0-47a32df5e531"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94ae2450>"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow1.set_entry_point(\"fun1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "ffe2166b",
      "metadata": {
        "id": "ffe2166b",
        "outputId": "879bb30e-27fa-4c8f-f9f7-b7e0e22cdf39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94ae2450>"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow1.set_finish_point(\"fun2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "72631973",
      "metadata": {
        "id": "72631973"
      },
      "outputs": [],
      "source": [
        "app = workflow1.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "a2eece4f",
      "metadata": {
        "id": "a2eece4f"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "18685ba4",
      "metadata": {
        "id": "18685ba4",
        "outputId": "f740bf65-8e3a-4fff-e6a5-cde9652e08a6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Image(app.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "e402942c",
      "metadata": {
        "id": "e402942c",
        "outputId": "d6a6fa74-d02f-4bde-eb3f-47a058820abc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hi this is Sainadh from first function Bahadursha from second function'"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app.invoke(\"Hi this is Sainadh\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "38ff59b1",
      "metadata": {
        "id": "38ff59b1",
        "outputId": "aa4f00d5-269d-4998-eece-814c564d57dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here is output from fun1\n",
            "___________\n",
            "hi this is Sainadh from first function\n",
            "\n",
            "\n",
            "here is output from fun2\n",
            "___________\n",
            "hi this is Sainadh from first function Bahadursha from second function\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for output in app.stream(\"hi this is Sainadh\"):\n",
        "    for key,value in output.items():\n",
        "        print(f\"here is output from {key}\")\n",
        "        print(\"___________\")\n",
        "        print(value)\n",
        "        print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "3474cabe",
      "metadata": {
        "id": "3474cabe"
      },
      "outputs": [],
      "source": [
        "def llm(input):\n",
        "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "    model=ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
        "    output=model.invoke(input)\n",
        "    return output.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "add673f5",
      "metadata": {
        "id": "add673f5"
      },
      "outputs": [],
      "source": [
        "def token_counter(input):\n",
        "    token=input.split()\n",
        "    token_number=len(token)\n",
        "    return f\"total token number in the generated answer is {token_number}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "237c5260",
      "metadata": {
        "id": "237c5260"
      },
      "outputs": [],
      "source": [
        "workflow2 = Graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "8164e715",
      "metadata": {
        "id": "8164e715",
        "outputId": "8afb391b-122f-4749-961c-c9880c033154"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94c5edd0>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow2.add_node(\"My_LLM\",llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "eb3a2ab7",
      "metadata": {
        "id": "eb3a2ab7",
        "outputId": "c770d42d-ee7d-4c5f-9b66-ca5c3cc23642"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94c5edd0>"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow2.add_node(\"LLM_Output_Token_Counter\",token_counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "74aa047b",
      "metadata": {
        "id": "74aa047b",
        "outputId": "bfcee4ec-f78f-412a-8503-d1dbb7d30def"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94c5edd0>"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow2.add_edge(\"My_LLM\",\"LLM_Output_Token_Counter\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "8bc79c3b",
      "metadata": {
        "id": "8bc79c3b",
        "outputId": "d388ba76-a665-47ed-c05f-6b7cf99d6b22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94c5edd0>"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow2.set_entry_point(\"My_LLM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "01142311",
      "metadata": {
        "id": "01142311",
        "outputId": "ea81246d-3a1c-4b86-fb86-49461b14fc99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94c5edd0>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow2.set_finish_point(\"LLM_Output_Token_Counter\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "48d7a68a",
      "metadata": {
        "id": "48d7a68a"
      },
      "outputs": [],
      "source": [
        "app=workflow2.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "75ae064f",
      "metadata": {
        "id": "75ae064f",
        "outputId": "32a75083-4845-4922-edda-b413da62c4be"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Image(app.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "d42406d1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "0991d0f0",
      "metadata": {
        "id": "0991d0f0",
        "outputId": "5509dc3c-9849-45fa-e253-8fb4412ec774"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'total token number in the generated answer is 68'"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app.invoke(\"can you tell me about the india's capital?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "37ea37d8",
      "metadata": {
        "id": "37ea37d8",
        "outputId": "3e9eab31-fac1-4811-c3a0-3ecc43649096"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'total token number in the generated answer is 667'"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app.invoke(\"tell me about the tata enterpirse in very detail.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "04d63af3",
      "metadata": {
        "id": "04d63af3",
        "outputId": "47c967df-ac77-4392-8613-815f7404df73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here is output from My_LLM\n",
            "_______\n",
            "Tata Enterprises, more accurately referred to as the **Tata Group**, is a massive Indian multinational conglomerate headquartered in Mumbai, Maharashtra.  It's not a single entity but a network of over 100 operating companies, spanning diverse sectors and employing millions of people globally.  Understanding its complexity requires looking at several key aspects:\n",
            "\n",
            "**I. History and Structure:**\n",
            "\n",
            "* **Origins:** The group traces its roots back to 1868 when Jamsetji Tata founded the Tata & Sons trading company.  His vision extended beyond profit, encompassing social responsibility and nation-building, a philosophy that continues to define the group.\n",
            "* **Structure:**  The Tata Group isn't a typical corporation.  It's a complex web of independent companies, many publicly listed, held together by a shared philosophy and the overarching influence of Tata Sons, the holding company.  Tata Sons owns substantial stakes in many group companies, but doesn't directly manage their day-to-day operations.  Instead, each company has its own board and management team.\n",
            "* **Trusts:**  A significant portion of Tata Sons is owned by philanthropic trusts, including the Sir Dorabji Tata Trust and the Sir Ratan Tata Trust.  These trusts play a crucial role in shaping the group's social responsibility initiatives and ensuring long-term sustainability.  Their ownership structure contributes to the group's unique character and long-term focus.\n",
            "* **Leadership:** The group's leadership has historically been characterized by strong, visionary leaders, starting with Jamsetji Tata himself and continuing through figures like J.R.D. Tata and Ratan Tata.  The chairman of Tata Sons plays a crucial role in setting the overall direction and strategy for the entire group.\n",
            "\n",
            "**II. Business Sectors:**\n",
            "\n",
            "The Tata Group's reach is extraordinary, encompassing nearly every major sector of the economy.  Some key areas include:\n",
            "\n",
            "* **Automotive:** Tata Motors, one of the largest automobile manufacturers in India, produces passenger cars, commercial vehicles, and even luxury vehicles (Jaguar Land Rover).\n",
            "* **Steel:** Tata Steel is a global steel giant, with operations across multiple countries.\n",
            "* **Information Technology:** Tata Consultancy Services (TCS) is a leading global IT services and consulting company, employing hundreds of thousands. Tata Elxsi is another significant player in the IT space, focusing on embedded systems, design, and software.\n",
            "* **Consumer Goods:**  The group has a substantial presence in consumer goods, with brands like Tata Tea, Tata Salt, and Tata Coffee dominating the Indian market.  They also have interests in packaged foods and personal care products.\n",
            "* **Chemicals:** Tata Chemicals is a significant player in the chemicals industry, producing a wide range of products.\n",
            "* **Energy:** Tata Power is a major player in the Indian power sector, involved in generation, transmission, and distribution.\n",
            "* **Telecommunications:** Tata Teleservices was once a major player, though it has since undergone restructuring.\n",
            "* **Hospitality:**  The Indian Hotels Company Limited (IHCL), which owns the Taj Hotels brand, is a leader in the luxury hospitality sector.\n",
            "* **Aerospace & Defence:** Tata Advanced Systems is a growing player in this sector.\n",
            "* **Financial Services:** Tata Capital and other entities offer a range of financial services.\n",
            "\n",
            "**III. Global Presence:**\n",
            "\n",
            "The Tata Group is not just an Indian giant; it has a significant international presence.  Jaguar Land Rover, acquired by Tata Motors, is a prime example.  TCS and other IT companies have global operations and serve clients worldwide.  The group also has operations in various other countries across Asia, Europe, and the Americas.\n",
            "\n",
            "**IV. Social Responsibility:**\n",
            "\n",
            "The Tata Group's commitment to social responsibility is a cornerstone of its identity.  The philanthropic trusts actively support initiatives in education, healthcare, rural development, and environmental sustainability.  This commitment is integrated into the group's business practices and is often cited as a key differentiator.\n",
            "\n",
            "**V. Challenges and Criticisms:**\n",
            "\n",
            "Despite its success, the Tata Group faces challenges:\n",
            "\n",
            "* **Complexity:** The sheer size and complexity of the group can make decision-making slow and coordination difficult.\n",
            "* **Competition:**  The group faces intense competition in many of its sectors.\n",
            "* **Economic Downturns:**  Like any large conglomerate, it's vulnerable to economic fluctuations.\n",
            "* **Succession Planning:**  Maintaining consistent leadership and vision after significant leadership changes is a constant challenge.\n",
            "* **Criticism regarding labor practices:**  Like many large corporations, the Tata Group has faced criticism regarding labor practices in some of its subsidiaries.\n",
            "\n",
            "\n",
            "In conclusion, the Tata Group is a multifaceted and influential conglomerate with a long history and a profound impact on India and the global economy.  Its unique structure, commitment to social responsibility, and diverse business portfolio make it a fascinating case study in corporate strategy and global business.  However, it's also a complex organization facing the challenges inherent in its size and scope.\n",
            "\n",
            "\n",
            "here is output from LLM_Output_Token_Counter\n",
            "_______\n",
            "total token number in the generated answer is 749\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for output in app.stream(\"tell me about the tata enterpirse in very detail.\"):\n",
        "    for key,value in output.items():\n",
        "        print(f\"here is output from {key}\")\n",
        "        print(\"_______\")\n",
        "        print(value)\n",
        "        print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fef12522",
      "metadata": {
        "id": "fef12522"
      },
      "source": [
        "## Langgraph Intro 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "680faf98",
      "metadata": {
        "id": "680faf98"
      },
      "source": [
        "### Config the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba13a88f",
      "metadata": {
        "id": "ba13a88f",
        "outputId": "57a92c09-0956-48c8-b344-e093aebf577a"
      },
      "outputs": [],
      "source": [
        "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# model=ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
        "# output=model.invoke(\"hi\")\n",
        "# print(output.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa63b77a",
      "metadata": {
        "id": "aa63b77a"
      },
      "source": [
        "### Config the embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48ae5bee",
      "metadata": {
        "id": "48ae5bee",
        "outputId": "4cd2db08-bd8c-4304-951b-75a5e3971b67"
      },
      "outputs": [],
      "source": [
        "# from langchain_huggingface import HuggingFaceEmbeddings\n",
        "# embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en\")\n",
        "# len(embeddings.embed_query(\"hi\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57003fe4",
      "metadata": {
        "id": "57003fe4"
      },
      "source": [
        "### lets take a data embedd it and store in VDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0994875e",
      "metadata": {
        "id": "0994875e"
      },
      "outputs": [],
      "source": [
        "# from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
        "# from langchain_community.vectorstores import Chroma\n",
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1da8893f",
      "metadata": {
        "id": "1da8893f"
      },
      "outputs": [],
      "source": [
        "# loader=DirectoryLoader(\"data\",glob=\"./*.txt\",loader_cls=TextLoader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6516d2cd",
      "metadata": {
        "id": "6516d2cd"
      },
      "outputs": [],
      "source": [
        "# docs=loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d100ab2",
      "metadata": {
        "id": "0d100ab2",
        "outputId": "3d2ef504-de8b-4ab2-9ce8-9c33c9c96b3d"
      },
      "outputs": [],
      "source": [
        "# docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32db3be9",
      "metadata": {
        "id": "32db3be9",
        "outputId": "84b014b4-379e-457c-9947-2184f4c65583"
      },
      "outputs": [],
      "source": [
        "# docs[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75a338e8",
      "metadata": {
        "id": "75a338e8"
      },
      "outputs": [],
      "source": [
        "# text_splitter=RecursiveCharacterTextSplitter(\n",
        "#     chunk_size=200,\n",
        "#     chunk_overlap=50\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cdeb0c1",
      "metadata": {
        "id": "9cdeb0c1"
      },
      "outputs": [],
      "source": [
        "# new_docs=text_splitter.split_documents(documents=docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51c77f95",
      "metadata": {
        "id": "51c77f95",
        "outputId": "0ec67e22-4b9c-4b19-f2ed-6d588a2dc93c"
      },
      "outputs": [],
      "source": [
        "# new_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae5f2527",
      "metadata": {
        "id": "ae5f2527"
      },
      "outputs": [],
      "source": [
        "# doc_string=[doc.page_content for doc in new_docs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b36086cc",
      "metadata": {
        "id": "b36086cc",
        "outputId": "47cb0a19-55db-42d3-c9bb-dab651c279c3"
      },
      "outputs": [],
      "source": [
        "# doc_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9de078e",
      "metadata": {
        "id": "e9de078e",
        "outputId": "c468b4c3-aa2e-4eae-b511-25d708c9d4ed"
      },
      "outputs": [],
      "source": [
        "# len(doc_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae02f542",
      "metadata": {
        "id": "ae02f542",
        "outputId": "55f6b50e-a2ab-42f6-8684-446b2351e342"
      },
      "outputs": [],
      "source": [
        "# db=Chroma.from_documents(new_docs[:5],embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ae4692f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# retriever=db.as_retriever(search_kwargs={\"k\": 3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d5ef2a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# retriever.invoke(\"industrial growth of usa?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f53813d1",
      "metadata": {},
      "source": [
        "## Lang graph Intro 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "2dec551c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import operator\n",
        "from typing import List\n",
        "from pydantic import BaseModel , Field\n",
        "from langchain.prompts import PromptTemplate\n",
        "from typing import TypedDict, Annotated, Sequence\n",
        "from langchain_core.messages import BaseMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langgraph.graph import StateGraph,END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "cd2717c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "class TopicSelectionParser(BaseModel):\n",
        "    Topic:str=Field(description=\"selected topic\")\n",
        "    Reasoning:str=Field(description='Reasoning behind topic selection')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "aa9482a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.output_parsers import PydanticOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "40f38ab0",
      "metadata": {},
      "outputs": [],
      "source": [
        "parser=PydanticOutputParser(pydantic_object=TopicSelectionParser)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "5976eaae",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"Topic\": {\"description\": \"selected topic\", \"title\": \"Topic\", \"type\": \"string\"}, \"Reasoning\": {\"description\": \"Reasoning behind topic selection\", \"title\": \"Reasoning\", \"type\": \"string\"}}, \"required\": [\"Topic\", \"Reasoning\"]}\\n```'"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parser.get_format_instructions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "818e9458",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"Topic\": {\"description\": \"selected topic\", \"title\": \"Topic\", \"type\": \"string\"}, \"Reasoning\": {\"description\": \"Reasoning behind topic selection\", \"title\": \"Reasoning\", \"type\": \"string\"}}, \"required\": [\"Topic\", \"Reasoning\"]}\\n```'"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"Topic\": {\"description\": \"selected topic\", \"title\": \"Topic\", \"type\": \"string\"}, \"Reasoning\": {\"description\": \"Reasoning behind topic selection\", \"title\": \"Reasoning\", \"type\": \"string\"}}, \"required\": [\"Topic\", \"Reasoning\"]}\\n```'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a58e92eb",
      "metadata": {},
      "source": [
        "### this below agentstate is just for the explnation like how state works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "e90647aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "Agentstate={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "6941a3b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "Agentstate[\"messages\"]=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "0a1d26a9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': []}"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Agentstate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "04538362",
      "metadata": {},
      "outputs": [],
      "source": [
        "Agentstate[\"messages\"].append(\"hi how are you?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "b386dfa7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': ['hi how are you?']}"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Agentstate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "6293e839",
      "metadata": {},
      "outputs": [],
      "source": [
        "Agentstate[\"messages\"].append(\"what are you doing?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "4ba759a1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': ['hi how are you?', 'what are you doing?']}"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Agentstate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "24f91dba",
      "metadata": {},
      "outputs": [],
      "source": [
        "Agentstate[\"messages\"].append(\"i hope everything fine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "1dcf10b7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': ['hi how are you?',\n",
              "  'what are you doing?',\n",
              "  'i hope everything fine']}"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Agentstate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "6204ad9f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'i hope everything fine'"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Agentstate[\"messages\"][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "eaf4d755",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'hi how are you?'"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Agentstate[\"messages\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d318b01",
      "metadata": {},
      "source": [
        "### this agentstate class you need to inside the stategraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "4c20fb4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "5c61fb48",
      "metadata": {},
      "outputs": [],
      "source": [
        "state={\"messages\":[\"hi\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "a65ffb5a",
      "metadata": {},
      "outputs": [],
      "source": [
        "state=\"hi\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "8aa6baec",
      "metadata": {},
      "outputs": [],
      "source": [
        "def function_1(state:AgentState):\n",
        "    \n",
        "    question=state[\"messages\"][-1]\n",
        "    \n",
        "    print(\"Question\",question)\n",
        "    \n",
        "    template=\"\"\"\n",
        "    Your task is to classify the given user query into one of the following categories: [USA,Not Related]. \n",
        "    Only respond with the category name and nothing else.\n",
        "\n",
        "    User query: {question}\n",
        "    {format_instructions}\n",
        "    \"\"\"\n",
        "    \n",
        "    prompt= PromptTemplate(\n",
        "        template=template,\n",
        "        input_variable=[\"question\"],\n",
        "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        "    )\n",
        "    \n",
        "    \n",
        "    chain= prompt | model | parser\n",
        "    \n",
        "    response = chain.invoke({\"question\":question})\n",
        "    \n",
        "    print(\"Parsed response:\", response)\n",
        "    \n",
        "    return {\"messages\": [response.Topic]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "a6558ef3",
      "metadata": {},
      "outputs": [],
      "source": [
        "state={\"messages\":[\"what is a today weather?\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "df51a043",
      "metadata": {},
      "outputs": [],
      "source": [
        "state={\"messages\":[\"what is a GDP of usa??\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "3b96f34d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi there! How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model=ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
        "output=model.invoke(\"hi\")\n",
        "print(output.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "cbc2b835",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question what is a GDP of usa??\n",
            "Parsed response: Topic='USA' Reasoning='The query explicitly asks about the GDP of the USA.'\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'messages': ['USA']}"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "function_1(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "9f3fdb81",
      "metadata": {},
      "outputs": [],
      "source": [
        "class TopicSelectionParser(BaseModel):\n",
        "    Topic:str=Field(description=\"selected topic\")\n",
        "    Reasoning:str=Field(description='Reasoning behind topic selection')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "5e13e200",
      "metadata": {},
      "outputs": [],
      "source": [
        "def router(state:AgentState):\n",
        "    print(\"-> ROUTER ->\")\n",
        "    \n",
        "    last_message=state[\"messages\"][-1]\n",
        "    print(\"last_message:\", last_message)\n",
        "    \n",
        "    if \"usa\" in last_message.lower():\n",
        "        return \"RAG Call\"\n",
        "    else:\n",
        "        return \"LLM Call\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "1bf18d5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "c0fbde21",
      "metadata": {},
      "outputs": [],
      "source": [
        "# RAG Function\n",
        "def function_2(state:AgentState):\n",
        "    print(\"-> RAG Call ->\")\n",
        "    \n",
        "    question = state[\"messages\"][0]\n",
        "    \n",
        "    prompt=PromptTemplate(\n",
        "        template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\"\",\n",
        "        \n",
        "        input_variables=['context', 'question']\n",
        "    )\n",
        "    \n",
        "    rag_chain = (\n",
        "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | model\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "    result = rag_chain.invoke(question)\n",
        "    return  {\"messages\": [result]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "982f04eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# LLM Function\n",
        "def function_3(state:AgentState):\n",
        "    print(\"-> LLM Call ->\")\n",
        "    question = state[\"messages\"][0]\n",
        "    \n",
        "    # Normal LLM call\n",
        "    complete_query = \"Anwer the follow question with you knowledge of the real world. Following is the user question: \" + question\n",
        "    response = model.invoke(complete_query)\n",
        "    return {\"messages\": [response.content]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "ad429a23",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph,END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "de558b73",
      "metadata": {},
      "outputs": [],
      "source": [
        "workflow=StateGraph(AgentState)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "a81dddc4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x16f98510990>"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_node(\"Supervisor\",function_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "338a953e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x16f98510990>"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_node(\"RAG\",function_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "231fc436",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x16f98510990>"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_node(\"LLM\",function_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "d4bca978",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x16f98510990>"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.set_entry_point(\"Supervisor\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "d8f151b0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x16f98510990>"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_conditional_edges(\n",
        "    \"Supervisor\",\n",
        "    router,\n",
        "    {\n",
        "        \"RAG Call\": \"RAG\",\n",
        "        \"LLM Call\": \"LLM\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "19aecd62",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x16f98510990>"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_edge(\"RAG\",END)\n",
        "workflow.add_edge(\"LLM\",END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "71874793",
      "metadata": {},
      "outputs": [],
      "source": [
        "app=workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "74d71a34",
      "metadata": {},
      "outputs": [],
      "source": [
        "state={\"messages\":[\"hi\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "0deccf3e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question hi\n",
            "Parsed response: Topic='Not Related' Reasoning=\"The query 'hi' is a generic greeting and does not contain any information related to the USA.\"\n",
            "-> ROUTER ->\n",
            "last_message: Not Related\n",
            "-> LLM Call ->\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'messages': ['hi', 'Not Related', 'Hi there!  How can I help you today?']}"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app.invoke(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "f42d269c",
      "metadata": {},
      "outputs": [],
      "source": [
        "state={\"messages\":[\"what is a gdp of usa?\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "4c502034",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question what is a gdp of usa?\n",
            "Parsed response: Topic='USA' Reasoning='The query explicitly asks for the GDP of the USA.'\n",
            "-> ROUTER ->\n",
            "last_message: USA\n",
            "-> RAG Call ->\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'retriever' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[122]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2719\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2716\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2717\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2719\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2720\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2723\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2724\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2725\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2728\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2730\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2734\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langgraph\\pregel\\runner.py:161\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    159\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[108]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mfunction_2\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      5\u001b[39m question = state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m      7\u001b[39m prompt=PromptTemplate(\n\u001b[32m      8\u001b[39m     template=\u001b[33m\"\"\"\u001b[39m\u001b[33mYou are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt know the answer, just say that you don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt know. Use three sentences maximum and keep the answer concise.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mQuestion: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mContext: \u001b[39m\u001b[38;5;132;01m{context}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAnswer:\u001b[39m\u001b[33m\"\"\"\u001b[39m,\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m     input_variables=[\u001b[33m'\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m rag_chain = (\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mretriever\u001b[49m | format_docs, \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: RunnablePassthrough()}\n\u001b[32m     15\u001b[39m     | prompt\n\u001b[32m     16\u001b[39m     | model\n\u001b[32m     17\u001b[39m     | StrOutputParser()\n\u001b[32m     18\u001b[39m )\n\u001b[32m     19\u001b[39m result = rag_chain.invoke(question)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m  {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [result]}\n",
            "\u001b[31mNameError\u001b[39m: name 'retriever' is not defined",
            "During task with name 'RAG' and id '01acc013-c5c0-b8ed-ed84-a170c3cd1fb0'"
          ]
        }
      ],
      "source": [
        "app.invoke(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67437444",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "818da502",
      "metadata": {
        "id": "818da502"
      },
      "source": [
        "## Langgraph Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc7104c0",
      "metadata": {
        "id": "dc7104c0"
      },
      "source": [
        "### Config the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5444e4f",
      "metadata": {
        "id": "a5444e4f",
        "outputId": "d6ee19e0-0943-4265-8837-30598b6a8b28"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model=ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
        "output=model.invoke(\"hi\")\n",
        "print(output.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b647d2e0",
      "metadata": {
        "id": "b647d2e0"
      },
      "source": [
        "### Config the embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab66123a",
      "metadata": {
        "id": "ab66123a",
        "outputId": "28fcd021-0233-4a85-ba96-0e9adfcf5de6"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en\")\n",
        "len(embeddings.embed_query(\"hi\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88ba396b",
      "metadata": {
        "id": "88ba396b"
      },
      "source": [
        "### Creating the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f35373b8",
      "metadata": {
        "id": "f35373b8"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "from typing import List\n",
        "from pydantic import BaseModel , Field\n",
        "from langchain.prompts import PromptTemplate\n",
        "from typing import TypedDict, Annotated, Sequence\n",
        "from langchain_core.messages import BaseMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langgraph.graph import StateGraph,END, START\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48683055",
      "metadata": {
        "id": "48683055"
      },
      "outputs": [],
      "source": [
        "class TopicSelectionParser(BaseModel):\n",
        "    Topic:str=Field(description=\"selected topic\")\n",
        "    Reasoning:str=Field(description='Reasoning behind topic selection')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bc84af3",
      "metadata": {
        "id": "4bc84af3",
        "outputId": "89151ca1-f138-4023-b438-af8bf73d3f70"
      },
      "outputs": [],
      "source": [
        "parser=PydanticOutputParser(pydantic_object=TopicSelectionParser)\n",
        "parser.get_format_instructions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2776cbfa",
      "metadata": {
        "id": "2776cbfa"
      },
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c7b56a8",
      "metadata": {
        "id": "6c7b56a8"
      },
      "outputs": [],
      "source": [
        "def function_1(state:AgentState):\n",
        "\n",
        "    question=state[\"messages\"][-1]\n",
        "\n",
        "    print(\"Question\",question)\n",
        "\n",
        "    template=\"\"\"\n",
        "    Your task is to classify the given user query into one of the following related categories: [Constitution,LLM, Latest]. If question is about\n",
        "    Indian constitution then Constitution, if question is generic then LLM and if question is about some recent thing which you don't know then Latest.\n",
        "    Only respond with the category name and nothing else.\n",
        "\n",
        "    User query: {question}\n",
        "    {format_instructions}\n",
        "    \"\"\"\n",
        "\n",
        "    prompt= PromptTemplate(\n",
        "        template=template,\n",
        "        input_variable=[\"question\"],\n",
        "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        "    )\n",
        "\n",
        "\n",
        "    chain= prompt | model | parser\n",
        "\n",
        "\n",
        "    response = chain.invoke({\"question\":question})\n",
        "\n",
        "    print(\"Parsed response:\", response)\n",
        "\n",
        "    return {\"messages\": [response.Topic]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14436bdf",
      "metadata": {
        "id": "14436bdf"
      },
      "outputs": [],
      "source": [
        "def router(state:AgentState):\n",
        "    print(\"-> ROUTER ->\")\n",
        "\n",
        "    last_message=state[\"messages\"][-1]\n",
        "    print(\"last_message:\", last_message)\n",
        "\n",
        "    if \"constitution\" in last_message.lower():\n",
        "        return \"RAG Call\"\n",
        "    elif \"latest\" in last_message.lower():\n",
        "        return \"WEB Call\"\n",
        "    else:\n",
        "        return \"LLM Call\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "669f58e1",
      "metadata": {
        "id": "669f58e1"
      },
      "outputs": [],
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ba60dd6",
      "metadata": {
        "id": "7ba60dd6",
        "outputId": "837f6ef2-6b5b-44db-e4a3-853ba75a8f9e"
      },
      "outputs": [],
      "source": [
        "# Load a PDF and validate the page count\n",
        "file_path = r\"C:\\Users\\saina\\Desktop\\DS_ML_AI\\Krish_Naik_Courses\\Krish_naik_1_Agentic_AI_and_Gen_AI\\Practice\\agentic_ai_2\\data\\2023050195.pdf\"\n",
        "loader = PyPDFLoader(file_path)\n",
        "pages = loader.load()\n",
        "\n",
        "if len(pages) < 200:\n",
        "    raise ValueError(\"The PDF must have at least 200 pages.\")\n",
        "\n",
        "#Using semantic chunking with recursive text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "chunks = text_splitter.split_documents(pages)\n",
        "\n",
        "\n",
        "# Hugging Face embedding\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "faiss_flat = FAISS.from_documents(chunks, embedding_model)\n",
        "retriever_flat = faiss_flat.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e367c54b",
      "metadata": {
        "id": "e367c54b"
      },
      "outputs": [],
      "source": [
        "# RAG Function\n",
        "def function_2(state:AgentState):\n",
        "    print(\"-> RAG Call ->\")\n",
        "\n",
        "    question = state[\"messages\"][0]\n",
        "\n",
        "    prompt=PromptTemplate(\n",
        "        template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\"\",\n",
        "\n",
        "        input_variables=['context', 'question']\n",
        "    )\n",
        "\n",
        "    rag_chain = (\n",
        "        {\"context\": retriever_flat | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | model\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "    result = rag_chain.invoke(question)\n",
        "    return  {\"messages\": [result]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4445aba2",
      "metadata": {
        "id": "4445aba2"
      },
      "outputs": [],
      "source": [
        "# LLM Function\n",
        "def function_3(state:AgentState):\n",
        "    print(\"-> LLM Call ->\")\n",
        "    question = state[\"messages\"][0]\n",
        "\n",
        "    # Normal LLM call\n",
        "    complete_query = \"Answer the follow question with you knowledge of the real world. Following is the user question: \" + question\n",
        "    response = model.invoke(complete_query)\n",
        "    return {\"messages\": [response.content]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58ade2a6",
      "metadata": {
        "id": "58ade2a6"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "def search_fun(state:AgentState):\n",
        "    search=DuckDuckGoSearchRun()\n",
        "    result = search.invoke({\"query\":state[\"messages\"][0]})\n",
        "    return {\"messages\": [result]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77310b33",
      "metadata": {
        "id": "77310b33"
      },
      "outputs": [],
      "source": [
        "def function_4(state:AgentState):\n",
        "\n",
        "    question = state[\"messages\"][0]\n",
        "    answer=state[\"messages\"][-1]\n",
        "\n",
        "    print(\"answer\",answer)\n",
        "\n",
        "    template=\"\"\"\n",
        "    Your task is to check if the response is related to the user question.\n",
        "    Only respond with yes or no and nothing else.\n",
        "\n",
        "    User query: {question}\n",
        "    response: {answer}\n",
        "    {format_instructions}\n",
        "    \"\"\"\n",
        "\n",
        "    prompt= PromptTemplate(\n",
        "        template=template,\n",
        "        input_variable=[\"question\",\"answer\"],\n",
        "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        "    )\n",
        "\n",
        "\n",
        "    chain= prompt | model | parser\n",
        "\n",
        "    response = chain.invoke({\"question\":question,\"answer\":answer})\n",
        "\n",
        "    print(\"Parsed response:\", response)\n",
        "\n",
        "    return {\"messages\": [response.Topic]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "566638da",
      "metadata": {
        "id": "566638da"
      },
      "outputs": [],
      "source": [
        "def router_1(state:AgentState):\n",
        "    print(\"-> ROUTER_1 ->\")\n",
        "\n",
        "    last_message=state[\"messages\"][-1]\n",
        "    print(\"last_message:\", last_message)\n",
        "\n",
        "    if \"yes\" in last_message.lower():\n",
        "        return \"yes\"\n",
        "    else:\n",
        "        return \"no\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4a6205f",
      "metadata": {
        "id": "e4a6205f",
        "outputId": "047527db-2481-44c6-c885-b28d4616c193"
      },
      "outputs": [],
      "source": [
        "workflow=StateGraph(AgentState)\n",
        "workflow.add_node(\"Supervisor\",function_1)\n",
        "workflow.add_node(\"RAG\",function_2)\n",
        "workflow.add_node(\"LLM\",function_3)\n",
        "workflow.add_node(\"WEB\", search_fun)\n",
        "workflow.add_node(\"VALIDATION\",function_4)\n",
        "workflow.set_entry_point(\"Supervisor\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44d40cd0",
      "metadata": {
        "id": "44d40cd0",
        "outputId": "03023829-b6f5-4720-be61-3066d21e5e90"
      },
      "outputs": [],
      "source": [
        "workflow.add_conditional_edges(\n",
        "    \"Supervisor\",\n",
        "    router,\n",
        "    {\n",
        "        \"RAG Call\": \"RAG\",\n",
        "        \"LLM Call\": \"LLM\",\n",
        "        \"WEB Call\": \"WEB\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51f3a5fa",
      "metadata": {
        "id": "51f3a5fa",
        "outputId": "bf6a0370-7033-47d8-b118-c7526fda147d"
      },
      "outputs": [],
      "source": [
        "workflow.add_edge(\"RAG\",\"VALIDATION\")\n",
        "workflow.add_edge(\"LLM\",\"VALIDATION\")\n",
        "workflow.add_edge(\"WEB\",\"VALIDATION\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"VALIDATION\",\n",
        "    router_1,\n",
        "    {\n",
        "        \"yes\": END,\n",
        "        \"no\":\"Supervisor\"\n",
        "    }\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0449aa2a",
      "metadata": {
        "id": "0449aa2a"
      },
      "outputs": [],
      "source": [
        "app=workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cf74c81",
      "metadata": {
        "id": "9cf74c81",
        "outputId": "7c0bb0a9-0f51-427a-a52c-1f2e1bd8a2fd"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30ba3393",
      "metadata": {
        "id": "30ba3393",
        "outputId": "f5d8a310-c981-469d-9c07-267cd97e8958"
      },
      "outputs": [],
      "source": [
        "state={\"messages\":[\"How to make black tea?, list down in simple steps\"]}\n",
        "app.invoke(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24e60f3d",
      "metadata": {
        "id": "24e60f3d",
        "outputId": "a4e98415-402c-4154-fe9c-a4e33f2f57a5"
      },
      "outputs": [],
      "source": [
        "state={\"messages\":[\"List all the fundamental duties?\"]}\n",
        "app.invoke(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48f18648",
      "metadata": {
        "id": "48f18648",
        "outputId": "c7c69ebb-7572-4c97-cfdf-cdbfcc39f4a5"
      },
      "outputs": [],
      "source": [
        "state={\"messages\":[\"what is the net worth of Elon Musk\"]}\n",
        "app.invoke(state)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98e728fb",
      "metadata": {
        "id": "98e728fb"
      },
      "source": [
        "# Last"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27668149",
      "metadata": {
        "id": "27668149"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "agentic_base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
