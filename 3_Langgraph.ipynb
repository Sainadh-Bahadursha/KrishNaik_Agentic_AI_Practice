{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "o7F9oe3WJuXp",
      "metadata": {
        "id": "o7F9oe3WJuXp"
      },
      "source": [
        "# Lang Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6454e5e",
      "metadata": {
        "id": "f6454e5e"
      },
      "source": [
        "## Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "582fbea0",
      "metadata": {
        "id": "582fbea0"
      },
      "source": [
        "### Wikipedia API Wrapper Tool (Summary from wikipedia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "09df7eeb",
      "metadata": {
        "id": "09df7eeb"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools import WikipediaQueryRun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "27350042",
      "metadata": {
        "id": "27350042"
      },
      "outputs": [],
      "source": [
        "from langchain_community.utilities import WikipediaAPIWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "349ce79b",
      "metadata": {
        "id": "349ce79b"
      },
      "outputs": [],
      "source": [
        "api_wrapper=WikipediaAPIWrapper(top_k_results=5,doc_content_chars_max= 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fde85dee",
      "metadata": {
        "id": "fde85dee"
      },
      "outputs": [],
      "source": [
        "wiki_tool=WikipediaQueryRun(api_wrapper=api_wrapper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "98b780a7",
      "metadata": {
        "id": "98b780a7",
        "outputId": "47a97f50-8dd2-4160-f4df-6e2266c3966d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'wikipedia'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wiki_tool.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9845643a",
      "metadata": {
        "id": "9845643a",
        "outputId": "58596aef-ddd7-4cbc-8235-be789a90c934"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wiki_tool.description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e0376b73",
      "metadata": {
        "id": "e0376b73",
        "outputId": "97d249c9-27e6-4b81-c186-b568069dc4a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': {'description': 'query to look up on wikipedia',\n",
              "  'title': 'Query',\n",
              "  'type': 'string'}}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wiki_tool.args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1e4a274f",
      "metadata": {
        "id": "1e4a274f",
        "outputId": "c5df7a65-a078-4f4c-b04f-382bcb0b82df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Page: Elon Musk\\nSummary: Elon Reeve Musk ( EE-lon; born June 28, 1971) is a businessman. He is known for his leadership of Tesla, SpaceX, X (formerly Twitter), and the Department of Government Efficiency (DOGE). Musk has been considered the wealthiest person in the world since 2021; as of May 2025, Forbes estimates his net worth to be US$424.7 billion. \\nBorn to a wealthy family in Pretoria, South Africa, Musk emigrated in 1989 to Canada. He received bachelor's degrees from the University of Penn\""
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wiki_tool.run({\"query\":\"elon musk\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "740fa568",
      "metadata": {
        "id": "740fa568",
        "outputId": "5bd6bcf1-b81e-433e-cc63-0656ff181f29"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file c:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Page: Royal Challengers Bengaluru\\nSummary: The Royal Challengers Bengaluru, formerly Royal Challengers Bangalore, also known as RCB, are a professional Twenty20 cricket team based in Bengaluru, Karnataka, that competes in the Indian Premier League (IPL). Founded in 2008 by United Spirits, the team's home ground is M. Chinnaswamy Stadium. They won their first title in 2025. The team finished as the runners-up on three occasions: in 2009, 2011, and 2016. They have also qualified for the playoffs i\""
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wiki_tool.run(\"RCB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8500a32a",
      "metadata": {
        "id": "8500a32a"
      },
      "source": [
        "### Youtube Search Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a4018c56",
      "metadata": {
        "id": "a4018c56"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools import YouTubeSearchTool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "098d336c",
      "metadata": {
        "id": "098d336c"
      },
      "outputs": [],
      "source": [
        "tool=YouTubeSearchTool()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5750f96f",
      "metadata": {
        "id": "5750f96f",
        "outputId": "97210823-5815-43d1-bb6f-c38cd4ca2fc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'youtube_search'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f2d2e6ea",
      "metadata": {
        "id": "f2d2e6ea",
        "outputId": "f17e3c17-084d-4a17-edac-403b8bc30517"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'search for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool.description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "9dcb154b",
      "metadata": {
        "id": "9dcb154b",
        "outputId": "bc3614eb-e429-414a-e9c0-414978741564"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"['https://www.youtube.com/watch?v=Jj1-zb38Yfw&pp=ygUKQWdlbnRpYyBBSQ%3D%3D', 'https://www.youtube.com/watch?v=dIb-DujRNEo&pp=ygUKQWdlbnRpYyBBSQ%3D%3D']\""
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool.run(\"Agentic AI\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2814b8c",
      "metadata": {
        "id": "c2814b8c"
      },
      "source": [
        "### Tavily Search Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "d3a9b887",
      "metadata": {
        "id": "d3a9b887"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ee5261b2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b98b226a",
      "metadata": {
        "id": "b98b226a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "a9cf56f1",
      "metadata": {
        "id": "a9cf56f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\saina\\AppData\\Local\\Temp\\ipykernel_1796\\1068719361.py:1: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  tool=TavilySearchResults(tavily_api_key=TAVILY_API_KEY)\n"
          ]
        }
      ],
      "source": [
        "tool=TavilySearchResults(tavily_api_key=TAVILY_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "503163b0",
      "metadata": {
        "id": "503163b0",
        "outputId": "fdf900d7-18ee-40ac-d312-efb5eaaa67b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'title': \"Bengaluru stampede case: What we know so far on RCB's ...\",\n",
              "  'url': 'https://timesofindia.indiatimes.com/sports/cricket/ipl/top-stories/bengaluru-stampede-case-what-we-know-so-far-on-rcbs-celebrations-that-turned-catastrophic/articleshow/121670873.cms',\n",
              "  'content': \"[Follow us](https://news.google.com/publications/CAAqBwgKMM6y_Qowwu70Ag)\\n\\nRoyal Challengers Bengaluru's IPL victory celebrations turned tragic as a stampede at M Chinnaswamy Stadium resulted in 11 deaths and 75 injuries. FIRs have been filed against RCB, events organisers DNA, and Karnataka State Cricket Association for alleged negligence. The Karnataka High Court has sought a report from the government while arrests have been and officials suspended.\\n\\nRead More [...] [](https://timesofindia.indiatimes.com/city/bengaluru/celebrations-turn-tragic-bloodbath-at-rcbs-maiden-ipl-trophy-victory-day-to-remember-forever-see-pics/photostory/121646177.cms)[Celebrations turn tragic: Bloodbath at RCB’s maiden IPL trophy victory, day to remember forever | see pics Lakhs of fans had gathered around Chinnaswamy Stadium, celebrating RCB’s historic first-ever IPL title with joy and excitement.Times Of\",\n",
              "  'score': 0.8455478},\n",
              " {'title': 'Chinnaswamy Stadium Stampede: What triggered the deadly chaos ...',\n",
              "  'url': 'https://m.economictimes.com/news/bengaluru-news/chinnaswamy-stadium-stampede-what-triggered-the-chaos-that-turned-deadly-in-rcbs-victory-celebration/articleshow/121624517.cms',\n",
              "  'content': \"![Image 3](https://img.etimg.com/thumb/msid-121625936,width-300,height-225,imgsize-121910,resizemode-75/.jpg)\\n\\nRCB's IPL victory celebrations turn tragic: Stampede in Bengaluru; 11 dead, 33 injured\\n\\nThe celebrations after RCB took a heart-breaking turn when a deadly [stampede](https://m.economictimes.com/topic/stampede) near the M Chinnaswamy Stadium killed over 11 fans dead and nearly 33 others injured.\",\n",
              "  'score': 0.83710164},\n",
              " {'title': \"Several Killed as RCB's Victory Celebration Turns Deadly - YouTube\",\n",
              "  'url': 'https://www.youtube.com/watch?v=gz8chxY7elU',\n",
              "  'content': \"At least 11 people were killed and 30 injured in a stampede outside the Chinnaswamy cricket stadium in Bengaluru. The incident happened during the Royal Challengers' victory celebrations after their first IPL triumph in 18 years. Did the state government underestimate the rush? Were crowd control measures not in place? Palki Sharma tells you.\\n\\n--- [...] It was supposed to be a day of pure joy, of celebration and pride. Instead, Bengaluru is in shock today. I'm sure you've seen the news and the pictures. Bengaluru was all decked up for a massive celebration today. Their IPL team had finally won the tournament. The Royal Challengers beat Punjab Kings yesterday. It was their first IPL trophy in 18 years. Now the RCB fans are a very passionate lot. Plus they've been waiting for a win since 2008. So they packed the streets of Bengaluru in [...] soon the fan frenzy turned fatal. The exact details are not clear yet but reports say the rush led to a stampede. At least 11 people were killed, including children, and more than 30 were injured. Like I said, the exact sequence of events is unclear, but these pictures give you an idea. Uh you can see fans climbing up fences and trees. In some places, the police pushed back with force. We will show you the pictures, but as always, viewer discretion is advised. [Applause] [Music] [Applause] Such\",\n",
              "  'score': 0.83290404},\n",
              " {'title': 'RCB victory parade stampede updates: Bengaluru city chief B ...',\n",
              "  'url': 'https://www.thehindu.com/news/national/rcb-ipl-victory-parade-stampede-death-toll-virat-kohli-chinnaswamy-stadium-live/article69656707.ece',\n",
              "  'content': 'Sachin Tendulkar has offered his condolences on the loss of 11 lives in a stampede outside Bengaluru’s Chinnaswamy Stadium during RCB’s IPL victory celebrations, describing the incident as “beyond tragic”.\\n\\nOn the day the stampede broke out in Bengaluru while celebrating the victory of Royal Challengers Bengaluru (RCB) in the IPL final, killing 11 and leaving scores injured, the Namma Metro witnessed unprecedented footfall. [...] A stampede that broke out near the Chinnaswamy stadium in Bengaluru, after fans gathered to celebrate Royal Challengers Bengaluru’s IPL win, led to the [deaths of 11 persons and injuries to 33](https://www.thehindu.com/news/cities/bangalore/rcb-ipl-victory-celebrations-stampede-bengaluru-death-toll/article69656538.ece) on Wednesday (June 4, 2025). The tragedy unfolded near the gates of the stadium, where over 2 lakh fans had gathered to mark RCB’s historic first title win in 18 years. [...] In a post on X, Mr. Bommai said following the Royal Challengers Bangalore (RCB) team lifting the IPL trophy, the state government hastily organised a victory celebration event without proper planning, leading to a tragic stampede that claimed the lives of more than ten innocent people. Organising two events in a hurry without any prior preparation and allowing an overwhelming number of people to attend both clearly demonstrates the government’s complete negligence and irresponsibility.',\n",
              "  'score': 0.82492816},\n",
              " {'title': \"How did celebration of RCB's historic win in IPL spiral into chaos ...\",\n",
              "  'url': 'https://www.thehindu.com/news/national/karnataka/how-did-celebration-of-rcbs-historic-win-in-ipl-spiral-into-chaos-and-crisis-explained/article69668074.ece',\n",
              "  'content': 'A stampede during RCB’s victory celebrations in Bengaluru on June 4 claimed 11 lives and left several others with injuries, turning a moment of triumph into tragedy. Facing a backlash for mismanagement and hurried planning, the Congress government in Karnataka suspended top police officials [...] Remove [SEE ALL](https://www.thehindu.com/myaccount/?tab=bookmarks)\\n\\nPRINT\\n\\n![Image 12: Footwear left behind by fans of Royal Challenge Bengaluru (RCB) after a stampede at the victory celebrations, in Bengaluru on June 5, 2025. ](https://www.thehindu.com/theme/images/th-online/1x1_spacer.png)\\n\\nFootwear left behind by fans of Royal Challenge Bengaluru (RCB) after a stampede at the victory celebrations, in Bengaluru on June 5, 2025. | Photo Credit: SUDHAKARA JAIN\\n\\n#### The story so far',\n",
              "  'score': 0.818055}]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool.invoke({\"query\":\"what happend in RCB victory celebration?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f1f2463",
      "metadata": {
        "id": "4f1f2463"
      },
      "source": [
        "### Custom tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "fc844561",
      "metadata": {
        "id": "fc844561"
      },
      "outputs": [],
      "source": [
        "def multiply(a:int,b:int)->int:\n",
        "    return a*b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7f37c964",
      "metadata": {
        "id": "7f37c964",
        "outputId": "a03c4208-06a7-48f0-beec-4f0f98e40d80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multiply(10,20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "39fe75c0",
      "metadata": {
        "id": "39fe75c0",
        "outputId": "8a8767ab-4654-462a-c441-058752976154"
      },
      "outputs": [],
      "source": [
        "# multiply.run(10,20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a8da091",
      "metadata": {
        "id": "6a8da091"
      },
      "source": [
        "---------------------------------------------------------------------------\n",
        "AttributeError                            Traceback (most recent call last)\n",
        "Cell In[52], line 1\n",
        "----> 1 multiply.run(10,20)\n",
        "\n",
        "AttributeError: 'function' object has no attribute 'run'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "480b255d",
      "metadata": {
        "id": "480b255d",
        "outputId": "f1fa9034-1d50-4612-a949-462875a744cf"
      },
      "outputs": [],
      "source": [
        "# multiply.invoke(10,20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b0ff8c1",
      "metadata": {
        "id": "3b0ff8c1"
      },
      "source": [
        "---------------------------------------------------------------------------\n",
        "AttributeError                            Traceback (most recent call last)\n",
        "Cell In[53], line 1\n",
        "----> 1 multiply.invoke(10,20)\n",
        "\n",
        "AttributeError: 'function' object has no attribute 'invoke'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "2c3b4b97",
      "metadata": {
        "id": "2c3b4b97"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import tool\n",
        "@tool\n",
        "def multiply(a:int,b:int)->int:\n",
        "    '''this tool is for the multiplication'''\n",
        "    return a*b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "4bd8cbf7",
      "metadata": {
        "id": "4bd8cbf7",
        "outputId": "4b1f0a31-6d04-480e-a189-03b8dccc7038"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multiply.invoke({\"a\":10,\"b\":20})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "888d6268",
      "metadata": {
        "id": "888d6268",
        "outputId": "0a346cf1-97e9-434e-a961-3527af1184f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'multiply'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multiply.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "420df80b",
      "metadata": {
        "id": "420df80b",
        "outputId": "9380cbc6-e834-45d8-bba7-d84ba349bfea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'this tool is for the multiplication'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multiply.description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "365e78d7",
      "metadata": {
        "id": "365e78d7",
        "outputId": "1076e637-614f-4907-df66-c1789e10e940"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'a': {'title': 'A', 'type': 'integer'},\n",
              " 'b': {'title': 'B', 'type': 'integer'}}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multiply.args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "5941e644",
      "metadata": {
        "id": "5941e644"
      },
      "outputs": [],
      "source": [
        "def get_word_length(word:str)->int:\n",
        "    return len(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "d56fafdd",
      "metadata": {
        "id": "d56fafdd",
        "outputId": "1566e601-3088-4312-d3db-c395a7facd75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_word_length(\"Sainadh bahadursha\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "b176fc8a",
      "metadata": {
        "id": "b176fc8a",
        "outputId": "5d80649d-6e89-4189-f913-e1640286aa9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_word_length(\"narendra modi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "c1cfb06e",
      "metadata": {
        "id": "c1cfb06e"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def get_word_length(word:str)->int:\n",
        "    \"\"\"this function is calculating a length of the word\"\"\"\n",
        "    return len(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "efd94c98",
      "metadata": {
        "id": "efd94c98",
        "outputId": "54bbff7d-bfed-47f5-b1d6-6c9e7222449f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'get_word_length'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_word_length.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "d7a4cc82",
      "metadata": {
        "id": "d7a4cc82",
        "outputId": "ee26eba5-b4c2-48b2-8182-e9c6e7a9c9f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'this function is calculating a length of the word'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_word_length.description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "5bd42de8",
      "metadata": {
        "id": "5bd42de8",
        "outputId": "acc39742-b57a-4335-beba-f2cf0841ee47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'word': {'title': 'Word', 'type': 'string'}}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_word_length.args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "88d450b3",
      "metadata": {
        "id": "88d450b3",
        "outputId": "bdb847dd-6916-439b-f5f6-54953f829c24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\saina\\AppData\\Local\\Temp\\ipykernel_1796\\1704822211.py:1: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  get_word_length(\"sainadh\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_word_length(\"sainadh\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "784c9efc",
      "metadata": {
        "id": "784c9efc",
        "outputId": "42124ab2-c1f1-4778-8d47-e8e267e47845"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_word_length.invoke(\"sainadh\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ae74a74",
      "metadata": {
        "id": "8ae74a74"
      },
      "source": [
        "### Gmail tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "02d0863e",
      "metadata": {
        "id": "02d0863e"
      },
      "outputs": [],
      "source": [
        "# @tool\n",
        "# def call_gmail_api(args):\n",
        "#     \"\"\"this is my gmail api calling funtion\"\"\"\n",
        "#     pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "71b335ff",
      "metadata": {
        "id": "71b335ff"
      },
      "outputs": [],
      "source": [
        "# from langchain.agents import tool\n",
        "# import os\n",
        "# import base64\n",
        "# from email import message_from_bytes\n",
        "# from google.auth.transport.requests import Request\n",
        "# from google.oauth2.credentials import Credentials\n",
        "# from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "# from googleapiclient.discovery import build\n",
        "\n",
        "# SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']\n",
        "# from langchain.tools import tool\n",
        "# from pydantic import BaseModel, Field\n",
        "\n",
        "# class GmailArgs(BaseModel):\n",
        "#     max_results: int = Field(..., description=\"Number of unread emails to fetch\")\n",
        "\n",
        "# @tool\n",
        "# def call_gmail_api(args: GmailArgs) -> str:\n",
        "#     \"\"\"\n",
        "#     Reads unread emails from Gmail inbox using Gmail API.\n",
        "#     Args:\n",
        "#         max_results (int): Maximum number of unread emails to fetch. Default is 5.\n",
        "#     Returns:\n",
        "#         A string summary of unread emails.\n",
        "#     \"\"\"\n",
        "#     max_results = args.max_results\n",
        "\n",
        "#     try:\n",
        "#         creds = None\n",
        "#         if os.path.exists('token.json'):\n",
        "#             creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
        "#         if not creds or not creds.valid:\n",
        "#             if creds and creds.expired and creds.refresh_token:\n",
        "#                 creds.refresh(Request())\n",
        "#             else:\n",
        "#                 flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)\n",
        "#                 creds = flow.run_local_server(port=0)\n",
        "#             with open('token.json', 'w') as token:\n",
        "#                 token.write(creds.to_json())\n",
        "\n",
        "#         service = build('gmail', 'v1', credentials=creds)\n",
        "#         results = service.users().messages().list(userId='me', labelIds=['INBOX', 'UNREAD'], maxResults=max_results).execute()\n",
        "#         messages = results.get('messages', [])\n",
        "\n",
        "#         if not messages:\n",
        "#             return \"No unread emails found.\"\n",
        "\n",
        "#         summaries = []\n",
        "#         for msg in messages:\n",
        "#             msg_data = service.users().messages().get(userId='me', id=msg['id']).execute()\n",
        "#             headers = msg_data['payload']['headers']\n",
        "#             subject = next((h['value'] for h in headers if h['name'] == 'Subject'), '(No Subject)')\n",
        "#             sender = next((h['value'] for h in headers if h['name'] == 'From'), '(Unknown Sender)')\n",
        "#             snippet = msg_data.get('snippet', '')\n",
        "#             summaries.append(f\"From: {sender}\\nSubject: {subject}\\nSnippet: {snippet}\")\n",
        "\n",
        "#         return \"\\n\\n\".join(summaries)\n",
        "\n",
        "#     except Exception as e:\n",
        "#         return f\"Error accessing Gmail API: {e}\"\n",
        "\n",
        "# # @tool\n",
        "# # def call_gmail_api(max_results: int = 5) -> str:\n",
        "# #     \"\"\"\n",
        "# #     Reads unread emails from Gmail inbox using Gmail API.\n",
        "# #     Args:\n",
        "# #         max_results (int): Maximum number of unread emails to fetch. Default is 5.\n",
        "# #     Returns:\n",
        "# #         A string summary of unread emails.\n",
        "# #     \"\"\"\n",
        "# #     try:\n",
        "# #         creds = None\n",
        "# #         if os.path.exists('token.json'):\n",
        "# #             creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
        "# #         if not creds or not creds.valid:\n",
        "# #             if creds and creds.expired and creds.refresh_token:\n",
        "# #                 creds.refresh(Request())\n",
        "# #             else:\n",
        "# #                 flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)\n",
        "# #                 creds = flow.run_local_server(port=0)\n",
        "# #             with open('token.json', 'w') as token:\n",
        "# #                 token.write(creds.to_json())\n",
        "\n",
        "# #         service = build('gmail', 'v1', credentials=creds)\n",
        "# #         results = service.users().messages().list(userId='me', labelIds=['INBOX', 'UNREAD'], maxResults=max_results).execute()\n",
        "# #         messages = results.get('messages', [])\n",
        "\n",
        "# #         if not messages:\n",
        "# #             return \"No unread emails found.\"\n",
        "\n",
        "# #         summaries = []\n",
        "# #         for msg in messages:\n",
        "# #             msg_data = service.users().messages().get(userId='me', id=msg['id']).execute()\n",
        "# #             headers = msg_data['payload']['headers']\n",
        "# #             subject = next((h['value'] for h in headers if h['name'] == 'Subject'), '(No Subject)')\n",
        "# #             sender = next((h['value'] for h in headers if h['name'] == 'From'), '(Unknown Sender)')\n",
        "# #             snippet = msg_data.get('snippet', '')\n",
        "# #             summaries.append(f\"From: {sender}\\nSubject: {subject}\\nSnippet: {snippet}\")\n",
        "\n",
        "# #         return \"\\n\\n\".join(summaries)\n",
        "\n",
        "# #     except Exception as e:\n",
        "# #         return f\"Error accessing Gmail API: {e}\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "6eee951c",
      "metadata": {
        "id": "6eee951c",
        "outputId": "f89f26fd-0835-4a7f-d7ec-3de2f111481a"
      },
      "outputs": [],
      "source": [
        "# # from langchain.agents import initialize_agent\n",
        "# # from langchain.agents.agent_types import AgentType\n",
        "# # from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# # # Register the tool\n",
        "# # tools = [call_gmail_api]\n",
        "\n",
        "# # llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# # agent = initialize_agent(\n",
        "# #     tools=tools,\n",
        "# #     llm=llm,\n",
        "# #     agent_type=AgentType.OPENAI_FUNCTIONS,\n",
        "# #     verbose=True,\n",
        "# # )\n",
        "\n",
        "# # # Example query\n",
        "# # response = agent.run(\"Read my last 3 unread emails.\")\n",
        "# # print(response)\n",
        "\n",
        "# from langchain.agents import initialize_agent, AgentType\n",
        "# from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# tools = [call_gmail_api]\n",
        "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# agent = initialize_agent(\n",
        "#     tools=tools,\n",
        "#     llm=llm,\n",
        "#     agent_type=AgentType.OPENAI_FUNCTIONS,  # Requires structured input\n",
        "#     verbose=True,\n",
        "# )\n",
        "\n",
        "# # Test\n",
        "# response = agent.run(\"Get my last 3 unread emails.\")\n",
        "# print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e677c1ba",
      "metadata": {
        "id": "e677c1ba"
      },
      "source": [
        "## Langgraph Intro 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f5ef2219",
      "metadata": {
        "id": "f5ef2219"
      },
      "outputs": [],
      "source": [
        "def function1(input1):\n",
        "    return input1 + \" from first function\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3e85c2f7",
      "metadata": {
        "id": "3e85c2f7"
      },
      "outputs": [],
      "source": [
        "def function2(input2):\n",
        "    return input2 + \" Bahadursha from second function\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "37b6edbc",
      "metadata": {
        "id": "37b6edbc"
      },
      "outputs": [],
      "source": [
        "def function3(input3):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9851a3ef",
      "metadata": {
        "id": "9851a3ef",
        "outputId": "af639098-380c-469d-8910-dff99ad0cced"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Sainadh from first function'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "function1(\"Sainadh\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "e030fa62",
      "metadata": {
        "id": "e030fa62",
        "outputId": "e02d9c96-888a-4de5-aa33-b31a94fd520c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Bahadursha Bahadursha from second function'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "function2(\"Bahadursha\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "36a9e3dc",
      "metadata": {
        "id": "36a9e3dc"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "1975fb71",
      "metadata": {
        "id": "1975fb71"
      },
      "outputs": [],
      "source": [
        "workflow1 = Graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "2acc4344",
      "metadata": {
        "id": "2acc4344",
        "outputId": "c8d89e42-7502-466e-bba9-5f5e29b98d66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94ae2450>"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow1.add_node(\"fun1\",function1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "0eb9b0a9",
      "metadata": {
        "id": "0eb9b0a9",
        "outputId": "69600744-a866-491d-e520-623dddc0aa42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94ae2450>"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow1.add_node(\"fun2\",function2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "4de9ba38",
      "metadata": {
        "id": "4de9ba38",
        "outputId": "02700687-e4ab-4897-fda5-7f7e5a5fc19c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94ae2450>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow1.add_edge(\"fun1\",\"fun2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "67deaa83",
      "metadata": {
        "id": "67deaa83",
        "outputId": "22fef9fd-4ca7-4c0e-dac0-47a32df5e531"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94ae2450>"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow1.set_entry_point(\"fun1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "ffe2166b",
      "metadata": {
        "id": "ffe2166b",
        "outputId": "879bb30e-27fa-4c8f-f9f7-b7e0e22cdf39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94ae2450>"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow1.set_finish_point(\"fun2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "72631973",
      "metadata": {
        "id": "72631973"
      },
      "outputs": [],
      "source": [
        "app = workflow1.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "a2eece4f",
      "metadata": {
        "id": "a2eece4f"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "18685ba4",
      "metadata": {
        "id": "18685ba4",
        "outputId": "f740bf65-8e3a-4fff-e6a5-cde9652e08a6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Image(app.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "e402942c",
      "metadata": {
        "id": "e402942c",
        "outputId": "d6a6fa74-d02f-4bde-eb3f-47a058820abc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hi this is Sainadh from first function Bahadursha from second function'"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app.invoke(\"Hi this is Sainadh\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "38ff59b1",
      "metadata": {
        "id": "38ff59b1",
        "outputId": "aa4f00d5-269d-4998-eece-814c564d57dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here is output from fun1\n",
            "___________\n",
            "hi this is Sainadh from first function\n",
            "\n",
            "\n",
            "here is output from fun2\n",
            "___________\n",
            "hi this is Sainadh from first function Bahadursha from second function\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for output in app.stream(\"hi this is Sainadh\"):\n",
        "    for key,value in output.items():\n",
        "        print(f\"here is output from {key}\")\n",
        "        print(\"___________\")\n",
        "        print(value)\n",
        "        print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "3474cabe",
      "metadata": {
        "id": "3474cabe"
      },
      "outputs": [],
      "source": [
        "def llm(input):\n",
        "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "    model=ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
        "    output=model.invoke(input)\n",
        "    return output.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "add673f5",
      "metadata": {
        "id": "add673f5"
      },
      "outputs": [],
      "source": [
        "def token_counter(input):\n",
        "    token=input.split()\n",
        "    token_number=len(token)\n",
        "    return f\"total token number in the generated answer is {token_number}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "237c5260",
      "metadata": {
        "id": "237c5260"
      },
      "outputs": [],
      "source": [
        "workflow2 = Graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "8164e715",
      "metadata": {
        "id": "8164e715",
        "outputId": "8afb391b-122f-4749-961c-c9880c033154"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94c5edd0>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow2.add_node(\"My_LLM\",llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "eb3a2ab7",
      "metadata": {
        "id": "eb3a2ab7",
        "outputId": "c770d42d-ee7d-4c5f-9b66-ca5c3cc23642"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94c5edd0>"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow2.add_node(\"LLM_Output_Token_Counter\",token_counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "74aa047b",
      "metadata": {
        "id": "74aa047b",
        "outputId": "bfcee4ec-f78f-412a-8503-d1dbb7d30def"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94c5edd0>"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow2.add_edge(\"My_LLM\",\"LLM_Output_Token_Counter\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "8bc79c3b",
      "metadata": {
        "id": "8bc79c3b",
        "outputId": "d388ba76-a665-47ed-c05f-6b7cf99d6b22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94c5edd0>"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow2.set_entry_point(\"My_LLM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "01142311",
      "metadata": {
        "id": "01142311",
        "outputId": "ea81246d-3a1c-4b86-fb86-49461b14fc99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x16f94c5edd0>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow2.set_finish_point(\"LLM_Output_Token_Counter\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "48d7a68a",
      "metadata": {
        "id": "48d7a68a"
      },
      "outputs": [],
      "source": [
        "app=workflow2.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "75ae064f",
      "metadata": {
        "id": "75ae064f",
        "outputId": "32a75083-4845-4922-edda-b413da62c4be"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Image(app.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "d42406d1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "0991d0f0",
      "metadata": {
        "id": "0991d0f0",
        "outputId": "5509dc3c-9849-45fa-e253-8fb4412ec774"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'total token number in the generated answer is 68'"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app.invoke(\"can you tell me about the india's capital?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "37ea37d8",
      "metadata": {
        "id": "37ea37d8",
        "outputId": "3e9eab31-fac1-4811-c3a0-3ecc43649096"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'total token number in the generated answer is 667'"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app.invoke(\"tell me about the tata enterpirse in very detail.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "04d63af3",
      "metadata": {
        "id": "04d63af3",
        "outputId": "47c967df-ac77-4392-8613-815f7404df73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here is output from My_LLM\n",
            "_______\n",
            "Tata Enterprises, more accurately referred to as the **Tata Group**, is a massive Indian multinational conglomerate headquartered in Mumbai, Maharashtra.  It's not a single entity but a network of over 100 operating companies, spanning diverse sectors and employing millions of people globally.  Understanding its complexity requires looking at several key aspects:\n",
            "\n",
            "**I. History and Structure:**\n",
            "\n",
            "* **Origins:** The group traces its roots back to 1868 when Jamsetji Tata founded the Tata & Sons trading company.  His vision extended beyond profit, encompassing social responsibility and nation-building, a philosophy that continues to define the group.\n",
            "* **Structure:**  The Tata Group isn't a typical corporation.  It's a complex web of independent companies, many publicly listed, held together by a shared philosophy and the overarching influence of Tata Sons, the holding company.  Tata Sons owns substantial stakes in many group companies, but doesn't directly manage their day-to-day operations.  Instead, each company has its own board and management team.\n",
            "* **Trusts:**  A significant portion of Tata Sons is owned by philanthropic trusts, including the Sir Dorabji Tata Trust and the Sir Ratan Tata Trust.  These trusts play a crucial role in shaping the group's social responsibility initiatives and ensuring long-term sustainability.  Their ownership structure contributes to the group's unique character and long-term focus.\n",
            "* **Leadership:** The group's leadership has historically been characterized by strong, visionary leaders, starting with Jamsetji Tata himself and continuing through figures like J.R.D. Tata and Ratan Tata.  The chairman of Tata Sons plays a crucial role in setting the overall direction and strategy for the entire group.\n",
            "\n",
            "**II. Business Sectors:**\n",
            "\n",
            "The Tata Group's reach is extraordinary, encompassing nearly every major sector of the economy.  Some key areas include:\n",
            "\n",
            "* **Automotive:** Tata Motors, one of the largest automobile manufacturers in India, produces passenger cars, commercial vehicles, and even luxury vehicles (Jaguar Land Rover).\n",
            "* **Steel:** Tata Steel is a global steel giant, with operations across multiple countries.\n",
            "* **Information Technology:** Tata Consultancy Services (TCS) is a leading global IT services and consulting company, employing hundreds of thousands. Tata Elxsi is another significant player in the IT space, focusing on embedded systems, design, and software.\n",
            "* **Consumer Goods:**  The group has a substantial presence in consumer goods, with brands like Tata Tea, Tata Salt, and Tata Coffee dominating the Indian market.  They also have interests in packaged foods and personal care products.\n",
            "* **Chemicals:** Tata Chemicals is a significant player in the chemicals industry, producing a wide range of products.\n",
            "* **Energy:** Tata Power is a major player in the Indian power sector, involved in generation, transmission, and distribution.\n",
            "* **Telecommunications:** Tata Teleservices was once a major player, though it has since undergone restructuring.\n",
            "* **Hospitality:**  The Indian Hotels Company Limited (IHCL), which owns the Taj Hotels brand, is a leader in the luxury hospitality sector.\n",
            "* **Aerospace & Defence:** Tata Advanced Systems is a growing player in this sector.\n",
            "* **Financial Services:** Tata Capital and other entities offer a range of financial services.\n",
            "\n",
            "**III. Global Presence:**\n",
            "\n",
            "The Tata Group is not just an Indian giant; it has a significant international presence.  Jaguar Land Rover, acquired by Tata Motors, is a prime example.  TCS and other IT companies have global operations and serve clients worldwide.  The group also has operations in various other countries across Asia, Europe, and the Americas.\n",
            "\n",
            "**IV. Social Responsibility:**\n",
            "\n",
            "The Tata Group's commitment to social responsibility is a cornerstone of its identity.  The philanthropic trusts actively support initiatives in education, healthcare, rural development, and environmental sustainability.  This commitment is integrated into the group's business practices and is often cited as a key differentiator.\n",
            "\n",
            "**V. Challenges and Criticisms:**\n",
            "\n",
            "Despite its success, the Tata Group faces challenges:\n",
            "\n",
            "* **Complexity:** The sheer size and complexity of the group can make decision-making slow and coordination difficult.\n",
            "* **Competition:**  The group faces intense competition in many of its sectors.\n",
            "* **Economic Downturns:**  Like any large conglomerate, it's vulnerable to economic fluctuations.\n",
            "* **Succession Planning:**  Maintaining consistent leadership and vision after significant leadership changes is a constant challenge.\n",
            "* **Criticism regarding labor practices:**  Like many large corporations, the Tata Group has faced criticism regarding labor practices in some of its subsidiaries.\n",
            "\n",
            "\n",
            "In conclusion, the Tata Group is a multifaceted and influential conglomerate with a long history and a profound impact on India and the global economy.  Its unique structure, commitment to social responsibility, and diverse business portfolio make it a fascinating case study in corporate strategy and global business.  However, it's also a complex organization facing the challenges inherent in its size and scope.\n",
            "\n",
            "\n",
            "here is output from LLM_Output_Token_Counter\n",
            "_______\n",
            "total token number in the generated answer is 749\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for output in app.stream(\"tell me about the tata enterpirse in very detail.\"):\n",
        "    for key,value in output.items():\n",
        "        print(f\"here is output from {key}\")\n",
        "        print(\"_______\")\n",
        "        print(value)\n",
        "        print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fef12522",
      "metadata": {
        "id": "fef12522"
      },
      "source": [
        "## Langgraph Intro 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "680faf98",
      "metadata": {
        "id": "680faf98"
      },
      "source": [
        "### Config the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ba13a88f",
      "metadata": {
        "id": "ba13a88f",
        "outputId": "57a92c09-0956-48c8-b344-e093aebf577a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi there! How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model=ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
        "output=model.invoke(\"hi\")\n",
        "print(output.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa63b77a",
      "metadata": {
        "id": "aa63b77a"
      },
      "source": [
        "### Config the embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "48ae5bee",
      "metadata": {
        "id": "48ae5bee",
        "outputId": "4cd2db08-bd8c-4304-951b-75a5e3971b67"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en\")\n",
        "len(embeddings.embed_query(\"hi\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57003fe4",
      "metadata": {
        "id": "57003fe4"
      },
      "source": [
        "### lets take a data embedd it and store in VDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0994875e",
      "metadata": {
        "id": "0994875e"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "# from langchain_community.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1da8893f",
      "metadata": {
        "id": "1da8893f"
      },
      "outputs": [],
      "source": [
        "loader=DirectoryLoader(\"data\",glob=\"./*.txt\",loader_cls=TextLoader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6516d2cd",
      "metadata": {
        "id": "6516d2cd"
      },
      "outputs": [],
      "source": [
        "docs=loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0d100ab2",
      "metadata": {
        "id": "0d100ab2",
        "outputId": "3d2ef504-de8b-4ab2-9ce8-9c33c9c96b3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'data\\\\speech.txt'}, page_content='The world must be made safe for democracy. Its peace must be planted upon the tested foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no dominion. We seek no indemnities for ourselves, no material compensation for the sacrifices we shall freely make. We are but one of the champions of the rights of mankind. We shall be satisfied when those rights have been made as secure as the faith and the freedom of nations can make them.\\n\\nJust because we fight without rancor and without selfish object, seeking nothing for ourselves but what we shall wish to share with all free peoples, we shall, I feel confident, conduct our operations as belligerents without passion and ourselves observe with proud punctilio the principles of right and of fair play we profess to be fighting for.\\n\\n…\\n\\nIt will be all the easier for us to conduct ourselves as belligerents in a high spirit of right and fairness because we act without animus, not in enmity toward a people or with the desire to bring any injury or disadvantage upon them, but only in armed opposition to an irresponsible government which has thrown aside all considerations of humanity and of right and is running amuck. We are, let me say again, the sincere friends of the German people, and shall desire nothing so much as the early reestablishment of intimate relations of mutual advantage between us—however hard it may be for them, for the time being, to believe that this is spoken from our hearts.\\n\\nWe have borne with their present government through all these bitter months because of that friendship—exercising a patience and forbearance which would otherwise have been impossible. We shall, happily, still have an opportunity to prove that friendship in our daily attitude and actions toward the millions of men and women of German birth and native sympathy who live among us and share our life, and we shall be proud to prove it toward all who are in fact loyal to their neighbors and to the government in the hour of test. They are, most of them, as true and loyal Americans as if they had never known any other fealty or allegiance. They will be prompt to stand with us in rebuking and restraining the few who may be of a different mind and purpose. If there should be disloyalty, it will be dealt with with a firm hand of stern repression; but, if it lifts its head at all, it will lift it only here and there and without countenance except from a lawless and malignant few.\\n\\nIt is a distressing and oppressive duty, gentlemen of the Congress, which I have performed in thus addressing you. There are, it may be, many months of fiery trial and sacrifice ahead of us. It is a fearful thing to lead this great peaceful people into war, into the most terrible and disastrous of all wars, civilization itself seeming to be in the balance. But the right is more precious than peace, and we shall fight for the things which we have always carried nearest our hearts—for democracy, for the right of those who submit to authority to have a voice in their own governments, for the rights and liberties of small nations, for a universal dominion of right by such a concert of free peoples as shall bring peace and safety to all nations and make the world itself at last free.\\n\\nTo such a task we can dedicate our lives and our fortunes, everything that we are and everything that we have, with the pride of those who know that the day has come when America is privileged to spend her blood and her might for the principles that gave her birth and happiness and the peace which she has treasured. God helping her, she can do no other.'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content=\"🇺🇸 Overview of the U.S. Economy\\nThe United States of America possesses the largest economy in the world in terms of nominal GDP, making it the most powerful economic force globally. It operates under a capitalist mixed economy, where the private sector dominates, but the government plays a significant regulatory and fiscal role. With a population of over 335 million people and a high level of technological advancement, the U.S. economy thrives on a foundation of consumer spending, innovation, global trade, and financial services. It has a highly diversified structure with strong sectors in technology, healthcare, finance, real estate, defense, and agriculture.\\n\\nU.S. GDP – Size, Composition, and Global Share\\nAs of 2024, the United States’ nominal GDP is estimated to be around $28 trillion USD, accounting for approximately 25% of the global economy. It ranks #1 in the world by nominal GDP, far ahead of China (which ranks 2nd). The U.S. GDP per capita is also among the highest, hovering around $83,000, which indicates a high standard of living and productivity. In terms of Purchasing Power Parity (PPP), the U.S. ranks second, but nominal GDP is considered more reflective of actual economic size and financial influence.\\n\\nThe GDP is predominantly driven by the services sector, which contributes more than 77% to the total GDP. This includes industries such as finance, insurance, real estate, healthcare, education, and information technology. The industrial sector (manufacturing, construction, mining) makes up around 19%, while agriculture, although technologically advanced and export-oriented, contributes only about 1%. Despite its small share in GDP, U.S. agriculture is globally significant in terms of productivity and exports.\\n\\nGDP Growth Trends and Dynamics\\nHistorically, the U.S. economy has enjoyed consistent long-term growth, averaging around 2-3% annually. Post-pandemic, the economy bounced back strongly, but 2022 and 2023 saw rising inflation due to supply chain issues and stimulus-driven demand. In 2024, the U.S. GDP grew at a modest pace of around 2.1%, as the Federal Reserve’s interest rate hikes aimed at controlling inflation also moderated economic expansion. Consumer spending, which makes up nearly 70% of GDP, remains a dominant force in economic stability.\\n\\nThe U.S. maintains its GDP growth through strong innovation, entrepreneurship, and investment in R&D. With companies like Apple, Google, Amazon, Microsoft, and Tesla leading global markets, the U.S. consistently produces high value across sectors, especially in technology and advanced services. Additionally, the economy benefits from intellectual property exports, financial services, and higher education, all of which contribute significantly to GDP through both domestic and international markets.\\n\\nRole in the Global Economy\\nThe U.S. Dollar (USD) is the global reserve currency, held by over 60% of the world’s central bank reserves. This gives the U.S. an enormous advantage in global trade and borrowing. The U.S. is a key member of international institutions like the World Bank, IMF, G7, G20, and WTO, and plays a central role in setting global economic policy.\\n\\nAs a global innovation hub, the U.S. attracts billions in foreign investment and hosts many of the world's largest and most valuable companies. Its exports include high-tech machinery, aircraft, pharmaceuticals, semiconductors, and financial services, while its imports cover consumer goods, electronics, automobiles, and industrial materials. The trade deficit remains large (around $900 billion in 2024), primarily because the U.S. consumes more than it exports, but its ability to finance this through capital inflows and reserve currency status sustains balance.\\n\\nKey Economic Strengths\\nThe core strength of the U.S. economy lies in its flexible labor market, deep capital markets, technological superiority, and legal system that encourages innovation and property rights. It has a large, highly educated workforce, a diverse immigration pipeline, and access to vast natural resources including oil, gas, coal, and farmland. The presence of top-tier universities and research institutions fuels the knowledge economy, with billions spent annually on R&D—over $700 billion USD, more than any other country.\\n\\nThe U.S. leads in many critical sectors, including software, biotechnology, aerospace, defense, financial services, and media. Its startup ecosystem, especially in Silicon Valley, produces unicorns and tech giants at a scale unmatched globally. Its financial markets—particularly Wall Street—are the most liquid and globally integrated in the world.\\n\\nChallenges and Structural Issues\\nDespite its strength, the U.S. economy faces several serious long-term issues. The national debt has surpassed $34 trillion USD, raising concerns about fiscal sustainability, especially as interest payments alone are growing rapidly. The income and wealth inequality gap has widened, with a small percentage of Americans owning a disproportionate share of wealth. Access to affordable healthcare, housing shortages, and a declining labor force participation in some sectors are additional structural issues.\\n\\nAnother growing concern is political polarization, which often stalls crucial economic reforms and budget agreements, as seen in recurrent debt ceiling crises. The U.S. also faces challenges from global competition, especially from China in areas like AI, semiconductors, and green technology. Moreover, climate change, cybersecurity threats, and geopolitical risks (like Ukraine and Taiwan conflicts) add layers of vulnerability to economic planning.\\n\\nFuture Outlook (2025–2030)\\nLooking forward, the U.S. economy is expected to grow at a moderate pace, powered by innovation in AI, green energy, robotics, biotech, and quantum computing. The Biden administration’s Inflation Reduction Act and CHIPS Act are pumping massive investments into semiconductors, clean energy, and infrastructure. There is a strong push for reshoring of manufacturing, especially in critical sectors like chips, pharmaceuticals, and batteries.\\n\\nHowever, economic leadership will depend on managing the national debt, reforming entitlement programs, upgrading infrastructure, and ensuring the next generation is equipped with digital-age skills. If the U.S. can handle these challenges, it is well-positioned to remain a global economic powerhouse through 2030 and beyond.\\n\\nFinal Summary\\nThe U.S. economy remains the engine of global growth, backed by unmatched innovation, financial dominance, and a strong institutional framework. Its $28 trillion GDP and influence over global finance, trade, and technology make it the centerpiece of the modern economic system. Yet, rising debt, inequality, political gridlock, and competition from emerging powers demand careful policy navigation. If successfully addressed, the U.S. will continue to dominate the global economy well into the future.\")]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "32db3be9",
      "metadata": {
        "id": "32db3be9",
        "outputId": "84b014b4-379e-457c-9947-2184f4c65583"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The world must be made safe for democracy. Its peace must be planted upon the tested foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no dominion. We seek no indemnities for ourselves, no material compensation for the sacrifices we shall freely make. We are but one of the champions of the rights of mankind. We shall be satisfied when those rights have been made as secure as the faith and the freedom of nations can make them.\\n\\nJust because we fight without rancor and without selfish object, seeking nothing for ourselves but what we shall wish to share with all free peoples, we shall, I feel confident, conduct our operations as belligerents without passion and ourselves observe with proud punctilio the principles of right and of fair play we profess to be fighting for.\\n\\n…\\n\\nIt will be all the easier for us to conduct ourselves as belligerents in a high spirit of right and fairness because we act without animus, not in enmity toward a people or with the desire to bring any injury or disadvantage upon them, but only in armed opposition to an irresponsible government which has thrown aside all considerations of humanity and of right and is running amuck. We are, let me say again, the sincere friends of the German people, and shall desire nothing so much as the early reestablishment of intimate relations of mutual advantage between us—however hard it may be for them, for the time being, to believe that this is spoken from our hearts.\\n\\nWe have borne with their present government through all these bitter months because of that friendship—exercising a patience and forbearance which would otherwise have been impossible. We shall, happily, still have an opportunity to prove that friendship in our daily attitude and actions toward the millions of men and women of German birth and native sympathy who live among us and share our life, and we shall be proud to prove it toward all who are in fact loyal to their neighbors and to the government in the hour of test. They are, most of them, as true and loyal Americans as if they had never known any other fealty or allegiance. They will be prompt to stand with us in rebuking and restraining the few who may be of a different mind and purpose. If there should be disloyalty, it will be dealt with with a firm hand of stern repression; but, if it lifts its head at all, it will lift it only here and there and without countenance except from a lawless and malignant few.\\n\\nIt is a distressing and oppressive duty, gentlemen of the Congress, which I have performed in thus addressing you. There are, it may be, many months of fiery trial and sacrifice ahead of us. It is a fearful thing to lead this great peaceful people into war, into the most terrible and disastrous of all wars, civilization itself seeming to be in the balance. But the right is more precious than peace, and we shall fight for the things which we have always carried nearest our hearts—for democracy, for the right of those who submit to authority to have a voice in their own governments, for the rights and liberties of small nations, for a universal dominion of right by such a concert of free peoples as shall bring peace and safety to all nations and make the world itself at last free.\\n\\nTo such a task we can dedicate our lives and our fortunes, everything that we are and everything that we have, with the pride of those who know that the day has come when America is privileged to spend her blood and her might for the principles that gave her birth and happiness and the peace which she has treasured. God helping her, she can do no other.'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "75a338e8",
      "metadata": {
        "id": "75a338e8"
      },
      "outputs": [],
      "source": [
        "text_splitter=RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=50\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9cdeb0c1",
      "metadata": {
        "id": "9cdeb0c1"
      },
      "outputs": [],
      "source": [
        "new_docs=text_splitter.split_documents(documents=docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "51c77f95",
      "metadata": {
        "id": "51c77f95",
        "outputId": "0ec67e22-4b9c-4b19-f2ed-6d588a2dc93c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'data\\\\speech.txt'}, page_content='The world must be made safe for democracy. Its peace must be planted upon the tested foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no dominion. We seek no'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='We desire no conquest, no dominion. We seek no indemnities for ourselves, no material compensation for the sacrifices we shall freely make. We are but one of the champions of the rights of mankind.'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='one of the champions of the rights of mankind. We shall be satisfied when those rights have been made as secure as the faith and the freedom of nations can make them.'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='Just because we fight without rancor and without selfish object, seeking nothing for ourselves but what we shall wish to share with all free peoples, we shall, I feel confident, conduct our'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='peoples, we shall, I feel confident, conduct our operations as belligerents without passion and ourselves observe with proud punctilio the principles of right and of fair play we profess to be'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='of right and of fair play we profess to be fighting for.'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='…'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='It will be all the easier for us to conduct ourselves as belligerents in a high spirit of right and fairness because we act without animus, not in enmity toward a people or with the desire to bring'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='toward a people or with the desire to bring any injury or disadvantage upon them, but only in armed opposition to an irresponsible government which has thrown aside all considerations of humanity and'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='thrown aside all considerations of humanity and of right and is running amuck. We are, let me say again, the sincere friends of the German people, and shall desire nothing so much as the early'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='and shall desire nothing so much as the early reestablishment of intimate relations of mutual advantage between us—however hard it may be for them, for the time being, to believe that this is spoken'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='the time being, to believe that this is spoken from our hearts.'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='We have borne with their present government through all these bitter months because of that friendship—exercising a patience and forbearance which would otherwise have been impossible. We shall,'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='would otherwise have been impossible. We shall, happily, still have an opportunity to prove that friendship in our daily attitude and actions toward the millions of men and women of German birth and'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='the millions of men and women of German birth and native sympathy who live among us and share our life, and we shall be proud to prove it toward all who are in fact loyal to their neighbors and to'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='who are in fact loyal to their neighbors and to the government in the hour of test. They are, most of them, as true and loyal Americans as if they had never known any other fealty or allegiance. They'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='never known any other fealty or allegiance. They will be prompt to stand with us in rebuking and restraining the few who may be of a different mind and purpose. If there should be disloyalty, it will'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='purpose. If there should be disloyalty, it will be dealt with with a firm hand of stern repression; but, if it lifts its head at all, it will lift it only here and there and without countenance'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='it only here and there and without countenance except from a lawless and malignant few.'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='It is a distressing and oppressive duty, gentlemen of the Congress, which I have performed in thus addressing you. There are, it may be, many months of fiery trial and sacrifice ahead of us. It is a'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='of fiery trial and sacrifice ahead of us. It is a fearful thing to lead this great peaceful people into war, into the most terrible and disastrous of all wars, civilization itself seeming to be in'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='of all wars, civilization itself seeming to be in the balance. But the right is more precious than peace, and we shall fight for the things which we have always carried nearest our hearts—for'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='we have always carried nearest our hearts—for democracy, for the right of those who submit to authority to have a voice in their own governments, for the rights and liberties of small nations, for a'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='the rights and liberties of small nations, for a universal dominion of right by such a concert of free peoples as shall bring peace and safety to all nations and make the world itself at last free.'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='To such a task we can dedicate our lives and our fortunes, everything that we are and everything that we have, with the pride of those who know that the day has come when America is privileged to'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='the day has come when America is privileged to spend her blood and her might for the principles that gave her birth and happiness and the peace which she has treasured. God helping her, she can do no'),\n",
              " Document(metadata={'source': 'data\\\\speech.txt'}, page_content='she has treasured. God helping her, she can do no other.'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='🇺🇸 Overview of the U.S. Economy'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='The United States of America possesses the largest economy in the world in terms of nominal GDP, making it the most powerful economic force globally. It operates under a capitalist mixed economy,'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='It operates under a capitalist mixed economy, where the private sector dominates, but the government plays a significant regulatory and fiscal role. With a population of over 335 million people and a'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='a population of over 335 million people and a high level of technological advancement, the U.S. economy thrives on a foundation of consumer spending, innovation, global trade, and financial services.'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='innovation, global trade, and financial services. It has a highly diversified structure with strong sectors in technology, healthcare, finance, real estate, defense, and agriculture.'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='U.S. GDP – Size, Composition, and Global Share'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='As of 2024, the United States’ nominal GDP is estimated to be around $28 trillion USD, accounting for approximately 25% of the global economy. It ranks #1 in the world by nominal GDP, far ahead of'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='#1 in the world by nominal GDP, far ahead of China (which ranks 2nd). The U.S. GDP per capita is also among the highest, hovering around $83,000, which indicates a high standard of living and'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='which indicates a high standard of living and productivity. In terms of Purchasing Power Parity (PPP), the U.S. ranks second, but nominal GDP is considered more reflective of actual economic size and'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='more reflective of actual economic size and financial influence.'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='The GDP is predominantly driven by the services sector, which contributes more than 77% to the total GDP. This includes industries such as finance, insurance, real estate, healthcare, education, and'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='real estate, healthcare, education, and information technology. The industrial sector (manufacturing, construction, mining) makes up around 19%, while agriculture, although technologically advanced'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='agriculture, although technologically advanced and export-oriented, contributes only about 1%. Despite its small share in GDP, U.S. agriculture is globally significant in terms of productivity and'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='globally significant in terms of productivity and exports.'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='GDP Growth Trends and Dynamics'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='Historically, the U.S. economy has enjoyed consistent long-term growth, averaging around 2-3% annually. Post-pandemic, the economy bounced back strongly, but 2022 and 2023 saw rising inflation due to'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='but 2022 and 2023 saw rising inflation due to supply chain issues and stimulus-driven demand. In 2024, the U.S. GDP grew at a modest pace of around 2.1%, as the Federal Reserve’s interest rate hikes'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='as the Federal Reserve’s interest rate hikes aimed at controlling inflation also moderated economic expansion. Consumer spending, which makes up nearly 70% of GDP, remains a dominant force in'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='up nearly 70% of GDP, remains a dominant force in economic stability.'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='The U.S. maintains its GDP growth through strong innovation, entrepreneurship, and investment in R&D. With companies like Apple, Google, Amazon, Microsoft, and Tesla leading global markets, the U.S.'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='and Tesla leading global markets, the U.S. consistently produces high value across sectors, especially in technology and advanced services. Additionally, the economy benefits from intellectual'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='the economy benefits from intellectual property exports, financial services, and higher education, all of which contribute significantly to GDP through both domestic and international markets.'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='Role in the Global Economy'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='The U.S. Dollar (USD) is the global reserve currency, held by over 60% of the world’s central bank reserves. This gives the U.S. an enormous advantage in global trade and borrowing. The U.S. is a key'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='in global trade and borrowing. The U.S. is a key member of international institutions like the World Bank, IMF, G7, G20, and WTO, and plays a central role in setting global economic policy.'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content=\"As a global innovation hub, the U.S. attracts billions in foreign investment and hosts many of the world's largest and most valuable companies. Its exports include high-tech machinery, aircraft,\"),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='exports include high-tech machinery, aircraft, pharmaceuticals, semiconductors, and financial services, while its imports cover consumer goods, electronics, automobiles, and industrial materials. The'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='automobiles, and industrial materials. The trade deficit remains large (around $900 billion in 2024), primarily because the U.S. consumes more than it exports, but its ability to finance this through'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='exports, but its ability to finance this through capital inflows and reserve currency status sustains balance.'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='Key Economic Strengths'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='The core strength of the U.S. economy lies in its flexible labor market, deep capital markets, technological superiority, and legal system that encourages innovation and property rights. It has a'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='innovation and property rights. It has a large, highly educated workforce, a diverse immigration pipeline, and access to vast natural resources including oil, gas, coal, and farmland. The presence of'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='oil, gas, coal, and farmland. The presence of top-tier universities and research institutions fuels the knowledge economy, with billions spent annually on R&D—over $700 billion USD, more than any'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='on R&D—over $700 billion USD, more than any other country.'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='The U.S. leads in many critical sectors, including software, biotechnology, aerospace, defense, financial services, and media. Its startup ecosystem, especially in Silicon Valley, produces unicorns'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='especially in Silicon Valley, produces unicorns and tech giants at a scale unmatched globally. Its financial markets—particularly Wall Street—are the most liquid and globally integrated in the world.'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='Challenges and Structural Issues'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='Despite its strength, the U.S. economy faces several serious long-term issues. The national debt has surpassed $34 trillion USD, raising concerns about fiscal sustainability, especially as interest'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='fiscal sustainability, especially as interest payments alone are growing rapidly. The income and wealth inequality gap has widened, with a small percentage of Americans owning a disproportionate'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='percentage of Americans owning a disproportionate share of wealth. Access to affordable healthcare, housing shortages, and a declining labor force participation in some sectors are additional'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='participation in some sectors are additional structural issues.'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='Another growing concern is political polarization, which often stalls crucial economic reforms and budget agreements, as seen in recurrent debt ceiling crises. The U.S. also faces challenges from'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='crises. The U.S. also faces challenges from global competition, especially from China in areas like AI, semiconductors, and green technology. Moreover, climate change, cybersecurity threats, and'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='climate change, cybersecurity threats, and geopolitical risks (like Ukraine and Taiwan conflicts) add layers of vulnerability to economic planning.'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='Future Outlook (2025–2030)'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='Looking forward, the U.S. economy is expected to grow at a moderate pace, powered by innovation in AI, green energy, robotics, biotech, and quantum computing. The Biden administration’s Inflation'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='computing. The Biden administration’s Inflation Reduction Act and CHIPS Act are pumping massive investments into semiconductors, clean energy, and infrastructure. There is a strong push for reshoring'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='There is a strong push for reshoring of manufacturing, especially in critical sectors like chips, pharmaceuticals, and batteries.'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='However, economic leadership will depend on managing the national debt, reforming entitlement programs, upgrading infrastructure, and ensuring the next generation is equipped with digital-age skills.'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='generation is equipped with digital-age skills. If the U.S. can handle these challenges, it is well-positioned to remain a global economic powerhouse through 2030 and beyond.'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='Final Summary'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='The U.S. economy remains the engine of global growth, backed by unmatched innovation, financial dominance, and a strong institutional framework. Its $28 trillion GDP and influence over global'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='Its $28 trillion GDP and influence over global finance, trade, and technology make it the centerpiece of the modern economic system. Yet, rising debt, inequality, political gridlock, and competition'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='inequality, political gridlock, and competition from emerging powers demand careful policy navigation. If successfully addressed, the U.S. will continue to dominate the global economy well into the'),\n",
              " Document(metadata={'source': 'data\\\\usa.txt'}, page_content='to dominate the global economy well into the future.')]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ae5f2527",
      "metadata": {
        "id": "ae5f2527"
      },
      "outputs": [],
      "source": [
        "doc_string=[doc.page_content for doc in new_docs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b36086cc",
      "metadata": {
        "id": "b36086cc",
        "outputId": "47cb0a19-55db-42d3-c9bb-dab651c279c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The world must be made safe for democracy. Its peace must be planted upon the tested foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no dominion. We seek no',\n",
              " 'We desire no conquest, no dominion. We seek no indemnities for ourselves, no material compensation for the sacrifices we shall freely make. We are but one of the champions of the rights of mankind.',\n",
              " 'one of the champions of the rights of mankind. We shall be satisfied when those rights have been made as secure as the faith and the freedom of nations can make them.',\n",
              " 'Just because we fight without rancor and without selfish object, seeking nothing for ourselves but what we shall wish to share with all free peoples, we shall, I feel confident, conduct our',\n",
              " 'peoples, we shall, I feel confident, conduct our operations as belligerents without passion and ourselves observe with proud punctilio the principles of right and of fair play we profess to be',\n",
              " 'of right and of fair play we profess to be fighting for.',\n",
              " '…',\n",
              " 'It will be all the easier for us to conduct ourselves as belligerents in a high spirit of right and fairness because we act without animus, not in enmity toward a people or with the desire to bring',\n",
              " 'toward a people or with the desire to bring any injury or disadvantage upon them, but only in armed opposition to an irresponsible government which has thrown aside all considerations of humanity and',\n",
              " 'thrown aside all considerations of humanity and of right and is running amuck. We are, let me say again, the sincere friends of the German people, and shall desire nothing so much as the early',\n",
              " 'and shall desire nothing so much as the early reestablishment of intimate relations of mutual advantage between us—however hard it may be for them, for the time being, to believe that this is spoken',\n",
              " 'the time being, to believe that this is spoken from our hearts.',\n",
              " 'We have borne with their present government through all these bitter months because of that friendship—exercising a patience and forbearance which would otherwise have been impossible. We shall,',\n",
              " 'would otherwise have been impossible. We shall, happily, still have an opportunity to prove that friendship in our daily attitude and actions toward the millions of men and women of German birth and',\n",
              " 'the millions of men and women of German birth and native sympathy who live among us and share our life, and we shall be proud to prove it toward all who are in fact loyal to their neighbors and to',\n",
              " 'who are in fact loyal to their neighbors and to the government in the hour of test. They are, most of them, as true and loyal Americans as if they had never known any other fealty or allegiance. They',\n",
              " 'never known any other fealty or allegiance. They will be prompt to stand with us in rebuking and restraining the few who may be of a different mind and purpose. If there should be disloyalty, it will',\n",
              " 'purpose. If there should be disloyalty, it will be dealt with with a firm hand of stern repression; but, if it lifts its head at all, it will lift it only here and there and without countenance',\n",
              " 'it only here and there and without countenance except from a lawless and malignant few.',\n",
              " 'It is a distressing and oppressive duty, gentlemen of the Congress, which I have performed in thus addressing you. There are, it may be, many months of fiery trial and sacrifice ahead of us. It is a',\n",
              " 'of fiery trial and sacrifice ahead of us. It is a fearful thing to lead this great peaceful people into war, into the most terrible and disastrous of all wars, civilization itself seeming to be in',\n",
              " 'of all wars, civilization itself seeming to be in the balance. But the right is more precious than peace, and we shall fight for the things which we have always carried nearest our hearts—for',\n",
              " 'we have always carried nearest our hearts—for democracy, for the right of those who submit to authority to have a voice in their own governments, for the rights and liberties of small nations, for a',\n",
              " 'the rights and liberties of small nations, for a universal dominion of right by such a concert of free peoples as shall bring peace and safety to all nations and make the world itself at last free.',\n",
              " 'To such a task we can dedicate our lives and our fortunes, everything that we are and everything that we have, with the pride of those who know that the day has come when America is privileged to',\n",
              " 'the day has come when America is privileged to spend her blood and her might for the principles that gave her birth and happiness and the peace which she has treasured. God helping her, she can do no',\n",
              " 'she has treasured. God helping her, she can do no other.',\n",
              " '🇺🇸 Overview of the U.S. Economy',\n",
              " 'The United States of America possesses the largest economy in the world in terms of nominal GDP, making it the most powerful economic force globally. It operates under a capitalist mixed economy,',\n",
              " 'It operates under a capitalist mixed economy, where the private sector dominates, but the government plays a significant regulatory and fiscal role. With a population of over 335 million people and a',\n",
              " 'a population of over 335 million people and a high level of technological advancement, the U.S. economy thrives on a foundation of consumer spending, innovation, global trade, and financial services.',\n",
              " 'innovation, global trade, and financial services. It has a highly diversified structure with strong sectors in technology, healthcare, finance, real estate, defense, and agriculture.',\n",
              " 'U.S. GDP – Size, Composition, and Global Share',\n",
              " 'As of 2024, the United States’ nominal GDP is estimated to be around $28 trillion USD, accounting for approximately 25% of the global economy. It ranks #1 in the world by nominal GDP, far ahead of',\n",
              " '#1 in the world by nominal GDP, far ahead of China (which ranks 2nd). The U.S. GDP per capita is also among the highest, hovering around $83,000, which indicates a high standard of living and',\n",
              " 'which indicates a high standard of living and productivity. In terms of Purchasing Power Parity (PPP), the U.S. ranks second, but nominal GDP is considered more reflective of actual economic size and',\n",
              " 'more reflective of actual economic size and financial influence.',\n",
              " 'The GDP is predominantly driven by the services sector, which contributes more than 77% to the total GDP. This includes industries such as finance, insurance, real estate, healthcare, education, and',\n",
              " 'real estate, healthcare, education, and information technology. The industrial sector (manufacturing, construction, mining) makes up around 19%, while agriculture, although technologically advanced',\n",
              " 'agriculture, although technologically advanced and export-oriented, contributes only about 1%. Despite its small share in GDP, U.S. agriculture is globally significant in terms of productivity and',\n",
              " 'globally significant in terms of productivity and exports.',\n",
              " 'GDP Growth Trends and Dynamics',\n",
              " 'Historically, the U.S. economy has enjoyed consistent long-term growth, averaging around 2-3% annually. Post-pandemic, the economy bounced back strongly, but 2022 and 2023 saw rising inflation due to',\n",
              " 'but 2022 and 2023 saw rising inflation due to supply chain issues and stimulus-driven demand. In 2024, the U.S. GDP grew at a modest pace of around 2.1%, as the Federal Reserve’s interest rate hikes',\n",
              " 'as the Federal Reserve’s interest rate hikes aimed at controlling inflation also moderated economic expansion. Consumer spending, which makes up nearly 70% of GDP, remains a dominant force in',\n",
              " 'up nearly 70% of GDP, remains a dominant force in economic stability.',\n",
              " 'The U.S. maintains its GDP growth through strong innovation, entrepreneurship, and investment in R&D. With companies like Apple, Google, Amazon, Microsoft, and Tesla leading global markets, the U.S.',\n",
              " 'and Tesla leading global markets, the U.S. consistently produces high value across sectors, especially in technology and advanced services. Additionally, the economy benefits from intellectual',\n",
              " 'the economy benefits from intellectual property exports, financial services, and higher education, all of which contribute significantly to GDP through both domestic and international markets.',\n",
              " 'Role in the Global Economy',\n",
              " 'The U.S. Dollar (USD) is the global reserve currency, held by over 60% of the world’s central bank reserves. This gives the U.S. an enormous advantage in global trade and borrowing. The U.S. is a key',\n",
              " 'in global trade and borrowing. The U.S. is a key member of international institutions like the World Bank, IMF, G7, G20, and WTO, and plays a central role in setting global economic policy.',\n",
              " \"As a global innovation hub, the U.S. attracts billions in foreign investment and hosts many of the world's largest and most valuable companies. Its exports include high-tech machinery, aircraft,\",\n",
              " 'exports include high-tech machinery, aircraft, pharmaceuticals, semiconductors, and financial services, while its imports cover consumer goods, electronics, automobiles, and industrial materials. The',\n",
              " 'automobiles, and industrial materials. The trade deficit remains large (around $900 billion in 2024), primarily because the U.S. consumes more than it exports, but its ability to finance this through',\n",
              " 'exports, but its ability to finance this through capital inflows and reserve currency status sustains balance.',\n",
              " 'Key Economic Strengths',\n",
              " 'The core strength of the U.S. economy lies in its flexible labor market, deep capital markets, technological superiority, and legal system that encourages innovation and property rights. It has a',\n",
              " 'innovation and property rights. It has a large, highly educated workforce, a diverse immigration pipeline, and access to vast natural resources including oil, gas, coal, and farmland. The presence of',\n",
              " 'oil, gas, coal, and farmland. The presence of top-tier universities and research institutions fuels the knowledge economy, with billions spent annually on R&D—over $700 billion USD, more than any',\n",
              " 'on R&D—over $700 billion USD, more than any other country.',\n",
              " 'The U.S. leads in many critical sectors, including software, biotechnology, aerospace, defense, financial services, and media. Its startup ecosystem, especially in Silicon Valley, produces unicorns',\n",
              " 'especially in Silicon Valley, produces unicorns and tech giants at a scale unmatched globally. Its financial markets—particularly Wall Street—are the most liquid and globally integrated in the world.',\n",
              " 'Challenges and Structural Issues',\n",
              " 'Despite its strength, the U.S. economy faces several serious long-term issues. The national debt has surpassed $34 trillion USD, raising concerns about fiscal sustainability, especially as interest',\n",
              " 'fiscal sustainability, especially as interest payments alone are growing rapidly. The income and wealth inequality gap has widened, with a small percentage of Americans owning a disproportionate',\n",
              " 'percentage of Americans owning a disproportionate share of wealth. Access to affordable healthcare, housing shortages, and a declining labor force participation in some sectors are additional',\n",
              " 'participation in some sectors are additional structural issues.',\n",
              " 'Another growing concern is political polarization, which often stalls crucial economic reforms and budget agreements, as seen in recurrent debt ceiling crises. The U.S. also faces challenges from',\n",
              " 'crises. The U.S. also faces challenges from global competition, especially from China in areas like AI, semiconductors, and green technology. Moreover, climate change, cybersecurity threats, and',\n",
              " 'climate change, cybersecurity threats, and geopolitical risks (like Ukraine and Taiwan conflicts) add layers of vulnerability to economic planning.',\n",
              " 'Future Outlook (2025–2030)',\n",
              " 'Looking forward, the U.S. economy is expected to grow at a moderate pace, powered by innovation in AI, green energy, robotics, biotech, and quantum computing. The Biden administration’s Inflation',\n",
              " 'computing. The Biden administration’s Inflation Reduction Act and CHIPS Act are pumping massive investments into semiconductors, clean energy, and infrastructure. There is a strong push for reshoring',\n",
              " 'There is a strong push for reshoring of manufacturing, especially in critical sectors like chips, pharmaceuticals, and batteries.',\n",
              " 'However, economic leadership will depend on managing the national debt, reforming entitlement programs, upgrading infrastructure, and ensuring the next generation is equipped with digital-age skills.',\n",
              " 'generation is equipped with digital-age skills. If the U.S. can handle these challenges, it is well-positioned to remain a global economic powerhouse through 2030 and beyond.',\n",
              " 'Final Summary',\n",
              " 'The U.S. economy remains the engine of global growth, backed by unmatched innovation, financial dominance, and a strong institutional framework. Its $28 trillion GDP and influence over global',\n",
              " 'Its $28 trillion GDP and influence over global finance, trade, and technology make it the centerpiece of the modern economic system. Yet, rising debt, inequality, political gridlock, and competition',\n",
              " 'inequality, political gridlock, and competition from emerging powers demand careful policy navigation. If successfully addressed, the U.S. will continue to dominate the global economy well into the',\n",
              " 'to dominate the global economy well into the future.']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e9de078e",
      "metadata": {
        "id": "e9de078e",
        "outputId": "c468b4c3-aa2e-4eae-b511-25d708c9d4ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "82"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(doc_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9fda30f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import faiss\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1c0a7a54",
      "metadata": {},
      "outputs": [],
      "source": [
        "index=faiss.IndexFlatL2(384)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "018943bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "vector_store=FAISS(\n",
        "    embedding_function=embeddings,\n",
        "    index=index,\n",
        "    docstore=InMemoryDocstore(),\n",
        "    index_to_docstore_id={},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "724abefa",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['feee9286-d62a-44e3-948b-f9a2fd2f3799',\n",
              " 'f6d85f2d-f418-403c-962a-f6525db9958d',\n",
              " '1f891550-e7e5-4090-8118-841d0ada75f5',\n",
              " '0c3ae827-84e7-414c-92e0-bfb5b000a760',\n",
              " '963a96e9-29a3-4bd0-aeeb-61850e905823',\n",
              " '5b359f6e-1543-4b05-844b-bd241c43f18a',\n",
              " '197bd707-3b34-4f2a-9a19-8c5616944cab',\n",
              " 'f15d0c29-5258-40cb-b3a0-13ab1eacef9a',\n",
              " '0d4307c1-0a5e-45d7-97a2-c7d6df288afe',\n",
              " '8a5397bf-4518-4307-9b1c-c03867ae601c',\n",
              " 'b2273e94-221c-40d7-9d25-566d80e5d2fc',\n",
              " 'ba3a8fca-4e56-4827-9d3b-ea259b21dcdf',\n",
              " '1e20efbd-7a42-4ceb-b1d9-dd06af49ca19',\n",
              " 'cc92b10b-8e32-498f-8516-04e41e9f2f78',\n",
              " '49cd2078-0927-4070-8bba-803eca851c3a',\n",
              " '28b9c5a5-8bce-4c3f-bcfa-521eb3bcfbcd',\n",
              " '44ccbe72-7fb6-430c-93cf-a0a81173d973',\n",
              " 'f4dbac3b-27f9-4d3e-b211-062faa6d274e',\n",
              " '7605ad29-192c-4f1e-b2e3-4e81a50b800a',\n",
              " '4cc19501-260a-4f54-b5b0-623a03df5ef5',\n",
              " '01309805-7f68-4395-b358-b17fcfbf5883',\n",
              " '0db055f5-8034-4041-a53f-c4fa5286d772',\n",
              " '5497909c-9d49-4733-a969-0050b1ccdc70',\n",
              " '05dcb502-0287-4ab1-9e64-56378c8c8d30',\n",
              " '637ff41b-e060-4df0-84f8-ce88b43ec690',\n",
              " 'd68d8d3a-eefa-4db0-b3f6-dcd429007512',\n",
              " '839b6050-5059-4a36-a153-a81f1cf2ee04',\n",
              " '4dbe0204-a353-4c58-8230-132c1f4ae06c',\n",
              " '5f6e4c16-a88f-4061-ad3a-81016e3aaaf9',\n",
              " 'c7959db0-996c-4240-87e5-f925713dc9c6',\n",
              " '344d0c8f-9a4e-404c-aac3-29ede1654790',\n",
              " '727cfc4d-2de9-45b1-891e-9988f45f7688',\n",
              " '55aae830-e8c2-463b-a906-4c33588953aa',\n",
              " '0fb224de-acdb-426e-a172-c88cbd225c29',\n",
              " '4d690caa-a83d-4fed-acfd-76c099485054',\n",
              " '6ae6baeb-eef1-4e25-a592-7b80b6bb2c49',\n",
              " 'ee7aad5d-5336-4aec-bf67-dc870adda342',\n",
              " '0d9f85f3-43c8-4900-92a5-370359be1e05',\n",
              " 'c8a575f6-5147-4c77-95bd-b4cd65159b0b',\n",
              " '7deca8eb-d6fa-47a0-97f8-67ad602ea6c7',\n",
              " 'c75c6b16-8626-4d86-83f0-86fd5a071369',\n",
              " 'c3800f1e-f67f-4287-9370-52dbeb820ed6',\n",
              " 'a790502f-149f-4888-b927-3ff9c5bd4cc7',\n",
              " '385b42fd-1ea6-4d44-8fd1-25a1caf72021',\n",
              " 'bafcc498-49ca-47d1-a690-cbad2975bde2',\n",
              " '57430e27-73cd-492a-8de1-b96b3104f8f3',\n",
              " '5b08f3a3-78bd-451c-9021-dd0383fa8f7e',\n",
              " '3c7107ae-0f11-4e98-b68c-045a25802ef7',\n",
              " '5ddc2681-8ab2-41b8-ab01-990641bb5f49',\n",
              " '3943bf4b-334b-4576-8902-86c616f8c808',\n",
              " '0289d389-b74d-452b-ab4b-6cb33f666ba1',\n",
              " 'b072854e-5839-4cbb-bda1-850482e8b83b',\n",
              " '856a599c-530a-46f4-9db8-85e63246b5db',\n",
              " '974f8c7e-18d7-4d96-bbe5-016eb443eb7a',\n",
              " '67ade63c-446d-45b9-aa2e-ba70fc610157',\n",
              " '04a21ea9-9605-4f36-94cf-16bb1b08970b',\n",
              " 'eabcb572-f188-45b0-922d-e5329c38bb81',\n",
              " 'ac7577ec-ed88-4379-b485-5e6f0045faac',\n",
              " '12807ea6-31ae-4263-af5c-3123a3d3dc12',\n",
              " '39dfca94-87a9-4528-9897-f522d91d7b04',\n",
              " '0ce7e759-9fb5-4dfb-adf5-3b9a6e3f757c',\n",
              " '8ed97bdd-e3be-4fa6-a34f-66e7402036a3',\n",
              " '10a2a477-2c03-49fe-b287-d00a26283052',\n",
              " 'd0d4092a-9a17-4c3e-9115-26d40552df1f',\n",
              " '3b8a038e-f153-41a7-8922-35086ce56d49',\n",
              " '64623ec1-32fc-4fb0-afc3-0e2c9215aee0',\n",
              " '30ce0366-fdab-4e9f-a6b0-ee6f0fc99a9c',\n",
              " '24479e94-7559-4855-8ed6-888bb14dbb8c',\n",
              " 'd1e1563e-4f96-432b-bb28-f0bc9840b48f',\n",
              " 'c0b1828d-3545-48c2-81ee-3a9d85525d01',\n",
              " '6b048686-bf8f-463e-aba1-412f3873ef91',\n",
              " '2573680e-23a0-4c3e-b554-79543ef4995f',\n",
              " '533f92d5-a784-4652-b42d-b3cae7d8fc0e',\n",
              " '201c7d27-8562-4f70-9866-b135529415e2',\n",
              " 'add0099e-bec9-4ee9-a636-5919b21c0ed5',\n",
              " '9020f218-7626-4b61-8dbe-9b0d3e2c91ef',\n",
              " '0adfabe9-c33b-4fec-8f97-ee1b900afb44',\n",
              " '97fff75e-0813-468d-93fe-67a0870614d6',\n",
              " 'f65c07f8-469e-4d75-9fca-d5a67bd37ba4',\n",
              " '6e483ee6-7743-4182-aed1-bfa5453fb75a',\n",
              " '59926e63-aa2f-4511-be64-925bb900d506',\n",
              " '28a2072c-2fd8-413c-a8c0-74297430246a']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_store.add_documents(documents=new_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ae02f542",
      "metadata": {
        "id": "ae02f542",
        "outputId": "55f6b50e-a2ab-42f6-8684-446b2351e342"
      },
      "outputs": [],
      "source": [
        "# db=Chroma.from_documents(new_docs[:5],embeddings) # Do not use chroma to avoid in memory problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "7ae4692f",
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever=vector_store.as_retriever(search_kwargs={\"k\": 3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7d5ef2a4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='533f92d5-a784-4652-b42d-b3cae7d8fc0e', metadata={'source': 'data\\\\usa.txt'}, page_content='Looking forward, the U.S. economy is expected to grow at a moderate pace, powered by innovation in AI, green energy, robotics, biotech, and quantum computing. The Biden administration’s Inflation'),\n",
              " Document(id='4dbe0204-a353-4c58-8230-132c1f4ae06c', metadata={'source': 'data\\\\usa.txt'}, page_content='🇺🇸 Overview of the U.S. Economy'),\n",
              " Document(id='f65c07f8-469e-4d75-9fca-d5a67bd37ba4', metadata={'source': 'data\\\\usa.txt'}, page_content='The U.S. economy remains the engine of global growth, backed by unmatched innovation, financial dominance, and a strong institutional framework. Its $28 trillion GDP and influence over global')]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.invoke(\"industrial growth of usa?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f53813d1",
      "metadata": {},
      "source": [
        "## Lang graph Intro 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "2dec551c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import operator\n",
        "from typing import List\n",
        "from pydantic import BaseModel , Field\n",
        "from langchain.prompts import PromptTemplate\n",
        "from typing import TypedDict, Annotated, Sequence\n",
        "from langchain_core.messages import BaseMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langgraph.graph import StateGraph,END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "cd2717c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "class TopicSelectionParser(BaseModel):\n",
        "    Topic:str=Field(description=\"selected topic\")\n",
        "    Reasoning:str=Field(description='Reasoning behind topic selection')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "aa9482a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.output_parsers import PydanticOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "40f38ab0",
      "metadata": {},
      "outputs": [],
      "source": [
        "parser=PydanticOutputParser(pydantic_object=TopicSelectionParser)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "5976eaae",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"Topic\": {\"description\": \"selected topic\", \"title\": \"Topic\", \"type\": \"string\"}, \"Reasoning\": {\"description\": \"Reasoning behind topic selection\", \"title\": \"Reasoning\", \"type\": \"string\"}}, \"required\": [\"Topic\", \"Reasoning\"]}\\n```'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parser.get_format_instructions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "818e9458",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"Topic\": {\"description\": \"selected topic\", \"title\": \"Topic\", \"type\": \"string\"}, \"Reasoning\": {\"description\": \"Reasoning behind topic selection\", \"title\": \"Reasoning\", \"type\": \"string\"}}, \"required\": [\"Topic\", \"Reasoning\"]}\\n```'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"Topic\": {\"description\": \"selected topic\", \"title\": \"Topic\", \"type\": \"string\"}, \"Reasoning\": {\"description\": \"Reasoning behind topic selection\", \"title\": \"Reasoning\", \"type\": \"string\"}}, \"required\": [\"Topic\", \"Reasoning\"]}\\n```'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a58e92eb",
      "metadata": {},
      "source": [
        "### this below agentstate is just for the explnation like how state works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "e90647aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "Agentstate={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "6941a3b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "Agentstate[\"messages\"]=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "0a1d26a9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': []}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Agentstate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "04538362",
      "metadata": {},
      "outputs": [],
      "source": [
        "Agentstate[\"messages\"].append(\"hi how are you?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b386dfa7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': ['hi how are you?']}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Agentstate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "6293e839",
      "metadata": {},
      "outputs": [],
      "source": [
        "Agentstate[\"messages\"].append(\"what are you doing?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "4ba759a1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': ['hi how are you?', 'what are you doing?']}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Agentstate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "24f91dba",
      "metadata": {},
      "outputs": [],
      "source": [
        "Agentstate[\"messages\"].append(\"i hope everything fine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "1dcf10b7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': ['hi how are you?',\n",
              "  'what are you doing?',\n",
              "  'i hope everything fine']}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Agentstate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "6204ad9f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'i hope everything fine'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Agentstate[\"messages\"][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "eaf4d755",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'hi how are you?'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Agentstate[\"messages\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d318b01",
      "metadata": {},
      "source": [
        "### this agentstate class you need to inside the stategraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "4c20fb4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "5c61fb48",
      "metadata": {},
      "outputs": [],
      "source": [
        "state={\"messages\":[\"hi\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "a65ffb5a",
      "metadata": {},
      "outputs": [],
      "source": [
        "state=\"hi\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "8aa6baec",
      "metadata": {},
      "outputs": [],
      "source": [
        "def function_1(state:AgentState):\n",
        "    \n",
        "    question=state[\"messages\"][-1]\n",
        "    \n",
        "    print(\"Question\",question)\n",
        "    \n",
        "    template=\"\"\"\n",
        "    Your task is to classify the given user query into one of the following categories: [USA,Not Related]. \n",
        "    Only respond with the category name and nothing else.\n",
        "\n",
        "    User query: {question}\n",
        "    {format_instructions}\n",
        "    \"\"\"\n",
        "    \n",
        "    prompt= PromptTemplate(\n",
        "        template=template,\n",
        "        input_variable=[\"question\"],\n",
        "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        "    )\n",
        "    \n",
        "    \n",
        "    chain= prompt | model | parser\n",
        "    \n",
        "    response = chain.invoke({\"question\":question})\n",
        "    \n",
        "    print(\"Parsed response:\", response)\n",
        "    \n",
        "    return {\"messages\": [response.Topic]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "a6558ef3",
      "metadata": {},
      "outputs": [],
      "source": [
        "state={\"messages\":[\"what is a today weather?\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "df51a043",
      "metadata": {},
      "outputs": [],
      "source": [
        "state={\"messages\":[\"what is a GDP of usa??\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "3b96f34d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi there! How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model=ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
        "output=model.invoke(\"hi\")\n",
        "print(output.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "cbc2b835",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question what is a GDP of usa??\n",
            "Parsed response: Topic='USA' Reasoning='The query explicitly asks for the GDP of the USA.'\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'messages': ['USA']}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "function_1(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "9f3fdb81",
      "metadata": {},
      "outputs": [],
      "source": [
        "class TopicSelectionParser(BaseModel):\n",
        "    Topic:str=Field(description=\"selected topic\")\n",
        "    Reasoning:str=Field(description='Reasoning behind topic selection')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "5e13e200",
      "metadata": {},
      "outputs": [],
      "source": [
        "def router(state:AgentState):\n",
        "    print(\"-> ROUTER ->\")\n",
        "    \n",
        "    last_message=state[\"messages\"][-1]\n",
        "    print(\"last_message:\", last_message)\n",
        "    \n",
        "    if \"usa\" in last_message.lower():\n",
        "        return \"RAG Call\"\n",
        "    else:\n",
        "        return \"LLM Call\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "1bf18d5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "c0fbde21",
      "metadata": {},
      "outputs": [],
      "source": [
        "# RAG Function\n",
        "def function_2(state:AgentState):\n",
        "    print(\"-> RAG Call ->\")\n",
        "    \n",
        "    question = state[\"messages\"][0]\n",
        "    \n",
        "    prompt=PromptTemplate(\n",
        "        template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\"\",\n",
        "        \n",
        "        input_variables=['context', 'question']\n",
        "    )\n",
        "    \n",
        "    rag_chain = (\n",
        "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | model\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "    result = rag_chain.invoke(question)\n",
        "    return  {\"messages\": [result]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "982f04eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# LLM Function\n",
        "def function_3(state:AgentState):\n",
        "    print(\"-> LLM Call ->\")\n",
        "    question = state[\"messages\"][0]\n",
        "    \n",
        "    # Normal LLM call\n",
        "    complete_query = \"Anwer the follow question with you knowledge of the real world. Following is the user question: \" + question\n",
        "    response = model.invoke(complete_query)\n",
        "    return {\"messages\": [response.content]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "ad429a23",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph,END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "de558b73",
      "metadata": {},
      "outputs": [],
      "source": [
        "workflow=StateGraph(AgentState)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "a81dddc4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b833ab290>"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_node(\"Supervisor\",function_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "338a953e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b833ab290>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_node(\"RAG\",function_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "231fc436",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b833ab290>"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_node(\"LLM\",function_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "d4bca978",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b833ab290>"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.set_entry_point(\"Supervisor\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "d8f151b0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b833ab290>"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_conditional_edges(\n",
        "    \"Supervisor\",\n",
        "    router,\n",
        "    {\n",
        "        \"RAG Call\": \"RAG\",\n",
        "        \"LLM Call\": \"LLM\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "19aecd62",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b833ab290>"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_edge(\"RAG\",END)\n",
        "workflow.add_edge(\"LLM\",END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "71874793",
      "metadata": {},
      "outputs": [],
      "source": [
        "app=workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "74d71a34",
      "metadata": {},
      "outputs": [],
      "source": [
        "state={\"messages\":[\"hi\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "0deccf3e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question hi\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsed response: Topic='Not Related' Reasoning='The query \"hi\" is a generic greeting and does not relate to the USA.'\n",
            "-> ROUTER ->\n",
            "last_message: Not Related\n",
            "-> LLM Call ->\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'messages': ['hi', 'Not Related', 'Hi there!']}"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app.invoke(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "f42d269c",
      "metadata": {},
      "outputs": [],
      "source": [
        "state={\"messages\":[\"what is a gdp of usa?\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "4c502034",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question what is a gdp of usa?\n",
            "Parsed response: Topic='USA' Reasoning='The query explicitly asks for the GDP of the USA.'\n",
            "-> ROUTER ->\n",
            "last_message: USA\n",
            "-> RAG Call ->\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'messages': ['what is a gdp of usa?',\n",
              "  'USA',\n",
              "  \"The nominal GDP of the USA in 2024 is estimated to be approximately $28 trillion USD.  This represents about 25% of the global economy.  The US has the world's largest nominal GDP.\"]}"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app.invoke(state)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "818da502",
      "metadata": {
        "id": "818da502"
      },
      "source": [
        "## Langgraph Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc7104c0",
      "metadata": {
        "id": "dc7104c0"
      },
      "source": [
        "### Config the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "a5444e4f",
      "metadata": {
        "id": "a5444e4f",
        "outputId": "d6ee19e0-0943-4265-8837-30598b6a8b28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi there! How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model=ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
        "output=model.invoke(\"hi\")\n",
        "print(output.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b647d2e0",
      "metadata": {
        "id": "b647d2e0"
      },
      "source": [
        "### Config the embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "ab66123a",
      "metadata": {
        "id": "ab66123a",
        "outputId": "28fcd021-0233-4a85-ba96-0e9adfcf5de6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en\")\n",
        "len(embeddings.embed_query(\"hi\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88ba396b",
      "metadata": {
        "id": "88ba396b"
      },
      "source": [
        "### Creating the agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a56112d",
      "metadata": {},
      "source": [
        "Assignment:4\n",
        "1. you have to create one supervisor node.\n",
        "2. create one router function\n",
        "3. create three more node\n",
        "3.1 llm call (llm node)\n",
        "3.2 RAG (rag node)\n",
        "3.3 web crawler(fetch the info in realtime from internet)\n",
        "4. created one more node after this for validation for generated output --> explore the validation part how to do that\n",
        "5. if validation going to be failed in that case again go to supervioser node and then supervisor node will again decide what needs to be call next\n",
        "6. once the validation will pass then only generate the final output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "f35373b8",
      "metadata": {
        "id": "f35373b8"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "from typing import List\n",
        "from pydantic import BaseModel , Field\n",
        "from langchain.prompts import PromptTemplate\n",
        "from typing import TypedDict, Annotated, Sequence\n",
        "from langchain_core.messages import BaseMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langgraph.graph import StateGraph,END, START\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "48683055",
      "metadata": {
        "id": "48683055"
      },
      "outputs": [],
      "source": [
        "class TopicSelectionParser(BaseModel):\n",
        "    Topic:str=Field(description=\"selected topic\")\n",
        "    Reasoning:str=Field(description='Reasoning behind topic selection')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "4bc84af3",
      "metadata": {
        "id": "4bc84af3",
        "outputId": "89151ca1-f138-4023-b438-af8bf73d3f70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"Topic\": {\"description\": \"selected topic\", \"title\": \"Topic\", \"type\": \"string\"}, \"Reasoning\": {\"description\": \"Reasoning behind topic selection\", \"title\": \"Reasoning\", \"type\": \"string\"}}, \"required\": [\"Topic\", \"Reasoning\"]}\\n```'"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parser=PydanticOutputParser(pydantic_object=TopicSelectionParser)\n",
        "parser.get_format_instructions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "2776cbfa",
      "metadata": {
        "id": "2776cbfa"
      },
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "6c7b56a8",
      "metadata": {
        "id": "6c7b56a8"
      },
      "outputs": [],
      "source": [
        "def function_1(state:AgentState):\n",
        "\n",
        "    question=state[\"messages\"][-1]\n",
        "\n",
        "    print(\"Question\",question)\n",
        "\n",
        "    template=\"\"\"\n",
        "    Your task is to classify the given user query into one of the following related categories: [Constitution,LLM, Latest]. If question is about\n",
        "    Indian constitution then Constitution, if question is generic then LLM and if question is about some recent thing which you don't know then Latest.\n",
        "    Only respond with the category name and nothing else.\n",
        "\n",
        "    User query: {question}\n",
        "    {format_instructions}\n",
        "    \"\"\"\n",
        "\n",
        "    prompt= PromptTemplate(\n",
        "        template=template,\n",
        "        input_variable=[\"question\"],\n",
        "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        "    )\n",
        "\n",
        "\n",
        "    chain= prompt | model | parser\n",
        "\n",
        "\n",
        "    response = chain.invoke({\"question\":question})\n",
        "\n",
        "    print(\"Parsed response:\", response)\n",
        "\n",
        "    return {\"messages\": [response.Topic]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "14436bdf",
      "metadata": {
        "id": "14436bdf"
      },
      "outputs": [],
      "source": [
        "def router(state:AgentState):\n",
        "    print(\"-> ROUTER ->\")\n",
        "\n",
        "    last_message=state[\"messages\"][-1]\n",
        "    print(\"last_message:\", last_message)\n",
        "\n",
        "    if \"constitution\" in last_message.lower():\n",
        "        return \"RAG Call\"\n",
        "    elif \"latest\" in last_message.lower():\n",
        "        return \"WEB Call\"\n",
        "    else:\n",
        "        return \"LLM Call\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "669f58e1",
      "metadata": {
        "id": "669f58e1"
      },
      "outputs": [],
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "7ba60dd6",
      "metadata": {
        "id": "7ba60dd6",
        "outputId": "837f6ef2-6b5b-44db-e4a3-853ba75a8f9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\saina\\AppData\\Local\\Temp\\ipykernel_4808\\3562440359.py:15: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
          ]
        }
      ],
      "source": [
        "# Load a PDF and validate the page count\n",
        "file_path = r\"C:\\Users\\saina\\Desktop\\DS_ML_AI\\Krish_Naik_Courses\\Krish_naik_1_Agentic_AI_and_Gen_AI\\Practice\\agentic_ai_2\\data\\2023050195.pdf\"\n",
        "loader = PyPDFLoader(file_path)\n",
        "pages = loader.load()\n",
        "\n",
        "if len(pages) < 200:\n",
        "    raise ValueError(\"The PDF must have at least 200 pages.\")\n",
        "\n",
        "#Using semantic chunking with recursive text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "chunks = text_splitter.split_documents(pages)\n",
        "\n",
        "\n",
        "# Hugging Face embedding\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "faiss_flat = FAISS.from_documents(chunks, embedding_model)\n",
        "retriever_flat = faiss_flat.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "e367c54b",
      "metadata": {
        "id": "e367c54b"
      },
      "outputs": [],
      "source": [
        "# RAG Function\n",
        "def function_2(state:AgentState):\n",
        "    print(\"-> RAG Call ->\")\n",
        "\n",
        "    question = state[\"messages\"][0]\n",
        "\n",
        "    prompt=PromptTemplate(\n",
        "        template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\"\",\n",
        "\n",
        "        input_variables=['context', 'question']\n",
        "    )\n",
        "\n",
        "    rag_chain = (\n",
        "        {\"context\": retriever_flat | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | model\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "    result = rag_chain.invoke(question)\n",
        "    return  {\"messages\": [result]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "4445aba2",
      "metadata": {
        "id": "4445aba2"
      },
      "outputs": [],
      "source": [
        "# LLM Function\n",
        "def function_3(state:AgentState):\n",
        "    print(\"-> LLM Call ->\")\n",
        "    question = state[\"messages\"][0]\n",
        "\n",
        "    # Normal LLM call\n",
        "    complete_query = \"Answer the follow question with you knowledge of the real world. Following is the user question: \" + question\n",
        "    response = model.invoke(complete_query)\n",
        "    return {\"messages\": [response.content]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "58ade2a6",
      "metadata": {
        "id": "58ade2a6"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "def search_fun(state:AgentState):\n",
        "    search=DuckDuckGoSearchRun()\n",
        "    result = search.invoke({\"query\":state[\"messages\"][0]})\n",
        "    return {\"messages\": [result]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "77310b33",
      "metadata": {
        "id": "77310b33"
      },
      "outputs": [],
      "source": [
        "def function_4(state:AgentState):\n",
        "\n",
        "    question = state[\"messages\"][0]\n",
        "    answer=state[\"messages\"][-1]\n",
        "\n",
        "    print(\"answer\",answer)\n",
        "\n",
        "    template=\"\"\"\n",
        "    Your task is to check if the response is related to the user question.\n",
        "    Respond in the specified JSON format.\n",
        "\n",
        "    User query: {question}\n",
        "    response: {answer}\n",
        "\n",
        "    {format_instructions}\n",
        "    \"\"\"\n",
        "\n",
        "    prompt= PromptTemplate(\n",
        "        template=template,\n",
        "        input_variable=[\"question\",\"answer\"],\n",
        "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        "    )\n",
        "\n",
        "\n",
        "    chain= prompt | model | parser\n",
        "\n",
        "    response = chain.invoke({\"question\":question,\"answer\":answer})\n",
        "\n",
        "    print(\"Parsed response:\", response)\n",
        "\n",
        "    return {\"messages\": [response.Topic]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "566638da",
      "metadata": {
        "id": "566638da"
      },
      "outputs": [],
      "source": [
        "def router_1(state:AgentState):\n",
        "    print(\"-> ROUTER_1 ->\")\n",
        "\n",
        "    last_message=state[\"messages\"][-1]\n",
        "    print(\"last_message:\", last_message)\n",
        "\n",
        "    if \"yes\" in last_message.lower():\n",
        "        return \"yes\"\n",
        "    else:\n",
        "        return \"no\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "e4a6205f",
      "metadata": {
        "id": "e4a6205f",
        "outputId": "047527db-2481-44c6-c885-b28d4616c193"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b853d6e90>"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow=StateGraph(AgentState)\n",
        "workflow.add_node(\"Supervisor\",function_1)\n",
        "workflow.add_node(\"RAG\",function_2)\n",
        "workflow.add_node(\"LLM\",function_3)\n",
        "workflow.add_node(\"WEB\", search_fun)\n",
        "workflow.add_node(\"VALIDATION\",function_4)\n",
        "workflow.set_entry_point(\"Supervisor\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "44d40cd0",
      "metadata": {
        "id": "44d40cd0",
        "outputId": "03023829-b6f5-4720-be61-3066d21e5e90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b853d6e90>"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_conditional_edges(\n",
        "    \"Supervisor\",\n",
        "    router,\n",
        "    {\n",
        "        \"RAG Call\": \"RAG\",\n",
        "        \"LLM Call\": \"LLM\",\n",
        "        \"WEB Call\": \"WEB\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "51f3a5fa",
      "metadata": {
        "id": "51f3a5fa",
        "outputId": "bf6a0370-7033-47d8-b118-c7526fda147d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b853d6e90>"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_edge(\"RAG\",\"VALIDATION\")\n",
        "workflow.add_edge(\"LLM\",\"VALIDATION\")\n",
        "workflow.add_edge(\"WEB\",\"VALIDATION\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"VALIDATION\",\n",
        "    router_1,\n",
        "    {\n",
        "        \"yes\": END,\n",
        "        \"no\":\"Supervisor\"\n",
        "    }\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "0449aa2a",
      "metadata": {
        "id": "0449aa2a"
      },
      "outputs": [],
      "source": [
        "app=workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "9cf74c81",
      "metadata": {
        "id": "9cf74c81",
        "outputId": "7c0bb0a9-0f51-427a-a52c-1f2e1bd8a2fd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30ba3393",
      "metadata": {
        "id": "30ba3393",
        "outputId": "f5d8a310-c981-469d-9c07-267cd97e8958"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question How to make black tea?, list down in simple steps\n",
            "Parsed response: Topic='LLM' Reasoning='The query is a generic question about making tea, not related to the Indian Constitution or recent events.'\n",
            "-> ROUTER ->\n",
            "last_message: LLM\n",
            "-> LLM Call ->\n",
            "answer How to Make Black Tea (Simple Steps):\n",
            "\n",
            "1. **Boil Water:** Heat fresh water to a rolling boil.  The temperature is crucial for optimal flavor extraction;  around 200-212°F (93-100°C) is ideal.\n",
            "\n",
            "2. **Warm the Teapot (Optional):**  Pour a small amount of boiling water into your teapot and swirl it around to preheat it. This helps maintain the water temperature and prevents the tea from cooling down too quickly.  Empty the water before adding tea.\n",
            "\n",
            "3. **Add Tea Leaves:** Place 1-2 teaspoons of loose leaf black tea, or one tea bag, per cup of water into the teapot.  Adjust to your taste preference; more tea makes a stronger brew.\n",
            "\n",
            "4. **Pour Water Over Tea:** Slowly pour the boiling water over the tea leaves or tea bag.  Make sure all the leaves are submerged.\n",
            "\n",
            "5. **Steep:** Let the tea steep for 3-5 minutes.  Steeping for longer will result in a stronger, more bitter tea. Experiment to find your perfect steeping time.\n",
            "\n",
            "6. **Remove Tea Leaves/Bag:** Remove the tea bag or strain the loose leaf tea from the teapot.\n",
            "\n",
            "7. **Serve and Enjoy:** Pour the tea into your cup and enjoy! You can add milk, sugar, lemon, or honey to taste.\n",
            "Parsed response: Topic='How to Make Black Tea' Reasoning=\"The response provides a step-by-step guide on how to make black tea, directly addressing the user's question.  It covers key aspects like water temperature, steeping time, and leaf quantity, fulfilling the request for simple steps.\"\n",
            "-> ROUTER_1 ->\n",
            "last_message: How to Make Black Tea\n",
            "Question How to Make Black Tea\n",
            "Parsed response: Topic='LLM' Reasoning='The query is a generic question about making black tea, unrelated to Indian Constitution or recent events.'\n",
            "-> ROUTER ->\n",
            "last_message: LLM\n",
            "-> LLM Call ->\n",
            "answer How to Make Black Tea (Simple Steps):\n",
            "\n",
            "1. **Boil Water:** Heat fresh, clean water to a rolling boil.  The exact temperature isn't critical for black tea, but generally between 200-212°F (93-100°C) is fine.\n",
            "\n",
            "2. **Warm the Teapot (Optional):**  Pour a small amount of boiling water into your teapot to warm it. This helps keep the tea hotter for longer. Empty the teapot afterward.\n",
            "\n",
            "3. **Add Tea Leaves:** Place 1 teaspoon of loose leaf black tea, or one tea bag, for every 8 ounces (237ml) of water into the warmed teapot.\n",
            "\n",
            "4. **Pour Water Over Tea:** Slowly pour the boiling water over the tea leaves or tea bag.\n",
            "\n",
            "5. **Steep:** Let the tea steep for 3-5 minutes.  Steeping for longer will result in a stronger, more bitter brew.  Experiment to find your preferred strength.\n",
            "\n",
            "6. **Remove Tea Leaves/Bag:** Remove the tea leaves or tea bag from the teapot.  For loose leaf tea, you can use a strainer to pour the tea into your cup.\n",
            "\n",
            "7. **Serve and Enjoy:** Pour the tea into your cup and enjoy! You can add milk, sugar, lemon, or honey to taste.\n",
            "Parsed response: Topic='Relevant' Reasoning=\"The response directly answers the user's question by providing a step-by-step guide on how to make black tea.  It covers all the essential steps, from boiling water to serving the tea, and even includes optional steps and tips for adjusting the strength and flavor.\"\n",
            "-> ROUTER_1 ->\n",
            "last_message: Relevant\n",
            "Question Relevant\n",
            "Parsed response: Topic='LLM' Reasoning=\"The word 'Relevant' is too generic and doesn't relate to the Indian Constitution or any specific recent event.  It's a general term applicable to many contexts.\"\n",
            "-> ROUTER ->\n",
            "last_message: LLM\n",
            "-> LLM Call ->\n",
            "answer How to Make Black Tea (Simple Steps):\n",
            "\n",
            "1. **Boil Water:**  Bring fresh, cold water to a rolling boil in a kettle or pot.  The amount depends on how much tea you're making (see step 2).\n",
            "\n",
            "2. **Heat Water to Correct Temperature:** For black tea, the ideal water temperature is between 200-212°F (93-100°C).  If your kettle doesn't have a temperature setting, let the boiled water sit for a minute or two to cool slightly.\n",
            "\n",
            "3. **Warm Teacup (Optional):**  Preheating your teacup with hot water helps keep your tea warmer for longer.\n",
            "\n",
            "4. **Add Tea Leaves:** Place one tea bag (or about 1 teaspoon of loose leaf tea per 8 ounces of water) into your teacup or teapot.\n",
            "\n",
            "5. **Pour Water Over Tea:** Slowly pour the hot water over the tea leaves, ensuring all the leaves are submerged.\n",
            "\n",
            "6. **Steep:** Let the tea steep for 3-5 minutes.  Steeping for longer will result in a stronger, more bitter tea. Experiment to find your preferred strength.\n",
            "\n",
            "7. **Remove Tea Bag or Leaves:** Remove the tea bag or strain out the loose leaves.\n",
            "\n",
            "8. **Serve and Enjoy:**  Add milk, sugar, lemon, or other sweeteners to taste (optional).  Enjoy your freshly brewed black tea!\n",
            "Parsed response: Topic='How to make black tea' Reasoning=\"The response provides a step-by-step guide on how to make black tea, directly addressing the user's question.  The steps are clearly explained and cover all the essential aspects of the process.\"\n",
            "-> ROUTER_1 ->\n",
            "last_message: How to make black tea\n",
            "Question How to make black tea\n",
            "Parsed response: Topic='LLM' Reasoning='The query is a generic question about making tea, not related to the Indian Constitution or recent events.'\n",
            "-> ROUTER ->\n",
            "last_message: LLM\n",
            "-> LLM Call ->\n",
            "answer How to Make Black Tea:\n",
            "\n",
            "1. **Boil water:**  Use fresh, cold water and bring it to a rolling boil in a kettle.\n",
            "\n",
            "2. **Warm the pot (optional):**  Pour a small amount of boiling water into your teapot to warm it.  This helps keep the tea warmer for longer. Empty the water out immediately.\n",
            "\n",
            "3. **Add tea leaves:** Use one teaspoon of loose leaf tea or one tea bag per cup of water (adjust to your preference; some like it stronger).\n",
            "\n",
            "4. **Pour hot water over tea leaves:**  Pour the boiling water over the tea leaves in the pot. Make sure all the leaves are submerged.\n",
            "\n",
            "5. **Steep:** Let the tea steep for 3-5 minutes.  Steeping time affects the strength and flavor.  Experiment to find your preferred taste.  Longer steeping times generally result in a stronger, more bitter tea.\n",
            "\n",
            "6. **Remove tea leaves:**  If using loose leaf tea, pour the tea through a strainer into your cup(s). If using tea bags, remove them after steeping.\n",
            "\n",
            "7. **Serve and enjoy:** Add milk, sugar, lemon, or honey to taste (optional).  Enjoy your freshly brewed black tea!\n",
            "Parsed response: Topic='How to make black tea' Reasoning=\"The response provides a step-by-step guide on how to make black tea, directly answering the user's question.  It covers all the essential steps from boiling water to serving the tea, aligning perfectly with the user's request for simple instructions.\"\n",
            "-> ROUTER_1 ->\n",
            "last_message: How to make black tea\n",
            "Question How to make black tea\n",
            "Parsed response: Topic='LLM' Reasoning='The query is a general question about making black tea, not related to the Indian Constitution or recent events.'\n",
            "-> ROUTER ->\n",
            "last_message: LLM\n",
            "-> LLM Call ->\n",
            "answer How to Make Black Tea: Simple Steps\n",
            "\n",
            "1. **Boil Water:**  Heat fresh water to a rolling boil.  The temperature is crucial for optimal flavor extraction; generally, 200-212°F (93-100°C) is ideal.\n",
            "\n",
            "2. **Warm the Teapot (Optional but Recommended):** Pour a small amount of boiling water into your teapot and swirl it around to preheat it. This helps maintain the water temperature and prevents the tea from cooling down too quickly. Empty the water out.\n",
            "\n",
            "3. **Add Tea Leaves:** Place one teaspoon of loose leaf black tea or one tea bag per cup of water into the warmed teapot.  Adjust the amount to your taste preference; some people prefer stronger tea.\n",
            "\n",
            "4. **Pour Water Over Tea:** Slowly pour the boiling water over the tea leaves.  Make sure all the leaves are submerged.\n",
            "\n",
            "5. **Steep:** Let the tea steep for 3-5 minutes.  Steeping time affects the strength and bitterness of the tea.  Experiment to find your perfect timing.  Longer steeping generally results in a stronger, more bitter brew.\n",
            "\n",
            "6. **Remove Tea Leaves/Bag:** Remove the tea bag or strain the loose leaf tea from the teapot.  You can do this by pouring the tea through a strainer into your cup, or using a tea infuser.\n",
            "\n",
            "7. **Serve and Enjoy:** Pour the tea into your cup and enjoy! You can add milk, sugar, lemon, or honey to taste.\n",
            "Parsed response: Topic='How to Make Black Tea' Reasoning=\"The response provides a step-by-step guide on how to make black tea, directly addressing the user's question.\"\n",
            "-> ROUTER_1 ->\n",
            "last_message: How to Make Black Tea\n",
            "Question How to Make Black Tea\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 16\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "ename": "ResourceExhausted",
          "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 15\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 14\n}\n]",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mResourceExhausted\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m state={\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m:[\u001b[33m\"\u001b[39m\u001b[33mHow to make black tea?, list down in simple steps\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2719\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2716\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2717\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2719\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2720\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2723\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2724\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2725\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2728\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2730\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2734\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langgraph\\pregel\\runner.py:161\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    159\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mfunction_1\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     16\u001b[39m prompt= PromptTemplate(\n\u001b[32m     17\u001b[39m     template=template,\n\u001b[32m     18\u001b[39m     input_variable=[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     19\u001b[39m     partial_variables={\u001b[33m\"\u001b[39m\u001b[33mformat_instructions\u001b[39m\u001b[33m\"\u001b[39m: parser.get_format_instructions()}\n\u001b[32m     20\u001b[39m )\n\u001b[32m     23\u001b[39m chain= prompt | model | parser\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m response = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mParsed response:\u001b[39m\u001b[33m\"\u001b[39m, response)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [response.Topic]}\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = context.run(step.invoke, input_, config)\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1255\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   1250\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1251\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1252\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.\u001b[39m\u001b[33m\"\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mcode_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1253\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1255\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:372\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    367\u001b[39m     **kwargs: Any,\n\u001b[32m    368\u001b[39m ) -> BaseMessage:\n\u001b[32m    369\u001b[39m     config = ensure_config(config)\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    371\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    382\u001b[39m     ).message\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:957\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    950\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    954\u001b[39m     **kwargs: Any,\n\u001b[32m    955\u001b[39m ) -> LLMResult:\n\u001b[32m    956\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:776\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    775\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    784\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1022\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1020\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1026\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1342\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1318\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1329\u001b[39m     **kwargs: Any,\n\u001b[32m   1330\u001b[39m ) -> ChatResult:\n\u001b[32m   1331\u001b[39m     request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m   1332\u001b[39m         messages,\n\u001b[32m   1333\u001b[39m         stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1340\u001b[39m         tool_choice=tool_choice,\n\u001b[32m   1341\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m     response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1347\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1348\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:210\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\tenacity\\__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:208\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[32m    205\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:192\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_with_retry\u001b[39m(**kwargs: Any) -> Any:\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.FailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:868\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    865\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    867\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    876\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    167\u001b[39m     time.sleep(next_sleep)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    216\u001b[39m     on_error_fn(exc)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
            "\u001b[31mResourceExhausted\u001b[39m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 15\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 14\n}\n]",
            "During task with name 'Supervisor' and id 'f3594e6a-0db8-9c18-a6e3-fec2c47b09a9'"
          ]
        }
      ],
      "source": [
        "state={\"messages\":[\"\"]}\n",
        "app.invoke(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "24e60f3d",
      "metadata": {
        "id": "24e60f3d",
        "outputId": "a4e98415-402c-4154-fe9c-a4e33f2f57a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question List all the fundamental duties?\n",
            "Parsed response: Topic='Constitution' Reasoning='The query asks about fundamental duties, a key component of the Indian Constitution.'\n",
            "-> ROUTER ->\n",
            "last_message: Constitution\n",
            "-> RAG Call ->\n",
            "answer The fundamental duties of Indian citizens include abiding by the Constitution and respecting its ideals, cherishing the ideals of the freedom struggle, and upholding India's sovereignty.  Additional duties involve defending the country, protecting the environment, and safeguarding national monuments.\n",
            "Parsed response: Topic='yes' Reasoning=\"The response lists several fundamental duties, directly answering the user's question.\"\n",
            "-> ROUTER_1 ->\n",
            "last_message: yes\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'messages': ['List all the fundamental duties?',\n",
              "  'Constitution',\n",
              "  \"The fundamental duties of Indian citizens include abiding by the Constitution and respecting its ideals, cherishing the ideals of the freedom struggle, and upholding India's sovereignty.  Additional duties involve defending the country, protecting the environment, and safeguarding national monuments.\",\n",
              "  'yes']}"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state={\"messages\":[\"List all the fundamental duties?\"]}\n",
        "app.invoke(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa587c1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "state={\"messages\":[\"List all the fundamental duties?\"]}\n",
        "app.invoke(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "48f18648",
      "metadata": {
        "id": "48f18648",
        "outputId": "c7c69ebb-7572-4c97-cfdf-cdbfcc39f4a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question what is the net worth of Elon Musk\n",
            "Parsed response: Topic='Latest' Reasoning=\"The query asks about Elon Musk's net worth, which is a current event and not related to the Indian Constitution or LLMs.\"\n",
            "-> ROUTER ->\n",
            "last_message: Latest\n",
            "answer View net worth over: Max 1 year 1 quarter 1 month 1 week. Net Worth Summary. Cash. Private asset. ... 1971 Elon Musk is born in Pretoria, South Africa. 1981 Buys first computer at age 10. Elon Musk's net worth peaked at $486 billion in December 2024, but by March 2025, his fortune had decreased to approximately $330 billion. The market capitalization of Tesla's stock fell from ... Elon Musk on the 2025 The Richest Person In Every State. ... Elon Musk's net worth fell by the equivalent of almost five times Trump's $5.5 billion net worth Thursday. Elon Musk is a South African-born Canadian-American businessman, inventor, and investor who has a net worth of $368 billion. Elon Musk is currently the richest person in the world. In November ... Tesla shares fell after Elon Musk's public disagreement with the president. Musk's net worth, though still the world's highest, has fluctuated significantly, peaking at $400 billion in December 2024.\n",
            "Parsed response: Topic='Related' Reasoning=\"The response directly addresses the user's query by providing information about Elon Musk's net worth, including its peak value, recent fluctuations, and current estimate.  It also includes biographical details relevant to understanding his wealth.\"\n",
            "-> ROUTER_1 ->\n",
            "last_message: Related\n",
            "Question Related\n",
            "Parsed response: Topic='LLM' Reasoning=\"The query 'Related' is too generic and doesn't relate to the Indian Constitution or any specific recent event.\"\n",
            "-> ROUTER ->\n",
            "last_message: LLM\n",
            "-> LLM Call ->\n",
            "answer I cannot provide you with a precise, up-to-the-minute net worth for Elon Musk.  His net worth fluctuates constantly based on the stock performance of Tesla and SpaceX (which is privately held and thus its valuation is less certain), as well as his other investments.  Any number I could give you right now would likely be outdated within hours, if not minutes.\n",
            "\n",
            "To find the most current estimate, you should consult reputable financial news sources like Bloomberg Billionaires Index or Forbes Real-Time Billionaires list.  These sites use sophisticated algorithms and real-time data to track the net worth of prominent individuals.\n",
            "Parsed response: Topic='Related' Reasoning=\"The response directly addresses the user's question about Elon Musk's net worth by explaining the challenges in providing a precise figure due to its constant fluctuation and suggesting reliable sources for up-to-date information.\"\n",
            "-> ROUTER_1 ->\n",
            "last_message: Related\n",
            "Question Related\n",
            "Parsed response: Topic='LLM' Reasoning=\"The query 'Related' is too generic and does not pertain to the Indian Constitution or a specific recent event.  It's a request for related information, which is a general LLM task.\"\n",
            "-> ROUTER ->\n",
            "last_message: LLM\n",
            "-> LLM Call ->\n",
            "answer I cannot provide you with a precise, up-to-the-minute net worth for Elon Musk.  His net worth fluctuates dramatically on a daily, even hourly basis, depending on the performance of Tesla stock and SpaceX valuations (which are not publicly traded in the same way as Tesla).  Any number I could give you right now would likely be outdated very quickly.\n",
            "\n",
            "To find an estimate, you should consult reputable financial news sources like Bloomberg Billionaires Index or Forbes Real-Time Billionaires list.  Keep in mind that even these estimations are approximations and subject to change.\n",
            "Parsed response: Topic='Related' Reasoning=\"The response acknowledges the user's query about Elon Musk's net worth and explains why providing a specific number is difficult due to its volatility.  It then offers suggestions on where to find estimated net worth information from reliable sources.\"\n",
            "-> ROUTER_1 ->\n",
            "last_message: Related\n",
            "Question Related\n",
            "Parsed response: Topic='LLM' Reasoning='The query \"Related\" is too generic and doesn\\'t pertain to the Indian Constitution or any specific recent event.  It\\'s a request for related information, a common LLM task.'\n",
            "-> ROUTER ->\n",
            "last_message: LLM\n",
            "-> LLM Call ->\n",
            "answer I cannot provide you with a precise, up-to-the-minute net worth for Elon Musk.  His net worth fluctuates constantly based on the performance of Tesla stock and SpaceX valuations, both of which are subject to significant daily and even hourly changes in the market.  Any number I could give you right now would likely be outdated very quickly.\n",
            "\n",
            "To find an estimate, you should consult reputable financial news sources like Bloomberg Billionaires Index or Forbes Real-Time Billionaires list.  These sites track net worths in real-time (or as close to real-time as possible) and will give you the most current available figure.  Keep in mind that even these estimates are approximations.\n",
            "Parsed response: Topic='Related' Reasoning=\"The response acknowledges the user's question about Elon Musk's net worth and explains why providing a precise figure is impossible due to its constant fluctuation.  It then directs the user to reliable sources for up-to-date estimates.\"\n",
            "-> ROUTER_1 ->\n",
            "last_message: Related\n",
            "Question Related\n",
            "Parsed response: Topic='LLM' Reasoning='The query \"Related\" is too generic and doesn\\'t relate to the Indian Constitution or any specific recent event.'\n",
            "-> ROUTER ->\n",
            "last_message: LLM\n",
            "-> LLM Call ->\n",
            "answer I cannot provide you with a precise, up-to-the-minute net worth for Elon Musk.  His net worth fluctuates constantly based on the value of Tesla stock and other investments.  Publicly available information from sources like Forbes or Bloomberg will give you an estimate, but these are snapshots in time and can change dramatically within hours or days.\n",
            "Parsed response: Topic='Related' Reasoning=\"The response acknowledges the user's question about Elon Musk's net worth and explains why a precise answer cannot be given in real-time, instead suggesting reliable sources for estimates.\"\n",
            "-> ROUTER_1 ->\n",
            "last_message: Related\n",
            "Question Related\n",
            "Parsed response: Topic='LLM' Reasoning='The query \"Related\" is too generic and doesn\\'t relate to the Indian Constitution or any specific recent event.  It\\'s a broad term that could be related to many things, making it a generic LLM question.'\n",
            "-> ROUTER ->\n",
            "last_message: LLM\n",
            "-> LLM Call ->\n",
            "answer I cannot provide you with a precise, up-to-the-minute net worth for Elon Musk.  His net worth fluctuates constantly based on the market performance of Tesla and SpaceX (both of which are privately held in part), as well as his other investments.  Any number I could give you right now would likely be outdated within hours, if not minutes.\n",
            "\n",
            "To find an estimate, you should consult reputable financial news sources like Bloomberg Billionaires Index or Forbes Real-Time Billionaires list.  These sources regularly update their estimations, but keep in mind that even their figures are approximations.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 19\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "ename": "ResourceExhausted",
          "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 15\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 16\n}\n]",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mResourceExhausted\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[129]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m state={\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m:[\u001b[33m\"\u001b[39m\u001b[33mwhat is the net worth of Elon Musk\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2719\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2716\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2717\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2719\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2720\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2723\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2724\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2725\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2728\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2730\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2734\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langgraph\\pregel\\runner.py:161\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    159\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[122]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mfunction_4\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     18\u001b[39m prompt= PromptTemplate(\n\u001b[32m     19\u001b[39m     template=template,\n\u001b[32m     20\u001b[39m     input_variable=[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     21\u001b[39m     partial_variables={\u001b[33m\"\u001b[39m\u001b[33mformat_instructions\u001b[39m\u001b[33m\"\u001b[39m: parser.get_format_instructions()}\n\u001b[32m     22\u001b[39m )\n\u001b[32m     25\u001b[39m chain= prompt | model | parser\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m response = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manswer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43manswer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mParsed response:\u001b[39m\u001b[33m\"\u001b[39m, response)\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [response.Topic]}\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = context.run(step.invoke, input_, config)\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1255\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   1250\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1251\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1252\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.\u001b[39m\u001b[33m\"\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mcode_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1253\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1255\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:372\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    367\u001b[39m     **kwargs: Any,\n\u001b[32m    368\u001b[39m ) -> BaseMessage:\n\u001b[32m    369\u001b[39m     config = ensure_config(config)\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    371\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    382\u001b[39m     ).message\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:957\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    950\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    954\u001b[39m     **kwargs: Any,\n\u001b[32m    955\u001b[39m ) -> LLMResult:\n\u001b[32m    956\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:776\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    775\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    784\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1022\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1020\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1026\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1342\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1318\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1329\u001b[39m     **kwargs: Any,\n\u001b[32m   1330\u001b[39m ) -> ChatResult:\n\u001b[32m   1331\u001b[39m     request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m   1332\u001b[39m         messages,\n\u001b[32m   1333\u001b[39m         stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1340\u001b[39m         tool_choice=tool_choice,\n\u001b[32m   1341\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m     response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1347\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1348\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:210\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\tenacity\\__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:208\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[32m    205\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:192\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_with_retry\u001b[39m(**kwargs: Any) -> Any:\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.FailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:868\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    865\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    867\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    876\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    167\u001b[39m     time.sleep(next_sleep)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    216\u001b[39m     on_error_fn(exc)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saina\\.conda\\envs\\agentic_base\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
            "\u001b[31mResourceExhausted\u001b[39m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 15\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 16\n}\n]",
            "During task with name 'VALIDATION' and id '4fca5323-d16a-fb61-1e15-c19af6d3d0c4'"
          ]
        }
      ],
      "source": [
        "state={\"messages\":[\"what is the net worth of Elon Musk\"]}\n",
        "app.invoke(state)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35920de1",
      "metadata": {},
      "source": [
        "## Langgraph Agent Tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "2eeb4997",
      "metadata": {},
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "8b7dcfed",
      "metadata": {},
      "outputs": [],
      "source": [
        "state={\"messages\":[\"hi\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "48bb9a40",
      "metadata": {},
      "outputs": [],
      "source": [
        "state=\"hi\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "25c90f65",
      "metadata": {},
      "outputs": [],
      "source": [
        "def function_1(state:AgentState):\n",
        "    \n",
        "    question=state[\"messages\"][-1]\n",
        "    \n",
        "    print(\"Question\",question)\n",
        "    \n",
        "    template=\"\"\"\n",
        "    Your task is to classify the given user query into one of the following categories: [USA,Not Related]. \n",
        "    Only respond with the category name and nothing else.\n",
        "\n",
        "    User query: {question}\n",
        "    {format_instructions}\n",
        "    \"\"\"\n",
        "    \n",
        "    prompt= PromptTemplate(\n",
        "        template=template,\n",
        "        input_variable=[\"question\"],\n",
        "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        "    )\n",
        "    \n",
        "    \n",
        "    chain= prompt | model | parser\n",
        "    \n",
        "    response = chain.invoke({\"question\":question})\n",
        "    \n",
        "    print(\"Parsed response:\", response)\n",
        "    \n",
        "    return {\"messages\": [response.Topic]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "b213f879",
      "metadata": {},
      "outputs": [],
      "source": [
        "state={\"messages\":[\"what is a today weather?\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "b75862b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "state={\"messages\":[\"what is a GDP of usa??\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "0d6c7ff3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question what is a GDP of usa??\n",
            "Parsed response: Topic='USA' Reasoning='The query explicitly asks for the GDP of the USA.'\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'messages': ['USA']}"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "function_1(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "9d9efd5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "class TopicSelectionParser(BaseModel):\n",
        "    Topic:str=Field(description=\"selected topic\")\n",
        "    Reasoning:str=Field(description='Reasoning behind topic selection')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "b77ffaa1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def router(state:AgentState):\n",
        "    print(\"-> ROUTER ->\")\n",
        "    \n",
        "    last_message=state[\"messages\"][-1]\n",
        "    print(\"last_message:\", last_message)\n",
        "    \n",
        "    if \"usa\" in last_message.lower():\n",
        "        return \"RAG Call\"\n",
        "    else:\n",
        "        return \"LLM Call\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1370290f",
      "metadata": {},
      "source": [
        "workflow.add_conditional_edges(\n",
        "    \"Supervisor\",\n",
        "    router,\n",
        "    {\n",
        "        \"RAG Call\": \"RAG\"(function_2),\n",
        "        \"LLM Call\": \"LLM\"(function_3),\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "39ea58c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "2be8b78d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# RAG Function\n",
        "def function_2(state:AgentState):\n",
        "    print(\"-> RAG Call ->\")\n",
        "    \n",
        "    question = state[\"messages\"][0]\n",
        "    \n",
        "    prompt=PromptTemplate(\n",
        "        template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\"\",\n",
        "        \n",
        "        input_variables=['context', 'question']\n",
        "    )\n",
        "    \n",
        "    rag_chain = (\n",
        "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | model\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "    result = rag_chain.invoke(question)\n",
        "    return  {\"messages\": [result]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "bcf5722e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# LLM Function\n",
        "def function_3(state:AgentState):\n",
        "    print(\"-> LLM Call ->\")\n",
        "    question = state[\"messages\"][0]\n",
        "    \n",
        "    # Normal LLM call\n",
        "    complete_query = \"Anwer the follow question with you knowledge of the real world. Following is the user question: \" + question\n",
        "    response = model.invoke(complete_query)\n",
        "    return {\"messages\": [response.content]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "842b2768",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph,END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "5fa25634",
      "metadata": {},
      "outputs": [],
      "source": [
        "workflow=StateGraph(AgentState)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "d2f4e5fd",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b893c8310>"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_node(\"Supervisor\",function_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "85165bcc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b893c8310>"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_node(\"RAG\",function_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "118b392f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b893c8310>"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_node(\"LLM\",function_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "2a35422c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b893c8310>"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.set_entry_point(\"Supervisor\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "a94d4a78",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b893c8310>"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_conditional_edges(\n",
        "    \"Supervisor\",\n",
        "    router,\n",
        "    {\n",
        "        \"RAG Call\": \"RAG\",\n",
        "        \"LLM Call\": \"LLM\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "e44b1f46",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b893c8310>"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_edge(\"RAG\",END)\n",
        "workflow.add_edge(\"LLM\",END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "c0c6a338",
      "metadata": {},
      "outputs": [],
      "source": [
        "app=workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "0d49bf14",
      "metadata": {},
      "outputs": [],
      "source": [
        "state={\"messages\":[\"hi\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "db6aaee4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question hi\n",
            "Parsed response: Topic='Not Related' Reasoning=\"The query 'hi' is a greeting and does not relate to the USA.\"\n",
            "-> ROUTER ->\n",
            "last_message: Not Related\n",
            "-> LLM Call ->\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'messages': ['hi', 'Not Related', 'Hi there!']}"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app.invoke(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "9b69cbab",
      "metadata": {},
      "outputs": [],
      "source": [
        "state={\"messages\":[\"what is a gdp of usa?\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "8081aa4e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question what is a gdp of usa?\n",
            "Parsed response: Topic='USA' Reasoning='The query explicitly asks for the GDP of the USA.'\n",
            "-> ROUTER ->\n",
            "last_message: USA\n",
            "-> RAG Call ->\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'messages': ['what is a gdp of usa?',\n",
              "  'USA',\n",
              "  'The nominal GDP of the USA is approximately $28 trillion USD as of 2024.  This represents about 25% of the global economy.  It holds the #1 ranking worldwide by nominal GDP.']}"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app.invoke(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "e6a7c184",
      "metadata": {},
      "outputs": [],
      "source": [
        "state={\"messages\":[\"can you tell me the industrial growth of world's most powerful economy?\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "52467649",
      "metadata": {},
      "outputs": [],
      "source": [
        "state={\"messages\":[\"can you tell me the industrial growth of world's poor economy?\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "9c979457",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question can you tell me the industrial growth of world's poor economy?\n",
            "Parsed response: Topic='Not Related' Reasoning=\"The query asks about the industrial growth of the world's poor economies, which is a global issue not specific to the USA.\"\n",
            "-> ROUTER ->\n",
            "last_message: Not Related\n",
            "-> LLM Call ->\n"
          ]
        }
      ],
      "source": [
        "result=app.invoke(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "137599cf",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'There\\'s no single, easily quantifiable answer to \"the industrial growth of the world\\'s poor economies.\"  The term \"poor economies\" itself is broad and encompasses a vast range of nations with vastly different levels of development, industrial bases, and growth trajectories.  Furthermore, data collection in many of these regions is unreliable or incomplete.\\n\\nHowever, we can make some general observations:\\n\\n* **Uneven Growth:** Industrial growth in poorer economies is highly uneven. Some countries have experienced significant industrialization, often driven by specific sectors like textiles, garments, or resource extraction.  Others remain largely agrarian, with minimal industrial development.  Success stories often involve strategic government policies, foreign investment, and access to global markets.\\n\\n* **Challenges to Industrialization:** Many poor economies face significant hurdles to industrial growth, including:\\n    * **Lack of Infrastructure:** Inadequate transportation, energy, and communication networks hinder industrial development.\\n    * **Limited Access to Capital:**  Securing funding for investment in factories, equipment, and technology is difficult.\\n    * **Skills Gaps:**  A lack of skilled labor limits the ability to adopt advanced technologies and improve productivity.\\n    * **Political Instability and Corruption:**  Uncertainty and corruption deter investment and hinder economic growth.\\n    * **Dependence on Commodity Exports:** Many poor economies rely heavily on exporting raw materials, making them vulnerable to price fluctuations and limiting value-added production.\\n    * **Climate Change:**  The impacts of climate change disproportionately affect poor economies, further hindering development.\\n\\n* **Shifting Global Landscape:** Globalization has both positive and negative impacts.  While it offers opportunities for participation in global value chains, it can also lead to exploitation and dependence on developed nations.\\n\\n* **Measuring Industrial Growth:**  Even with reliable data, measuring industrial growth is complex.  It involves considering various factors like manufacturing output, employment in the industrial sector, and technological advancements.  Different metrics will yield different results.\\n\\n\\nIn summary, while some poor economies have witnessed industrial growth, it\\'s far from uniform.  The overall picture is complex, characterized by significant disparities, ongoing challenges, and a highly variable future trajectory depending on numerous internal and external factors.  To get a more precise answer, one would need to specify particular countries or regions and define \"industrial growth\" more precisely (e.g., growth in manufacturing output, employment in the industrial sector, etc.).'"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[\"messages\"][-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7a2a55e",
      "metadata": {},
      "source": [
        "## ReAct Agent using Langgraph with Multiple tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "3a467430",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "import os\n",
        "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "b8ca8d26",
      "metadata": {},
      "outputs": [],
      "source": [
        "model=\"deepseek-r1-distill-llama-70b\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc5f3469",
      "metadata": {},
      "source": [
        "> Advanced reasoning model with Chain of thought"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78e1328d",
      "metadata": {},
      "source": [
        "### Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "3d2368f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "llm = ChatGroq(model_name=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "4ccd842e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='<think>\\n\\n</think>\\n\\nHello! How can I assist you today? 😊', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 4, 'total_tokens': 20, 'completion_time': 0.086264148, 'prompt_time': 5.7009e-05, 'queue_time': 0.056542881, 'total_time': 0.086321157}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None}, id='run--e31b652a-0743-41ee-8951-fd72c22767dd-0', usage_metadata={'input_tokens': 4, 'output_tokens': 16, 'total_tokens': 20})"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"hi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "4fbeff7d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<think>\n",
            "\n",
            "</think>\n",
            "\n",
            "Hello! How can I assist you today? 😊\n"
          ]
        }
      ],
      "source": [
        "print(llm.invoke(\"hi\").content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "4e24f2bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import operator\n",
        "# from typing import List\n",
        "# from langgraph.graph.message import add_messages\n",
        "# from pydantic import BaseModel , Field\n",
        "# from typing import TypedDict, Annotated, Sequence\n",
        "# from langchain_core.messages import BaseMessage\n",
        "# from langchain_core.output_parsers import StrOutputParser\n",
        "# from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langgraph.graph import StateGraph,MessagesState,START,END\n",
        "from langgraph.prebuilt import ToolNode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "059952f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def call_model(state: MessagesState):\n",
        "    messages = state['messages']\n",
        "    response = llm.invoke(messages)\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "9fd1a7b5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [AIMessage(content=\"<think>\\n\\n</think>\\n\\nHello! I'm just a virtual assistant, so I don't have feelings, but I'm here and ready to help you with whatever you need. How are you doing? 😊\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 9, 'total_tokens': 51, 'completion_time': 0.211081382, 'prompt_time': 0.000201307, 'queue_time': 0.057544522, 'total_time': 0.211282689}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None}, id='run--09f4317a-1a80-4bd6-9c90-0837a5914057-0', usage_metadata={'input_tokens': 9, 'output_tokens': 42, 'total_tokens': 51})]}"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state={\"messages\":[\"hi hello how are you?\"]}\n",
        "call_model(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a354d3a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from langchain_core.messages import AnyMessage\n",
        "# # class MessagesState(TypedDict):\n",
        "# #     messages: Annotated[list[AnyMessage], add_messages]\n",
        "\n",
        "\n",
        "# class AgentState(TypedDict):\n",
        "#     messages: Annotated[Sequence[BaseMessage], operator.add]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3727b873",
      "metadata": {},
      "source": [
        "### Design a simple workflow without tool calling/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "965efac3",
      "metadata": {},
      "outputs": [],
      "source": [
        "workflow=StateGraph(MessagesState)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "44399e00",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b89483990>"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_node(\"mybot\",call_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "6d5afc3e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b89483990>"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_edge(START,\"mybot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "9b8a8460",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b89483990>"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_edge(\"mybot\",END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "279168c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "app=workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "e10acd1f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGoAAADqCAIAAADF80cYAAAAAXNSR0IArs4c6QAAFeZJREFUeJztnWl8FEXegKun575zTEgmk5DLAAkBQxLCYRQkhAABJCC3Lq7KAruw6Lr8XHXxQNTfu7oeq4uwoOtqVF5RREIEZI0QECFAAoSQhARyn5Nk7qu7p98PwzuLOHdNkwlbzyfoqur+55nq7uqq7iqMpmmACBTWUAcwvEH6oED6oED6oED6oED6oGBDlu9uthh1lMVIWUwURQyPNhDOwfhCnC/CxTJ8xEg+zK6wwNp912uM12qMTRcNEjlbGs7hi3C+iMXhDo+6TNjsFqPdbKR0/YRRSyaPFyeNFSWkiwLYld/6etusP3zRS1jto7KlKXeL5QpOAEcNHTR9xNUqff1ZPU/AmvZglELF86u4H/oogj7+VV9LnSm3MHxMrjSgaEOXy6d0Zw71J2WI71us8L2Ur/rMBurAzs4RI/n3LfJj78MLiqCP7+tTd1iLHlcKxLgvRXzS199l++b9jrunhWVOlwcjzpDm3NHBiye0C9Yqw6O5XjN712fUkp+/3pa3MDJ1giR4QYY09Wf1P5aqlzwZL5J6qYNe7pWkzf7Njs5xebL/HncAgFHZkvTJsgM7OyjSS93you/0oQG5gpNTEB7U8IYBE2eFi+XsM4cHPGfzpE+rJuoq9fkro4Md2/CgYFX0lTM6/SDpIY8nfSe+VucUhHO4GAOxDQO4fNaE6WEVX/d5yONWn1ZNqLusGVNlzMQ2PBiXJ+9psXqogG71Xa0yZEyVYcPjMYwpWDjImCq7WqV3m8FdQuMF/cgxgTwGwjBt2rTu7m5/S33++ecvvfQSMxGBkWOEjdUGd6mu9Rk0pFlPRcR4bzcGkfb2doPBbaAeqK2tZSCcGyhUPN0A6e78dd1h1dVs8ffh2Xdomi4pKSkrK2tpaUlOTp40adLatWvPnTu3bt06AEBRUdG0adNef/31xsbGvXv3VlZWdnd3JycnL1q0aMGCBQCAhoaGFStWvP322y+++GJUVJRAIKiqqgIAfPPNN59++mlqamrQA45S8XrbrJIwF65c67MaKYEEtivQHSUlJR999NHq1auTk5M7Ozvfe+89mUy2cuXKN99884knnigtLY2OjgYAvPHGGz09PX/6058wDGtqatq6dWt8fHxmZiaXywUA7Nq165FHHhk/fnxaWtrDDz+ckpKyZcsWhgIWSHCriXKZ5Eaf2S707Zk5AKqrq8eOHbty5UrHf7Ozs2022y+zvfbaayaTKSYmxpFn3759J0+ezMzMdKROmTJl+fLlDEV4CwIxbjXbXSa51me30ziHqeZeRkbG9u3bt27dmpWVlZeXFx8f7yYGe0lJyY8//tja2urYkpaW5kwdM2YMQ+H9Eg6X5e7pzbU+gQhXd7moEUFh1apVEomkvLx8y5YtbDZ79uzZGzduDAsLuzkPRVEbNmygaXrDhg0TJ04UiUSrVq1yJGEYBgDg86E62f3CpCej4lwfzrU+oYRtajAxFA2O48XFxcXFxU1NTWfOnNmxY4fFYnn11VdvzlNbW1tXV7djx46srCzHFudN+fa/VWLSUUKJ60uZm9onwc161xdLeEpLS9PT0xMTE5OTk5OTk/v7+48ePeqsVg70ej0AQKG40TVbX1/f3t7uvPDdws0FmcCoJ4VS16Jct/sUsTx1h9VOMfI7l5aWbt68uaKiQqfTVVRUHD9+fNy4cQAAlUoFADhy5Mjly5eTkpIwDCspKTEYDNeuXXv77bdzc3O7urpc7jA2Nrampubs2bODg4NBj5YkaE0v4bYJTLth//aOposGd6kwdHV1Pfnkk1lZWVlZWbNmzdq5c6fZbHYkPfvss7m5uWvXrqVp+tChQ4sXL87KyiouLq6trf3uu++ysrKWL19+/fr1rKysyspK5w4rKysXLlw4ceLEM2fOBD3axmr9gZ0d7lLd9jbXnNR2XrMUPDQi6L/n8OLwv7rjUoVpk1wPjbl95k3NkrQ1mDz3dt3x6AfJ9qvmu9z3tHsa67hwXNN5zTJ7tevu0o6ODmfT9xZYLJbd7rqduWTJkvXr1/sQeSBs2rSpurraZZJcLtdoNC6Ttm3bNnXqVJdJZR90qe4Sjstz22vnSZ+dAp+80jx1gSJ5nIuuF7vdbjQaXRa0WCzu2mUcDoe5JpvJZKIo1w0GgiA4HNcj+gKBgM12cWNtOKc/Vdb/8LMJnnrtPF84e9ssO59pGui2Bf2SHOKoO607n2nqbbN4zualO1Sh4hWsij64u9NmcX0y3pHYLPaDuzpnr47x2u3k0zB5/Tl99Q+aoseUIhlT/Qihg0FDHtzdlTld7svYrK8vaXQ0mcv39Basio6KZ6ofMBTobbUe/rg7f8WImESfLtB+vCKkGyAP7OxITBdPnBXOvuOG3wgbffrb/rZ609zHlNJwX/s6/XtBjSLo2tO6+nP6sVNkyePEHN6dIJGw2hsvGC6f0qXlSt01j90R4OuR12qM1y8ZDRoiIoYnlrP5IpwvwofLiDBhoy1GymKkDBpS3WWVhHGSMkSJt+f1yFvoum4Z6LZp1YSmz2YxBfnu3N/fDwCIiIgI7m75IpY8kitTcCKiudEJQ/Fy7u1hx44dGIatWbNmqANxy3/3MDg0SB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8USB8UofhZzNy5cymKomnabDYDAEQiEUVRHA7n4MGDQx3arTA1TRoMMTExVVVVzsltHJ/YZ2dnD3VcLgjFk3fZsmVy+c+mJ4+IiHDOYRVShKK+/Pz8lJSUm7ckJCTcd999QxeRW0JRn2O+EpnsxvQfcrl8xYoVQx2Ra0JU34wZMxISEhz/Hjly5P333z/UEbkmRPUBAJYuXSoSiUQi0dKlS4c6FrdA3XltFru6w8pQyyc9KW9MwlQcx9OT8joazUwcAsNAZCyPyw+8DgXY7murN5080G81UyIpG4Dh8Q2+K2ijjuQL8anzI1V3CQIoH0jtO/3twNUq/YyVsWJ5KDYb/UU/SPz7k87RE6U5BWE+ZP8Zftfbliumyz9pCx+NuzPcAQAkYZzCx+IundC01vt9ifBb34n9fZPmRvEgrhchCF/AmjQ36qTHxRFc4p8FkqB1A6Qq9XbPZX8bUI0SafoJ0s+V+vzTp+m1ySK5DM+0OjRgGJBFcjR9hF+l/NNntwPWnejOAQYw2s5k7UPcAtIHBdIHBdIHBdIHBdIHBdIHBdIHBdIHBdIHBdIHRajr+/LLzwoKJw91FG4JdX2B0dR0ddVDD9yGA92Z+urqL9+eAzGu7/kXNm975bnDh0tnzpo0pyjvqT+uNxgMuz/4+/QZ2cWLC/6x610AwLnzZ6bPyK6tveQsVVdfO31G9rnzZwCGYRjW1tby/Aub586799HHl31ffsSZrbW1+YknfzN33r0PFOf//onHL16sAgB8+M/3X3/j5Y7O9ukzsr/88jNG/zrG9XE4nAsXz9dfvbL3i8PvvvNh9YVzGzc9yucLykorNj+15dPP/nnpUvWEzJwRI6KPfn/IWerYsaORkYoJmTkYAHa7/fW/vlxUVPzy1r+OHpW+9eVnOjrbAQD9/erf/m51XNzI3f/Y885buyQS6dZtz1it1kdWr13y4KpYpar832cXLWJ2JUHG9WEYZrfb1699QiaVJSWljByZyOVwV654RCAQTJp0D5/Pb7hah2HY3DkLy8uPOBcrKf/hSMHMuRiG0TRNkuSi4uU52ZMy785es2YjhmHHjh0FAPzvF58IhMJNv386OjomPj7hj09t0WgGy77dz/RfdDOM66NpWqlUOZdjEQpFIxOSnKkikdhoNAAAZhfO12o1Z8+dBgA0XK3r6emeM+cB5xpsuRNvLIYjk8oSE5O7ujoAAM3NTampY1gsljNJpYq/UlfD9F90M7dDn/MvdIC5GlaPjFRMnpz3fflhx5k7ZszYWKXKUZzNZvN4/1nlgs8X6HRaAED/gJrH/dnqFwKB0GJm5H0Ed4TQnXdO4YITJ8rNZvOJkz/MKihybMQwjCRJgvjPCI7JZJRIpDdkWS0378FsNoWHB3mCe8+EkL5Jk+7h8wWflOzu6GibPr3AsdExcnP1ap3jv3qDvq2tRalUAQBGpaZduVJDkjeWQtNqNe3trYmJKbdh2UUnIaQPx/HZhfO//Oqze6ZOk0purJuBAcDhcHbtfq+9o40giF273qUo6v7pswAAC+Yv1mgG33zr1YGB/mvXGl95bYtIJHZUW6VS1dvXc/Lksfb2VkZjDiF9AIApU+6zWq0z8+c4t9gIm1gsKV64bOPvHy0onFxz+cLzW16Ljo4BAMTFjXzxhf9paLiy6MFZf/jjOhzH33lrl2MVsymT7x09Ov25LX8o/+E7RgP27w2r3jbr95/3zl0Tx1A0JZ9+WFb29cf/2nfL3eb2ULqjLX9FlF+LsofKaz7V1ec6Ots+Kdm97eU3h8RdYISKvs1P/w7H8TWPb5yQmTPUsfhBqOg7cujUUIcQCMPmNAlNkD4okD4okD4okD4okD4okD4okD4okD4okD4o/NM3fJ7lA4PG/PxwwD8fMgVXo7b5GdOwQasm5AqOX0X808fhYgIxru60+hnYMEDdYRXJ2GwOk7UPAJAzM/z43i5rsFcyHlqsJur43q6cWeH+Fgzke95TB/trftRNKlIkpIn9LRuCXL9sOFPWlzFVljv7tugDALQ3mE/s79OoiQglz+W4bVCw0zQAgMXYsBkN6P5Oq1zBvWdBgJ9DQ80ixOjH+ACAAwcOAADmzZvH0P7hP8aH6m3m8lnK5EB+NB/BhIMYhsWmMHgISO7whhzTIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QIH1QhOLa5EVFRZ2dnTRNO2cxpGlaqVSG4NrkoVj7ioqKcBzHcZz1/7DZ7Pnz5w91XC4IRX1LlixRqVQ3b4mPj1+2bNnQReSWUNQXHh5eWFjoPHMxDMvPz3eutR1ShKI+AMDixYvj4m7MUalSqZYvZ3by74AJUX0RERH5+fkYhmEYVlhYKJfLhzoi14SoPsfa5PHx8bGxsaG8NnkQGi5GLdl4waDtJ816ymKkrNagtYT6evsABhQKRbB2yONhfBEulODSCHbKeLFIBjt5ZuD6KII+X65pqNLr+gl5jIjN4+BcnM3BcXbo1miKtJMERREUaSI0PUZpBHdMjnh8nhz3cwINJwHqazhvqNjXxxFxw2KkkihhYMcecnS9Jk2XjjDa8hYqUicEMq2F3/qsZnvpP7q1Gio6JVwYxg/gkKGGccDc0zgoC8fnr4nh8Pyrhv7p0w2Q+97tECkkkQmh2AqDoe+6xjxofGCdUhruxwXRD309rZayD3oUqRHisNCdmwEGQ7+lt1E977Fo3ycO9/Uyb9JRBz/oUaZH3anuAADiCL4yPap0d7dRR/lYxCd9JEHv+3tHVHIET8yFizDU4Yu5iuSI/e93UqRPJ6VP+n4qGxCGi8WRd2y9uxlxhIAvE54+NOBLZu/6jFqqudYUFnen3Ss8EB4vb7poMmpJrzm96zv2VZ8sNkQfOZlDppRV7O/3ms2LPovR3t5olihCtGE8qOl+6s+5tXUngr5naZSopdZoMXq5h3jR13hBL1WIghrYMAED0hGiazUGz7m86LtabRRFhmjVYxpxuLCx2uQ5j5cWdl+bJXlK0Do8bkGr6/vm27da2i4RhHX0XZNnTn8sMkIFAKg4tae84uPfrP7bR58/3dvXHBN91/R7Hpowfpaj1PmLhw8f3WGxGtNG592T+yBwTCTHAAI5r/mM2nMeT7WPJGiSpBnqQaEo8v0Pf9vSdmnJA889teEzgUDyzs5fD2q6AQBsNtds0X1d9sbShc/95aWf0kfl7dn3kt4wAADo6mn8bO/zudkLnt60NzOj4OuyvzIRmwM2FycIu93jLKOe1GjVhEDs30yyvnOtuapP3bJ80QupKRMl4vB5hZt4XEHFqT2OwQ2CsBbOWDsyLgPDsKy7Z1MU2dFZDwA48dMX4WGx99/7K4FAkpoyceIEpmZGdMAXsrVqwkMGT/oMGpLNwxmICgAAmlsvcjn85MQJjv/iOJ4QP7659YJjVBcAEK9KdyTx+WIAgMVqAAD0D7SPiEp07kQVO8axlhtDcARsg8ZT68/TtY/NxZgbQ7dYjTbC8tSfc2/eGCaPAQAAmv7lSn8Op2azXiwKc27ksHnOJCagKBr3WH886ROKccrqveUdGBJxBJ8nWr3iLzdvZHkOFgA+X2wj/rMupY0wM7qkImmlhFKPNcxDmkDCtll87Xvwl5joFIvVGCaPjgiPdWxRD7RLxZGeS4XJoxsaTzvf36hr+JHR2keYSaHE0y/q6drHF7LYXBZhYaQCjkrJTU3J/WL/Kxptj8E4WHFqz1vbf3XuwreeS41Ln6HTq0sP/w0AcLWp8qezXwPGGi42E8nh457n1fXS7osfLdT3mcLjpMGODQAAHnvorVOVX32859mWtktRioTcrAWTcxZ6LpI2auqcgt/+VLnv2MmSMHnMsuIt2z9YZ7czcoro1abEsV6euLz0NjddMJw6pFWNiw52bMOA9gvdU4rkSR4NemkSq1KF2l6zzcTUDSRksZlJXZ85LtXLA6uXk5cnYI3KknZfG1SNdf3oRlHk86/NcplEkjY2znXZKouNSV336+2eD+0Xf96WTwPXp5HdTrFYLi7/8ar0Nb96x90OexsHRuVIOVwvV1XvQ0VmA/XR1uaEbCXfTU/9wGCny+0Wi8HR4v0lOM6RSYP5KO0uBgCAjbByOS6GfthsrlTi+kZv0dtaznetfj6BJ/Bydvo00lb1w+D5cl1ijpKFh+4bBMHCTtqvV3bmzJSNy/PeSeyTjrvvlSuUnPaavhB8kze40DTddrEnUsnJmOrT4IRP+jAWNufXMRyc6q73aQBl+NJVN8Dl0nMfjfFx0SJfT0Y2B1u4XglIa2t1j923QbzhhZ2kW6t7MLtt4fpY35fc8e8lDYqkv/1nd0+rLT4zmsMPlaWR4SEsZMv5bmUSb9ZDI3C2H88wgbxhdfbI4NnvByPjZeHxMhbOXHfR7YCi6IEWTX+rLntmWHZ+mA8lfkaAL6gN9hBVxzTXa4xCuVAg54kjBGwuUz2DTEBaKMOg2aS1mgdNSRmizGlyf5cYcwD1dilJ0M2XTQ3VxrYrBhpgfDGHK+SweSF6UtM0oGykzURYjDaMBvFp4rsyRSnjoMYRg/ZVkUFDavoIrZrwZXB+aMCASMqWRXLkCo5YHpzfOBQ/yhpG3PlPEYyC9EGB9EGB9EGB9EGB9EHxfy+BEiGqWr3hAAAAAElFTkSuQmCC",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(app.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "3d8654d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "input={\"messages\":[\"hi hello how are you?\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "d8be0db0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='hi hello how are you?', additional_kwargs={}, response_metadata={}, id='dea5852d-13de-43e7-8b3c-076c9f081757'),\n",
              "  AIMessage(content=\"<think>\\n\\n</think>\\n\\nHello! I'm just a virtual assistant, so I don't have feelings, but I'm here and ready to help you with whatever you need. How are you doing? 😊\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 9, 'total_tokens': 51, 'completion_time': 0.224766455, 'prompt_time': 0.000198757, 'queue_time': 0.057345373, 'total_time': 0.224965212}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None}, id='run--135d36e9-297d-423f-b82d-c72c518941e6-0', usage_metadata={'input_tokens': 9, 'output_tokens': 42, 'total_tokens': 51})]}"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app.invoke(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "id": "cbc547a6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output from mybot Node\n",
            "_______\n",
            "{'messages': [AIMessage(content=\"<think>\\n\\n</think>\\n\\nHello! I'm just a virtual assistant, so I don't have feelings, but I'm here and ready to help you with whatever you need. How are you doing? 😊\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 9, 'total_tokens': 51, 'completion_time': 0.203039575, 'prompt_time': 0.000454873, 'queue_time': 0.057552045999999996, 'total_time': 0.203494448}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None}, id='run--b471116e-c875-4848-9893-733c01c10fd5-0', usage_metadata={'input_tokens': 9, 'output_tokens': 42, 'total_tokens': 51})]}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for output in app.stream(input):\n",
        "    for key,value in output.items():\n",
        "        print(f\"Output from {key} Node\")\n",
        "        print(\"_______\")\n",
        "        print(value)\n",
        "        print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a50558e3",
      "metadata": {},
      "source": [
        "### this is a workflow with tool calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "id": "7d7a690c",
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def search(query:str):\n",
        "    \"\"\"this is my custom tool for searching a weather\"\"\"\n",
        "    if \"delhi\" in query.lower():\n",
        "        return \"the temp is 45 degree and sunny\"\n",
        "    return \"the temp is 25 degree and cloudy\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3fffdb9",
      "metadata": {},
      "source": [
        "### testing a tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "id": "9ace4dfa",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'the temp is 25 degree and cloudy'"
            ]
          },
          "execution_count": 167,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search.invoke(\"what is a tempurature in kashmir?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "id": "c66650f2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 168,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"delhi\" in \"What is a temperature in Kashmir?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "id": "b8eefa44",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "StructuredTool(name='search', description='this is my custom tool for searching a weather', args_schema=<class 'langchain_core.utils.pydantic.search'>, func=<function search at 0x0000028B8958AFC0>)"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "id": "011d100f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content=\"<think>\\nOkay, so I need to figure out what the weather in Delhi is like. I'm not exactly sure where to start, but I'll try to break it down step by step. First, I know Delhi is a city in India, so maybe the climate there is similar to other parts of India, but I'm not certain. I think India has a monsoon season, so maybe Delhi experiences that too.\\n\\nI remember hearing that Delhi has really hot summers. I think the summer months might be from April to June, but I'm not sure about the exact temperatures. It must get pretty hot, maybe even over 40 degrees Celsius sometimes. Then, I think there's a monsoon season, which brings a lot of rain. That probably happens around July to September. I wonder how much rainfall they get during that time.\\n\\nAfter the monsoon, the weather might cool down a bit. So, maybe October to November is autumn or fall, where it's more pleasant, not too hot and not too cold. Then comes winter, from December to February. I've heard that Delhi can get quite chilly in the winter, especially in January. I think temperatures can drop below 10 degrees Celsius, maybe even lower. There's also fog during the winters, which might cause some issues with transportation.\\n\\nI'm not sure about the spring season. Maybe it's a short period, perhaps in March, where the weather starts to warm up again after winter. The temperatures might be mild, making it a nice time to be outside.\\n\\nI also remember hearing about air pollution in Delhi, especially during the winter months. The AQI (Air Quality Index) can be very poor, which is a health concern. I'm not entirely sure what causes the pollution, but I think it's a mix of vehicle emissions, industrial activity, and maybe even crop burning in nearby areas.\\n\\nI should consider checking a reliable source to confirm the exact seasons and temperature ranges. Maybe looking up the average temperatures for each month would give a clearer picture. Also, understanding the factors that influence Delhi's climate, like its inland location and the surrounding geography, could help explain why the seasons are so distinct.\\n\\nI'm a bit confused about the monsoon season's impact. Does it bring consistent rain throughout the season, or are there periods of heavy rain followed by dry spells? Also, how does the monsoon affect daily life in Delhi? I imagine the rains could cause flooding or traffic issues, but I'm not certain.\\n\\nAnother thing I'm curious about is the variation in temperature throughout the day during different seasons. For example, in summer, how much does the temperature drop at night? And in winter, how cold does it get in the mornings versus the afternoons?\\n\\nI think it would be helpful to look at annual climate data for Delhi, including average rainfall, temperature highs and lows, and any extreme weather events. This would provide a more comprehensive understanding of the city's weather patterns.\\n\\nI should also consider the impact of climate change on Delhi's weather. Are the summers getting hotter? Is the monsoon season becoming more unpredictable? Understanding these aspects could offer insights into how the weather might change in the future.\\n\\nOverall, I need to gather information on the seasonal breakdown, temperature ranges, rainfall distribution, and any notable weather-related issues like pollution or fog. This will help me describe the weather in Delhi accurately.\\n</think>\\n\\nDelhi, the capital of India, experiences a diverse climate with distinct seasons, influenced by its inland location and regional geography. Here's a detailed overview of Delhi's weather:\\n\\n1. **Seasonal Breakdown**:\\n   - **Summer (April to June)**: Characterized by high temperatures, often exceeding 40°C, with May being the hottest month.\\n   - **Monsoon (July to September)**: Brings significant rainfall, with July and August being the wettest months. The rains can be intense, sometimes leading to flooding and traffic disruptions.\\n   - **Autumn (October to November)**: A transitional period with pleasant weather, mild temperatures, and lower humidity.\\n   - **Winter (December to February)**: Cool to chilly, with temperatures sometimes dropping below 10°C. January is the coldest month, with dense fog affecting visibility and transportation.\\n\\n2. **Spring (March)**: A brief period of mild temperatures before the onset of summer, making it a pleasant time for outdoor activities.\\n\\n3. **Climate Factors**:\\n   - Delhi's climate is influenced by its inland position, leading to extreme temperature variations between summer and winter.\\n   - The monsoon season is crucial for agriculture but can cause urban flooding due to heavy rainfall.\\n\\n4. **Air Quality**:\\n   - Notable for poor air quality, especially in winter, due to factors like vehicle emissions, industrial activity, and crop burning in nearby regions. The Air Quality Index often reaches hazardous levels.\\n\\n5. **Daily Temperature Variation**:\\n   - Summers see significant diurnal variation, with nights being much cooler than days.\\n   - Winters have colder mornings and relatively warmer afternoons.\\n\\n6. **Impact of Climate Change**:\\n   - Observations suggest rising summer temperatures and more unpredictable monsoon patterns, indicating potential future climate shifts.\\n\\nIn summary, Delhi's weather is marked by hot summers, a rainy monsoon, a mild autumn, and a cool winter, with significant air quality issues in winter. Understanding these patterns provides insight into the city's climate and its future trends.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1104, 'prompt_tokens': 11, 'total_tokens': 1115, 'completion_time': 4.884057374, 'prompt_time': 0.000312686, 'queue_time': 0.054146914, 'total_time': 4.88437006}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None}, id='run--c404ff25-50d5-4734-930b-cd241cae80b3-0', usage_metadata={'input_tokens': 11, 'output_tokens': 1104, 'total_tokens': 1115})"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"what is a weather in delhi?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac1d8d91",
      "metadata": {},
      "source": [
        "### Binding a tool to the LLM\n",
        "\n",
        "### Special Note: use some good for agentic workflow since opensource model might not give you the correct output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "id": "530b8a51",
      "metadata": {},
      "outputs": [],
      "source": [
        "tools=[search]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "id": "b6f80339",
      "metadata": {},
      "outputs": [],
      "source": [
        "llm_with_tool=llm.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03c0014d",
      "metadata": {},
      "source": [
        "### testig my llm_with_tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "id": "1f13fe6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "response=llm_with_tool.invoke(\"what is a weather is delhi?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "id": "d54a1e7a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8hhhffgyt', 'function': {'arguments': '{\"query\":\"weather in Delhi\"}', 'name': 'search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 91, 'prompt_tokens': 133, 'total_tokens': 224, 'completion_time': 0.429744112, 'prompt_time': 0.008945821, 'queue_time': 0.052231799, 'total_time': 0.438689933}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--bdf2d013-75b2-47a5-937b-37040fa2fb98-0', tool_calls=[{'name': 'search', 'args': {'query': 'weather in Delhi'}, 'id': '8hhhffgyt', 'type': 'tool_call'}], usage_metadata={'input_tokens': 133, 'output_tokens': 91, 'total_tokens': 224})"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "id": "137a0b46",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "id": "f7bf5415",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'search',\n",
              "  'args': {'query': 'weather in Delhi'},\n",
              "  'id': '8hhhffgyt',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.tool_calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "id": "26757959",
      "metadata": {},
      "outputs": [],
      "source": [
        "def call_model(state:MessagesState):\n",
        "    question=state[\"messages\"]\n",
        "    response=llm_with_tool.invoke(question)\n",
        "    return {\"messages\":[response]}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fcf8d65",
      "metadata": {},
      "source": [
        "### Testing code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "id": "3a8b51ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "input={\"messages\":[\"what is a weather in delhi?\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "id": "11f4ac99",
      "metadata": {},
      "outputs": [],
      "source": [
        "response=call_model(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "id": "9516c0a9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 180,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response[\"messages\"][-1].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "id": "065b2105",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'search',\n",
              "  'args': {'query': 'weather in Delhi'},\n",
              "  'id': 'r1g8s26bk',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "execution_count": 181,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response[\"messages\"][-1].tool_calls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d916dfd1",
      "metadata": {},
      "source": [
        "### here my router function\n",
        "\n",
        "#### now whatever will come from call_model router funtion will redirect this to the appropriate tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "id": "3ffa9bdb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# def router_function(state:MessagesState):\n",
        "#     message=state[\"messages\"]\n",
        "#     last_message=message[-1]\n",
        "#     if last_message.tool_calls:\n",
        "#         return \"tools\"\n",
        "#     return END\n",
        "\n",
        "def router_function(state: MessagesState):\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    \n",
        "    # If the message contains a tool call → go to tools\n",
        "    if last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    \n",
        "    # If it has final content → end\n",
        "    if last_message.content and not last_message.tool_calls:\n",
        "        return END\n",
        "\n",
        "    # Fallback\n",
        "    return END\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "id": "9d342bbb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[StructuredTool(name='search', description='this is my custom tool for searching a weather', args_schema=<class 'langchain_core.utils.pydantic.search'>, func=<function search at 0x0000028B8958AFC0>)]"
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "id": "1c8f7c43",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "tool_node=ToolNode(tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "id": "95cb5c38",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tools(tags=None, recurse=True, explode_args=False, func_accepts_config=True, func_accepts={'store': ('__pregel_store', None)}, tools_by_name={'search': StructuredTool(name='search', description='this is my custom tool for searching a weather', args_schema=<class 'langchain_core.utils.pydantic.search'>, func=<function search at 0x0000028B8958AFC0>)}, tool_to_state_args={'search': {}}, tool_to_store_arg={'search': None}, handle_tool_errors=True, messages_key='messages')"
            ]
          },
          "execution_count": 185,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool_node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "id": "01183dff",
      "metadata": {},
      "outputs": [],
      "source": [
        "workflow2=StateGraph(MessagesState)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "id": "5adc902d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b890bd050>"
            ]
          },
          "execution_count": 187,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow2.add_node(\"llmwithtool\",call_model)\n",
        "\n",
        "workflow2.add_node(\"mytools\",tool_node)\n",
        "\n",
        "workflow2.add_edge(START,\"llmwithtool\")\n",
        "\n",
        "workflow2.add_conditional_edges(\"llmwithtool\",\n",
        "                                router_function,\n",
        "                                {\"tools\":\"mytools\",\n",
        "                                 END:END})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "id": "5119a429",
      "metadata": {},
      "outputs": [],
      "source": [
        "app2=workflow2.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "id": "c560449f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(app2.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "id": "e484cabd",
      "metadata": {},
      "outputs": [],
      "source": [
        "response=app2.invoke({\"messages\":[\"what is a weather in bengraluru?\"]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "id": "9adbd3a3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'the temp is 25 degree and cloudy'"
            ]
          },
          "execution_count": 191,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response[\"messages\"][-1].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "id": "94dd9f09",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='what is a weather in delhi?', additional_kwargs={}, response_metadata={}, id='2b016b2b-db4d-4c04-aace-905141f254b8'),\n",
              "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'xzvsaxm1c', 'function': {'arguments': '{\"query\":\"weather in Delhi\"}', 'name': 'search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 162, 'prompt_tokens': 133, 'total_tokens': 295, 'completion_time': 0.707019253, 'prompt_time': 0.014652949, 'queue_time': 0.054244861000000005, 'total_time': 0.721672202}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d865ff2b-7bb1-4830-a829-22cbdc5a9299-0', tool_calls=[{'name': 'search', 'args': {'query': 'weather in Delhi'}, 'id': 'xzvsaxm1c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 133, 'output_tokens': 162, 'total_tokens': 295}),\n",
              "  ToolMessage(content='the temp is 45 degree and sunny', name='search', id='052eaafa-6280-4d02-b4e0-c3639104b989', tool_call_id='xzvsaxm1c')]}"
            ]
          },
          "execution_count": 192,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app2.invoke({\"messages\":[\"what is a weather in delhi?\"]})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11b37e9f",
      "metadata": {},
      "source": [
        "### use good resoning based model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "id": "50333057",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='hi how are you?', additional_kwargs={}, response_metadata={}, id='c783bbf9-1564-4b8e-aed0-5094d79728fd'),\n",
              "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '2epgj3mpt', 'function': {'arguments': '{\"query\":\"weather in Tokyo\"}', 'name': 'search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 218, 'prompt_tokens': 130, 'total_tokens': 348, 'completion_time': 0.999828091, 'prompt_time': 0.014856975, 'queue_time': 0.05226332499999999, 'total_time': 1.014685066}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a68e28dd-278c-4c70-9d46-89844e2e7f2f-0', tool_calls=[{'name': 'search', 'args': {'query': 'weather in Tokyo'}, 'id': '2epgj3mpt', 'type': 'tool_call'}], usage_metadata={'input_tokens': 130, 'output_tokens': 218, 'total_tokens': 348}),\n",
              "  ToolMessage(content='the temp is 25 degree and cloudy', name='search', id='7787e45a-c094-4703-b4c2-f3e86d61dd82', tool_call_id='2epgj3mpt')]}"
            ]
          },
          "execution_count": 193,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app2.invoke({\"messages\":[\"hi how are you?\"]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "id": "35538245",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x28b890bd050>"
            ]
          },
          "execution_count": 194,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow2.add_edge(\"mytools\",\"llmwithtool\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "id": "15c96c3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "app3=workflow2.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "id": "07768724",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(app3.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "id": "dc945533",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here is output from llmwithtool\n",
            "_______\n",
            "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'yj1by5z3n', 'function': {'arguments': '{\"query\":\"weather in New Delhi\"}', 'name': 'search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 173, 'prompt_tokens': 134, 'total_tokens': 307, 'completion_time': 0.785341994, 'prompt_time': 0.015464317, 'queue_time': 0.057919593, 'total_time': 0.800806311}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--0d2d071a-213f-48a8-bae3-145aaefa01cd-0', tool_calls=[{'name': 'search', 'args': {'query': 'weather in New Delhi'}, 'id': 'yj1by5z3n', 'type': 'tool_call'}], usage_metadata={'input_tokens': 134, 'output_tokens': 173, 'total_tokens': 307})]}\n",
            "\n",
            "\n",
            "here is output from mytools\n",
            "_______\n",
            "{'messages': [ToolMessage(content='the temp is 45 degree and sunny', name='search', id='bc46c4d3-8a0e-4323-b88e-cfb1222c1286', tool_call_id='yj1by5z3n')]}\n",
            "\n",
            "\n",
            "here is output from llmwithtool\n",
            "_______\n",
            "{'messages': [AIMessage(content='The weather in New Delhi is currently **45 degrees** and sunny.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 189, 'prompt_tokens': 195, 'total_tokens': 384, 'completion_time': 0.877894489, 'prompt_time': 0.016306675, 'queue_time': 0.05488951500000001, 'total_time': 0.894201164}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None}, id='run--035c647c-cfa3-4393-9e07-d61515e0b965-0', usage_metadata={'input_tokens': 195, 'output_tokens': 189, 'total_tokens': 384})]}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for output in app3.stream({\"messages\":[\"what is a weather in new delhi?\"]}):\n",
        "    for key,value in output.items():\n",
        "        print(f\"here is output from {key}\")\n",
        "        print(\"_______\")\n",
        "        print(value)\n",
        "        print(\"\\n\")\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98e728fb",
      "metadata": {
        "id": "98e728fb"
      },
      "source": [
        "# Last"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27668149",
      "metadata": {
        "id": "27668149"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "agentic_base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
